{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e88c1c8",
   "metadata": {},
   "source": [
    "# Building and evaluating a discrete-time neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60efe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adebfa",
   "metadata": {},
   "source": [
    "## Load the support dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059398bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_support_dataset(random_state=0):\n",
    "\n",
    "    FILL_VALUES = {\n",
    "        'alb': 3.5,\n",
    "        'pafi': 333.3,\n",
    "        'bili': 1.01,\n",
    "        'crea': 1.01,\n",
    "        'bun': 6.51,\n",
    "        'wblc': 9.,\n",
    "        'urine': 2502.\n",
    "    }\n",
    "\n",
    "    COLUMNS_TO_DROP = [\n",
    "        'aps', 'sps', 'surv2m', 'surv6m', 'prg2m',\n",
    "        'prg6m', 'dnr', 'dnrday', 'sfdm2', 'hospdead'\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        pd.read_csv('../data/support2.csv')\n",
    "        .drop(COLUMNS_TO_DROP,axis=1)\n",
    "        .fillna(value=FILL_VALUES)\n",
    "        .sample(frac=1, random_state=random_state)\n",
    "    )\n",
    "\n",
    "    # one-hot encode categorical variables\n",
    "    # converts each value of categorical variable to be a separate column with each row value being a True or False\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "\n",
    "    # fill missing values to the median\n",
    "    df = df.fillna(df.median())\n",
    "\n",
    "    # standardize numeric columns\n",
    "    numeric_cols = df.dtypes == 'float64'\n",
    "    df.loc[:, numeric_cols] = df.loc[:, numeric_cols].transform(\n",
    "        lambda x: (x - x.mean()) / x.std())\n",
    "    \n",
    "    features = (\n",
    "        df\n",
    "        .drop(['death', 'd.time'], axis=1)\n",
    "        .values\n",
    "        .astype(float)\n",
    "    )\n",
    "    \n",
    "    event_indicator = df['death'].values.astype(float)\n",
    "    event_time = df['d.time'].values.astype(float)\n",
    "\n",
    "    return features, event_indicator, event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e9bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, s, t = load_support_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5078c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = len(X) * 4 // 5 ## dividing the data into train and test sets where training on 80% of the data and testing on the rest of the 20%\n",
    "\n",
    "### defining the train and test set\n",
    "\n",
    "train_X, train_s, train_t = (arr[:test_idx] for arr in (X, s, t))\n",
    "test_X, test_s, test_t = (arr[test_idx:] for arr in (X, s, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e5d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BIN_BOUNDARIES = np.arange(11) * (t.max() / 10)\n",
    "\n",
    "plt.hist(t[s == 1], alpha=.3, bins=BIN_BOUNDARIES, label='Observed')\n",
    "plt.hist(t[s == 0], alpha=.3, bins=BIN_BOUNDARIES, label='Censored')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e936d0",
   "metadata": {},
   "source": [
    "# Define a Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a168eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteTimeNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes, num_bins):\n",
    "        super(DiscreteTimeNN, self).__init__()\n",
    "\n",
    "        self.encoder_layers = [\n",
    "            torch.nn.LazyLinear(size)\n",
    "            for size in hidden_layer_sizes\n",
    "        ]\n",
    "        \n",
    "        ### defining the layers in the NN model \n",
    "        ## activation layer with ReLU, prediction layer or hidden layers use LazyLinear and output layer uses softmax\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.prediction_head = torch.nn.LazyLinear(num_bins + 1)\n",
    "        # self.softmax = torch.nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        x = self.prediction_head(x)\n",
    "        alphas = F.relu(x) + 1\n",
    "\n",
    "        return alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877ed74",
   "metadata": {},
   "source": [
    "## Define the Negative Log-Likelihood (Loss) for the Discrete Time Failure Time Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958c711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "class EvidentialDiscreteFailureTimeLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, bin_boundaries, tolerance=1e-8, annealing_step=10, kl_scale=0.01):\n",
    "        super(EvidentialDiscreteFailureTimeLoss, self).__init__()\n",
    "        \n",
    "        # Discrete time bin boundaries\n",
    "        self.bin_starts = torch.tensor(bin_boundaries[:-1])\n",
    "        self.bin_ends = torch.tensor(bin_boundaries[1:])\n",
    "        self.bin_lengths = self.bin_ends - self.bin_starts\n",
    "        \n",
    "        # Tolerance to avoid log(0) issues\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        # Annealing coefficient for KL divergence\n",
    "        self.annealing_step = annealing_step\n",
    "        self.kl_scale = kl_scale  # Scale factor for KL divergence term\n",
    "\n",
    "    def _discretize_times(self, times):\n",
    "        # Determine which time bins the event times fall into\n",
    "        return (\n",
    "            (times[:, None] > self.bin_starts[None, :])\n",
    "            & (times[:, None] <= self.bin_ends[None, :])\n",
    "        )\n",
    "\n",
    "    def _get_proportion_of_bins_completed(self, times):\n",
    "        # Calculate the proportion of each bin that is completed\n",
    "        return torch.maximum(\n",
    "            torch.minimum(\n",
    "                (times[:, None] - self.bin_starts[None, :]) / self.bin_lengths[None, :],\n",
    "                torch.tensor(1.0)\n",
    "            ),\n",
    "            torch.tensor(0.0)\n",
    "        )\n",
    "\n",
    "    def kl_divergence(self, alpha, num_classes, device=None):\n",
    "        \n",
    "        if not device:\n",
    "            device = alpha.device  # Use the device of the input tensor if none is provided\n",
    "        ones = torch.ones([1, num_classes], dtype=torch.float32, device=device)\n",
    "        sum_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
    "        \n",
    "        first_term = (\n",
    "            torch.lgamma(sum_alpha)\n",
    "            - torch.lgamma(alpha).sum(dim=1, keepdim=True)\n",
    "            + torch.lgamma(ones).sum(dim=1, keepdim=True)\n",
    "            - torch.lgamma(ones.sum(dim=1, keepdim=True))\n",
    "        )\n",
    "\n",
    "        second_term = ((alpha - ones)\n",
    "           .mul(torch.digamma(alpha) \n",
    "           - torch.digamma(sum_alpha))\n",
    "           .sum(dim=1, keepdim=True)\n",
    "        )\n",
    "        \n",
    "        kl = first_term + second_term\n",
    "        return kl\n",
    "\n",
    "    def forward(self, alphas, event_indicators, event_times, current_epoch):\n",
    "        \"\"\"\n",
    "        alphas: Dirichlet parameters from model (shape: [batch_size, num_bins + 1])\n",
    "        event_indicators: Binary indicators if the event occurred (1) or was censored (0)\n",
    "        event_times: Observed time to event or censoring (shape: [batch_size])\n",
    "        current_epoch: Current epoch number for annealing the KL term\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dirichlet distribution based on alpha parameters\n",
    "        dirichlet_dist = Dirichlet(alphas)\n",
    "        predictions = dirichlet_dist.mean  # Expected probabilities for each bin\n",
    "        \n",
    "        # Calculate event and nonevent likelihoods\n",
    "        event_likelihood = torch.sum(\n",
    "            self._discretize_times(event_times) * predictions[:, :-1],\n",
    "            -1\n",
    "        ) + self.tolerance\n",
    "\n",
    "        nonevent_likelihood = 1 - torch.sum(\n",
    "            self._get_proportion_of_bins_completed(event_times) * predictions[:, :-1],\n",
    "            -1\n",
    "        ) + self.tolerance\n",
    "\n",
    "        # Compute negative log-likelihood loss\n",
    "        log_likelihood = event_indicators * torch.log(event_likelihood) + (1 - event_indicators) * torch.log(nonevent_likelihood)\n",
    "        nll_loss = -torch.mean(log_likelihood)\n",
    "        print(f\"NLL Loss is: {nll_loss}\")\n",
    "        \n",
    "        # Calculate KL Divergence term\n",
    "        kl_loss = torch.mean(self.kl_divergence(alphas, alphas.size(1), alphas.device))\n",
    "        kl_loss_scaled = self.kl_scale * kl_loss  # Apply scaling to KL divergence\n",
    "        print(f\"Scaled KL Loss is: {kl_loss_scaled}\")\n",
    "        \n",
    "        # Annealing coefficient to gradually introduce KL term (exponential decay for smoother introduction)\n",
    "        annealing_coefficient = min(1.0, (current_epoch / self.annealing_step))\n",
    "        print(f\"Annealing coefficient is: {annealing_coefficient}\")\n",
    "        \n",
    "        # Total evidential loss with scaled KL term\n",
    "        evidential_loss = nll_loss + annealing_coefficient * kl_loss_scaled\n",
    "        print(f\"Total Loss is: {evidential_loss}\")\n",
    "        \n",
    "        return evidential_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9abf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Workbench/Academia/Software/Miniconda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = DiscreteTimeNN((100, ), 10)\n",
    "loss_fn = EvidentialDiscreteFailureTimeLoss(BIN_BOUNDARIES)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb9a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(*arrs, batch_size=1):\n",
    "    l = len(arrs[0])\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield (torch.tensor(arr[ndx:min(ndx + batch_size, l)], dtype=torch.float) for arr in arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b518f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL Loss is: 1.9947051232793263\n",
      "Scaled KL Loss is: 0.005384130869060755\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.9947051232793263\n",
      "NLL Loss is: 2.0009283930566686\n",
      "Scaled KL Loss is: 0.004372028633952141\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 2.0009283930566686\n",
      "NLL Loss is: 1.9761523763998072\n",
      "Scaled KL Loss is: 0.0038456686306744814\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.9761523763998072\n",
      "NLL Loss is: 1.8716961295642023\n",
      "Scaled KL Loss is: 0.004330887459218502\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.8716961295642023\n",
      "NLL Loss is: 1.9415540451891087\n",
      "Scaled KL Loss is: 0.002111095702275634\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.9415540451891087\n",
      "NLL Loss is: 1.738358043620637\n",
      "Scaled KL Loss is: 0.002643861807882786\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.738358043620637\n",
      "NLL Loss is: 1.8941808680212509\n",
      "Scaled KL Loss is: 0.0015955585986375809\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.8941808680212509\n",
      "NLL Loss is: 1.766413321718332\n",
      "Scaled KL Loss is: 0.0021138263400644064\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.766413321718332\n",
      "NLL Loss is: 1.7639418030275262\n",
      "Scaled KL Loss is: 0.0015844444278627634\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7639418030275262\n",
      "NLL Loss is: 1.7497567450716272\n",
      "Scaled KL Loss is: 0.0025153150781989098\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7497567450716272\n",
      "NLL Loss is: 1.785158783030787\n",
      "Scaled KL Loss is: 0.002184435725212097\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.785158783030787\n",
      "NLL Loss is: 1.812038245289248\n",
      "Scaled KL Loss is: 0.0022880774922668934\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.812038245289248\n",
      "NLL Loss is: 1.7302158819894071\n",
      "Scaled KL Loss is: 0.002525372663512826\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7302158819894071\n",
      "NLL Loss is: 1.8269445125729933\n",
      "Scaled KL Loss is: 0.0036869330797344446\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.8269445125729933\n",
      "NLL Loss is: 1.7893450531423531\n",
      "Scaled KL Loss is: 0.0035673831589519978\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7893450531423531\n",
      "NLL Loss is: 1.8777636340947976\n",
      "Scaled KL Loss is: 0.0033200790639966726\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.8777636340947976\n",
      "NLL Loss is: 1.745860474127999\n",
      "Scaled KL Loss is: 0.0032634749077260494\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.745860474127999\n",
      "NLL Loss is: 1.6638242941822134\n",
      "Scaled KL Loss is: 0.004276087507605553\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6638242941822134\n",
      "NLL Loss is: 1.6153349614926724\n",
      "Scaled KL Loss is: 0.004712860099971294\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6153349614926724\n",
      "NLL Loss is: 1.6691611332510536\n",
      "Scaled KL Loss is: 0.003845071420073509\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6691611332510536\n",
      "NLL Loss is: 1.6145839711786383\n",
      "Scaled KL Loss is: 0.006118665914982557\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6145839711786383\n",
      "NLL Loss is: 1.6717882757284863\n",
      "Scaled KL Loss is: 0.004299468826502562\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6717882757284863\n",
      "NLL Loss is: 1.6222240227382558\n",
      "Scaled KL Loss is: 0.004430551081895828\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6222240227382558\n",
      "NLL Loss is: 1.7951649421327014\n",
      "Scaled KL Loss is: 0.006995979230850935\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7951649421327014\n",
      "NLL Loss is: 1.533511844021155\n",
      "Scaled KL Loss is: 0.00596102187409997\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.533511844021155\n",
      "NLL Loss is: 1.565886801854617\n",
      "Scaled KL Loss is: 0.007160302717238665\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.565886801854617\n",
      "NLL Loss is: 1.6401522237514983\n",
      "Scaled KL Loss is: 0.007788562681525946\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6401522237514983\n",
      "NLL Loss is: 1.472586183403002\n",
      "Scaled KL Loss is: 0.0069677941501140594\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.472586183403002\n",
      "NLL Loss is: 1.5921131806760227\n",
      "Scaled KL Loss is: 0.007843381725251675\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5921131806760227\n",
      "NLL Loss is: 1.538996077554821\n",
      "Scaled KL Loss is: 0.008548995479941368\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.538996077554821\n",
      "NLL Loss is: 1.5194360693070161\n",
      "Scaled KL Loss is: 0.007983697578310966\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5194360693070161\n",
      "NLL Loss is: 1.6577357447834529\n",
      "Scaled KL Loss is: 0.009142948314547539\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6577357447834529\n",
      "NLL Loss is: 1.5878381792415002\n",
      "Scaled KL Loss is: 0.009233950637280941\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5878381792415002\n",
      "NLL Loss is: 1.458507076143432\n",
      "Scaled KL Loss is: 0.009549018926918507\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.458507076143432\n",
      "NLL Loss is: 1.636830351277523\n",
      "Scaled KL Loss is: 0.009790594689548016\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.636830351277523\n",
      "NLL Loss is: 1.6523822361130058\n",
      "Scaled KL Loss is: 0.010341179557144642\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6523822361130058\n",
      "NLL Loss is: 1.499683367081963\n",
      "Scaled KL Loss is: 0.012101398780941963\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.499683367081963\n",
      "NLL Loss is: 1.489123752006356\n",
      "Scaled KL Loss is: 0.009974067099392414\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.489123752006356\n",
      "NLL Loss is: 1.6535125945868177\n",
      "Scaled KL Loss is: 0.010651364922523499\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6535125945868177\n",
      "NLL Loss is: 1.6429145576018649\n",
      "Scaled KL Loss is: 0.012155801057815552\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6429145576018649\n",
      "NLL Loss is: 1.472334749926681\n",
      "Scaled KL Loss is: 0.012252800166606903\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.472334749926681\n",
      "NLL Loss is: 1.4951996926391746\n",
      "Scaled KL Loss is: 0.010345546528697014\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4951996926391746\n",
      "NLL Loss is: 1.5199066101430623\n",
      "Scaled KL Loss is: 0.010849330574274063\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5199066101430623\n",
      "NLL Loss is: 1.5644835833293402\n",
      "Scaled KL Loss is: 0.01594238169491291\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5644835833293402\n",
      "NLL Loss is: 1.5422786795309356\n",
      "Scaled KL Loss is: 0.012629853561520576\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5422786795309356\n",
      "NLL Loss is: 1.4878743485165171\n",
      "Scaled KL Loss is: 0.012207920663058758\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4878743485165171\n",
      "NLL Loss is: 1.5256183551890832\n",
      "Scaled KL Loss is: 0.013972220942378044\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5256183551890832\n",
      "NLL Loss is: 1.4975457632051223\n",
      "Scaled KL Loss is: 0.012022081762552261\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4975457632051223\n",
      "NLL Loss is: 1.466529488256085\n",
      "Scaled KL Loss is: 0.014378855936229229\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.466529488256085\n",
      "NLL Loss is: 1.4992225323128314\n",
      "Scaled KL Loss is: 0.013900929130613804\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4992225323128314\n",
      "NLL Loss is: 1.5855034258788694\n",
      "Scaled KL Loss is: 0.013831540942192078\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5855034258788694\n",
      "NLL Loss is: 1.4385141857110892\n",
      "Scaled KL Loss is: 0.014184778556227684\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4385141857110892\n",
      "NLL Loss is: 1.4432624125806672\n",
      "Scaled KL Loss is: 0.016280194744467735\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4432624125806672\n",
      "NLL Loss is: 1.5365308431339173\n",
      "Scaled KL Loss is: 0.012562581337988377\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5365308431339173\n",
      "NLL Loss is: 1.6058540152118195\n",
      "Scaled KL Loss is: 0.013530075550079346\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6058540152118195\n",
      "NLL Loss is: 1.6051912853586645\n",
      "Scaled KL Loss is: 0.013133368454873562\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6051912853586645\n",
      "NLL Loss is: 1.5568956011600195\n",
      "Scaled KL Loss is: 0.016122067347168922\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5568956011600195\n",
      "NLL Loss is: 1.497223315577483\n",
      "Scaled KL Loss is: 0.016311543062329292\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.497223315577483\n",
      "NLL Loss is: 1.4959214032904584\n",
      "Scaled KL Loss is: 0.013229520991444588\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4959214032904584\n",
      "NLL Loss is: 1.3996908201675695\n",
      "Scaled KL Loss is: 0.018142180517315865\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.3996908201675695\n",
      "NLL Loss is: 1.4864298776783107\n",
      "Scaled KL Loss is: 0.01531301625072956\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4864298776783107\n",
      "NLL Loss is: 1.5271831312800097\n",
      "Scaled KL Loss is: 0.01739305630326271\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5271831312800097\n",
      "NLL Loss is: 1.6039043400694626\n",
      "Scaled KL Loss is: 0.017230583354830742\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.6039043400694626\n",
      "NLL Loss is: 1.4967282723873472\n",
      "Scaled KL Loss is: 0.014394182711839676\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4967282723873472\n",
      "NLL Loss is: 1.5282114385445666\n",
      "Scaled KL Loss is: 0.01575535722076893\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5282114385445666\n",
      "NLL Loss is: 1.569927298009976\n",
      "Scaled KL Loss is: 0.01590234413743019\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.569927298009976\n",
      "NLL Loss is: 1.5531972941919259\n",
      "Scaled KL Loss is: 0.01646289974451065\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5531972941919259\n",
      "NLL Loss is: 1.5342441744570052\n",
      "Scaled KL Loss is: 0.018445972353219986\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5342441744570052\n",
      "NLL Loss is: 1.4801329904074145\n",
      "Scaled KL Loss is: 0.019964205101132393\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4801329904074145\n",
      "NLL Loss is: 1.485058493126931\n",
      "Scaled KL Loss is: 0.017529351636767387\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.485058493126931\n",
      "NLL Loss is: 1.594465070051251\n",
      "Scaled KL Loss is: 0.018322177231311798\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.594465070051251\n",
      "NLL Loss is: 1.5080205531371502\n",
      "Scaled KL Loss is: 0.016289634630084038\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5080205531371502\n",
      "NLL Loss is: 1.520207047537535\n",
      "Scaled KL Loss is: 0.019565248861908913\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.520207047537535\n",
      "NLL Loss is: 1.506445448598543\n",
      "Scaled KL Loss is: 0.01786353625357151\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.506445448598543\n",
      "NLL Loss is: 1.5100273621811515\n",
      "Scaled KL Loss is: 0.017060942947864532\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5100273621811515\n",
      "NLL Loss is: 1.39829292164489\n",
      "Scaled KL Loss is: 0.01674114167690277\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.39829292164489\n",
      "NLL Loss is: 1.542224979988472\n",
      "Scaled KL Loss is: 0.019606852903962135\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.542224979988472\n",
      "NLL Loss is: 1.5322038784902134\n",
      "Scaled KL Loss is: 0.01609811931848526\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5322038784902134\n",
      "NLL Loss is: 1.4720781583062705\n",
      "Scaled KL Loss is: 0.021555444225668907\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4720781583062705\n",
      "NLL Loss is: 1.4425871391568688\n",
      "Scaled KL Loss is: 0.019061006605625153\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4425871391568688\n",
      "NLL Loss is: 1.4932227209767392\n",
      "Scaled KL Loss is: 0.01784801483154297\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4932227209767392\n",
      "NLL Loss is: 1.4048825756728425\n",
      "Scaled KL Loss is: 0.01944153942167759\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4048825756728425\n",
      "NLL Loss is: 1.4860472331450822\n",
      "Scaled KL Loss is: 0.01709424890577793\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4860472331450822\n",
      "NLL Loss is: 1.4094559323390472\n",
      "Scaled KL Loss is: 0.019668681547045708\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4094559323390472\n",
      "NLL Loss is: 1.5615378128907975\n",
      "Scaled KL Loss is: 0.020179247483611107\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5615378128907975\n",
      "NLL Loss is: 1.5978992407447328\n",
      "Scaled KL Loss is: 0.014134909026324749\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5978992407447328\n",
      "NLL Loss is: 1.5479975901288885\n",
      "Scaled KL Loss is: 0.017209656536579132\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5479975901288885\n",
      "NLL Loss is: 1.4402822741591195\n",
      "Scaled KL Loss is: 0.019556671380996704\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.4402822741591195\n",
      "NLL Loss is: 1.3857055455692353\n",
      "Scaled KL Loss is: 0.016795998439192772\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.3857055455692353\n",
      "NLL Loss is: 1.5746099979407158\n",
      "Scaled KL Loss is: 0.016163956373929977\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.5746099979407158\n",
      "NLL Loss is: 1.456500052772384\n",
      "Scaled KL Loss is: 0.016631152480840683\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.456500052772384\n",
      "NLL Loss is: 1.7866858580078808\n",
      "Scaled KL Loss is: 0.012831233441829681\n",
      "Annealing coefficient is: 0.0\n",
      "Total Loss is: 1.7866858580078808\n",
      "NLL Loss is: 1.4917727896498674 1.619; test loss = 1.503\n",
      "Scaled KL Loss is: 0.019163837656378746\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4936891733922222\n",
      "NLL Loss is: 1.5532438346355422\n",
      "Scaled KL Loss is: 0.018151741474866867\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5550590087597458\n",
      "NLL Loss is: 1.5364054003888745\n",
      "Scaled KL Loss is: 0.019002925604581833\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5383056929726158\n",
      "NLL Loss is: 1.5475736843386398\n",
      "Scaled KL Loss is: 0.02251596935093403\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5498252812271671\n",
      "NLL Loss is: 1.5302467606081342\n",
      "Scaled KL Loss is: 0.01622062548995018\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5318688231338462\n",
      "NLL Loss is: 1.5130809602135908\n",
      "Scaled KL Loss is: 0.019493374973535538\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5150302977575105\n",
      "NLL Loss is: 1.5471231439264823\n",
      "Scaled KL Loss is: 0.015974273905158043\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5487205713402812\n",
      "NLL Loss is: 1.430242607909891\n",
      "Scaled KL Loss is: 0.018896715715527534\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4321322794581608\n",
      "NLL Loss is: 1.4836641568175395\n",
      "Scaled KL Loss is: 0.017993927001953125\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.485463549564301\n",
      "NLL Loss is: 1.4290125331899026\n",
      "Scaled KL Loss is: 0.021095991134643555\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4311221322568008\n",
      "NLL Loss is: 1.4485420462988503\n",
      "Scaled KL Loss is: 0.020214391872286797\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4505634854395129\n",
      "NLL Loss is: 1.5498461030306776\n",
      "Scaled KL Loss is: 0.018103795126080513\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5516564825898518\n",
      "NLL Loss is: 1.4437017717822764\n",
      "Scaled KL Loss is: 0.019626637920737267\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4456644356209163\n",
      "NLL Loss is: 1.6211227345431052\n",
      "Scaled KL Loss is: 0.020646488294005394\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.6231873833259396\n",
      "NLL Loss is: 1.4802525886943811\n",
      "Scaled KL Loss is: 0.0206596776843071\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4823185564628119\n",
      "NLL Loss is: 1.6340689194048679\n",
      "Scaled KL Loss is: 0.018612872809171677\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.635930206685785\n",
      "NLL Loss is: 1.547863201648523\n",
      "Scaled KL Loss is: 0.016910884529352188\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5495542900781751\n",
      "NLL Loss is: 1.4548560435974394\n",
      "Scaled KL Loss is: 0.020135285332798958\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4568695720841531\n",
      "NLL Loss is: 1.4110766385052915\n",
      "Scaled KL Loss is: 0.019512051716446877\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4130278437002193\n",
      "NLL Loss is: 1.475596720180834\n",
      "Scaled KL Loss is: 0.01724039949476719\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.47732076020016\n",
      "NLL Loss is: 1.4807947757979292\n",
      "Scaled KL Loss is: 0.02185768634080887\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4829805444785762\n",
      "NLL Loss is: 1.5246643174820924\n",
      "Scaled KL Loss is: 0.017069675028324127\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5263712849616418\n",
      "NLL Loss is: 1.4391597683790809\n",
      "Scaled KL Loss is: 0.01729116588830948\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.440888885037761\n",
      "NLL Loss is: 1.6427819567116908\n",
      "Scaled KL Loss is: 0.022089798003435135\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.6449909365120343\n",
      "NLL Loss is: 1.3245939090538599\n",
      "Scaled KL Loss is: 0.02000189758837223\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3265940989058294\n",
      "NLL Loss is: 1.424664548404264\n",
      "Scaled KL Loss is: 0.021871136501431465\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4268516621475393\n",
      "NLL Loss is: 1.4963497957733514\n",
      "Scaled KL Loss is: 0.02199861966073513\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4985496576928587\n",
      "NLL Loss is: 1.317914595340452\n",
      "Scaled KL Loss is: 0.020097892731428146\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3199243845670288\n",
      "NLL Loss is: 1.4631961382914074\n",
      "Scaled KL Loss is: 0.02124295011162758\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4653204333957024\n",
      "NLL Loss is: 1.3686331741345987\n",
      "Scaled KL Loss is: 0.0219249464571476\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3708256688268796\n",
      "NLL Loss is: 1.3617472516231957\n",
      "Scaled KL Loss is: 0.020800482481718063\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3638272998248013\n",
      "NLL Loss is: 1.5282958465041923\n",
      "Scaled KL Loss is: 0.02209939993917942\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5305057864981102\n",
      "NLL Loss is: 1.4932729549450436\n",
      "Scaled KL Loss is: 0.022050967440009117\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.495478051828743\n",
      "NLL Loss is: 1.3699554959303795\n",
      "Scaled KL Loss is: 0.022085627540946007\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3721640587310402\n",
      "NLL Loss is: 1.5636719406545019\n",
      "Scaled KL Loss is: 0.02165459655225277\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5658374004494255\n",
      "NLL Loss is: 1.5717516521372337\n",
      "Scaled KL Loss is: 0.022935733199119568\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.574045225596844\n",
      "NLL Loss is: 1.3823187386124882\n",
      "Scaled KL Loss is: 0.02573023922741413\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3848917626283619\n",
      "NLL Loss is: 1.3653028080671012\n",
      "Scaled KL Loss is: 0.0218410175293684\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3674869099131703\n",
      "NLL Loss is: 1.5359995938697921\n",
      "Scaled KL Loss is: 0.02248789556324482\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5382483835192489\n",
      "NLL Loss is: 1.5680198967363876\n",
      "Scaled KL Loss is: 0.024366414174437523\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5704565381072653\n",
      "NLL Loss is: 1.385089712282413\n",
      "Scaled KL Loss is: 0.02452515810728073\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.387542228046575\n",
      "NLL Loss is: 1.3902366657757799\n",
      "Scaled KL Loss is: 0.021145861595869064\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3923512520750652\n",
      "NLL Loss is: 1.4120651083965934\n",
      "Scaled KL Loss is: 0.02176123484969139\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4142412318349964\n",
      "NLL Loss is: 1.44116561010493\n",
      "Scaled KL Loss is: 0.029068054631352425\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4440724157077636\n",
      "NLL Loss is: 1.4582725523558033\n",
      "Scaled KL Loss is: 0.023603929206728935\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4606329454161746\n",
      "NLL Loss is: 1.389646944593293\n",
      "Scaled KL Loss is: 0.023527752608060837\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3919997199006653\n",
      "NLL Loss is: 1.4168200104155357\n",
      "Scaled KL Loss is: 0.02557864785194397\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4193778752938624\n",
      "NLL Loss is: 1.372863689299362\n",
      "Scaled KL Loss is: 0.022756977006793022\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3751393869534752\n",
      "NLL Loss is: 1.3939653235483453\n",
      "Scaled KL Loss is: 0.026080548763275146\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3965733785643712\n",
      "NLL Loss is: 1.4022652012638048\n",
      "Scaled KL Loss is: 0.024688899517059326\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.404734091308643\n",
      "NLL Loss is: 1.4806311776666103\n",
      "Scaled KL Loss is: 0.02462637424468994\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4830938150445132\n",
      "NLL Loss is: 1.3995580056946872\n",
      "Scaled KL Loss is: 0.024782711640000343\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4020362769518195\n",
      "NLL Loss is: 1.3638798777096646\n",
      "Scaled KL Loss is: 0.0277172289788723\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3666516005609857\n",
      "NLL Loss is: 1.4659830114006138\n",
      "Scaled KL Loss is: 0.021951422095298767\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4681781536101437\n",
      "NLL Loss is: 1.5155653708149035\n",
      "Scaled KL Loss is: 0.023283476009964943\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5178937184624661\n",
      "NLL Loss is: 1.5326858167371942\n",
      "Scaled KL Loss is: 0.02258833311498165\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5349446500021262\n",
      "NLL Loss is: 1.503587210336427\n",
      "Scaled KL Loss is: 0.026566660031676292\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5062438764327268\n",
      "NLL Loss is: 1.411763390772141\n",
      "Scaled KL Loss is: 0.026719318702816963\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4144353226424227\n",
      "NLL Loss is: 1.3983748121084303\n",
      "Scaled KL Loss is: 0.022318534553050995\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4006066656568676\n",
      "NLL Loss is: 1.3308304576753214\n",
      "Scaled KL Loss is: 0.02889925427734852\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.33372038305649\n",
      "NLL Loss is: 1.418202398603606\n",
      "Scaled KL Loss is: 0.02486833557486534\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4206892322076587\n",
      "NLL Loss is: 1.461659221310107\n",
      "Scaled KL Loss is: 0.027256133034825325\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4643848346135895\n",
      "NLL Loss is: 1.5302232397238322\n",
      "Scaled KL Loss is: 0.02663690783083439\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5328869305534818\n",
      "NLL Loss is: 1.419066994235475\n",
      "Scaled KL Loss is: 0.02321813441812992\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4213888077238541\n",
      "NLL Loss is: 1.4559899096819644\n",
      "Scaled KL Loss is: 0.024776339530944824\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.458467543681625\n",
      "NLL Loss is: 1.503905399493885\n",
      "Scaled KL Loss is: 0.024921922013163567\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5063975916952013\n",
      "NLL Loss is: 1.5016245775314272\n",
      "Scaled KL Loss is: 0.025131678208708763\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5041377454454303\n",
      "NLL Loss is: 1.4764116357714456\n",
      "Scaled KL Loss is: 0.02759796753525734\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4791714325715375\n",
      "NLL Loss is: 1.429477787623914\n",
      "Scaled KL Loss is: 0.029655568301677704\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.432443344547214\n",
      "NLL Loss is: 1.425606135209362\n",
      "Scaled KL Loss is: 0.02626081369817257\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4282322166723116\n",
      "NLL Loss is: 1.5519735908326588\n",
      "Scaled KL Loss is: 0.027307532727718353\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5547043441054307\n",
      "NLL Loss is: 1.457543515116937\n",
      "Scaled KL Loss is: 0.024625936523079872\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4600061087226788\n",
      "NLL Loss is: 1.4788269021515814\n",
      "Scaled KL Loss is: 0.028766296803951263\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.481703531971675\n",
      "NLL Loss is: 1.4453882655246557\n",
      "Scaled KL Loss is: 0.026374809443950653\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4480257466087492\n",
      "NLL Loss is: 1.4894876223345772\n",
      "Scaled KL Loss is: 0.025588855147361755\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4920465079424456\n",
      "NLL Loss is: 1.360391295339183\n",
      "Scaled KL Loss is: 0.02491879090666771\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3628831743832837\n",
      "NLL Loss is: 1.5136014554973274\n",
      "Scaled KL Loss is: 0.028354249894618988\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5164368805799215\n",
      "NLL Loss is: 1.4921297954172343\n",
      "Scaled KL Loss is: 0.02418806031346321\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4945486014951468\n",
      "NLL Loss is: 1.4188024802863288\n",
      "Scaled KL Loss is: 0.031045015901327133\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4219069819230277\n",
      "NLL Loss is: 1.393875419512553\n",
      "Scaled KL Loss is: 0.028111442923545837\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3966865638514736\n",
      "NLL Loss is: 1.4579579574910984\n",
      "Scaled KL Loss is: 0.02618207409977913\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4605761648545101\n",
      "NLL Loss is: 1.3638488328000924\n",
      "Scaled KL Loss is: 0.028587473556399345\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3667075802954307\n",
      "NLL Loss is: 1.437471442488907\n",
      "Scaled KL Loss is: 0.02524607628583908\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4399960500709248\n",
      "NLL Loss is: 1.375915967347327\n",
      "Scaled KL Loss is: 0.02883766032755375\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3787997334266484\n",
      "NLL Loss is: 1.5279487820242519\n",
      "Scaled KL Loss is: 0.02914157323539257\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5308629394874895\n",
      "NLL Loss is: 1.5539002387971539\n",
      "Scaled KL Loss is: 0.02165362797677517\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5560656017345298\n",
      "NLL Loss is: 1.5019446540808243\n",
      "Scaled KL Loss is: 0.025022253394126892\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.504446879420237\n",
      "NLL Loss is: 1.4058897352262185\n",
      "Scaled KL Loss is: 0.02872261218726635\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4087619964449452\n",
      "NLL Loss is: 1.3353607837625634\n",
      "Scaled KL Loss is: 0.025173164904117584\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.3378781002529752\n",
      "NLL Loss is: 1.5174524387247703\n",
      "Scaled KL Loss is: 0.024283647537231445\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.5198808034319273\n",
      "NLL Loss is: 1.4189339078035248\n",
      "Scaled KL Loss is: 0.024843422695994377\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.4214182501196904\n",
      "NLL Loss is: 1.7541892572963689\n",
      "Scaled KL Loss is: 0.019660329446196556\n",
      "Annealing coefficient is: 0.1\n",
      "Total Loss is: 1.7561552901944224\n",
      "NLL Loss is: 1.4413067137591367 1.467; test loss = 1.464\n",
      "Scaled KL Loss is: 0.028081675991415977\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4469230489574199\n",
      "NLL Loss is: 1.501214087453219\n",
      "Scaled KL Loss is: 0.02651265822350979\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.506516619097921\n",
      "NLL Loss is: 1.481109139844974\n",
      "Scaled KL Loss is: 0.027518387883901596\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4866128176080189\n",
      "NLL Loss is: 1.5215297403188819\n",
      "Scaled KL Loss is: 0.03188341483473778\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5279064235652262\n",
      "NLL Loss is: 1.4735702505569819\n",
      "Scaled KL Loss is: 0.023963749408721924\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4783630004387263\n",
      "NLL Loss is: 1.4940193115642555\n",
      "Scaled KL Loss is: 0.02788238227367401\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4995957880189903\n",
      "NLL Loss is: 1.4962938650923576\n",
      "Scaled KL Loss is: 0.023391665890812874\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5009721982705202\n",
      "NLL Loss is: 1.3853539130456083\n",
      "Scaled KL Loss is: 0.026849035173654556\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3907237201734715\n",
      "NLL Loss is: 1.4472534701638124\n",
      "Scaled KL Loss is: 0.025941994041204453\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4524418691583179\n",
      "NLL Loss is: 1.3764895631650287\n",
      "Scaled KL Loss is: 0.029660560190677643\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3824216753894287\n",
      "NLL Loss is: 1.390304707468713\n",
      "Scaled KL Loss is: 0.028542906045913696\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.396013288771028\n",
      "NLL Loss is: 1.502600805741006\n",
      "Scaled KL Loss is: 0.025697557255625725\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5077403172852635\n",
      "NLL Loss is: 1.393023197709344\n",
      "Scaled KL Loss is: 0.02776629664003849\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3985764572236161\n",
      "NLL Loss is: 1.5854888114232477\n",
      "Scaled KL Loss is: 0.02842395007610321\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5911736016247329\n",
      "NLL Loss is: 1.4125035726249178\n",
      "Scaled KL Loss is: 0.02867715060710907\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4182390030257364\n",
      "NLL Loss is: 1.578277685648397\n",
      "Scaled KL Loss is: 0.02605404146015644\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.583488494126693\n",
      "NLL Loss is: 1.5069283838643344\n",
      "Scaled KL Loss is: 0.02382764220237732\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5116939125842066\n",
      "NLL Loss is: 1.4123574884613135\n",
      "Scaled KL Loss is: 0.027852855622768402\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.417928059865264\n",
      "NLL Loss is: 1.3640826396607306\n",
      "Scaled KL Loss is: 0.0267197173088789\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3694265830293741\n",
      "NLL Loss is: 1.4336496158533072\n",
      "Scaled KL Loss is: 0.024170493707060814\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4384837145947194\n",
      "NLL Loss is: 1.4541405478684855\n",
      "Scaled KL Loss is: 0.02948138862848282\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.460036825594182\n",
      "NLL Loss is: 1.4905880175069435\n",
      "Scaled KL Loss is: 0.02376605197787285\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4953412280887826\n",
      "NLL Loss is: 1.3938273683706348\n",
      "Scaled KL Loss is: 0.02414148673415184\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3986556659037297\n",
      "NLL Loss is: 1.6086242730226217\n",
      "Scaled KL Loss is: 0.029738789424300194\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.614572031000614\n",
      "NLL Loss is: 1.270788464365332\n",
      "Scaled KL Loss is: 0.027375096455216408\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.276263483935772\n",
      "NLL Loss is: 1.3929306293439843\n",
      "Scaled KL Loss is: 0.02939573861658573\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.398809777253566\n",
      "NLL Loss is: 1.4582583201745059\n",
      "Scaled KL Loss is: 0.02936701290309429\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4641317227551247\n",
      "NLL Loss is: 1.2799470120981937\n",
      "Scaled KL Loss is: 0.02708575129508972\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.2853641625434762\n",
      "NLL Loss is: 1.429041496005047\n",
      "Scaled KL Loss is: 0.02834596112370491\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4347106884160525\n",
      "NLL Loss is: 1.3169023706490663\n",
      "Scaled KL Loss is: 0.029048584401607513\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3227120875293878\n",
      "NLL Loss is: 1.316542084271206\n",
      "Scaled KL Loss is: 0.02772415429353714\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3220869153161778\n",
      "NLL Loss is: 1.4880642640217452\n",
      "Scaled KL Loss is: 0.029041912406682968\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4938726467824786\n",
      "NLL Loss is: 1.4687282660199878\n",
      "Scaled KL Loss is: 0.02902338281273842\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4745329425825355\n",
      "NLL Loss is: 1.3473184721662097\n",
      "Scaled KL Loss is: 0.028936831280589104\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3531058387017243\n",
      "NLL Loss is: 1.5414504006923098\n",
      "Scaled KL Loss is: 0.02817295305430889\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5470849912100393\n",
      "NLL Loss is: 1.5531965319324978\n",
      "Scaled KL Loss is: 0.02989201433956623\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5591749350798079\n",
      "NLL Loss is: 1.3489109884390849\n",
      "Scaled KL Loss is: 0.03318018093705177\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.355547024533363\n",
      "NLL Loss is: 1.325576094093069\n",
      "Scaled KL Loss is: 0.02852552756667137\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3312811996995355\n",
      "NLL Loss is: 1.4961079403673119\n",
      "Scaled KL Loss is: 0.02920452691614628\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5019488458436734\n",
      "NLL Loss is: 1.548728659601038\n",
      "Scaled KL Loss is: 0.031232526525855064\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.554975164906209\n",
      "NLL Loss is: 1.3602249362239085\n",
      "Scaled KL Loss is: 0.03148242458701134\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3665214214207075\n",
      "NLL Loss is: 1.356843923920282\n",
      "Scaled KL Loss is: 0.027421681210398674\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3623282604417586\n",
      "NLL Loss is: 1.372106650365298\n",
      "Scaled KL Loss is: 0.02810276858508587\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.377727203989183\n",
      "NLL Loss is: 1.3941568479519295\n",
      "Scaled KL Loss is: 0.036438021808862686\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4014444522205698\n",
      "NLL Loss is: 1.4335533976278887\n",
      "Scaled KL Loss is: 0.029947277158498764\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.439542853245853\n",
      "NLL Loss is: 1.3560768732256037\n",
      "Scaled KL Loss is: 0.030141731724143028\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3621052194773\n",
      "NLL Loss is: 1.3774269057170079\n",
      "Scaled KL Loss is: 0.03231479227542877\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3838898643583581\n",
      "NLL Loss is: 1.3271203427020992\n",
      "Scaled KL Loss is: 0.029202720150351524\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3329608868253018\n",
      "NLL Loss is: 1.3710310387476108\n",
      "Scaled KL Loss is: 0.0329202376306057\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3776150865531287\n",
      "NLL Loss is: 1.366581538798664\n",
      "Scaled KL Loss is: 0.0310672540217638\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3727949896030167\n",
      "NLL Loss is: 1.4406167505514753\n",
      "Scaled KL Loss is: 0.031073758378624916\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4468315024134648\n",
      "NLL Loss is: 1.3902731596540747\n",
      "Scaled KL Loss is: 0.031107058748602867\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3964945714037953\n",
      "NLL Loss is: 1.3364107778853467\n",
      "Scaled KL Loss is: 0.03446531295776367\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3433038403837672\n",
      "NLL Loss is: 1.440476137946286\n",
      "Scaled KL Loss is: 0.027706414461135864\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.44601742111791\n",
      "NLL Loss is: 1.4820516738455418\n",
      "Scaled KL Loss is: 0.02922908030450344\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4878974901858393\n",
      "NLL Loss is: 1.5052949741625128\n",
      "Scaled KL Loss is: 0.02840052731335163\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5109750798114476\n",
      "NLL Loss is: 1.4861439709875435\n",
      "Scaled KL Loss is: 0.032874464988708496\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.492718863892153\n",
      "NLL Loss is: 1.378199431625329\n",
      "Scaled KL Loss is: 0.03301601856946945\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3848026353392229\n",
      "NLL Loss is: 1.3581660781010718\n",
      "Scaled KL Loss is: 0.028017546981573105\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3637695875905187\n",
      "NLL Loss is: 1.3045109622066478\n",
      "Scaled KL Loss is: 0.035440366715192795\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3115990357359508\n",
      "NLL Loss is: 1.3915826874079924\n",
      "Scaled KL Loss is: 0.03082781285047531\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3977482500712197\n",
      "NLL Loss is: 1.435945497432841\n",
      "Scaled KL Loss is: 0.03330855444073677\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.442607208227856\n",
      "NLL Loss is: 1.4992265039837829\n",
      "Scaled KL Loss is: 0.03246437385678291\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5057193790345362\n",
      "NLL Loss is: 1.3866848929411506\n",
      "Scaled KL Loss is: 0.028821365907788277\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.392449166402105\n",
      "NLL Loss is: 1.4250882711921964\n",
      "Scaled KL Loss is: 0.03044923208653927\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4311781177957688\n",
      "NLL Loss is: 1.4758188048319163\n",
      "Scaled KL Loss is: 0.03062610886991024\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4819440267921629\n",
      "NLL Loss is: 1.4808096895755178\n",
      "Scaled KL Loss is: 0.030606407672166824\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4869309711099512\n",
      "NLL Loss is: 1.4522312231545442\n",
      "Scaled KL Loss is: 0.03334277495741844\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4588997782391602\n",
      "NLL Loss is: 1.4101907037556827\n",
      "Scaled KL Loss is: 0.03571971133351326\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.417334645929253\n",
      "NLL Loss is: 1.4003897193507964\n",
      "Scaled KL Loss is: 0.03182309865951538\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4067543391758317\n",
      "NLL Loss is: 1.5357508916585851\n",
      "Scaled KL Loss is: 0.03300578519701958\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5423520487911213\n",
      "NLL Loss is: 1.4369944744353447\n",
      "Scaled KL Loss is: 0.02997785247862339\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4429900451173339\n",
      "NLL Loss is: 1.4633083539869698\n",
      "Scaled KL Loss is: 0.03462272509932518\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4702328989137026\n",
      "NLL Loss is: 1.4186837429980539\n",
      "Scaled KL Loss is: 0.03185863792896271\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4250554706769787\n",
      "NLL Loss is: 1.4854082412636291\n",
      "Scaled KL Loss is: 0.031097974628210068\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.491627836468668\n",
      "NLL Loss is: 1.346420390611997\n",
      "Scaled KL Loss is: 0.030178308486938477\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3524560524025169\n",
      "NLL Loss is: 1.504112713197729\n",
      "Scaled KL Loss is: 0.03388849273324013\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5108904118375093\n",
      "NLL Loss is: 1.4755018795710657\n",
      "Scaled KL Loss is: 0.02942781336605549\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4813874424305413\n",
      "NLL Loss is: 1.3970095238634819\n",
      "Scaled KL Loss is: 0.03698541224002838\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.404406606497752\n",
      "NLL Loss is: 1.3741737089055868\n",
      "Scaled KL Loss is: 0.03387284278869629\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3809482773701938\n",
      "NLL Loss is: 1.444955313399846\n",
      "Scaled KL Loss is: 0.03153277561068535\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4512618685219831\n",
      "NLL Loss is: 1.3479767611798024\n",
      "Scaled KL Loss is: 0.03440920263528824\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.35485860170686\n",
      "NLL Loss is: 1.4173405729261586\n",
      "Scaled KL Loss is: 0.030475681647658348\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4234357094419547\n",
      "NLL Loss is: 1.3645453983971132\n",
      "Scaled KL Loss is: 0.03466787189245224\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.3714789729618682\n",
      "NLL Loss is: 1.5154427964017052\n",
      "Scaled KL Loss is: 0.03481939062476158\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.5224066748060543\n",
      "NLL Loss is: 1.5356017245152627\n",
      "Scaled KL Loss is: 0.026600254699587822\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.540921775734577\n",
      "NLL Loss is: 1.481820718865205\n",
      "Scaled KL Loss is: 0.030045006424188614\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4878297201500428\n",
      "NLL Loss is: 1.3941398047814442\n",
      "Scaled KL Loss is: 0.03455544263124466\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4010508934939576\n",
      "NLL Loss is: 1.3151593649425146\n",
      "Scaled KL Loss is: 0.030564211308956146\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.321272207297438\n",
      "NLL Loss is: 1.4926454726560296\n",
      "Scaled KL Loss is: 0.02954397164285183\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4985542668914678\n",
      "NLL Loss is: 1.4051621735768842\n",
      "Scaled KL Loss is: 0.030171368271112442\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.4111964472311067\n",
      "NLL Loss is: 1.742415236276033\n",
      "Scaled KL Loss is: 0.024165445938706398\n",
      "Annealing coefficient is: 0.2\n",
      "Total Loss is: 1.7472483254637743\n",
      "NLL Loss is: 1.420735015107644= 1.435; test loss = 1.451\n",
      "Scaled KL Loss is: 0.0337674580514431\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.430865252895606\n",
      "NLL Loss is: 1.478136166605732\n",
      "Scaled KL Loss is: 0.031873919069767\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.487698342326662\n",
      "NLL Loss is: 1.456477109415584\n",
      "Scaled KL Loss is: 0.03297679126262665\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.466370146794372\n",
      "NLL Loss is: 1.512925084647394\n",
      "Scaled KL Loss is: 0.03779654577374458\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5242640487520465\n",
      "NLL Loss is: 1.447594629520246\n",
      "Scaled KL Loss is: 0.02900649979710579\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4562965798319067\n",
      "NLL Loss is: 1.4890277324104488\n",
      "Scaled KL Loss is: 0.03328986093401909\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.499014690876919\n",
      "NLL Loss is: 1.4733481309503211\n",
      "Scaled KL Loss is: 0.02827274426817894\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4818299547895684\n",
      "NLL Loss is: 1.366250344973746\n",
      "Scaled KL Loss is: 0.03197638317942619\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3758432599275738\n",
      "NLL Loss is: 1.4327398026985276\n",
      "Scaled KL Loss is: 0.03109915181994438\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.442069548244511\n",
      "NLL Loss is: 1.3531881575228828\n",
      "Scaled KL Loss is: 0.035192497074604034\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3637459068315285\n",
      "NLL Loss is: 1.3632652815226023\n",
      "Scaled KL Loss is: 0.03390170633792877\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.373435793423981\n",
      "NLL Loss is: 1.4811393682088103\n",
      "Scaled KL Loss is: 0.030694017186760902\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4903475733648386\n",
      "NLL Loss is: 1.369932646120165\n",
      "Scaled KL Loss is: 0.033099930733442307\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3798626253401978\n",
      "NLL Loss is: 1.569994074260365\n",
      "Scaled KL Loss is: 0.033489812165498734\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5800410182825437\n",
      "NLL Loss is: 1.378530866999797\n",
      "Scaled KL Loss is: 0.03388563543558121\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3886965583755295\n",
      "NLL Loss is: 1.5500920413088572\n",
      "Scaled KL Loss is: 0.031011763960123062\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5593955710556877\n",
      "NLL Loss is: 1.487707795449562\n",
      "Scaled KL Loss is: 0.028471948578953743\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4962493803957773\n",
      "NLL Loss is: 1.3929722843791073\n",
      "Scaled KL Loss is: 0.03292883187532425\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4028509346867626\n",
      "NLL Loss is: 1.3425074764561062\n",
      "Scaled KL Loss is: 0.03149855136871338\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3519570422392493\n",
      "NLL Loss is: 1.4150699827641098\n",
      "Scaled KL Loss is: 0.028818229213356972\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4237154520869104\n",
      "NLL Loss is: 1.4418149181587288\n",
      "Scaled KL Loss is: 0.03446005657315254\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4521529358757326\n",
      "NLL Loss is: 1.4740431141038042\n",
      "Scaled KL Loss is: 0.028271764516830444\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4825246436451178\n",
      "NLL Loss is: 1.3713440206912781\n",
      "Scaled KL Loss is: 0.028749722987413406\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3799689375875022\n",
      "NLL Loss is: 1.5953658664836583\n",
      "Scaled KL Loss is: 0.03475623205304146\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.6057927360995707\n",
      "NLL Loss is: 1.243168176123869\n",
      "Scaled KL Loss is: 0.03226694092154503\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.2528482591453907\n",
      "NLL Loss is: 1.3778960416223454\n",
      "Scaled KL Loss is: 0.03438691422343254\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3882121164481687\n",
      "NLL Loss is: 1.440718447706584\n",
      "Scaled KL Loss is: 0.03425370529294014\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4509945594807305\n",
      "NLL Loss is: 1.259176656518129\n",
      "Scaled KL Loss is: 0.03178822249174118\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.2687131240107095\n",
      "NLL Loss is: 1.4122803678466689\n",
      "Scaled KL Loss is: 0.0330839641392231\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4222055572747003\n",
      "NLL Loss is: 1.289303461596333\n",
      "Scaled KL Loss is: 0.03378668799996376\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.2994394679963222\n",
      "NLL Loss is: 1.2924906859443757\n",
      "Scaled KL Loss is: 0.032324399799108505\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3021880058841082\n",
      "NLL Loss is: 1.4667355085882121\n",
      "Scaled KL Loss is: 0.033662181347608566\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4768341633650237\n",
      "NLL Loss is: 1.4570089318568886\n",
      "Scaled KL Loss is: 0.03364855796098709\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4671034999902428\n",
      "NLL Loss is: 1.336849421169033\n",
      "Scaled KL Loss is: 0.03352128341794014\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.346905806939473\n",
      "NLL Loss is: 1.531737993586816\n",
      "Scaled KL Loss is: 0.032561045140028\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.541506307315089\n",
      "NLL Loss is: 1.5465447214617367\n",
      "Scaled KL Loss is: 0.03453354164958\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5569047845154043\n",
      "NLL Loss is: 1.3321852950007298\n",
      "Scaled KL Loss is: 0.038158051669597626\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3436327106878736\n",
      "NLL Loss is: 1.3044279538836365\n",
      "Scaled KL Loss is: 0.03307124227285385\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3143493267517572\n",
      "NLL Loss is: 1.4752420466583454\n",
      "Scaled KL Loss is: 0.033740103244781494\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4853640776317798\n",
      "NLL Loss is: 1.5404040616367853\n",
      "Scaled KL Loss is: 0.03583407774567604\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5511542855192817\n",
      "NLL Loss is: 1.348073068589743\n",
      "Scaled KL Loss is: 0.036164842545986176\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.358922522098597\n",
      "NLL Loss is: 1.3391881390567704\n",
      "Scaled KL Loss is: 0.0316791757941246\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3486918919812723\n",
      "NLL Loss is: 1.3510159562129522\n",
      "Scaled KL Loss is: 0.03244233503937721\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3607486570972944\n",
      "NLL Loss is: 1.369285432578834\n",
      "Scaled KL Loss is: 0.04137036204338074\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3816965417506417\n",
      "NLL Loss is: 1.4211604971400982\n",
      "Scaled KL Loss is: 0.034245532006025314\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4314341567419058\n",
      "NLL Loss is: 1.3392567522119179\n",
      "Scaled KL Loss is: 0.034651659429073334\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3496522502269044\n",
      "NLL Loss is: 1.3568136782231877\n",
      "Scaled KL Loss is: 0.03687894344329834\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3678773620012352\n",
      "NLL Loss is: 1.302176534102897\n",
      "Scaled KL Loss is: 0.03365533426403999\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.312273134382109\n",
      "NLL Loss is: 1.3602412504794708\n",
      "Scaled KL Loss is: 0.03753826394677162\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3715027304085603\n",
      "NLL Loss is: 1.3474317178617106\n",
      "Scaled KL Loss is: 0.03540216013789177\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.358052365903078\n",
      "NLL Loss is: 1.4179400966791689\n",
      "Scaled KL Loss is: 0.03547428548336029\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.428582383069235\n",
      "NLL Loss is: 1.3885812262157686\n",
      "Scaled KL Loss is: 0.0353933721780777\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.39919923861425\n",
      "NLL Loss is: 1.3212054127276067\n",
      "Scaled KL Loss is: 0.039002325385808945\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.332906110902143\n",
      "NLL Loss is: 1.4271834299056465\n",
      "Scaled KL Loss is: 0.03167938441038132\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.436687245228761\n",
      "NLL Loss is: 1.460480399677698\n",
      "Scaled KL Loss is: 0.033299196511507034\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4704701586311502\n",
      "NLL Loss is: 1.4902031692987885\n",
      "Scaled KL Loss is: 0.03239573538303375\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4999218900999631\n",
      "NLL Loss is: 1.4774283676999742\n",
      "Scaled KL Loss is: 0.037154220044612885\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.488574633713358\n",
      "NLL Loss is: 1.3608835531625214\n",
      "Scaled KL Loss is: 0.03729156404733658\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3720710227492514\n",
      "NLL Loss is: 1.3362434333792779\n",
      "Scaled KL Loss is: 0.031964171677827835\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3458326854414198\n",
      "NLL Loss is: 1.2905888551260603\n",
      "Scaled KL Loss is: 0.03988367319107056\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.302553957642175\n",
      "NLL Loss is: 1.3785284401057913\n",
      "Scaled KL Loss is: 0.0349394865334034\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.389010286624606\n",
      "NLL Loss is: 1.4226094637853766\n",
      "Scaled KL Loss is: 0.03743712231516838\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4338406012249851\n",
      "NLL Loss is: 1.4816602108027408\n",
      "Scaled KL Loss is: 0.03645194694399834\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4925957948859403\n",
      "NLL Loss is: 1.369194137295005\n",
      "Scaled KL Loss is: 0.03272559866309166\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3790118176389905\n",
      "NLL Loss is: 1.4077462007292678\n",
      "Scaled KL Loss is: 0.034351885318756104\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4180517665111592\n",
      "NLL Loss is: 1.4599510822743769\n",
      "Scaled KL Loss is: 0.03456336259841919\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4703200916126962\n",
      "NLL Loss is: 1.4697406053794657\n",
      "Scaled KL Loss is: 0.034397415816783905\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.480059830869559\n",
      "NLL Loss is: 1.4388108079690947\n",
      "Scaled KL Loss is: 0.037277594208717346\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.449994086604239\n",
      "NLL Loss is: 1.4004091880365297\n",
      "Scaled KL Loss is: 0.03986305743455887\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4123681056394264\n",
      "NLL Loss is: 1.3866302143406852\n",
      "Scaled KL Loss is: 0.0356597974896431\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3973281537738427\n",
      "NLL Loss is: 1.527454795181423\n",
      "Scaled KL Loss is: 0.03692270442843437\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5385316068824824\n",
      "NLL Loss is: 1.4259449898621128\n",
      "Scaled KL Loss is: 0.03367241844534874\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4360467161407755\n",
      "NLL Loss is: 1.4552651541483692\n",
      "Scaled KL Loss is: 0.03865635767579079\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4668620620099\n",
      "NLL Loss is: 1.4040325798030344\n",
      "Scaled KL Loss is: 0.03565986827015877\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.414730540656611\n",
      "NLL Loss is: 1.4852573666410842\n",
      "Scaled KL Loss is: 0.034909363836050034\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4957301765369573\n",
      "NLL Loss is: 1.3394526397969644\n",
      "Scaled KL Loss is: 0.033800844103097916\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3495928930278938\n",
      "NLL Loss is: 1.5000718773409885\n",
      "Scaled KL Loss is: 0.037655431777238846\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5113685072466891\n",
      "NLL Loss is: 1.4667066667265691\n",
      "Scaled KL Loss is: 0.03307375684380531\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4766287939659752\n",
      "NLL Loss is: 1.3854783102556716\n",
      "Scaled KL Loss is: 0.040996599942445755\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3977772909834634\n",
      "NLL Loss is: 1.3639770595997347\n",
      "Scaled KL Loss is: 0.0377984382212162\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3753165918111576\n",
      "NLL Loss is: 1.438685154741669\n",
      "Scaled KL Loss is: 0.03522082790732384\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4492514033001307\n",
      "NLL Loss is: 1.3398405982046229\n",
      "Scaled KL Loss is: 0.03839845210313797\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3513601345806223\n",
      "NLL Loss is: 1.4067276092672265\n",
      "Scaled KL Loss is: 0.03407127037644386\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4169489909389532\n",
      "NLL Loss is: 1.3591128103227\n",
      "Scaled KL Loss is: 0.03866055980324745\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3707109782636742\n",
      "NLL Loss is: 1.509162982024504\n",
      "Scaled KL Loss is: 0.038698092103004456\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5207724096554054\n",
      "NLL Loss is: 1.5260336447514613\n",
      "Scaled KL Loss is: 0.030087770894169807\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.5350599765785058\n",
      "NLL Loss is: 1.470873016069184\n",
      "Scaled KL Loss is: 0.033508919179439545\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4809256923818095\n",
      "NLL Loss is: 1.3885925628451017\n",
      "Scaled KL Loss is: 0.03855569288134575\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4001592707095054\n",
      "NLL Loss is: 1.3043899204225886\n",
      "Scaled KL Loss is: 0.03428930789232254\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.3146767135353434\n",
      "NLL Loss is: 1.4791391206405478\n",
      "Scaled KL Loss is: 0.03321133181452751\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4891025203711705\n",
      "NLL Loss is: 1.3983967454385813\n",
      "Scaled KL Loss is: 0.033884208649396896\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.4085620084059294\n",
      "NLL Loss is: 1.7363406367486511\n",
      "Scaled KL Loss is: 0.027323735877871513\n",
      "Annealing coefficient is: 0.3\n",
      "Total Loss is: 1.7445377580708061\n",
      "NLL Loss is: 1.4096980533103656 1.423; test loss = 1.448\n",
      "Scaled KL Loss is: 0.03767499700188637\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4247680521111201\n",
      "NLL Loss is: 1.4649343282746223\n",
      "Scaled KL Loss is: 0.03555980697274208\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4791582512499837\n",
      "NLL Loss is: 1.4430209973791124\n",
      "Scaled KL Loss is: 0.03673285245895386\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.457714138362694\n",
      "NLL Loss is: 1.509298913513222\n",
      "Scaled KL Loss is: 0.0418107733130455\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5260232224659112\n",
      "NLL Loss is: 1.4330266590123577\n",
      "Scaled KL Loss is: 0.03250513970851898\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4460287147095008\n",
      "NLL Loss is: 1.486852137942951\n",
      "Scaled KL Loss is: 0.03701905161142349\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5016597589600493\n",
      "NLL Loss is: 1.4605593519341864\n",
      "Scaled KL Loss is: 0.031669504940509796\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4732271540966548\n",
      "NLL Loss is: 1.3559691389592121\n",
      "Scaled KL Loss is: 0.035485029220581055\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3701631506474445\n",
      "NLL Loss is: 1.4252202153891014\n",
      "Scaled KL Loss is: 0.03463918715715408\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.439075890624492\n",
      "NLL Loss is: 1.3404772208760634\n",
      "Scaled KL Loss is: 0.03900282457470894\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.356078351078476\n",
      "NLL Loss is: 1.347830917582485\n",
      "Scaled KL Loss is: 0.03754120320081711\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3628473988628118\n",
      "NLL Loss is: 1.4688470253442814\n",
      "Scaled KL Loss is: 0.034176405519247055\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4825175881107737\n",
      "NLL Loss is: 1.3567365164588867\n",
      "Scaled KL Loss is: 0.036812230944633484\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3714614090230046\n",
      "NLL Loss is: 1.5617398059078216\n",
      "Scaled KL Loss is: 0.03699235990643501\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5765367502429246\n",
      "NLL Loss is: 1.3580163861032803\n",
      "Scaled KL Loss is: 0.03745889663696289\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3729999451305945\n",
      "NLL Loss is: 1.5331527391306872\n",
      "Scaled KL Loss is: 0.034501660615205765\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.546953403935563\n",
      "NLL Loss is: 1.4766819991996727\n",
      "Scaled KL Loss is: 0.03175576031208038\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4893843031382403\n",
      "NLL Loss is: 1.3820951119323899\n",
      "Scaled KL Loss is: 0.03645169734954834\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3966757910584737\n",
      "NLL Loss is: 1.329883410775965\n",
      "Scaled KL Loss is: 0.03483051434159279\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.343815616512602\n",
      "NLL Loss is: 1.4047360728675125\n",
      "Scaled KL Loss is: 0.032089002430438995\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.417571674212217\n",
      "NLL Loss is: 1.4348282756175967\n",
      "Scaled KL Loss is: 0.03788411617279053\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.449981922086713\n",
      "NLL Loss is: 1.4641895877426798\n",
      "Scaled KL Loss is: 0.03145458921790123\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4767714232435758\n",
      "NLL Loss is: 1.3582462860154092\n",
      "Scaled KL Loss is: 0.03200399875640869\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3710478857042372\n",
      "NLL Loss is: 1.5883687458695734\n",
      "Scaled KL Loss is: 0.03824087232351303\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.6036650951715077\n",
      "NLL Loss is: 1.227037009313502\n",
      "Scaled KL Loss is: 0.035673487931489944\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.2413064050448914\n",
      "NLL Loss is: 1.3694950909841281\n",
      "Scaled KL Loss is: 0.037869248539209366\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3846427909586054\n",
      "NLL Loss is: 1.4305450142976373\n",
      "Scaled KL Loss is: 0.03768116980791092\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.445617482034537\n",
      "NLL Loss is: 1.2469134597558769\n",
      "Scaled KL Loss is: 0.03510338440537453\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.2609548137042912\n",
      "NLL Loss is: 1.4025046406982102\n",
      "Scaled KL Loss is: 0.03639007359743118\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4170606705097117\n",
      "NLL Loss is: 1.2724089922779322\n",
      "Scaled KL Loss is: 0.037089958786964417\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.287244975792718\n",
      "NLL Loss is: 1.2778387201871582\n",
      "Scaled KL Loss is: 0.03550941124558449\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.292042484685392\n",
      "NLL Loss is: 1.4533142080336217\n",
      "Scaled KL Loss is: 0.03687382489442825\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4680637378051284\n",
      "NLL Loss is: 1.4500788342577926\n",
      "Scaled KL Loss is: 0.03684541955590248\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.464817001893889\n",
      "NLL Loss is: 1.3310503179324042\n",
      "Scaled KL Loss is: 0.03669364005327225\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3457277745125067\n",
      "NLL Loss is: 1.5260721388132759\n",
      "Scaled KL Loss is: 0.03562507778406143\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.540322170485694\n",
      "NLL Loss is: 1.5433843196123687\n",
      "Scaled KL Loss is: 0.0377366878092289\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5584789947360602\n",
      "NLL Loss is: 1.3223587342695418\n",
      "Scaled KL Loss is: 0.04161764681339264\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3390057937399569\n",
      "NLL Loss is: 1.2915163556156957\n",
      "Scaled KL Loss is: 0.0362708605825901\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3060246998487317\n",
      "NLL Loss is: 1.4624636992230533\n",
      "Scaled KL Loss is: 0.03690218925476074\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4772245752974866\n",
      "NLL Loss is: 1.5361330850952961\n",
      "Scaled KL Loss is: 0.03901832550764084\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.551740415112088\n",
      "NLL Loss is: 1.3404622347053528\n",
      "Scaled KL Loss is: 0.03940875828266144\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3562257391360044\n",
      "NLL Loss is: 1.3282030387341437\n",
      "Scaled KL Loss is: 0.034643881022930145\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3420605915158448\n",
      "NLL Loss is: 1.3375463854185674\n",
      "Scaled KL Loss is: 0.03550533577799797\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3517485201022956\n",
      "NLL Loss is: 1.3529377497971848\n",
      "Scaled KL Loss is: 0.04477947577834129\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3708495397359923\n",
      "NLL Loss is: 1.4138827743917335\n",
      "Scaled KL Loss is: 0.037223439663648605\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.428772150629722\n",
      "NLL Loss is: 1.3290226518897492\n",
      "Scaled KL Loss is: 0.03780995309352875\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3441466329408962\n",
      "NLL Loss is: 1.3442303131558078\n",
      "Scaled KL Loss is: 0.0400669127702713\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3602570782639163\n",
      "NLL Loss is: 1.2863991731308149\n",
      "Scaled KL Loss is: 0.03682553768157959\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3011293882034467\n",
      "NLL Loss is: 1.3541344355311742\n",
      "Scaled KL Loss is: 0.04074998199939728\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.370434428330933\n",
      "NLL Loss is: 1.3353391320857688\n",
      "Scaled KL Loss is: 0.03843278810381889\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.350712247513561\n",
      "NLL Loss is: 1.4041481510459397\n",
      "Scaled KL Loss is: 0.03856373205780983\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4195736440553282\n",
      "NLL Loss is: 1.3882933123353354\n",
      "Scaled KL Loss is: 0.038367461413145065\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4036402967143289\n",
      "NLL Loss is: 1.3121151215512759\n",
      "Scaled KL Loss is: 0.042142804712057114\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3289722445536858\n",
      "NLL Loss is: 1.4193464531631392\n",
      "Scaled KL Loss is: 0.03448783606290817\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.433141587774567\n",
      "NLL Loss is: 1.4481588093745859\n",
      "Scaled KL Loss is: 0.036143526434898376\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4626162205073387\n",
      "NLL Loss is: 1.4808340133669557\n",
      "Scaled KL Loss is: 0.035188473761081696\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.494909403430182\n",
      "NLL Loss is: 1.4725821056575938\n",
      "Scaled KL Loss is: 0.04014033079147339\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4886382390917703\n",
      "NLL Loss is: 1.3501078136125222\n",
      "Scaled KL Loss is: 0.040241844952106476\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3662045527109519\n",
      "NLL Loss is: 1.3227233431363437\n",
      "Scaled KL Loss is: 0.034736331552267075\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.336617875943515\n",
      "NLL Loss is: 1.2817864056021275\n",
      "Scaled KL Loss is: 0.04295121133327484\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.2989668912530246\n",
      "NLL Loss is: 1.370612678586842\n",
      "Scaled KL Loss is: 0.03782673925161362\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.385743374473752\n",
      "NLL Loss is: 1.4143516908361675\n",
      "Scaled KL Loss is: 0.040292076766490936\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.430468522287822\n",
      "NLL Loss is: 1.4704846261155173\n",
      "Scaled KL Loss is: 0.039222005754709244\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.486173429162459\n",
      "NLL Loss is: 1.3584031760857078\n",
      "Scaled KL Loss is: 0.03548956662416458\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3725990029216382\n",
      "NLL Loss is: 1.3966745541599213\n",
      "Scaled KL Loss is: 0.03706889599561691\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.411502112930697\n",
      "NLL Loss is: 1.4495861069752898\n",
      "Scaled KL Loss is: 0.03731902688741684\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4645137177302565\n",
      "NLL Loss is: 1.4628879906648142\n",
      "Scaled KL Loss is: 0.0370652861893177\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4777141049542768\n",
      "NLL Loss is: 1.4302449531471828\n",
      "Scaled KL Loss is: 0.04000650346279144\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4462475541597704\n",
      "NLL Loss is: 1.3944796140661833\n",
      "Scaled KL Loss is: 0.04273506626486778\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4115736413171884\n",
      "NLL Loss is: 1.3777984166105772\n",
      "Scaled KL Loss is: 0.038343340158462524\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3931357524876977\n",
      "NLL Loss is: 1.5224338132609017\n",
      "Scaled KL Loss is: 0.039649926126003265\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.538293784083832\n",
      "NLL Loss is: 1.4191966777256178\n",
      "Scaled KL Loss is: 0.03625253215432167\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4336976905873464\n",
      "NLL Loss is: 1.4502887863833354\n",
      "Scaled KL Loss is: 0.041475873440504074\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.466879135759537\n",
      "NLL Loss is: 1.3949112624636357\n",
      "Scaled KL Loss is: 0.038331855088472366\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4102440050578182\n",
      "NLL Loss is: 1.4859081248358068\n",
      "Scaled KL Loss is: 0.037580911070108414\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5009404898226437\n",
      "NLL Loss is: 1.33562227701724\n",
      "Scaled KL Loss is: 0.036325063556432724\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.350152302439813\n",
      "NLL Loss is: 1.4980178905253791\n",
      "Scaled KL Loss is: 0.040248189121484756\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.514117166546502\n",
      "NLL Loss is: 1.4613250257805115\n",
      "Scaled KL Loss is: 0.0356423482298851\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4755819650724655\n",
      "NLL Loss is: 1.3787638621669016\n",
      "Scaled KL Loss is: 0.04373280331492424\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3962569834928713\n",
      "NLL Loss is: 1.357698619890041\n",
      "Scaled KL Loss is: 0.04049265757203102\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3738956829188533\n",
      "NLL Loss is: 1.4350285219794392\n",
      "Scaled KL Loss is: 0.03779052570462227\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4501447320750236\n",
      "NLL Loss is: 1.3347905672287377\n",
      "Scaled KL Loss is: 0.041167426854372025\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3512575387155445\n",
      "NLL Loss is: 1.400190842568529\n",
      "Scaled KL Loss is: 0.03656703978776932\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4148176584836367\n",
      "NLL Loss is: 1.3558664125021682\n",
      "Scaled KL Loss is: 0.04143804311752319\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3724416297491775\n",
      "NLL Loss is: 1.5049786739476028\n",
      "Scaled KL Loss is: 0.04138241335749626\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5215316400356593\n",
      "NLL Loss is: 1.5200732946261064\n",
      "Scaled KL Loss is: 0.032577238976955414\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.5331041905894176\n",
      "NLL Loss is: 1.4638405615645511\n",
      "Scaled KL Loss is: 0.035928718745708466\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.47821204887657\n",
      "NLL Loss is: 1.3854258054424222\n",
      "Scaled KL Loss is: 0.041334353387355804\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4019595471698936\n",
      "NLL Loss is: 1.29821702207043\n",
      "Scaled KL Loss is: 0.036887213587760925\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.3129719078780635\n",
      "NLL Loss is: 1.4707875370681245\n",
      "Scaled KL Loss is: 0.03579790145158768\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4851066980212886\n",
      "NLL Loss is: 1.394487468834274\n",
      "Scaled KL Loss is: 0.03650775924324989\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.4090905723453095\n",
      "NLL Loss is: 1.7331894120000997\n",
      "Scaled KL Loss is: 0.029557062312960625\n",
      "Annealing coefficient is: 0.4\n",
      "Total Loss is: 1.745012237297813\n",
      "NLL Loss is: 1.4027282732178663 1.417; test loss = 1.447\n",
      "Scaled KL Loss is: 0.040400512516498566\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4229285294761156\n",
      "NLL Loss is: 1.4564443366853\n",
      "Scaled KL Loss is: 0.038123439997434616\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4755060566840172\n",
      "NLL Loss is: 1.4346236460863833\n",
      "Scaled KL Loss is: 0.039347775280475616\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.454297533726621\n",
      "NLL Loss is: 1.5068659000892148\n",
      "Scaled KL Loss is: 0.04456571489572525\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5291487575370775\n",
      "NLL Loss is: 1.4235610984620815\n",
      "Scaled KL Loss is: 0.03495051711797714\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.44103635702107\n",
      "NLL Loss is: 1.485721204306509\n",
      "Scaled KL Loss is: 0.039626866579055786\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5055346375960368\n",
      "NLL Loss is: 1.4524811643524789\n",
      "Scaled KL Loss is: 0.034052781760692596\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4695075552328252\n",
      "NLL Loss is: 1.3499539864717591\n",
      "Scaled KL Loss is: 0.03790662810206413\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3689073005227912\n",
      "NLL Loss is: 1.4208840818963244\n",
      "Scaled KL Loss is: 0.03708313778042793\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4394256507865384\n",
      "NLL Loss is: 1.3326431187625776\n",
      "Scaled KL Loss is: 0.041647061705589294\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3534666496153722\n",
      "NLL Loss is: 1.3379987261609907\n",
      "Scaled KL Loss is: 0.04001793637871742\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3580076943503494\n",
      "NLL Loss is: 1.4608802104503362\n",
      "Scaled KL Loss is: 0.03662221506237984\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4791913179815261\n",
      "NLL Loss is: 1.3483603873237626\n",
      "Scaled KL Loss is: 0.03941761329770088\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.368069193972613\n",
      "NLL Loss is: 1.5563660473678635\n",
      "Scaled KL Loss is: 0.03942953422665596\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5760808144811915\n",
      "NLL Loss is: 1.344515513239048\n",
      "Scaled KL Loss is: 0.03991108387708664\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3644710551775914\n",
      "NLL Loss is: 1.5219709191029103\n",
      "Scaled KL Loss is: 0.0369768850505352\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5404593616281779\n",
      "NLL Loss is: 1.4694573836002878\n",
      "Scaled KL Loss is: 0.03409090265631676\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4865028349284461\n",
      "NLL Loss is: 1.3751002359838231\n",
      "Scaled KL Loss is: 0.038901157677173615\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.39455081482241\n",
      "NLL Loss is: 1.3224889177696946\n",
      "Scaled KL Loss is: 0.03716127946972847\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3410695575045588\n",
      "NLL Loss is: 1.3985776987859504\n",
      "Scaled KL Loss is: 0.03439469262957573\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4157750451007383\n",
      "NLL Loss is: 1.4300975195540915\n",
      "Scaled KL Loss is: 0.040233269333839417\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4502141542210112\n",
      "NLL Loss is: 1.457277539391876\n",
      "Scaled KL Loss is: 0.033706869930028915\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4741309743568904\n",
      "NLL Loss is: 1.3498052748243174\n",
      "Scaled KL Loss is: 0.03430331498384476\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3669569323162398\n",
      "NLL Loss is: 1.5841116158693467\n",
      "Scaled KL Loss is: 0.04066307470202446\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.604443153220359\n",
      "NLL Loss is: 1.216777485593897\n",
      "Scaled KL Loss is: 0.038042645901441574\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2357988085446179\n",
      "NLL Loss is: 1.363917527167686\n",
      "Scaled KL Loss is: 0.04031326249241829\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3840741584138951\n",
      "NLL Loss is: 1.4239127579531219\n",
      "Scaled KL Loss is: 0.04009559005498886\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4439605529806163\n",
      "NLL Loss is: 1.2389480393619632\n",
      "Scaled KL Loss is: 0.037450551986694336\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2576733153553104\n",
      "NLL Loss is: 1.3960109273335075\n",
      "Scaled KL Loss is: 0.03870221599936485\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.41536203533319\n",
      "NLL Loss is: 1.2610801404835303\n",
      "Scaled KL Loss is: 0.03938981890678406\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2807750499369224\n",
      "NLL Loss is: 1.2680999281815493\n",
      "Scaled KL Loss is: 0.037703659385442734\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2869517578742706\n",
      "NLL Loss is: 1.4438882879882957\n",
      "Scaled KL Loss is: 0.03910364955663681\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4634401127666141\n",
      "NLL Loss is: 1.4452503060468365\n",
      "Scaled KL Loss is: 0.039041876792907715\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4647712444432903\n",
      "NLL Loss is: 1.327390975272999\n",
      "Scaled KL Loss is: 0.038880959153175354\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3468314548495868\n",
      "NLL Loss is: 1.522235726274226\n",
      "Scaled KL Loss is: 0.037757404148578644\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5411144283485154\n",
      "NLL Loss is: 1.541125826098\n",
      "Scaled KL Loss is: 0.039927806705236435\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5610897294506183\n",
      "NLL Loss is: 1.316263402759747\n",
      "Scaled KL Loss is: 0.04402167350053787\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.338274239510016\n",
      "NLL Loss is: 1.2830231380434183\n",
      "Scaled KL Loss is: 0.03852006047964096\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3022831682832388\n",
      "NLL Loss is: 1.4534665864032095\n",
      "Scaled KL Loss is: 0.03909330442547798\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4730132386159485\n",
      "NLL Loss is: 1.5333770462058096\n",
      "Scaled KL Loss is: 0.04120582342147827\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5539799579165487\n",
      "NLL Loss is: 1.3349353361854377\n",
      "Scaled KL Loss is: 0.04163490608334541\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3557527892271104\n",
      "NLL Loss is: 1.3204354224240342\n",
      "Scaled KL Loss is: 0.03668466582894325\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3387777553385058\n",
      "NLL Loss is: 1.32847016234367\n",
      "Scaled KL Loss is: 0.03765608370304108\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3472982041951906\n",
      "NLL Loss is: 1.3417954640590912\n",
      "Scaled KL Loss is: 0.04712232947349548\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.365356628795839\n",
      "NLL Loss is: 1.4088605402910692\n",
      "Scaled KL Loss is: 0.039258409291505814\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4284897449368221\n",
      "NLL Loss is: 1.3222559142606738\n",
      "Scaled KL Loss is: 0.0400024838745594\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3422571561979535\n",
      "NLL Loss is: 1.3359557338702956\n",
      "Scaled KL Loss is: 0.04226696863770485\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.357089218189148\n",
      "NLL Loss is: 1.2755531934204654\n",
      "Scaled KL Loss is: 0.03907093405723572\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2950886604490832\n",
      "NLL Loss is: 1.3500632209262589\n",
      "Scaled KL Loss is: 0.04294808208942413\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.371537261970971\n",
      "NLL Loss is: 1.3269173233488878\n",
      "Scaled KL Loss is: 0.040522851049900055\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3471787488738378\n",
      "NLL Loss is: 1.3947462390272136\n",
      "Scaled KL Loss is: 0.0407058522105217\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4150991651324745\n",
      "NLL Loss is: 1.3882167181615863\n",
      "Scaled KL Loss is: 0.04039200395345688\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4084127201383148\n",
      "NLL Loss is: 1.3057570467243627\n",
      "Scaled KL Loss is: 0.04427278786897659\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.327893440658851\n",
      "NLL Loss is: 1.414117751388541\n",
      "Scaled KL Loss is: 0.03644488379359245\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4323401932853372\n",
      "NLL Loss is: 1.4400101307822768\n",
      "Scaled KL Loss is: 0.03809618949890137\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4590582255317275\n",
      "NLL Loss is: 1.474234957167734\n",
      "Scaled KL Loss is: 0.037103455513715744\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4927866849245919\n",
      "NLL Loss is: 1.4693704831477195\n",
      "Scaled KL Loss is: 0.042180098593235016\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.490460532444337\n",
      "NLL Loss is: 1.3428291049180985\n",
      "Scaled KL Loss is: 0.04222780466079712\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.363943007248497\n",
      "NLL Loss is: 1.3138479945554449\n",
      "Scaled KL Loss is: 0.03664124384522438\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.332168616478057\n",
      "NLL Loss is: 1.2754964124643353\n",
      "Scaled KL Loss is: 0.04501822218298912\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.2980055235558299\n",
      "NLL Loss is: 1.365190379507777\n",
      "Scaled KL Loss is: 0.03981773182749748\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3850992454215258\n",
      "NLL Loss is: 1.408542097149524\n",
      "Scaled KL Loss is: 0.042215537279844284\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.429649865789446\n",
      "NLL Loss is: 1.4628906305134064\n",
      "Scaled KL Loss is: 0.041095443069934845\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4834383520483738\n",
      "NLL Loss is: 1.3511008435191638\n",
      "Scaled KL Loss is: 0.0374118834733963\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.369806785255862\n",
      "NLL Loss is: 1.3889942870405383\n",
      "Scaled KL Loss is: 0.038909152150154114\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4084488631156153\n",
      "NLL Loss is: 1.442623289461871\n",
      "Scaled KL Loss is: 0.03920097276568413\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.462223775844713\n",
      "NLL Loss is: 1.458202477366875\n",
      "Scaled KL Loss is: 0.03890277445316315\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4776538645934565\n",
      "NLL Loss is: 1.4241743044914392\n",
      "Scaled KL Loss is: 0.04184078052639961\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.445094694754639\n",
      "NLL Loss is: 1.3903393496672118\n",
      "Scaled KL Loss is: 0.044670529663562775\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4126746144989932\n",
      "NLL Loss is: 1.371615102073001\n",
      "Scaled KL Loss is: 0.04016566649079323\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3916979353183976\n",
      "NLL Loss is: 1.5187932555900034\n",
      "Scaled KL Loss is: 0.04149281233549118\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.539539661757749\n",
      "NLL Loss is: 1.4145037670735103\n",
      "Scaled KL Loss is: 0.03799765184521675\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4335025929961187\n",
      "NLL Loss is: 1.4464855479718526\n",
      "Scaled KL Loss is: 0.04339218884706497\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.468181642395385\n",
      "NLL Loss is: 1.3888329050662866\n",
      "Scaled KL Loss is: 0.04015810415148735\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4089119571420303\n",
      "NLL Loss is: 1.4863694507575744\n",
      "Scaled KL Loss is: 0.03939628601074219\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5060675937629455\n",
      "NLL Loss is: 1.3330455937069585\n",
      "Scaled KL Loss is: 0.03802204504609108\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.352056616230004\n",
      "NLL Loss is: 1.4965580096820004\n",
      "Scaled KL Loss is: 0.04196147993206978\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5175387496480353\n",
      "NLL Loss is: 1.4575434541208403\n",
      "Scaled KL Loss is: 0.037403009831905365\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.476244959036793\n",
      "NLL Loss is: 1.3743772681780526\n",
      "Scaled KL Loss is: 0.045518167316913605\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3971363518365094\n",
      "NLL Loss is: 1.3533186624141809\n",
      "Scaled KL Loss is: 0.0422627255320549\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3744500251802083\n",
      "NLL Loss is: 1.4323953144257433\n",
      "Scaled KL Loss is: 0.039521459490060806\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4521560441707737\n",
      "NLL Loss is: 1.331018298561933\n",
      "Scaled KL Loss is: 0.04302679002285004\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.352531693573358\n",
      "NLL Loss is: 1.3957879959908077\n",
      "Scaled KL Loss is: 0.038235340267419815\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4149056661245176\n",
      "NLL Loss is: 1.3531396649529739\n",
      "Scaled KL Loss is: 0.043308500200510025\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.374793915053229\n",
      "NLL Loss is: 1.5014688544757786\n",
      "Scaled KL Loss is: 0.04317428544163704\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5230559971965971\n",
      "NLL Loss is: 1.515893833238277\n",
      "Scaled KL Loss is: 0.03431679308414459\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.5330522297803493\n",
      "NLL Loss is: 1.4588832279795423\n",
      "Scaled KL Loss is: 0.037559930235147476\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.477663193097116\n",
      "NLL Loss is: 1.3829799099384235\n",
      "Scaled KL Loss is: 0.04320254176855087\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.404581180822699\n",
      "NLL Loss is: 1.2942227624072566\n",
      "Scaled KL Loss is: 0.03863971680402756\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.3135426208092704\n",
      "NLL Loss is: 1.4653305429583627\n",
      "Scaled KL Loss is: 0.03757543861865997\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4841182622676927\n",
      "NLL Loss is: 1.3916232677277136\n",
      "Scaled KL Loss is: 0.038314204663038254\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.4107803700592327\n",
      "NLL Loss is: 1.7309904447249995\n",
      "Scaled KL Loss is: 0.031087497249245644\n",
      "Annealing coefficient is: 0.5\n",
      "Total Loss is: 1.7465341933496223\n",
      "NLL Loss is: 1.3977126635301675 1.415; test loss = 1.448\n",
      "Scaled KL Loss is: 0.04224454239010811\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4230593897092905\n",
      "NLL Loss is: 1.4503388038700717\n",
      "Scaled KL Loss is: 0.03984351083636284\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4742449118620056\n",
      "NLL Loss is: 1.4290598344452592\n",
      "Scaled KL Loss is: 0.0411083921790123\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4537248716153117\n",
      "NLL Loss is: 1.5045785575281905\n",
      "Scaled KL Loss is: 0.04637947306036949\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5324062432270573\n",
      "NLL Loss is: 1.416935931682902\n",
      "Scaled KL Loss is: 0.03660053759813309\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.438896255359369\n",
      "NLL Loss is: 1.4843928840263527\n",
      "Scaled KL Loss is: 0.04139230027794838\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5092282656832379\n",
      "NLL Loss is: 1.4469566688865678\n",
      "Scaled KL Loss is: 0.03566354513168335\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4683547959655778\n",
      "NLL Loss is: 1.3461199367808447\n",
      "Scaled KL Loss is: 0.03950425237417221\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3698224893229352\n",
      "NLL Loss is: 1.4180094407626012\n",
      "Scaled KL Loss is: 0.03869626298546791\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.441227198926411\n",
      "NLL Loss is: 1.327429160831569\n",
      "Scaled KL Loss is: 0.04341255500912666\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.353476694209574\n",
      "NLL Loss is: 1.3312873934722065\n",
      "Scaled KL Loss is: 0.04161279276013374\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3562550695008158\n",
      "NLL Loss is: 1.4552568288626104\n",
      "Scaled KL Loss is: 0.038280874490737915\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4782253539295822\n",
      "NLL Loss is: 1.3425674167273138\n",
      "Scaled KL Loss is: 0.041187770664691925\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.367280079871187\n",
      "NLL Loss is: 1.5524600561236286\n",
      "Scaled KL Loss is: 0.0410604290664196\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5770963154261255\n",
      "NLL Loss is: 1.3352156139124034\n",
      "Scaled KL Loss is: 0.04151308536529541\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3601234655041097\n",
      "NLL Loss is: 1.5141103379048673\n",
      "Scaled KL Loss is: 0.038684580475091934\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5373210869349805\n",
      "NLL Loss is: 1.4642302273220138\n",
      "Scaled KL Loss is: 0.035702623426914215\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4856518013781623\n",
      "NLL Loss is: 1.3702084510721764\n",
      "Scaled KL Loss is: 0.04053674638271332\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3945305007644495\n",
      "NLL Loss is: 1.3174102043857232\n",
      "Scaled KL Loss is: 0.038727954030036926\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3406469782938615\n",
      "NLL Loss is: 1.3944760269898557\n",
      "Scaled KL Loss is: 0.035961706191301346\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4160530518222236\n",
      "NLL Loss is: 1.426258836312614\n",
      "Scaled KL Loss is: 0.04176320880651474\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.451316763086639\n",
      "NLL Loss is: 1.451926453490244\n",
      "Scaled KL Loss is: 0.035243865102529526\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4730727732968198\n",
      "NLL Loss is: 1.3439873700531302\n",
      "Scaled KL Loss is: 0.035871125757694244\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3655100466253338\n",
      "NLL Loss is: 1.5811389881778721\n",
      "Scaled KL Loss is: 0.0422745980322361\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.60650374848733\n",
      "NLL Loss is: 1.2100202148973107\n",
      "Scaled KL Loss is: 0.03961512818932533\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.233789293673551\n",
      "NLL Loss is: 1.3597554610359055\n",
      "Scaled KL Loss is: 0.04196247085928917\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3849329454141242\n",
      "NLL Loss is: 1.4191525877444962\n",
      "Scaled KL Loss is: 0.041737932711839676\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.444195348861716\n",
      "NLL Loss is: 1.2332325972608194\n",
      "Scaled KL Loss is: 0.03905494511127472\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.2566655654451713\n",
      "NLL Loss is: 1.3912861050170073\n",
      "Scaled KL Loss is: 0.04024657607078552\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4154340514045367\n",
      "NLL Loss is: 1.2530776080159247\n",
      "Scaled KL Loss is: 0.04091554507613182\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.2776269358066619\n",
      "NLL Loss is: 1.261113429079815\n",
      "Scaled KL Loss is: 0.039129626005887985\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.2845912050558768\n",
      "NLL Loss is: 1.436685423297\n",
      "Scaled KL Loss is: 0.04057393968105316\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.461029787478161\n",
      "NLL Loss is: 1.441227529091551\n",
      "Scaled KL Loss is: 0.04045965149998665\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4655033218541882\n",
      "NLL Loss is: 1.3244950275783638\n",
      "Scaled KL Loss is: 0.04030197486281395\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3486762128685812\n",
      "NLL Loss is: 1.5190533197265899\n",
      "Scaled KL Loss is: 0.03916630521416664\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.542553104717735\n",
      "NLL Loss is: 1.5389841694470716\n",
      "Scaled KL Loss is: 0.041332367807626724\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5637835908767057\n",
      "NLL Loss is: 1.3119255886223238\n",
      "Scaled KL Loss is: 0.04561156779527664\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3392925304170769\n",
      "NLL Loss is: 1.2770646876319929\n",
      "Scaled KL Loss is: 0.04003181681036949\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3010837780907436\n",
      "NLL Loss is: 1.4468307440469548\n",
      "Scaled KL Loss is: 0.04052700102329254\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4711469450334593\n",
      "NLL Loss is: 1.531159311921683\n",
      "Scaled KL Loss is: 0.04261542856693268\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5567285701794298\n",
      "NLL Loss is: 1.330075004822916\n",
      "Scaled KL Loss is: 0.04306754469871521\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3559155331322612\n",
      "NLL Loss is: 1.3144669504331674\n",
      "Scaled KL Loss is: 0.037998784333467484\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.337266222523364\n",
      "NLL Loss is: 1.32195112104097\n",
      "Scaled KL Loss is: 0.03909534588456154\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.345408329689294\n",
      "NLL Loss is: 1.3335126832653865\n",
      "Scaled KL Loss is: 0.048638422042131424\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3626957376082525\n",
      "NLL Loss is: 1.404985985302983\n",
      "Scaled KL Loss is: 0.04055304080247879\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4293178101569992\n",
      "NLL Loss is: 1.3173303120737305\n",
      "Scaled KL Loss is: 0.041441500186920166\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3421952129309407\n",
      "NLL Loss is: 1.3301914693208172\n",
      "Scaled KL Loss is: 0.043700847774744034\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3564119791032507\n",
      "NLL Loss is: 1.267555176812954\n",
      "Scaled KL Loss is: 0.0406000092625618\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.2919151834880782\n",
      "NLL Loss is: 1.3468692021205309\n",
      "Scaled KL Loss is: 0.044360578060150146\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.373485550074208\n",
      "NLL Loss is: 1.3205783621762557\n",
      "Scaled KL Loss is: 0.04187935218214989\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3457059742306037\n",
      "NLL Loss is: 1.3879445311039649\n",
      "Scaled KL Loss is: 0.04210960119962692\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4132102936863862\n",
      "NLL Loss is: 1.3878411594201139\n",
      "Scaled KL Loss is: 0.04167517274618149\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4128462634403518\n",
      "NLL Loss is: 1.3008082904461884\n",
      "Scaled KL Loss is: 0.045615050941705704\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.328177322128799\n",
      "NLL Loss is: 1.4103396742980043\n",
      "Scaled KL Loss is: 0.037732817232608795\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4329793661276857\n",
      "NLL Loss is: 1.4336614073321199\n",
      "Scaled KL Loss is: 0.0393528938293457\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4572731447473144\n",
      "NLL Loss is: 1.4690506400553391\n",
      "Scaled KL Loss is: 0.038331594318151474\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.492049597018759\n",
      "NLL Loss is: 1.4667113879227573\n",
      "Scaled KL Loss is: 0.04348099231719971\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4927999851757223\n",
      "NLL Loss is: 1.3378243148725877\n",
      "Scaled KL Loss is: 0.04346205294132233\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3639015481274972\n",
      "NLL Loss is: 1.3078629929615804\n",
      "Scaled KL Loss is: 0.03786658123135567\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3305829424454518\n",
      "NLL Loss is: 1.2705528964556674\n",
      "Scaled KL Loss is: 0.046304523944854736\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.2983356123126963\n",
      "NLL Loss is: 1.3616374020739044\n",
      "Scaled KL Loss is: 0.04110049083828926\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.386297696949407\n",
      "NLL Loss is: 1.4041742584618615\n",
      "Scaled KL Loss is: 0.043414581567049026\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.430223008147149\n",
      "NLL Loss is: 1.4571096110133035\n",
      "Scaled KL Loss is: 0.04226544126868248\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.482468876519571\n",
      "NLL Loss is: 1.346140079650124\n",
      "Scaled KL Loss is: 0.03867418318986893\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3693445906816324\n",
      "NLL Loss is: 1.3833100804177985\n",
      "Scaled KL Loss is: 0.040063947439193726\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4073484492538437\n",
      "NLL Loss is: 1.4370631303616168\n",
      "Scaled KL Loss is: 0.04039771109819412\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4613017577655913\n",
      "NLL Loss is: 1.45466209872038\n",
      "Scaled KL Loss is: 0.04008535295724869\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4787133123573744\n",
      "NLL Loss is: 1.4195734082941738\n",
      "Scaled KL Loss is: 0.042970046401023865\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4453554365073171\n",
      "NLL Loss is: 1.387071496319368\n",
      "Scaled KL Loss is: 0.04587023705244064\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4145936392958904\n",
      "NLL Loss is: 1.3668336258445108\n",
      "Scaled KL Loss is: 0.041311588138341904\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3916205805901611\n",
      "NLL Loss is: 1.5155953161522762\n",
      "Scaled KL Loss is: 0.0426386334002018\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5411784976825134\n",
      "NLL Loss is: 1.4109670565221344\n",
      "Scaled KL Loss is: 0.03908413648605347\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4344175391588245\n",
      "NLL Loss is: 1.4430956893830589\n",
      "Scaled KL Loss is: 0.04459609463810921\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4698533469109825\n",
      "NLL Loss is: 1.3845763706046315\n",
      "Scaled KL Loss is: 0.04131326451897621\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4093643311786623\n",
      "NLL Loss is: 1.4862729921531164\n",
      "Scaled KL Loss is: 0.04053507745265961\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5105940397422992\n",
      "NLL Loss is: 1.3310271335706698\n",
      "Scaled KL Loss is: 0.03906429931521416\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3544657139048564\n",
      "NLL Loss is: 1.4950734475995102\n",
      "Scaled KL Loss is: 0.042979028075933456\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5208608663077154\n",
      "NLL Loss is: 1.4545680565026335\n",
      "Scaled KL Loss is: 0.038524080067873\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4776825049158864\n",
      "NLL Loss is: 1.371177899324261\n",
      "Scaled KL Loss is: 0.0465521514415741\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3991091909342634\n",
      "NLL Loss is: 1.3498571298127624\n",
      "Scaled KL Loss is: 0.04330044984817505\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3758374012117836\n",
      "NLL Loss is: 1.4301095567575135\n",
      "Scaled KL Loss is: 0.04058801382780075\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.454462366171781\n",
      "NLL Loss is: 1.3277077382148972\n",
      "Scaled KL Loss is: 0.04416858032345772\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3542088871540299\n",
      "NLL Loss is: 1.3926052222822634\n",
      "Scaled KL Loss is: 0.03924604132771492\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4161528474514213\n",
      "NLL Loss is: 1.350310857398927\n",
      "Scaled KL Loss is: 0.04446412995457649\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.376989335744202\n",
      "NLL Loss is: 1.4979392417408153\n",
      "Scaled KL Loss is: 0.044261302798986435\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.5244960241652652\n",
      "NLL Loss is: 1.512574520673584\n",
      "Scaled KL Loss is: 0.03546019271016121\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.533850637044739\n",
      "NLL Loss is: 1.4549673392236477\n",
      "Scaled KL Loss is: 0.03856654837727547\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.478107268622542\n",
      "NLL Loss is: 1.3806622231205645\n",
      "Scaled KL Loss is: 0.044352125376462936\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4072734990915003\n",
      "NLL Loss is: 1.2914768906056695\n",
      "Scaled KL Loss is: 0.039721615612506866\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.3153098618358188\n",
      "NLL Loss is: 1.4616526771546905\n",
      "Scaled KL Loss is: 0.0387105830013752\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4848790277005737\n",
      "NLL Loss is: 1.389035471544182\n",
      "Scaled KL Loss is: 0.03947611153125763\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.4127211392079946\n",
      "NLL Loss is: 1.7291783572394517\n",
      "Scaled KL Loss is: 0.0320582278072834\n",
      "Annealing coefficient is: 0.6\n",
      "Total Loss is: 1.7484132939238217\n",
      "NLL Loss is: 1.3936630759284907 1.415; test loss = 1.450\n",
      "Scaled KL Loss is: 0.04339325428009033\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.424038353552025\n",
      "NLL Loss is: 1.4455875756691432\n",
      "Scaled KL Loss is: 0.040894489735364914\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4742137177388406\n",
      "NLL Loss is: 1.425172456170334\n",
      "Scaled KL Loss is: 0.042192645370960236\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4547073083025353\n",
      "NLL Loss is: 1.5019083996827276\n",
      "Scaled KL Loss is: 0.04744696989655495\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.535121277492729\n",
      "NLL Loss is: 1.411965639956244\n",
      "Scaled KL Loss is: 0.037616536021232605\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4382972155436358\n",
      "NLL Loss is: 1.4824740591160088\n",
      "Scaled KL Loss is: 0.04248917102813721\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5122164788357049\n",
      "NLL Loss is: 1.4429154540276392\n",
      "Scaled KL Loss is: 0.03665691614151001\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4685752945816382\n",
      "NLL Loss is: 1.343525902423025\n",
      "Scaled KL Loss is: 0.04044258967041969\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3718357151923188\n",
      "NLL Loss is: 1.4158297246095919\n",
      "Scaled KL Loss is: 0.03964487835764885\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.443581138714888\n",
      "NLL Loss is: 1.3237435333996899\n",
      "Scaled KL Loss is: 0.044476814568042755\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3548773024797327\n",
      "NLL Loss is: 1.3265154539965653\n",
      "Scaled KL Loss is: 0.042499344795942307\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.356264994608667\n",
      "NLL Loss is: 1.4510605703686088\n",
      "Scaled KL Loss is: 0.039308786392211914\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4785767212156862\n",
      "NLL Loss is: 1.3382311034568284\n",
      "Scaled KL Loss is: 0.042291849851608276\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3678353987254832\n",
      "NLL Loss is: 1.549385879553379\n",
      "Scaled KL Loss is: 0.04204435646533966\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5788169283340587\n",
      "NLL Loss is: 1.3286736403921264\n",
      "Scaled KL Loss is: 0.0424327589571476\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3583765720346588\n",
      "NLL Loss is: 1.508422647132533\n",
      "Scaled KL Loss is: 0.03978048637509346\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5362689872225694\n",
      "NLL Loss is: 1.4600574764522147\n",
      "Scaled KL Loss is: 0.03673261031508446\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4857703036727739\n",
      "NLL Loss is: 1.3666823229073435\n",
      "Scaled KL Loss is: 0.04151766747236252\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3957446890204102\n",
      "NLL Loss is: 1.3138676140399554\n",
      "Scaled KL Loss is: 0.03968112915754318\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3416444048227647\n",
      "NLL Loss is: 1.3915805705267708\n",
      "Scaled KL Loss is: 0.0369330458343029\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4174337014931957\n",
      "NLL Loss is: 1.4225351816402678\n",
      "Scaled KL Loss is: 0.042629092931747437\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.452375546692491\n",
      "NLL Loss is: 1.447348712294935\n",
      "Scaled KL Loss is: 0.03620315343141556\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4726909196969258\n",
      "NLL Loss is: 1.3397285995334534\n",
      "Scaled KL Loss is: 0.036845944821834564\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3655207605362085\n",
      "NLL Loss is: 1.5789820626524758\n",
      "Scaled KL Loss is: 0.043228376656770706\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.6092419251946282\n",
      "NLL Loss is: 1.2054880599223645\n",
      "Scaled KL Loss is: 0.040540896356105804\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.2338666862540515\n",
      "NLL Loss is: 1.356274171182815\n",
      "Scaled KL Loss is: 0.0429719015955925\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3863545026722588\n",
      "NLL Loss is: 1.4154337002977275\n",
      "Scaled KL Loss is: 0.0427582822740078\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.445364496771946\n",
      "NLL Loss is: 1.228685328535508\n",
      "Scaled KL Loss is: 0.0400618240237236\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.2567286042345274\n",
      "NLL Loss is: 1.3874928989709274\n",
      "Scaled KL Loss is: 0.0411723256111145\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4163135272712366\n",
      "NLL Loss is: 1.2472356476163258\n",
      "Scaled KL Loss is: 0.041813917458057404\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.276505389464437\n",
      "NLL Loss is: 1.25581577130537\n",
      "Scaled KL Loss is: 0.03993108496069908\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.2837675296602722\n",
      "NLL Loss is: 1.4308113467358965\n",
      "Scaled KL Loss is: 0.04142938554286957\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4598119158708471\n",
      "NLL Loss is: 1.4374617600167596\n",
      "Scaled KL Loss is: 0.041244443506002426\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4663328697259033\n",
      "NLL Loss is: 1.32180742134564\n",
      "Scaled KL Loss is: 0.041101470589637756\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3505784511309156\n",
      "NLL Loss is: 1.5159930653624776\n",
      "Scaled KL Loss is: 0.03999067842960358\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.543986539518142\n",
      "NLL Loss is: 1.536526241155489\n",
      "Scaled KL Loss is: 0.04210009053349495\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5659963049014645\n",
      "NLL Loss is: 1.3086231158202637\n",
      "Scaled KL Loss is: 0.04654660075902939\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.34120573411641\n",
      "NLL Loss is: 1.2727249527600037\n",
      "Scaled KL Loss is: 0.040948428213596344\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3013888525095212\n",
      "NLL Loss is: 1.441600281602631\n",
      "Scaled KL Loss is: 0.04134869575500488\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4705443678860763\n",
      "NLL Loss is: 1.529030052711821\n",
      "Scaled KL Loss is: 0.04339700564742088\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5594079566650156\n",
      "NLL Loss is: 1.3253710793864983\n",
      "Scaled KL Loss is: 0.043857887387275696\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3560716009301204\n",
      "NLL Loss is: 1.3095233390575236\n",
      "Scaled KL Loss is: 0.03872331231832504\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3366296576803511\n",
      "NLL Loss is: 1.316964495501593\n",
      "Scaled KL Loss is: 0.03995927423238754\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3449359867192061\n",
      "NLL Loss is: 1.3269658128038668\n",
      "Scaled KL Loss is: 0.04948912933468819\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3616082037106776\n",
      "NLL Loss is: 1.4016332130936484\n",
      "Scaled KL Loss is: 0.04124647378921509\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.430505744001041\n",
      "NLL Loss is: 1.3135946878115081\n",
      "Scaled KL Loss is: 0.042272184044122696\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.343185216269865\n",
      "NLL Loss is: 1.3260629061906508\n",
      "Scaled KL Loss is: 0.04451397806406021\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.357222690835493\n",
      "NLL Loss is: 1.2614085018955636\n",
      "Scaled KL Loss is: 0.04154946655035019\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.2904931284808088\n",
      "NLL Loss is: 1.3439843960345013\n",
      "Scaled KL Loss is: 0.04513297602534294\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3755774803698284\n",
      "NLL Loss is: 1.3154665256266553\n",
      "Scaled KL Loss is: 0.0426303893327713\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3453077977870662\n",
      "NLL Loss is: 1.3831632682589103\n",
      "Scaled KL Loss is: 0.04290701448917389\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.413198177283745\n",
      "NLL Loss is: 1.3864640517721454\n",
      "Scaled KL Loss is: 0.04234030097723007\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4161022620836774\n",
      "NLL Loss is: 1.297110690652961\n",
      "Scaled KL Loss is: 0.04630991816520691\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.329527634113664\n",
      "NLL Loss is: 1.4074451534607675\n",
      "Scaled KL Loss is: 0.038467030972242355\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4343720751413371\n",
      "NLL Loss is: 1.4314841281350204\n",
      "Scaled KL Loss is: 0.04003191739320755\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4595064695652076\n",
      "NLL Loss is: 1.4649795815598352\n",
      "Scaled KL Loss is: 0.03898509591817856\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4922691490750892\n",
      "NLL Loss is: 1.464763306111206\n",
      "Scaled KL Loss is: 0.044175028800964355\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.495685825154294\n",
      "NLL Loss is: 1.3333837986047028\n",
      "Scaled KL Loss is: 0.04406004026532173\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.364225827162957\n",
      "NLL Loss is: 1.3036006906375435\n",
      "Scaled KL Loss is: 0.03852670267224312\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3305693821355846\n",
      "NLL Loss is: 1.2661686544906012\n",
      "Scaled KL Loss is: 0.04693868011236191\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.2990257298241965\n",
      "NLL Loss is: 1.3576271102568125\n",
      "Scaled KL Loss is: 0.04180518910288811\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3868907426288342\n",
      "NLL Loss is: 1.4000829048891843\n",
      "Scaled KL Loss is: 0.04399509355425835\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4308794700046361\n",
      "NLL Loss is: 1.4533319548290617\n",
      "Scaled KL Loss is: 0.04284613952040672\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4833242521208174\n",
      "NLL Loss is: 1.3419870636915205\n",
      "Scaled KL Loss is: 0.039382584393024445\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3695548731391667\n",
      "NLL Loss is: 1.378946308914297\n",
      "Scaled KL Loss is: 0.040632765740156174\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4073892449324064\n",
      "NLL Loss is: 1.4341328520878036\n",
      "Scaled KL Loss is: 0.041016194969415665\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4628441878213365\n",
      "NLL Loss is: 1.4518099386818875\n",
      "Scaled KL Loss is: 0.04072738066315651\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.480319104773568\n",
      "NLL Loss is: 1.4156639360889047\n",
      "Scaled KL Loss is: 0.04350888729095459\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.446120156820044\n",
      "NLL Loss is: 1.3841513430053873\n",
      "Scaled KL Loss is: 0.046455901116132736\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4166704749042673\n",
      "NLL Loss is: 1.3630427668785656\n",
      "Scaled KL Loss is: 0.041881728917360306\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3923599763756598\n",
      "NLL Loss is: 1.5127710188897847\n",
      "Scaled KL Loss is: 0.04320073872804642\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5430115359994172\n",
      "NLL Loss is: 1.4079239338690346\n",
      "Scaled KL Loss is: 0.03961463272571564\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4356541771495646\n",
      "NLL Loss is: 1.439578874164485\n",
      "Scaled KL Loss is: 0.04520607367157936\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4712231253620616\n",
      "NLL Loss is: 1.3814706577909428\n",
      "Scaled KL Loss is: 0.04190811887383461\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.410806341002627\n",
      "NLL Loss is: 1.4854385723897028\n",
      "Scaled KL Loss is: 0.041106246411800385\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.514212943760376\n",
      "NLL Loss is: 1.3291389912484062\n",
      "Scaled KL Loss is: 0.039554253220558167\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3568269673852098\n",
      "NLL Loss is: 1.4934042138744195\n",
      "Scaled KL Loss is: 0.043410077691078186\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.523791267140587\n",
      "NLL Loss is: 1.4519317838497416\n",
      "Scaled KL Loss is: 0.03911121189594269\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4793096314318435\n",
      "NLL Loss is: 1.3689679217773583\n",
      "Scaled KL Loss is: 0.04695383831858635\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4018356067377236\n",
      "NLL Loss is: 1.34684659014307\n",
      "Scaled KL Loss is: 0.043720878660678864\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.377451204087958\n",
      "NLL Loss is: 1.4278279024211753\n",
      "Scaled KL Loss is: 0.04109611734747887\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4565951845644105\n",
      "NLL Loss is: 1.3244756345608713\n",
      "Scaled KL Loss is: 0.04470743238925934\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.3557708372333528\n",
      "NLL Loss is: 1.3900766064253458\n",
      "Scaled KL Loss is: 0.03970431908965111\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4178696301606306\n",
      "NLL Loss is: 1.3470638884892554\n",
      "Scaled KL Loss is: 0.045019831508398056\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.378577769427547\n",
      "NLL Loss is: 1.4941240767527881\n",
      "Scaled KL Loss is: 0.04475560039281845\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.525452997027761\n",
      "NLL Loss is: 1.5096947165791312\n",
      "Scaled KL Loss is: 0.03611118718981743\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.5349725472394744\n",
      "NLL Loss is: 1.4516825116383756\n",
      "Scaled KL Loss is: 0.0390457920730114\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4790145660894836\n",
      "NLL Loss is: 1.3780552358962541\n",
      "Scaled KL Loss is: 0.04489966854453087\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4094850035048967\n",
      "NLL Loss is: 1.2893475406432\n",
      "Scaled KL Loss is: 0.0402449406683445\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.317518997993454\n",
      "NLL Loss is: 1.4590620583773437\n",
      "Scaled KL Loss is: 0.03931516408920288\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4865826721221986\n",
      "NLL Loss is: 1.386354718749804\n",
      "Scaled KL Loss is: 0.04009779542684555\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.4144231755485959\n",
      "NLL Loss is: 1.7272567271420955\n",
      "Scaled KL Loss is: 0.03255682811141014\n",
      "Annealing coefficient is: 0.7\n",
      "Total Loss is: 1.7500465071926117\n",
      "NLL Loss is: 1.3900470324941614 1.416; test loss = 1.452\n",
      "Scaled KL Loss is: 0.04395837336778641\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4252137319334486\n",
      "NLL Loss is: 1.4416794478367936\n",
      "Scaled KL Loss is: 0.04138382896780968\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4747865125011574\n",
      "NLL Loss is: 1.4223949046734834\n",
      "Scaled KL Loss is: 0.04271167144179344\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4565642433170343\n",
      "NLL Loss is: 1.4986587728791287\n",
      "Scaled KL Loss is: 0.04788897559046745\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5369699526064446\n",
      "NLL Loss is: 1.4080519066787742\n",
      "Scaled KL Loss is: 0.03810417279601097\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.438535245660641\n",
      "NLL Loss is: 1.4799942424262043\n",
      "Scaled KL Loss is: 0.0430305190384388\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5144186591470714\n",
      "NLL Loss is: 1.439715871871713\n",
      "Scaled KL Loss is: 0.03713657706975937\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4694251346451075\n",
      "NLL Loss is: 1.341810648858135\n",
      "Scaled KL Loss is: 0.04083254560828209\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3744766875799348\n",
      "NLL Loss is: 1.414106921981412\n",
      "Scaled KL Loss is: 0.04004085808992386\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4461396091984091\n",
      "NLL Loss is: 1.3210160970925573\n",
      "Scaled KL Loss is: 0.044959478080272675\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3569836817919496\n",
      "NLL Loss is: 1.323046002297276\n",
      "Scaled KL Loss is: 0.04279610142111778\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3572828841792284\n",
      "NLL Loss is: 1.4476246428030641\n",
      "Scaled KL Loss is: 0.039815615862607956\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4794771377283247\n",
      "NLL Loss is: 1.3349548306490637\n",
      "Scaled KL Loss is: 0.04284350201487541\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.369229632260964\n",
      "NLL Loss is: 1.546369138562233\n",
      "Scaled KL Loss is: 0.04249228909611702\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5803629713292426\n",
      "NLL Loss is: 1.324163255725446\n",
      "Scaled KL Loss is: 0.042784273624420166\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.35839067537004\n",
      "NLL Loss is: 1.5040391819989298\n",
      "Scaled KL Loss is: 0.04036947712302208\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5363347629522894\n",
      "NLL Loss is: 1.456494652788014\n",
      "Scaled KL Loss is: 0.037282250821590424\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4863204538178154\n",
      "NLL Loss is: 1.363725724481639\n",
      "Scaled KL Loss is: 0.041956719011068344\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3972911004355517\n",
      "NLL Loss is: 1.3114377029464677\n",
      "Scaled KL Loss is: 0.04012728109955788\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.343539527826114\n",
      "NLL Loss is: 1.3894957340180065\n",
      "Scaled KL Loss is: 0.03741190955042839\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4194252620308783\n",
      "NLL Loss is: 1.418890371798966\n",
      "Scaled KL Loss is: 0.04294388368725777\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4532454794938303\n",
      "NLL Loss is: 1.4430973427692897\n",
      "Scaled KL Loss is: 0.03668232262134552\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4724432016114242\n",
      "NLL Loss is: 1.3365552666723368\n",
      "Scaled KL Loss is: 0.03733218461275101\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3664210139900086\n",
      "NLL Loss is: 1.5770714528801741\n",
      "Scaled KL Loss is: 0.043638233095407486\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.611982038611442\n",
      "NLL Loss is: 1.2026262086564572\n",
      "Scaled KL Loss is: 0.04093208536505699\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.235371879183677\n",
      "NLL Loss is: 1.3531145278707428\n",
      "Scaled KL Loss is: 0.04345281794667244\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.387876783718197\n",
      "NLL Loss is: 1.4123541200497582\n",
      "Scaled KL Loss is: 0.04326431825757027\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4469655761459306\n",
      "NLL Loss is: 1.2250137607178626\n",
      "Scaled KL Loss is: 0.04057485610246658\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.2574736455998359\n",
      "NLL Loss is: 1.3842150318019315\n",
      "Scaled KL Loss is: 0.041584715247154236\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.417482805489771\n",
      "NLL Loss is: 1.2428650577706293\n",
      "Scaled KL Loss is: 0.04218946769833565\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.2766166311842397\n",
      "NLL Loss is: 1.2517109613102937\n",
      "Scaled KL Loss is: 0.040211256593465805\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.2838799680751825\n",
      "NLL Loss is: 1.4257008778399425\n",
      "Scaled KL Loss is: 0.04177211597561836\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4591185721105533\n",
      "NLL Loss is: 1.4336639407072311\n",
      "Scaled KL Loss is: 0.04149792715907097\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.466862282434488\n",
      "NLL Loss is: 1.3191608485292077\n",
      "Scaled KL Loss is: 0.04138151556253433\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3522660617242932\n",
      "NLL Loss is: 1.5129136761792825\n",
      "Scaled KL Loss is: 0.04032393544912338\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5451728237935232\n",
      "NLL Loss is: 1.5335833332724258\n",
      "Scaled KL Loss is: 0.04233195260167122\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.567448896843879\n",
      "NLL Loss is: 1.3059432921790688\n",
      "Scaled KL Loss is: 0.0469348281621933\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3434911561989396\n",
      "NLL Loss is: 1.2695359756709217\n",
      "Scaled KL Loss is: 0.04136860743165016\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3026308623612999\n",
      "NLL Loss is: 1.4372288738158325\n",
      "Scaled KL Loss is: 0.04165434092283249\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4705523480442146\n",
      "NLL Loss is: 1.5266694654673443\n",
      "Scaled KL Loss is: 0.04364859312772751\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5615883399695263\n",
      "NLL Loss is: 1.320505141735107\n",
      "Scaled KL Loss is: 0.04410494863986969\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.355789102137119\n",
      "NLL Loss is: 1.3051539053324117\n",
      "Scaled KL Loss is: 0.03894924372434616\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3363133006844177\n",
      "NLL Loss is: 1.3131809554764016\n",
      "Scaled KL Loss is: 0.040341977030038834\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3454545385905488\n",
      "NLL Loss is: 1.3216687439622496\n",
      "Scaled KL Loss is: 0.0497782826423645\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3614913708211993\n",
      "NLL Loss is: 1.3984457454480566\n",
      "Scaled KL Loss is: 0.041430480778217316\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4315901300706304\n",
      "NLL Loss is: 1.3106078894014255\n",
      "Scaled KL Loss is: 0.042591653764247894\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3446812124128238\n",
      "NLL Loss is: 1.3230788404823322\n",
      "Scaled KL Loss is: 0.04480484873056412\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3589227194667834\n",
      "NLL Loss is: 1.2564482610791639\n",
      "Scaled KL Loss is: 0.042014941573143005\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.2900602143376783\n",
      "NLL Loss is: 1.3412464018632908\n",
      "Scaled KL Loss is: 0.0453675277531147\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3775404263009567\n",
      "NLL Loss is: 1.3112053170403979\n",
      "Scaled KL Loss is: 0.04287710413336754\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.345507000347092\n",
      "NLL Loss is: 1.3794145554166881\n",
      "Scaled KL Loss is: 0.04319998249411583\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.413974542902097\n",
      "NLL Loss is: 1.384609454741433\n",
      "Scaled KL Loss is: 0.04249387979507446\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4186045578324344\n",
      "NLL Loss is: 1.2936931884372758\n",
      "Scaled KL Loss is: 0.04646103456616402\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.330862015345149\n",
      "NLL Loss is: 1.404972574983301\n",
      "Scaled KL Loss is: 0.038741059601306915\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4359654237819337\n",
      "NLL Loss is: 1.4294195447337557\n",
      "Scaled KL Loss is: 0.0402299165725708\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4616034787368704\n",
      "NLL Loss is: 1.461321593862651\n",
      "Scaled KL Loss is: 0.039162084460258484\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4926512629209738\n",
      "NLL Loss is: 1.46262166411299\n",
      "Scaled KL Loss is: 0.044359009712934494\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4981088726283958\n",
      "NLL Loss is: 1.3301136866199932\n",
      "Scaled KL Loss is: 0.044136423617601395\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3654228262591324\n",
      "NLL Loss is: 1.3007738253128303\n",
      "Scaled KL Loss is: 0.03871757537126541\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3317478856098426\n",
      "NLL Loss is: 1.2622083996776148\n",
      "Scaled KL Loss is: 0.047031957656145096\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.2998339658025309\n",
      "NLL Loss is: 1.3545489431650197\n",
      "Scaled KL Loss is: 0.04202072694897652\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3881655269593751\n",
      "NLL Loss is: 1.3965031466772735\n",
      "Scaled KL Loss is: 0.044071342796087265\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4317602216592014\n",
      "NLL Loss is: 1.4501835031254813\n",
      "Scaled KL Loss is: 0.042937226593494415\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4845332836552187\n",
      "NLL Loss is: 1.339028757718927\n",
      "Scaled KL Loss is: 0.03963414207100868\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.370736070630676\n",
      "NLL Loss is: 1.3754689908769826\n",
      "Scaled KL Loss is: 0.040723346173763275\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4080476678159932\n",
      "NLL Loss is: 1.4316448163864561\n",
      "Scaled KL Loss is: 0.04115873575210571\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4645718042430826\n",
      "NLL Loss is: 1.4493279874470195\n",
      "Scaled KL Loss is: 0.04091719537973404\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4820617444958648\n",
      "NLL Loss is: 1.4123340137106613\n",
      "Scaled KL Loss is: 0.04355296865105629\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4471763893765643\n",
      "NLL Loss is: 1.3813693565477454\n",
      "Scaled KL Loss is: 0.04653051123023033\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4185937647868716\n",
      "NLL Loss is: 1.3597490114712592\n",
      "Scaled KL Loss is: 0.04197574406862259\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3933296089613314\n",
      "NLL Loss is: 1.5099551098325765\n",
      "Scaled KL Loss is: 0.04327601194381714\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5445759201326883\n",
      "NLL Loss is: 1.4052147996966438\n",
      "Scaled KL Loss is: 0.039683323353528976\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.436961459124525\n",
      "NLL Loss is: 1.4358095496827026\n",
      "Scaled KL Loss is: 0.04531809687614441\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.47206402643856\n",
      "NLL Loss is: 1.3791491228526551\n",
      "Scaled KL Loss is: 0.04203471168875694\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4127768936937768\n",
      "NLL Loss is: 1.483903468064406\n",
      "Scaled KL Loss is: 0.04120242968201637\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5168654140451934\n",
      "NLL Loss is: 1.3272269348979195\n",
      "Scaled KL Loss is: 0.03958124294877052\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.358891928511878\n",
      "NLL Loss is: 1.4914056093347217\n",
      "Scaled KL Loss is: 0.04334693029522896\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.526083155806079\n",
      "NLL Loss is: 1.4494416635561178\n",
      "Scaled KL Loss is: 0.03925338760018349\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4808443743813227\n",
      "NLL Loss is: 1.3673027790123877\n",
      "Scaled KL Loss is: 0.046821508556604385\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4047599880928454\n",
      "NLL Loss is: 1.344057363221754\n",
      "Scaled KL Loss is: 0.04362152889370918\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3789545863367214\n",
      "NLL Loss is: 1.4254108611273621\n",
      "Scaled KL Loss is: 0.04113631695508957\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4583199154364919\n",
      "NLL Loss is: 1.3211259146795586\n",
      "Scaled KL Loss is: 0.04474085196852684\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3569185969994382\n",
      "NLL Loss is: 1.3880129304928222\n",
      "Scaled KL Loss is: 0.03969813510775566\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4197714400691428\n",
      "NLL Loss is: 1.3432584347377543\n",
      "Scaled KL Loss is: 0.04507160931825638\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.3793157244275336\n",
      "NLL Loss is: 1.4898632426354521\n",
      "Scaled KL Loss is: 0.044751446694135666\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5256643999907606\n",
      "NLL Loss is: 1.507013679679887\n",
      "Scaled KL Loss is: 0.03635130450129509\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.5360947243985101\n",
      "NLL Loss is: 1.448715667267442\n",
      "Scaled KL Loss is: 0.03908202424645424\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4799812874096634\n",
      "NLL Loss is: 1.3750773331089818\n",
      "Scaled KL Loss is: 0.04494231566786766\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.411031186388334\n",
      "NLL Loss is: 1.2876361938481724\n",
      "Scaled KL Loss is: 0.040298957377672195\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.319875359005252\n",
      "NLL Loss is: 1.4573376079907587\n",
      "Scaled KL Loss is: 0.03947484493255615\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4889174861719778\n",
      "NLL Loss is: 1.3834062878216622\n",
      "Scaled KL Loss is: 0.04026806727051735\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.4156207431281922\n",
      "NLL Loss is: 1.7250690690321926\n",
      "Scaled KL Loss is: 0.03266126662492752\n",
      "Annealing coefficient is: 0.8\n",
      "Total Loss is: 1.7511980819596056\n",
      "NLL Loss is: 1.3866660627859222 1.417; test loss = 1.454\n",
      "Scaled KL Loss is: 0.044033002108335495\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.426295764310895\n",
      "NLL Loss is: 1.4382963900103918\n",
      "Scaled KL Loss is: 0.04139980301260948\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4755562108590952\n",
      "NLL Loss is: 1.4204302357862257\n",
      "Scaled KL Loss is: 0.04275548830628395\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4589101748893523\n",
      "NLL Loss is: 1.4948357006312176\n",
      "Scaled KL Loss is: 0.04780194163322449\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5378574466110035\n",
      "NLL Loss is: 1.404982096417529\n",
      "Scaled KL Loss is: 0.03814496845006943\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4393125687676496\n",
      "NLL Loss is: 1.4766158737084525\n",
      "Scaled KL Loss is: 0.043099112808704376\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5154050752362864\n",
      "NLL Loss is: 1.4371259695309686\n",
      "Scaled KL Loss is: 0.037177152931690216\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4705854056793737\n",
      "NLL Loss is: 1.3405849252948252\n",
      "Scaled KL Loss is: 0.04074838384985924\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3772584711322275\n",
      "NLL Loss is: 1.412462130692397\n",
      "Scaled KL Loss is: 0.03996250405907631\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4484283817378625\n",
      "NLL Loss is: 1.3190384718862223\n",
      "Scaled KL Loss is: 0.04494832828640938\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3594919654813455\n",
      "NLL Loss is: 1.3205965961240727\n",
      "Scaled KL Loss is: 0.042582910507917404\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.358921212973495\n",
      "NLL Loss is: 1.4448297142992002\n",
      "Scaled KL Loss is: 0.03987818583846092\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.480720081181286\n",
      "NLL Loss is: 1.3321785782741804\n",
      "Scaled KL Loss is: 0.04292990639805794\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3708154936599035\n",
      "NLL Loss is: 1.5436427123650045\n",
      "Scaled KL Loss is: 0.042480144649744034\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.581874841432187\n",
      "NLL Loss is: 1.3211866858892358\n",
      "Scaled KL Loss is: 0.04264878109097481\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.359570587008468\n",
      "NLL Loss is: 1.5008995094297968\n",
      "Scaled KL Loss is: 0.0405331514775753\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5373793438969694\n",
      "NLL Loss is: 1.4531915597811238\n",
      "Scaled KL Loss is: 0.03742410987615585\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.486873257924606\n",
      "NLL Loss is: 1.3614541057848675\n",
      "Scaled KL Loss is: 0.041931942105293274\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3991928536796314\n",
      "NLL Loss is: 1.309977417518814\n",
      "Scaled KL Loss is: 0.04014390707015991\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3461069331368998\n",
      "NLL Loss is: 1.3880165852728448\n",
      "Scaled KL Loss is: 0.03747186064720154\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.42174125836521\n",
      "NLL Loss is: 1.4148843625519232\n",
      "Scaled KL Loss is: 0.04278196394443512\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4533881286117987\n",
      "NLL Loss is: 1.4390079943256924\n",
      "Scaled KL Loss is: 0.03675243631005287\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4720851858871529\n",
      "NLL Loss is: 1.3340889617395388\n",
      "Scaled KL Loss is: 0.03740275278687477\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.367751437385081\n",
      "NLL Loss is: 1.5754989573118616\n",
      "Scaled KL Loss is: 0.04358062148094177\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.614721514409535\n",
      "NLL Loss is: 1.2009666514482942\n",
      "Scaled KL Loss is: 0.040866509079933167\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.237746509620234\n",
      "NLL Loss is: 1.3501242894183252\n",
      "Scaled KL Loss is: 0.04348368942737579\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3892596076677892\n",
      "NLL Loss is: 1.4096723765674326\n",
      "Scaled KL Loss is: 0.04333346709609032\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4486724965813849\n",
      "NLL Loss is: 1.2217313913885348\n",
      "Scaled KL Loss is: 0.04067128151655197\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.2583355425182574\n",
      "NLL Loss is: 1.3812785036326725\n",
      "Scaled KL Loss is: 0.04156014323234558\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4186826310516674\n",
      "NLL Loss is: 1.2395626113989635\n",
      "Scaled KL Loss is: 0.04212074726819992\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.2774712846854015\n",
      "NLL Loss is: 1.248421046782058\n",
      "Scaled KL Loss is: 0.04004582017660141\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.2844622841959412\n",
      "NLL Loss is: 1.4211040775480166\n",
      "Scaled KL Loss is: 0.0416770838201046\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4586134518685236\n",
      "NLL Loss is: 1.4296748966810955\n",
      "Scaled KL Loss is: 0.04129735752940178\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.466842516594912\n",
      "NLL Loss is: 1.31637808288484\n",
      "Scaled KL Loss is: 0.04121779650449753\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3534740989938296\n",
      "NLL Loss is: 1.5095874207912636\n",
      "Scaled KL Loss is: 0.04024236649274826\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.545805549889679\n",
      "NLL Loss is: 1.530122492068541\n",
      "Scaled KL Loss is: 0.04210831969976425\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5680199783082127\n",
      "NLL Loss is: 1.303689284403099\n",
      "Scaled KL Loss is: 0.04685842990875244\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.345861869085802\n",
      "NLL Loss is: 1.26720181238806\n",
      "Scaled KL Loss is: 0.04136999696493149\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3044348074213241\n",
      "NLL Loss is: 1.4334585175738936\n",
      "Scaled KL Loss is: 0.04152391850948334\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4708300449774867\n",
      "NLL Loss is: 1.5240647611548448\n",
      "Scaled KL Loss is: 0.04345158115029335\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5631711823274637\n",
      "NLL Loss is: 1.3153694754755005\n",
      "Scaled KL Loss is: 0.043891824781894684\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3548721185242638\n",
      "NLL Loss is: 1.3011427779844038\n",
      "Scaled KL Loss is: 0.03875330835580826\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3360207562496893\n",
      "NLL Loss is: 1.3101365970677115\n",
      "Scaled KL Loss is: 0.040318675339221954\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3464234056180693\n",
      "NLL Loss is: 1.317232002879257\n",
      "Scaled KL Loss is: 0.04959021136164665\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.361863193477268\n",
      "NLL Loss is: 1.3953294463859092\n",
      "Scaled KL Loss is: 0.04118189215660095\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.43239314932685\n",
      "NLL Loss is: 1.308193755070376\n",
      "Scaled KL Loss is: 0.04247932881116867\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3464251502553697\n",
      "NLL Loss is: 1.3209589792148362\n",
      "Scaled KL Loss is: 0.04465378075838089\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.361147381152321\n",
      "NLL Loss is: 1.2523530778780023\n",
      "Scaled KL Loss is: 0.042073607444763184\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.2902193238332311\n",
      "NLL Loss is: 1.3384760509443339\n",
      "Scaled KL Loss is: 0.045146457850933075\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3791078630101736\n",
      "NLL Loss is: 1.3075542489693632\n",
      "Scaled KL Loss is: 0.0426911786198616\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3459763082371226\n",
      "NLL Loss is: 1.3765470980700711\n",
      "Scaled KL Loss is: 0.04306364431977272\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4153043775853376\n",
      "NLL Loss is: 1.3820853886325342\n",
      "Scaled KL Loss is: 0.0422089509665966\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.420073444129942\n",
      "NLL Loss is: 1.2906721011780327\n",
      "Scaled KL Loss is: 0.046147506684064865\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.332204856076104\n",
      "NLL Loss is: 1.402832423282493\n",
      "Scaled KL Loss is: 0.038623254746198654\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4375933529266007\n",
      "NLL Loss is: 1.4284916056016832\n",
      "Scaled KL Loss is: 0.04001857340335846\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4645083194295316\n",
      "NLL Loss is: 1.458062010787858\n",
      "Scaled KL Loss is: 0.03893235698342323\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4931011302102937\n",
      "NLL Loss is: 1.4604634357058657\n",
      "Scaled KL Loss is: 0.044111695140600204\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5001639587247027\n",
      "NLL Loss is: 1.3274506171222757\n",
      "Scaled KL Loss is: 0.0437629297375679\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.366837254631145\n",
      "NLL Loss is: 1.298985431999539\n",
      "Scaled KL Loss is: 0.03850983828306198\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3336442849641788\n",
      "NLL Loss is: 1.2584473700510994\n",
      "Scaled KL Loss is: 0.046660393476486206\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3004417219447628\n",
      "NLL Loss is: 1.3516578692718866\n",
      "Scaled KL Loss is: 0.041822537779808044\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3892981540187719\n",
      "NLL Loss is: 1.3930527116056146\n",
      "Scaled KL Loss is: 0.04371223226189613\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.432393718033618\n",
      "NLL Loss is: 1.4477443648296364\n",
      "Scaled KL Loss is: 0.04260736331343651\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4860909906941422\n",
      "NLL Loss is: 1.3367445133484617\n",
      "Scaled KL Loss is: 0.039498548954725266\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3722932077802434\n",
      "NLL Loss is: 1.3726502305746362\n",
      "Scaled KL Loss is: 0.04040216654539108\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.409012178230314\n",
      "NLL Loss is: 1.4300012854953115\n",
      "Scaled KL Loss is: 0.04089494049549103\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4668067326863115\n",
      "NLL Loss is: 1.4469425514753598\n",
      "Scaled KL Loss is: 0.040722958743572235\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4835932128544587\n",
      "NLL Loss is: 1.4093600256004433\n",
      "Scaled KL Loss is: 0.04317266494035721\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4482154218115906\n",
      "NLL Loss is: 1.3786403434581995\n",
      "Scaled KL Loss is: 0.04616868868470192\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.420192160666728\n",
      "NLL Loss is: 1.3568705974050017\n",
      "Scaled KL Loss is: 0.04166093096137047\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3943654356427642\n",
      "NLL Loss is: 1.5070625934571522\n",
      "Scaled KL Loss is: 0.042935729026794434\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5457047503263253\n",
      "NLL Loss is: 1.4027194428305163\n",
      "Scaled KL Loss is: 0.0393596775829792\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4381431500474944\n",
      "NLL Loss is: 1.4317143381512323\n",
      "Scaled KL Loss is: 0.045004963874816895\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4722188048935094\n",
      "NLL Loss is: 1.3774305664030788\n",
      "Scaled KL Loss is: 0.04176413267850876\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4150182835785625\n",
      "NLL Loss is: 1.481683188585938\n",
      "Scaled KL Loss is: 0.04089460149407387\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5184883303031336\n",
      "NLL Loss is: 1.3252835360506845\n",
      "Scaled KL Loss is: 0.039214640855789185\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3605767128208948\n",
      "NLL Loss is: 1.4890489064712056\n",
      "Scaled KL Loss is: 0.04286004975438118\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5276229501325616\n",
      "NLL Loss is: 1.4470594969904238\n",
      "Scaled KL Loss is: 0.039019010961055756\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4821766053652579\n",
      "NLL Loss is: 1.366034196309284\n",
      "Scaled KL Loss is: 0.046230047941207886\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4076412372211968\n",
      "NLL Loss is: 1.341392526171863\n",
      "Scaled KL Loss is: 0.0430777408182621\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3801624903005958\n",
      "NLL Loss is: 1.4228992413524606\n",
      "Scaled KL Loss is: 0.04077521711587906\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4595969345215776\n",
      "NLL Loss is: 1.3176079495710236\n",
      "Scaled KL Loss is: 0.044341668486595154\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.357515449718843\n",
      "NLL Loss is: 1.3863103254333697\n",
      "Scaled KL Loss is: 0.039295993745326996\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.421676719059106\n",
      "NLL Loss is: 1.3388680448833568\n",
      "Scaled KL Loss is: 0.0446942076086998\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.3790928317311866\n",
      "NLL Loss is: 1.4850855783781514\n",
      "Scaled KL Loss is: 0.04432087019085884\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.524974358942221\n",
      "NLL Loss is: 1.5044660961609315\n",
      "Scaled KL Loss is: 0.036245767027139664\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.5370872861128282\n",
      "NLL Loss is: 1.4459287426428744\n",
      "Scaled KL Loss is: 0.038739852607250214\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4807946099893996\n",
      "NLL Loss is: 1.3716710458063415\n",
      "Scaled KL Loss is: 0.04455498233437538\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4117705287896922\n",
      "NLL Loss is: 1.286247463261471\n",
      "Scaled KL Loss is: 0.03995497524738312\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.322206941729174\n",
      "NLL Loss is: 1.4562929823367528\n",
      "Scaled KL Loss is: 0.039258889853954315\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.4916259824602536\n",
      "NLL Loss is: 1.3800944880029669\n",
      "Scaled KL Loss is: 0.0400572195649147\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.416145984866332\n",
      "NLL Loss is: 1.7226159949234883\n",
      "Scaled KL Loss is: 0.03243398666381836\n",
      "Annealing coefficient is: 0.9\n",
      "Total Loss is: 1.7518065818033377\n",
      "NLL Loss is: 1.3834343473301542 1.418; test loss = 1.455\n",
      "Scaled KL Loss is: 0.043688639998435974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4271229873285902\n",
      "NLL Loss is: 1.435291833154981\n",
      "Scaled KL Loss is: 0.04101182892918587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.476303662084167\n",
      "NLL Loss is: 1.4191026030628808\n",
      "Scaled KL Loss is: 0.04239561781287193\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4614982208757528\n",
      "NLL Loss is: 1.4903420897792103\n",
      "Scaled KL Loss is: 0.04726210981607437\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5376041995952847\n",
      "NLL Loss is: 1.4024704773042536\n",
      "Scaled KL Loss is: 0.03780798241496086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4402784597192144\n",
      "NLL Loss is: 1.4725088766493228\n",
      "Scaled KL Loss is: 0.04276781901717186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5152766956664947\n",
      "NLL Loss is: 1.4349584258968042\n",
      "Scaled KL Loss is: 0.036848798394203186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4718072242910074\n",
      "NLL Loss is: 1.3399061215290593\n",
      "Scaled KL Loss is: 0.040259912610054016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3801660341391133\n",
      "NLL Loss is: 1.410982235231129\n",
      "Scaled KL Loss is: 0.039483971893787384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4504662071249164\n",
      "NLL Loss is: 1.3176174099756892\n",
      "Scaled KL Loss is: 0.044515352696180344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3621327626718696\n",
      "NLL Loss is: 1.318945437368497\n",
      "Scaled KL Loss is: 0.041935887187719345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3608813245562164\n",
      "NLL Loss is: 1.4425440500667588\n",
      "Scaled KL Loss is: 0.03956488147377968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4821089315405385\n",
      "NLL Loss is: 1.3298138096329495\n",
      "Scaled KL Loss is: 0.0426267609000206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37244057053297\n",
      "NLL Loss is: 1.5409095513952602\n",
      "Scaled KL Loss is: 0.04207948222756386\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.582989033622824\n",
      "NLL Loss is: 1.3195118965635557\n",
      "Scaled KL Loss is: 0.0420992374420166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3616111340055723\n",
      "NLL Loss is: 1.4985476695901736\n",
      "Scaled KL Loss is: 0.04034334048628807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5388910100764617\n",
      "NLL Loss is: 1.4500464636659518\n",
      "Scaled KL Loss is: 0.037227269262075424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4872737329280272\n",
      "NLL Loss is: 1.3596207306851371\n",
      "Scaled KL Loss is: 0.04151704162359238\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4011377723087295\n",
      "NLL Loss is: 1.3089475033566973\n",
      "Scaled KL Loss is: 0.03979947790503502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3487469812617323\n",
      "NLL Loss is: 1.3869279281436762\n",
      "Scaled KL Loss is: 0.03718126192688942\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4241091900705656\n",
      "NLL Loss is: 1.4104513435952615\n",
      "Scaled KL Loss is: 0.04221319034695625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4526645339422177\n",
      "NLL Loss is: 1.434938872911549\n",
      "Scaled KL Loss is: 0.03647959977388382\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.471418472685433\n",
      "NLL Loss is: 1.3320649115099832\n",
      "Scaled KL Loss is: 0.037119608372449875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.369184519882433\n",
      "NLL Loss is: 1.574544286521587\n",
      "Scaled KL Loss is: 0.04311613366007805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6176604201816651\n",
      "NLL Loss is: 1.2000994382629788\n",
      "Scaled KL Loss is: 0.040403544902801514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2405029831657803\n",
      "NLL Loss is: 1.3470713391225346\n",
      "Scaled KL Loss is: 0.04313160479068756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3902029439132222\n",
      "NLL Loss is: 1.4072642878315083\n",
      "Scaled KL Loss is: 0.04302400350570679\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.450288291337215\n",
      "NLL Loss is: 1.2179414047210855\n",
      "Scaled KL Loss is: 0.040414683520793915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2583560882418794\n",
      "NLL Loss is: 1.3784418921503805\n",
      "Scaled KL Loss is: 0.041148439049720764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4195903312001013\n",
      "NLL Loss is: 1.2369438340955223\n",
      "Scaled KL Loss is: 0.041659679263830185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2786035133593525\n",
      "NLL Loss is: 1.245397484080511\n",
      "Scaled KL Loss is: 0.039485007524490356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2848824916050015\n",
      "NLL Loss is: 1.4167538799944948\n",
      "Scaled KL Loss is: 0.04119522497057915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.457949104965074\n",
      "NLL Loss is: 1.4252894693505456\n",
      "Scaled KL Loss is: 0.04068714380264282\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4659766131531884\n",
      "NLL Loss is: 1.3132921439351215\n",
      "Scaled KL Loss is: 0.040658287703990936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3539504316391124\n",
      "NLL Loss is: 1.5060372999643152\n",
      "Scaled KL Loss is: 0.03979320079088211\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5458305007551973\n",
      "NLL Loss is: 1.526439579597689\n",
      "Scaled KL Loss is: 0.04148675501346588\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.567926334611155\n",
      "NLL Loss is: 1.3010240305480847\n",
      "Scaled KL Loss is: 0.04638297110795975\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3474070016560444\n",
      "NLL Loss is: 1.2655104765765934\n",
      "Scaled KL Loss is: 0.041013769805431366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3065242463820248\n",
      "NLL Loss is: 1.4306131047161643\n",
      "Scaled KL Loss is: 0.041009802371263504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4716229070874278\n",
      "NLL Loss is: 1.5210785088701015\n",
      "Scaled KL Loss is: 0.0428612157702446\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5639397246403461\n",
      "NLL Loss is: 1.3095637329715195\n",
      "Scaled KL Loss is: 0.043279264122247696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3528429970937672\n",
      "NLL Loss is: 1.2973426666133872\n",
      "Scaled KL Loss is: 0.038190945982933044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3355336125963202\n",
      "NLL Loss is: 1.3078953463842828\n",
      "Scaled KL Loss is: 0.039956849068403244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.347852195452686\n",
      "NLL Loss is: 1.3128052083600108\n",
      "Scaled KL Loss is: 0.048983264714479446\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3617884730744902\n",
      "NLL Loss is: 1.392054178439082\n",
      "Scaled KL Loss is: 0.04055929183959961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4326134702786817\n",
      "NLL Loss is: 1.3061952768226315\n",
      "Scaled KL Loss is: 0.042002495378255844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3481977722008873\n",
      "NLL Loss is: 1.3195381522142873\n",
      "Scaled KL Loss is: 0.04412546008825302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3636636123025403\n",
      "NLL Loss is: 1.2487955593990687\n",
      "Scaled KL Loss is: 0.041791338473558426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2905868978726271\n",
      "NLL Loss is: 1.3356747799619735\n",
      "Scaled KL Loss is: 0.044540900737047195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3802156806990207\n",
      "NLL Loss is: 1.3042467214948865\n",
      "Scaled KL Loss is: 0.04213752970099449\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346384251195881\n",
      "NLL Loss is: 1.3743827358002352\n",
      "Scaled KL Loss is: 0.042560379952192307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4169431157524275\n",
      "NLL Loss is: 1.3790418959874087\n",
      "Scaled KL Loss is: 0.04154718667268753\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4205890826600962\n",
      "NLL Loss is: 1.2878278677053867\n",
      "Scaled KL Loss is: 0.045434869825839996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3332627375312267\n",
      "NLL Loss is: 1.4008161911596022\n",
      "Scaled KL Loss is: 0.03817044943571091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4389866405953131\n",
      "NLL Loss is: 1.4279998500958104\n",
      "Scaled KL Loss is: 0.039460454136133194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4674603042319436\n",
      "NLL Loss is: 1.4549881855953604\n",
      "Scaled KL Loss is: 0.038356486707925797\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4933446723032862\n",
      "NLL Loss is: 1.4580634543193063\n",
      "Scaled KL Loss is: 0.04349561035633087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5015590646756372\n",
      "NLL Loss is: 1.3253743300577974\n",
      "Scaled KL Loss is: 0.043001990765333176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3683763208231305\n",
      "NLL Loss is: 1.298117609676134\n",
      "Scaled KL Loss is: 0.03796560689806938\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3360832165742034\n",
      "NLL Loss is: 1.2548839455362744\n",
      "Scaled KL Loss is: 0.04588873311877251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3007726786550469\n",
      "NLL Loss is: 1.3490320043764898\n",
      "Scaled KL Loss is: 0.041275281459093094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.390307285835583\n",
      "NLL Loss is: 1.389660312145884\n",
      "Scaled KL Loss is: 0.042980775237083435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4326410873829674\n",
      "NLL Loss is: 1.4456594407183478\n",
      "Scaled KL Loss is: 0.04191874712705612\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.487578187845404\n",
      "NLL Loss is: 1.3351989912164948\n",
      "Scaled KL Loss is: 0.039035215973854065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3742342071903488\n",
      "NLL Loss is: 1.3703544968766324\n",
      "Scaled KL Loss is: 0.03973307088017464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410087567756807\n",
      "NLL Loss is: 1.428579802911902\n",
      "Scaled KL Loss is: 0.04028854891657829\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4688683518284802\n",
      "NLL Loss is: 1.4438485472450002\n",
      "Scaled KL Loss is: 0.04020607843995094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4840546256849512\n",
      "NLL Loss is: 1.4067595697947253\n",
      "Scaled KL Loss is: 0.04242950677871704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4491890765734423\n",
      "NLL Loss is: 1.3758753100908019\n",
      "Scaled KL Loss is: 0.04543807730078697\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4213133873915889\n",
      "NLL Loss is: 1.3540960108931626\n",
      "Scaled KL Loss is: 0.04100268706679344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395098697959956\n",
      "NLL Loss is: 1.504245049653219\n",
      "Scaled KL Loss is: 0.042247623205184937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5464926728584039\n",
      "NLL Loss is: 1.400429136732783\n",
      "Scaled KL Loss is: 0.0387081578373909\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.439137294570174\n",
      "NLL Loss is: 1.4272780026518201\n",
      "Scaled KL Loss is: 0.044332340359687805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.471610343011508\n",
      "NLL Loss is: 1.3761154622294398\n",
      "Scaled KL Loss is: 0.04115990921854973\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4172753714479895\n",
      "NLL Loss is: 1.4790131682383787\n",
      "Scaled KL Loss is: 0.04025118798017502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5192643562185537\n",
      "NLL Loss is: 1.323340623500662\n",
      "Scaled KL Loss is: 0.03852003812789917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3618606616285611\n",
      "NLL Loss is: 1.486453050748628\n",
      "Scaled KL Loss is: 0.04201430082321167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5284673515718397\n",
      "NLL Loss is: 1.444690794527318\n",
      "Scaled KL Loss is: 0.03847431764006615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4831651121673841\n",
      "NLL Loss is: 1.3653687822989156\n",
      "Scaled KL Loss is: 0.045245878398418427\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410614660697334\n",
      "NLL Loss is: 1.3387418183079833\n",
      "Scaled KL Loss is: 0.042158033698797226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3808998520067806\n",
      "NLL Loss is: 1.420131625099647\n",
      "Scaled KL Loss is: 0.04008230194449425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4602139270441412\n",
      "NLL Loss is: 1.313819345104759\n",
      "Scaled KL Loss is: 0.043579161167144775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3573985062719038\n",
      "NLL Loss is: 1.384846293422005\n",
      "Scaled KL Loss is: 0.0385604090988636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4234067025208685\n",
      "NLL Loss is: 1.3339737712033162\n",
      "Scaled KL Loss is: 0.04395404830574989\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377927819509066\n",
      "NLL Loss is: 1.4797797698622792\n",
      "Scaled KL Loss is: 0.043528441339731216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5233082112020104\n",
      "NLL Loss is: 1.5018436568778686\n",
      "Scaled KL Loss is: 0.03585774451494217\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5377014013928108\n",
      "NLL Loss is: 1.4431449335493027\n",
      "Scaled KL Loss is: 0.03808033466339111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4812252682126938\n",
      "NLL Loss is: 1.3680392532980676\n",
      "Scaled KL Loss is: 0.043803587555885315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.411842840853953\n",
      "NLL Loss is: 1.2851946714997877\n",
      "Scaled KL Loss is: 0.039279088377952576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3244737598777403\n",
      "NLL Loss is: 1.4557446992150014\n",
      "Scaled KL Loss is: 0.038731642067432404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4944763412824338\n",
      "NLL Loss is: 1.3761472638399015\n",
      "Scaled KL Loss is: 0.039525941014289856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4156732048541913\n",
      "NLL Loss is: 1.7200452055066517\n",
      "Scaled KL Loss is: 0.03193095698952675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7519761624961785\n",
      "NLL Loss is: 1.380133159512522 = 1.419; test loss = 1.456\n",
      "Scaled KL Loss is: 0.04299424961209297\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4231274091246149\n",
      "NLL Loss is: 1.4326775037684616\n",
      "Scaled KL Loss is: 0.040283527225255966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4729610309937176\n",
      "NLL Loss is: 1.4182623283457287\n",
      "Scaled KL Loss is: 0.04169775918126106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4599600875269898\n",
      "NLL Loss is: 1.4852721145247036\n",
      "Scaled KL Loss is: 0.04634124040603638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.53161335493074\n",
      "NLL Loss is: 1.4004321988715906\n",
      "Scaled KL Loss is: 0.03716052696108818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4375927258326788\n",
      "NLL Loss is: 1.4678656260169438\n",
      "Scaled KL Loss is: 0.04210453853011131\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5099701645470551\n",
      "NLL Loss is: 1.4330892310699965\n",
      "Scaled KL Loss is: 0.03622007742524147\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.469309308495238\n",
      "NLL Loss is: 1.339607715165264\n",
      "Scaled KL Loss is: 0.039443016052246094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37905073121751\n",
      "NLL Loss is: 1.4097081624770516\n",
      "Scaled KL Loss is: 0.038679566234350204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4483877287114018\n",
      "NLL Loss is: 1.316617587689139\n",
      "Scaled KL Loss is: 0.04374809190630913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3603656795954482\n",
      "NLL Loss is: 1.318001112966485\n",
      "Scaled KL Loss is: 0.040941111743450165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3589422247099352\n",
      "NLL Loss is: 1.4405613930632228\n",
      "Scaled KL Loss is: 0.03896361216902733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4795250052322502\n",
      "NLL Loss is: 1.327750676993284\n",
      "Scaled KL Loss is: 0.04202483966946602\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.36977551666275\n",
      "NLL Loss is: 1.5380267502275218\n",
      "Scaled KL Loss is: 0.04138070344924927\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.579407453676771\n",
      "NLL Loss is: 1.3188554443771354\n",
      "Scaled KL Loss is: 0.04123677313327789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3600922175104133\n",
      "NLL Loss is: 1.4967225001998474\n",
      "Scaled KL Loss is: 0.03989740461111069\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5366199048109581\n",
      "NLL Loss is: 1.4469560791293212\n",
      "Scaled KL Loss is: 0.036788832396268845\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.48374491152559\n",
      "NLL Loss is: 1.3580653944310206\n",
      "Scaled KL Loss is: 0.04082103818655014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3988864326175707\n",
      "NLL Loss is: 1.3084981102781428\n",
      "Scaled KL Loss is: 0.03920421749353409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3477023277716769\n",
      "NLL Loss is: 1.3860476146786171\n",
      "Scaled KL Loss is: 0.03665831312537193\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.422705927803989\n",
      "NLL Loss is: 1.405940614707005\n",
      "Scaled KL Loss is: 0.04136680066585541\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4473074153728605\n",
      "NLL Loss is: 1.430886304316898\n",
      "Scaled KL Loss is: 0.03598526865243912\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4668715729693371\n",
      "NLL Loss is: 1.3305662354089416\n",
      "Scaled KL Loss is: 0.03662308678030968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3671893221892513\n",
      "NLL Loss is: 1.5732108121138384\n",
      "Scaled KL Loss is: 0.04241081699728966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.615621629111128\n",
      "NLL Loss is: 1.20020752978057\n",
      "Scaled KL Loss is: 0.039712488651275635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2399200184318457\n",
      "NLL Loss is: 1.344244176707405\n",
      "Scaled KL Loss is: 0.04255449026823044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3867986669756354\n",
      "NLL Loss is: 1.4050129098554527\n",
      "Scaled KL Loss is: 0.04250606149435043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4475189713498031\n",
      "NLL Loss is: 1.2151804599382179\n",
      "Scaled KL Loss is: 0.039960477501153946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2551409374393718\n",
      "NLL Loss is: 1.375859294936376\n",
      "Scaled KL Loss is: 0.04054243490099907\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416401729837375\n",
      "NLL Loss is: 1.2348853321190523\n",
      "Scaled KL Loss is: 0.04100167006254196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2758870021815942\n",
      "NLL Loss is: 1.2431839615901186\n",
      "Scaled KL Loss is: 0.0387306846678257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2819146462579443\n",
      "NLL Loss is: 1.4126498406494863\n",
      "Scaled KL Loss is: 0.04052300006151199\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4531728407109983\n",
      "NLL Loss is: 1.4209658505023532\n",
      "Scaled KL Loss is: 0.03988911211490631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4608549626172596\n",
      "NLL Loss is: 1.3103788246510681\n",
      "Scaled KL Loss is: 0.039917875081300735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3502966997323689\n",
      "NLL Loss is: 1.5023018487586155\n",
      "Scaled KL Loss is: 0.03918210789561272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5414839566542282\n",
      "NLL Loss is: 1.5221621915344081\n",
      "Scaled KL Loss is: 0.04068220034241676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.562844391876825\n",
      "NLL Loss is: 1.2992924844500067\n",
      "Scaled KL Loss is: 0.045722126960754395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.345014611410761\n",
      "NLL Loss is: 1.2642772832316749\n",
      "Scaled KL Loss is: 0.04050065949559212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304777942727267\n",
      "NLL Loss is: 1.427357738570949\n",
      "Scaled KL Loss is: 0.04034104570746422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4676987842784133\n",
      "NLL Loss is: 1.5180165090023943\n",
      "Scaled KL Loss is: 0.042107801884412766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.560124310886807\n",
      "NLL Loss is: 1.3038868286219027\n",
      "Scaled KL Loss is: 0.04250034689903259\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3463871755209353\n",
      "NLL Loss is: 1.2934842924075922\n",
      "Scaled KL Loss is: 0.03748905658721924\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3309733489948115\n",
      "NLL Loss is: 1.3057404235475867\n",
      "Scaled KL Loss is: 0.039457183331251144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3451976068788378\n",
      "NLL Loss is: 1.3092548980828076\n",
      "Scaled KL Loss is: 0.048217859119176865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3574727572019845\n",
      "NLL Loss is: 1.3888364692942008\n",
      "Scaled KL Loss is: 0.03979834169149399\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4286348109856948\n",
      "NLL Loss is: 1.3044865615561665\n",
      "Scaled KL Loss is: 0.0413934662938118\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3458800278499783\n",
      "NLL Loss is: 1.3184278906049614\n",
      "Scaled KL Loss is: 0.04346496984362602\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3618928604485874\n",
      "NLL Loss is: 1.2455142705779496\n",
      "Scaled KL Loss is: 0.041394542902708054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2869088134806577\n",
      "NLL Loss is: 1.3329050358302181\n",
      "Scaled KL Loss is: 0.04379860311746597\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376703638947684\n",
      "NLL Loss is: 1.3011034328422368\n",
      "Scaled KL Loss is: 0.04146403819322586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3425674710354627\n",
      "NLL Loss is: 1.3723384068155418\n",
      "Scaled KL Loss is: 0.041945625096559525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4142840319121013\n",
      "NLL Loss is: 1.375879480820978\n",
      "Scaled KL Loss is: 0.04077443480491638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4166539156258944\n",
      "NLL Loss is: 1.285107062012452\n",
      "Scaled KL Loss is: 0.04460328817367554\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3297103501861276\n",
      "NLL Loss is: 1.3989199688569514\n",
      "Scaled KL Loss is: 0.03763269633054733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4365526651874987\n",
      "NLL Loss is: 1.427712722622433\n",
      "Scaled KL Loss is: 0.03881807625293732\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4665307988753704\n",
      "NLL Loss is: 1.4520648203473974\n",
      "Scaled KL Loss is: 0.0376998707652092\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4897646911126066\n",
      "NLL Loss is: 1.4557009066088973\n",
      "Scaled KL Loss is: 0.04279262572526932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4984935323341666\n",
      "NLL Loss is: 1.3234520114711308\n",
      "Scaled KL Loss is: 0.04215392470359802\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3656059361747288\n",
      "NLL Loss is: 1.297420087483991\n",
      "Scaled KL Loss is: 0.03735922649502754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3347793139790185\n",
      "NLL Loss is: 1.251411127643328\n",
      "Scaled KL Loss is: 0.04503415897488594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.296445286618214\n",
      "NLL Loss is: 1.3463836553029416\n",
      "Scaled KL Loss is: 0.04066880792379379\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3870524632267354\n",
      "NLL Loss is: 1.3861295133242861\n",
      "Scaled KL Loss is: 0.042185306549072266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4283148198733584\n",
      "NLL Loss is: 1.4436174215990554\n",
      "Scaled KL Loss is: 0.04117468371987343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4847921053189288\n",
      "NLL Loss is: 1.333445417488498\n",
      "Scaled KL Loss is: 0.038532692939043045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371978110427541\n",
      "NLL Loss is: 1.3681455507560554\n",
      "Scaled KL Loss is: 0.03902309760451317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4071686483605685\n",
      "NLL Loss is: 1.427035917194644\n",
      "Scaled KL Loss is: 0.039650626480579376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4666865436752234\n",
      "NLL Loss is: 1.4411185265940487\n",
      "Scaled KL Loss is: 0.03966480493545532\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.480783331529504\n",
      "NLL Loss is: 1.4043514728771442\n",
      "Scaled KL Loss is: 0.04165380820631981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446005281083464\n",
      "NLL Loss is: 1.3731964730358284\n",
      "Scaled KL Loss is: 0.04468611255288124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4178825855887096\n",
      "NLL Loss is: 1.3512133574333\n",
      "Scaled KL Loss is: 0.04033713415265083\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.391550491585951\n",
      "NLL Loss is: 1.5011797568970282\n",
      "Scaled KL Loss is: 0.041552815586328506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5427325724833567\n",
      "NLL Loss is: 1.39839611231079\n",
      "Scaled KL Loss is: 0.03806593269109726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4364620450018872\n",
      "NLL Loss is: 1.4230443559740418\n",
      "Scaled KL Loss is: 0.043655555695295334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.466699911669337\n",
      "NLL Loss is: 1.3748679745435228\n",
      "Scaled KL Loss is: 0.04056508094072342\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4154330554842462\n",
      "NLL Loss is: 1.476466647320588\n",
      "Scaled KL Loss is: 0.03962395712733269\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5160906044479208\n",
      "NLL Loss is: 1.321720211549022\n",
      "Scaled KL Loss is: 0.03784383460879326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3595640461578153\n",
      "NLL Loss is: 1.483663581371991\n",
      "Scaled KL Loss is: 0.041178591549396515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5248421729213875\n",
      "NLL Loss is: 1.44252293107715\n",
      "Scaled KL Loss is: 0.03794771432876587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4804706454059158\n",
      "NLL Loss is: 1.364461189550768\n",
      "Scaled KL Loss is: 0.044264115393161774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4087253049439297\n",
      "NLL Loss is: 1.3360787102724987\n",
      "Scaled KL Loss is: 0.04124300926923752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3773217195417362\n",
      "NLL Loss is: 1.417393168360296\n",
      "Scaled KL Loss is: 0.03940021991729736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4567933882775934\n",
      "NLL Loss is: 1.3099321810672557\n",
      "Scaled KL Loss is: 0.042826924473047256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.352759105540303\n",
      "NLL Loss is: 1.383549682038123\n",
      "Scaled KL Loss is: 0.03783624619245529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4213859282305783\n",
      "NLL Loss is: 1.3291679661488862\n",
      "Scaled KL Loss is: 0.04322358965873718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3723915558076234\n",
      "NLL Loss is: 1.4742871501094448\n",
      "Scaled KL Loss is: 0.04274317994713783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5170303300565826\n",
      "NLL Loss is: 1.499044476355649\n",
      "Scaled KL Loss is: 0.03548777848482132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5345322548404703\n",
      "NLL Loss is: 1.4400784976330678\n",
      "Scaled KL Loss is: 0.03743752837181091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4775160260048787\n",
      "NLL Loss is: 1.3647152867963035\n",
      "Scaled KL Loss is: 0.04305972903966904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4077750158359725\n",
      "NLL Loss is: 1.2845883717099036\n",
      "Scaled KL Loss is: 0.03861109912395477\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3231994708338584\n",
      "NLL Loss is: 1.4554187281016402\n",
      "Scaled KL Loss is: 0.038209784775972366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4936285128776126\n",
      "NLL Loss is: 1.3723058153918979\n",
      "Scaled KL Loss is: 0.03901093453168869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4113167499235866\n",
      "NLL Loss is: 1.7180105026849604\n",
      "Scaled KL Loss is: 0.03145118057727814\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7494616832622385\n",
      "NLL Loss is: 1.3769288571954377= 1.416; test loss = 1.453\n",
      "Scaled KL Loss is: 0.042310189455747604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4192390466511853\n",
      "NLL Loss is: 1.4301380223982454\n",
      "Scaled KL Loss is: 0.03956891968846321\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4697069420867086\n",
      "NLL Loss is: 1.417371514993539\n",
      "Scaled KL Loss is: 0.041018642485141754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4583901574786808\n",
      "NLL Loss is: 1.4798048978588443\n",
      "Scaled KL Loss is: 0.0454326756298542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5252375734886985\n",
      "NLL Loss is: 1.3980329645590541\n",
      "Scaled KL Loss is: 0.03653812035918236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4345710849182365\n",
      "NLL Loss is: 1.4636837851406437\n",
      "Scaled KL Loss is: 0.04146875813603401\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5051525432766777\n",
      "NLL Loss is: 1.431254395554457\n",
      "Scaled KL Loss is: 0.03562679886817932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4668811944226363\n",
      "NLL Loss is: 1.3395422342421537\n",
      "Scaled KL Loss is: 0.03865718096494675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3781994152071004\n",
      "NLL Loss is: 1.4088686695634964\n",
      "Scaled KL Loss is: 0.03790982812643051\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446778497689927\n",
      "NLL Loss is: 1.3153885958782576\n",
      "Scaled KL Loss is: 0.04300573840737343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358394334285631\n",
      "NLL Loss is: 1.3169756986926229\n",
      "Scaled KL Loss is: 0.03997557610273361\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569512747953565\n",
      "NLL Loss is: 1.4386860433873319\n",
      "Scaled KL Loss is: 0.03839391469955444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4770799580868863\n",
      "NLL Loss is: 1.325773964255073\n",
      "Scaled KL Loss is: 0.041463322937488556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3672372871925615\n",
      "NLL Loss is: 1.5350386982546156\n",
      "Scaled KL Loss is: 0.04071319103240967\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5757518892870253\n",
      "NLL Loss is: 1.3182354286197753\n",
      "Scaled KL Loss is: 0.04040878638625145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3586442150060267\n",
      "NLL Loss is: 1.494548322922099\n",
      "Scaled KL Loss is: 0.039501093327999115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5340494162500982\n",
      "NLL Loss is: 1.4438791576946561\n",
      "Scaled KL Loss is: 0.03639434650540352\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4802735042000597\n",
      "NLL Loss is: 1.3566851443699859\n",
      "Scaled KL Loss is: 0.04016631096601486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3968514553360007\n",
      "NLL Loss is: 1.306381838551986\n",
      "Scaled KL Loss is: 0.038646258413791656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3450280969657777\n",
      "NLL Loss is: 1.3848693652164483\n",
      "Scaled KL Loss is: 0.03618047013878822\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4210498353552365\n",
      "NLL Loss is: 1.401207408683011\n",
      "Scaled KL Loss is: 0.040554020553827286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4417614292368384\n",
      "NLL Loss is: 1.4270239095495914\n",
      "Scaled KL Loss is: 0.03553532436490059\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.462559233914492\n",
      "NLL Loss is: 1.3290951025167732\n",
      "Scaled KL Loss is: 0.03617557883262634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3652706813493996\n",
      "NLL Loss is: 1.571826205713394\n",
      "Scaled KL Loss is: 0.041747212409973145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6135734181233672\n",
      "NLL Loss is: 1.2004114315205607\n",
      "Scaled KL Loss is: 0.039068009704351425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2394794412249122\n",
      "NLL Loss is: 1.3416923513010373\n",
      "Scaled KL Loss is: 0.0420147180557251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3837070693567624\n",
      "NLL Loss is: 1.4026193627892376\n",
      "Scaled KL Loss is: 0.04203733801841736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444656700807655\n",
      "NLL Loss is: 1.2124863826496104\n",
      "Scaled KL Loss is: 0.03954882547259331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2520352081222037\n",
      "NLL Loss is: 1.37339452754251\n",
      "Scaled KL Loss is: 0.03998318314552307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.413377710688033\n",
      "NLL Loss is: 1.2328253634516835\n",
      "Scaled KL Loss is: 0.04039495810866356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.273220321560347\n",
      "NLL Loss is: 1.2410363350667786\n",
      "Scaled KL Loss is: 0.0380217507481575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.279058085814936\n",
      "NLL Loss is: 1.4085250220625811\n",
      "Scaled KL Loss is: 0.03989449143409729\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4484195134966784\n",
      "NLL Loss is: 1.4166516559412903\n",
      "Scaled KL Loss is: 0.039139192551374435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4557908484926647\n",
      "NLL Loss is: 1.3073632477841641\n",
      "Scaled KL Loss is: 0.03922722488641739\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3465904726705815\n",
      "NLL Loss is: 1.4981885666087111\n",
      "Scaled KL Loss is: 0.03862472623586655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5368132928445777\n",
      "NLL Loss is: 1.5178307021724786\n",
      "Scaled KL Loss is: 0.03993159905076027\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5577623012232389\n",
      "NLL Loss is: 1.2976310592142228\n",
      "Scaled KL Loss is: 0.04510677605867386\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3427378352728967\n",
      "NLL Loss is: 1.2629833583732664\n",
      "Scaled KL Loss is: 0.04003499448299408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3030183528562604\n",
      "NLL Loss is: 1.424038537918269\n",
      "Scaled KL Loss is: 0.03972797095775604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.463766508876025\n",
      "NLL Loss is: 1.5152544517501991\n",
      "Scaled KL Loss is: 0.041400279849767685\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5566547315999668\n",
      "NLL Loss is: 1.2982968767548988\n",
      "Scaled KL Loss is: 0.041769370436668396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3400662471915672\n",
      "NLL Loss is: 1.2896057088668778\n",
      "Scaled KL Loss is: 0.03683902323246002\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3264447320993378\n",
      "NLL Loss is: 1.3031348425293259\n",
      "Scaled KL Loss is: 0.03900258615612984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3421374286854557\n",
      "NLL Loss is: 1.3055815021112465\n",
      "Scaled KL Loss is: 0.047498688101768494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353080190213015\n",
      "NLL Loss is: 1.3858522858073263\n",
      "Scaled KL Loss is: 0.039087481796741486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4249397676040678\n",
      "NLL Loss is: 1.302739732176077\n",
      "Scaled KL Loss is: 0.04084102436900139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3435807565450784\n",
      "NLL Loss is: 1.3172486600505762\n",
      "Scaled KL Loss is: 0.04285823553800583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360106895588582\n",
      "NLL Loss is: 1.2422529822109012\n",
      "Scaled KL Loss is: 0.04105312377214432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2833061059830455\n",
      "NLL Loss is: 1.3301218372699526\n",
      "Scaled KL Loss is: 0.04311053827404976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3732323755440023\n",
      "NLL Loss is: 1.2979438296832826\n",
      "Scaled KL Loss is: 0.04083940386772156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3387832335510041\n",
      "NLL Loss is: 1.3702443856418274\n",
      "Scaled KL Loss is: 0.041385650634765625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.411630036276593\n",
      "NLL Loss is: 1.3727252422965308\n",
      "Scaled KL Loss is: 0.04005693271756172\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4127821750140925\n",
      "NLL Loss is: 1.282678072226365\n",
      "Scaled KL Loss is: 0.04382048174738884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.326498553973754\n",
      "NLL Loss is: 1.3971790881205084\n",
      "Scaled KL Loss is: 0.037149157375097275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4343282454956057\n",
      "NLL Loss is: 1.4276914069701894\n",
      "Scaled KL Loss is: 0.038231514394283295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4659229213644727\n",
      "NLL Loss is: 1.4492765881539227\n",
      "Scaled KL Loss is: 0.037101708352565765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4863782965064885\n",
      "NLL Loss is: 1.453593236122162\n",
      "Scaled KL Loss is: 0.04214295744895935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4957361935711213\n",
      "NLL Loss is: 1.3214955706047085\n",
      "Scaled KL Loss is: 0.0413597896695137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3628553602742222\n",
      "NLL Loss is: 1.2964943341071085\n",
      "Scaled KL Loss is: 0.03681078925728798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3333051233643964\n",
      "NLL Loss is: 1.2479542672293353\n",
      "Scaled KL Loss is: 0.044232018291950226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2921862855212856\n",
      "NLL Loss is: 1.3436864873123882\n",
      "Scaled KL Loss is: 0.040115393698215485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3838018810106036\n",
      "NLL Loss is: 1.3824426501179703\n",
      "Scaled KL Loss is: 0.041442036628723145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4238846867466934\n",
      "NLL Loss is: 1.441514795121453\n",
      "Scaled KL Loss is: 0.04048144072294235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4819962358443954\n",
      "NLL Loss is: 1.3311952443851538\n",
      "Scaled KL Loss is: 0.03808398172259331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.369279226107747\n",
      "NLL Loss is: 1.365885636279191\n",
      "Scaled KL Loss is: 0.038363393396139145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40424902967533\n",
      "NLL Loss is: 1.426062954763973\n",
      "Scaled KL Loss is: 0.03906397148966789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4651269262536408\n",
      "NLL Loss is: 1.4385845954629917\n",
      "Scaled KL Loss is: 0.03917776048183441\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.477762355944826\n",
      "NLL Loss is: 1.4018911473865636\n",
      "Scaled KL Loss is: 0.040920909494161606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4428120568807252\n",
      "NLL Loss is: 1.3705544567727137\n",
      "Scaled KL Loss is: 0.04398353025317192\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4145379870258856\n",
      "NLL Loss is: 1.348529994059564\n",
      "Scaled KL Loss is: 0.039705779403448105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3882357734630122\n",
      "NLL Loss is: 1.4982230790628643\n",
      "Scaled KL Loss is: 0.040903981775045395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5391270608379097\n",
      "NLL Loss is: 1.3960989256334992\n",
      "Scaled KL Loss is: 0.037465475499629974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4335644011331292\n",
      "NLL Loss is: 1.4185233377110615\n",
      "Scaled KL Loss is: 0.043022193014621735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4615455307256833\n",
      "NLL Loss is: 1.37363888177102\n",
      "Scaled KL Loss is: 0.04001303017139435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4136519119424142\n",
      "NLL Loss is: 1.4741580086261297\n",
      "Scaled KL Loss is: 0.03903045505285263\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5131884636789823\n",
      "NLL Loss is: 1.3197882943488866\n",
      "Scaled KL Loss is: 0.03720073401927948\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356989028368166\n",
      "NLL Loss is: 1.4809025025062947\n",
      "Scaled KL Loss is: 0.04037179797887802\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5212743004851728\n",
      "NLL Loss is: 1.4402190019235916\n",
      "Scaled KL Loss is: 0.037468064576387405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.477687066499979\n",
      "NLL Loss is: 1.3635895937165734\n",
      "Scaled KL Loss is: 0.043312907218933105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4069025009355065\n",
      "NLL Loss is: 1.3334497720745764\n",
      "Scaled KL Loss is: 0.04037390276789665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.373823674842473\n",
      "NLL Loss is: 1.4146387281370176\n",
      "Scaled KL Loss is: 0.0387602224946022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4533989506316198\n",
      "NLL Loss is: 1.30610152563931\n",
      "Scaled KL Loss is: 0.04211445897817612\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3482159846174862\n",
      "NLL Loss is: 1.382399490515014\n",
      "Scaled KL Loss is: 0.03714979812502861\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4195492886400427\n",
      "NLL Loss is: 1.324121225994711\n",
      "Scaled KL Loss is: 0.04252289608120918\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3666441220759202\n",
      "NLL Loss is: 1.468847575029231\n",
      "Scaled KL Loss is: 0.041991546750068665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5108391217792996\n",
      "NLL Loss is: 1.4963834689227034\n",
      "Scaled KL Loss is: 0.03517100214958191\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5315544710722853\n",
      "NLL Loss is: 1.4370609326390533\n",
      "Scaled KL Loss is: 0.03682197630405426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4738829089431076\n",
      "NLL Loss is: 1.3611882632532575\n",
      "Scaled KL Loss is: 0.04235533997416496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4035436032274224\n",
      "NLL Loss is: 1.283480553131219\n",
      "Scaled KL Loss is: 0.037994664162397385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3214752172936164\n",
      "NLL Loss is: 1.4551790131288544\n",
      "Scaled KL Loss is: 0.03774472698569298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4929237401145474\n",
      "NLL Loss is: 1.3681729698214895\n",
      "Scaled KL Loss is: 0.03853738307952881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4067103529010183\n",
      "NLL Loss is: 1.7150825969577825\n",
      "Scaled KL Loss is: 0.031010163947939873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7460927609057224\n",
      "NLL Loss is: 1.373704552352525 = 1.413; test loss = 1.449\n",
      "Scaled KL Loss is: 0.04165985435247421\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4153644067049993\n",
      "NLL Loss is: 1.4275258436280882\n",
      "Scaled KL Loss is: 0.03888795152306557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4664137951511538\n",
      "NLL Loss is: 1.4165518549015266\n",
      "Scaled KL Loss is: 0.04038124904036522\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4569331039418918\n",
      "NLL Loss is: 1.4747466103210451\n",
      "Scaled KL Loss is: 0.044559914618730545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5193065249397757\n",
      "NLL Loss is: 1.3959453664954042\n",
      "Scaled KL Loss is: 0.035959042608737946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4319044091041422\n",
      "NLL Loss is: 1.4590385045722813\n",
      "Scaled KL Loss is: 0.040863052010536194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4999015565828175\n",
      "NLL Loss is: 1.4293515553697136\n",
      "Scaled KL Loss is: 0.03507358953356743\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.464425144903281\n",
      "NLL Loss is: 1.3393654495832588\n",
      "Scaled KL Loss is: 0.037899501621723175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377264951204982\n",
      "NLL Loss is: 1.407802073231091\n",
      "Scaled KL Loss is: 0.03717731684446335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4449793900755543\n",
      "NLL Loss is: 1.314319676018122\n",
      "Scaled KL Loss is: 0.04231204092502594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3566317169431479\n",
      "NLL Loss is: 1.3160373224807496\n",
      "Scaled KL Loss is: 0.03904759883880615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3550849213195557\n",
      "NLL Loss is: 1.4369411463381556\n",
      "Scaled KL Loss is: 0.03787093237042427\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4748120787085799\n",
      "NLL Loss is: 1.323504634768058\n",
      "Scaled KL Loss is: 0.04095422476530075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3644588595333587\n",
      "NLL Loss is: 1.5322338694894746\n",
      "Scaled KL Loss is: 0.0400858148932457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5723196843827203\n",
      "NLL Loss is: 1.3175119892598124\n",
      "Scaled KL Loss is: 0.03963109105825424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571430803180666\n",
      "NLL Loss is: 1.492641140998456\n",
      "Scaled KL Loss is: 0.03916117921471596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5318023202131719\n",
      "NLL Loss is: 1.4406136145339863\n",
      "Scaled KL Loss is: 0.03605150058865547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4766651151226418\n",
      "NLL Loss is: 1.3555419112062137\n",
      "Scaled KL Loss is: 0.03955625370144844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3950981649076621\n",
      "NLL Loss is: 1.3051029302931767\n",
      "Scaled KL Loss is: 0.03814425319433212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3432471834875088\n",
      "NLL Loss is: 1.3838448551423468\n",
      "Scaled KL Loss is: 0.035755254328250885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4196001094705977\n",
      "NLL Loss is: 1.3961919598011434\n",
      "Scaled KL Loss is: 0.03977964073419571\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4359716005353391\n",
      "NLL Loss is: 1.42319480457544\n",
      "Scaled KL Loss is: 0.03513208404183388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4583268886172738\n",
      "NLL Loss is: 1.3274739172460333\n",
      "Scaled KL Loss is: 0.0357762910425663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3632502082885996\n",
      "NLL Loss is: 1.5710584695596663\n",
      "Scaled KL Loss is: 0.04112067446112633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6121791440207927\n",
      "NLL Loss is: 1.2003276099712452\n",
      "Scaled KL Loss is: 0.03846437484025955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2387919848115048\n",
      "NLL Loss is: 1.3390771513241093\n",
      "Scaled KL Loss is: 0.041524291038513184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3806014423626225\n",
      "NLL Loss is: 1.400338746751561\n",
      "Scaled KL Loss is: 0.04161032661795616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441949073369517\n",
      "NLL Loss is: 1.2091341836502716\n",
      "Scaled KL Loss is: 0.03918921947479248\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.248323403125064\n",
      "NLL Loss is: 1.3708936260436826\n",
      "Scaled KL Loss is: 0.03946078568696976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4103544117306523\n",
      "NLL Loss is: 1.230463698747595\n",
      "Scaled KL Loss is: 0.039829205721616745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2702929044692117\n",
      "NLL Loss is: 1.238601897207984\n",
      "Scaled KL Loss is: 0.03735058754682541\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2759524847548094\n",
      "NLL Loss is: 1.404269550555145\n",
      "Scaled KL Loss is: 0.03930558264255524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4435751331977003\n",
      "NLL Loss is: 1.4122964700585063\n",
      "Scaled KL Loss is: 0.038420990109443665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.45071746016795\n",
      "NLL Loss is: 1.3042951118353425\n",
      "Scaled KL Loss is: 0.038573190569877625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3428683024052201\n",
      "NLL Loss is: 1.4942271014986415\n",
      "Scaled KL Loss is: 0.03810637444257736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5323334759412188\n",
      "NLL Loss is: 1.513749732576117\n",
      "Scaled KL Loss is: 0.03922339901328087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5529731315893978\n",
      "NLL Loss is: 1.295568747450805\n",
      "Scaled KL Loss is: 0.044529981911182404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3400987293619875\n",
      "NLL Loss is: 1.261735084889679\n",
      "Scaled KL Loss is: 0.039620816707611084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.30135590159729\n",
      "NLL Loss is: 1.4209377816158184\n",
      "Scaled KL Loss is: 0.03915301337838173\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4600907949942001\n",
      "NLL Loss is: 1.5123017177776603\n",
      "Scaled KL Loss is: 0.04073713347315788\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5530388512508182\n",
      "NLL Loss is: 1.2925489551675333\n",
      "Scaled KL Loss is: 0.041080817580223083\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336297727477564\n",
      "NLL Loss is: 1.2855635581513005\n",
      "Scaled KL Loss is: 0.03623417392373085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3217977320750314\n",
      "NLL Loss is: 1.3007005360476072\n",
      "Scaled KL Loss is: 0.03860541433095932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3393059503785665\n",
      "NLL Loss is: 1.3018017124937398\n",
      "Scaled KL Loss is: 0.046818383038043976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3486200955317837\n",
      "NLL Loss is: 1.3827214924011997\n",
      "Scaled KL Loss is: 0.038418952375650406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.42114044477685\n",
      "NLL Loss is: 1.300973858803032\n",
      "Scaled KL Loss is: 0.040335629135370255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3413094879384022\n",
      "NLL Loss is: 1.3160860771192893\n",
      "Scaled KL Loss is: 0.0422978401184082\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3583839172376975\n",
      "NLL Loss is: 1.2388422268432664\n",
      "Scaled KL Loss is: 0.04075895994901657\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.279601186792283\n",
      "NLL Loss is: 1.3274850105247336\n",
      "Scaled KL Loss is: 0.042468685656785965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3699536961815195\n",
      "NLL Loss is: 1.2947123855490335\n",
      "Scaled KL Loss is: 0.04025822505354881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3349706106025823\n",
      "NLL Loss is: 1.36797649522261\n",
      "Scaled KL Loss is: 0.04086914286017418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408845638082784\n",
      "NLL Loss is: 1.3698555953978144\n",
      "Scaled KL Loss is: 0.03938006982207298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4092356652198874\n",
      "NLL Loss is: 1.2800190589864249\n",
      "Scaled KL Loss is: 0.04307808727025986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3230971462566847\n",
      "NLL Loss is: 1.3953310229865128\n",
      "Scaled KL Loss is: 0.036707423627376556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4320384466138893\n",
      "NLL Loss is: 1.4270736491740248\n",
      "Scaled KL Loss is: 0.03769245371222496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4647661028862498\n",
      "NLL Loss is: 1.4464595816094192\n",
      "Scaled KL Loss is: 0.03654811903834343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4830077006477627\n",
      "NLL Loss is: 1.4513886304979315\n",
      "Scaled KL Loss is: 0.041537702083587646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4929263325815192\n",
      "NLL Loss is: 1.3195099024199737\n",
      "Scaled KL Loss is: 0.04060434177517891\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3601142441951526\n",
      "NLL Loss is: 1.2954864501473333\n",
      "Scaled KL Loss is: 0.036312513053417206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3317989632007505\n",
      "NLL Loss is: 1.2445603251064816\n",
      "Scaled KL Loss is: 0.04347124323248863\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2880315683389703\n",
      "NLL Loss is: 1.340715048637383\n",
      "Scaled KL Loss is: 0.03961043804883957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3803254866862225\n",
      "NLL Loss is: 1.3785038942129075\n",
      "Scaled KL Loss is: 0.04073506221175194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4192389564246595\n",
      "NLL Loss is: 1.4393830598386785\n",
      "Scaled KL Loss is: 0.03982781618833542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.479210876027014\n",
      "NLL Loss is: 1.3292842699872391\n",
      "Scaled KL Loss is: 0.03768070042133331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3669649704085725\n",
      "NLL Loss is: 1.3635412379369307\n",
      "Scaled KL Loss is: 0.037742115557193756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4012833534941245\n",
      "NLL Loss is: 1.42534791732467\n",
      "Scaled KL Loss is: 0.038519103080034256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4638670204047042\n",
      "NLL Loss is: 1.4361215722095961\n",
      "Scaled KL Loss is: 0.038735855370759964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.474857427580356\n",
      "NLL Loss is: 1.3993873106285108\n",
      "Scaled KL Loss is: 0.04022344574332237\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4396107563718332\n",
      "NLL Loss is: 1.3678663668476545\n",
      "Scaled KL Loss is: 0.04332321137189865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4111895782195532\n",
      "NLL Loss is: 1.3458622659180646\n",
      "Scaled KL Loss is: 0.039105214178562164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3849674800966267\n",
      "NLL Loss is: 1.495479262310742\n",
      "Scaled KL Loss is: 0.040297649800777435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5357769121115195\n",
      "NLL Loss is: 1.3937096404397413\n",
      "Scaled KL Loss is: 0.036907508969306946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4306171494090483\n",
      "NLL Loss is: 1.4138939500117718\n",
      "Scaled KL Loss is: 0.04242687299847603\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4563208230102478\n",
      "NLL Loss is: 1.3722985809528734\n",
      "Scaled KL Loss is: 0.03950434923171997\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4118029301845934\n",
      "NLL Loss is: 1.4719742761066426\n",
      "Scaled KL Loss is: 0.03848201781511307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5104562939217556\n",
      "NLL Loss is: 1.3178327608340885\n",
      "Scaled KL Loss is: 0.03659684211015701\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544296029442455\n",
      "NLL Loss is: 1.4782220471751506\n",
      "Scaled KL Loss is: 0.039599597454071045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5178216446292216\n",
      "NLL Loss is: 1.437773020200191\n",
      "Scaled KL Loss is: 0.037033483386039734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4748065035862308\n",
      "NLL Loss is: 1.3629088141443708\n",
      "Scaled KL Loss is: 0.04239673912525177\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4053055532696226\n",
      "NLL Loss is: 1.3307504333586555\n",
      "Scaled KL Loss is: 0.03955009579658508\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3703005291552406\n",
      "NLL Loss is: 1.411903983190986\n",
      "Scaled KL Loss is: 0.03816119581460953\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4500651790055956\n",
      "NLL Loss is: 1.3023239445113663\n",
      "Scaled KL Loss is: 0.04144108295440674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343765027465773\n",
      "NLL Loss is: 1.3812777951430886\n",
      "Scaled KL Loss is: 0.036502718925476074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4177805140685646\n",
      "NLL Loss is: 1.3190602529455822\n",
      "Scaled KL Loss is: 0.041856564581394196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3609168175269764\n",
      "NLL Loss is: 1.4633830849618699\n",
      "Scaled KL Loss is: 0.04127654805779457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5046596330196644\n",
      "NLL Loss is: 1.4937541568010837\n",
      "Scaled KL Loss is: 0.034901831299066544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5286559881001502\n",
      "NLL Loss is: 1.4339413484892136\n",
      "Scaled KL Loss is: 0.036239441484212875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4701807899734265\n",
      "NLL Loss is: 1.357643501679466\n",
      "Scaled KL Loss is: 0.04168945550918579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3993329571886517\n",
      "NLL Loss is: 1.2822559651784502\n",
      "Scaled KL Loss is: 0.037423208355903625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3196791735343538\n",
      "NLL Loss is: 1.4548762813244993\n",
      "Scaled KL Loss is: 0.037329137325286865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4922054186497862\n",
      "NLL Loss is: 1.3639939163890273\n",
      "Scaled KL Loss is: 0.03810428828001022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4020982046690376\n",
      "NLL Loss is: 1.7119330158700081\n",
      "Scaled KL Loss is: 0.03060934692621231\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7425423627962204\n",
      "NLL Loss is: 1.3704954905075426= 1.410; test loss = 1.446\n",
      "Scaled KL Loss is: 0.04104449227452278\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4115399827820654\n",
      "NLL Loss is: 1.4249573281787524\n",
      "Scaled KL Loss is: 0.03824470564723015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4632020338259826\n",
      "NLL Loss is: 1.4156846879093237\n",
      "Scaled KL Loss is: 0.0397857204079628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4554704083172865\n",
      "NLL Loss is: 1.4698437402603366\n",
      "Scaled KL Loss is: 0.04372665286064148\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.513570393120978\n",
      "NLL Loss is: 1.3939066305298171\n",
      "Scaled KL Loss is: 0.03542548045516014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4293321109849773\n",
      "NLL Loss is: 1.4542859375821735\n",
      "Scaled KL Loss is: 0.04029025137424469\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4945761889564182\n",
      "NLL Loss is: 1.4273955077044402\n",
      "Scaled KL Loss is: 0.034563954919576645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4619594626240169\n",
      "NLL Loss is: 1.3392664876913891\n",
      "Scaled KL Loss is: 0.03717915341258049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3764456411039696\n",
      "NLL Loss is: 1.4067788232602556\n",
      "Scaled KL Loss is: 0.036489084362983704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4432679076232393\n",
      "NLL Loss is: 1.3132989723943773\n",
      "Scaled KL Loss is: 0.0416632704436779\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3549622428380552\n",
      "NLL Loss is: 1.3151492600154093\n",
      "Scaled KL Loss is: 0.03816269710659981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3533119571220091\n",
      "NLL Loss is: 1.4352610055815511\n",
      "Scaled KL Loss is: 0.037393610924482346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4726546165060335\n",
      "NLL Loss is: 1.3211268566143488\n",
      "Scaled KL Loss is: 0.040498726069927216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361625582684276\n",
      "NLL Loss is: 1.5292239649021866\n",
      "Scaled KL Loss is: 0.039502646774053574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5687266116762402\n",
      "NLL Loss is: 1.31674734574243\n",
      "Scaled KL Loss is: 0.03890464827418327\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3556519940166132\n",
      "NLL Loss is: 1.4906092441981156\n",
      "Scaled KL Loss is: 0.038875699043273926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5294849432413895\n",
      "NLL Loss is: 1.4372935613072395\n",
      "Scaled KL Loss is: 0.035761795938014984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4730553572452545\n",
      "NLL Loss is: 1.3543703678102366\n",
      "Scaled KL Loss is: 0.03899567201733589\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3933660398275725\n",
      "NLL Loss is: 1.3038485426462967\n",
      "Scaled KL Loss is: 0.03769826516509056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3415468078113872\n",
      "NLL Loss is: 1.3828514354752135\n",
      "Scaled KL Loss is: 0.03538456931710243\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418236004792316\n",
      "NLL Loss is: 1.391340666105469\n",
      "Scaled KL Loss is: 0.03905537351965904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.430396039625128\n",
      "NLL Loss is: 1.4194075282540504\n",
      "Scaled KL Loss is: 0.03478366136550903\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4541911896195594\n",
      "NLL Loss is: 1.3258603137887202\n",
      "Scaled KL Loss is: 0.03543735295534134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3612976667440615\n",
      "NLL Loss is: 1.5701389026364918\n",
      "Scaled KL Loss is: 0.040553100407123566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6106920030436154\n",
      "NLL Loss is: 1.2003109212054275\n",
      "Scaled KL Loss is: 0.03792238235473633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2382333035601638\n",
      "NLL Loss is: 1.3366382406292914\n",
      "Scaled KL Loss is: 0.04109171777963638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3777299584089278\n",
      "NLL Loss is: 1.398058808271914\n",
      "Scaled KL Loss is: 0.04124097898602486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.439299787257939\n",
      "NLL Loss is: 1.2060537522289791\n",
      "Scaled KL Loss is: 0.038884807378053665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2449385596070328\n",
      "NLL Loss is: 1.3684800765092995\n",
      "Scaled KL Loss is: 0.03899629786610603\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4074763743754055\n",
      "NLL Loss is: 1.228005517138776\n",
      "Scaled KL Loss is: 0.03932429850101471\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2673298156397907\n",
      "NLL Loss is: 1.236183554086786\n",
      "Scaled KL Loss is: 0.03673907369375229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2729226277805383\n",
      "NLL Loss is: 1.400060277389524\n",
      "Scaled KL Loss is: 0.03877311572432518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4388333931138493\n",
      "NLL Loss is: 1.408082410686591\n",
      "Scaled KL Loss is: 0.03776049613952637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4458429068261174\n",
      "NLL Loss is: 1.3014138351050764\n",
      "Scaled KL Loss is: 0.03797702118754387\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3393908562926202\n",
      "NLL Loss is: 1.4903501848294158\n",
      "Scaled KL Loss is: 0.03764369711279869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5279938819422145\n",
      "NLL Loss is: 1.5096409800015191\n",
      "Scaled KL Loss is: 0.038575444370508194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5482164243720273\n",
      "NLL Loss is: 1.2935842374970046\n",
      "Scaled KL Loss is: 0.04400787129998207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3375921087969866\n",
      "NLL Loss is: 1.2605218349905467\n",
      "Scaled KL Loss is: 0.039262719452381134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2997845544429278\n",
      "NLL Loss is: 1.4177399678891276\n",
      "Scaled KL Loss is: 0.03863392397761345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.456373891866741\n",
      "NLL Loss is: 1.5094184483185455\n",
      "Scaled KL Loss is: 0.040125492960214615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5495439412787602\n",
      "NLL Loss is: 1.28680218730734\n",
      "Scaled KL Loss is: 0.04044627025723457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3272484575645747\n",
      "NLL Loss is: 1.281451730536106\n",
      "Scaled KL Loss is: 0.03568281605839729\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3171345465945032\n",
      "NLL Loss is: 1.298243885813356\n",
      "Scaled KL Loss is: 0.03826422616839409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3365081119817501\n",
      "NLL Loss is: 1.297744423849362\n",
      "Scaled KL Loss is: 0.046184662729501724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3439290865788638\n",
      "NLL Loss is: 1.3795898013088062\n",
      "Scaled KL Loss is: 0.037801433354616165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4173912346634223\n",
      "NLL Loss is: 1.299134691521293\n",
      "Scaled KL Loss is: 0.03988739103078842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3390220825520813\n",
      "NLL Loss is: 1.3148632082254448\n",
      "Scaled KL Loss is: 0.041790593415498734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3566538016409435\n",
      "NLL Loss is: 1.2353582701994776\n",
      "Scaled KL Loss is: 0.040519677102565765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2758779473020434\n",
      "NLL Loss is: 1.3249243062701663\n",
      "Scaled KL Loss is: 0.04188103973865509\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3668053460088214\n",
      "NLL Loss is: 1.29141183427362\n",
      "Scaled KL Loss is: 0.03972787410020828\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3311397083738283\n",
      "NLL Loss is: 1.3656872033715701\n",
      "Scaled KL Loss is: 0.040404949337244034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4060921527088142\n",
      "NLL Loss is: 1.367127617801121\n",
      "Scaled KL Loss is: 0.03875546529889107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405883083100012\n",
      "NLL Loss is: 1.2774472151251732\n",
      "Scaled KL Loss is: 0.042387455701828\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3198346708270012\n",
      "NLL Loss is: 1.3932672881629937\n",
      "Scaled KL Loss is: 0.03631475940346718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.429582047566461\n",
      "NLL Loss is: 1.4263148196862026\n",
      "Scaled KL Loss is: 0.03720930591225624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4635241255984588\n",
      "NLL Loss is: 1.4436719705760015\n",
      "Scaled KL Loss is: 0.03604990988969803\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4797218804656995\n",
      "NLL Loss is: 1.4491965254559123\n",
      "Scaled KL Loss is: 0.04098603501915932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4901825604750716\n",
      "NLL Loss is: 1.3176366189332476\n",
      "Scaled KL Loss is: 0.039902813732624054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3575394326658716\n",
      "NLL Loss is: 1.2944101402532902\n",
      "Scaled KL Loss is: 0.03587263450026512\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3302827747535553\n",
      "NLL Loss is: 1.241246781623297\n",
      "Scaled KL Loss is: 0.042766354978084564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840131366013816\n",
      "NLL Loss is: 1.3379602366526298\n",
      "Scaled KL Loss is: 0.03916090726852417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377121143921154\n",
      "NLL Loss is: 1.374515195554169\n",
      "Scaled KL Loss is: 0.0400845892727375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4145997848269065\n",
      "NLL Loss is: 1.4369358928103702\n",
      "Scaled KL Loss is: 0.03923104330897331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4761669361193435\n",
      "NLL Loss is: 1.327570442792306\n",
      "Scaled KL Loss is: 0.03733706474304199\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.364907507535348\n",
      "NLL Loss is: 1.361149175324386\n",
      "Scaled KL Loss is: 0.03718213737010956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3983313126944956\n",
      "NLL Loss is: 1.424023728336079\n",
      "Scaled KL Loss is: 0.03803528472781181\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4620590130638909\n",
      "NLL Loss is: 1.4337141596002179\n",
      "Scaled KL Loss is: 0.0383528433740139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4720670029742318\n",
      "NLL Loss is: 1.396987526872672\n",
      "Scaled KL Loss is: 0.039581332355737686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4365688592284096\n",
      "NLL Loss is: 1.3652080859126783\n",
      "Scaled KL Loss is: 0.042724765837192535\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4079328517498708\n",
      "NLL Loss is: 1.3430407410998677\n",
      "Scaled KL Loss is: 0.03856619447469711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3816069355745648\n",
      "NLL Loss is: 1.4928197450145746\n",
      "Scaled KL Loss is: 0.03975485637784004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5325746013924146\n",
      "NLL Loss is: 1.391430540839319\n",
      "Scaled KL Loss is: 0.03641548752784729\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4278460283671663\n",
      "NLL Loss is: 1.4093983428829535\n",
      "Scaled KL Loss is: 0.041888222098350525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.451286564981304\n",
      "NLL Loss is: 1.370856517665723\n",
      "Scaled KL Loss is: 0.039056699723005295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099132173887283\n",
      "NLL Loss is: 1.4700158100276652\n",
      "Scaled KL Loss is: 0.037996336817741394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5080121468454066\n",
      "NLL Loss is: 1.3160509547226462\n",
      "Scaled KL Loss is: 0.03605644404888153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3521073987715277\n",
      "NLL Loss is: 1.475541466439613\n",
      "Scaled KL Loss is: 0.03888990357518196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5144313700147949\n",
      "NLL Loss is: 1.434420171907228\n",
      "Scaled KL Loss is: 0.03665618598461151\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4710763578918395\n",
      "NLL Loss is: 1.3623040220424878\n",
      "Scaled KL Loss is: 0.04154350236058235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4038475244030701\n",
      "NLL Loss is: 1.327968473575714\n",
      "Scaled KL Loss is: 0.03879474848508835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3667632220608024\n",
      "NLL Loss is: 1.40918177628268\n",
      "Scaled KL Loss is: 0.037624798715114594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4468065749977945\n",
      "NLL Loss is: 1.2985460260297634\n",
      "Scaled KL Loss is: 0.040831927210092545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.339377953239856\n",
      "NLL Loss is: 1.3801864996372932\n",
      "Scaled KL Loss is: 0.03591768816113472\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416104187798428\n",
      "NLL Loss is: 1.3142055298921747\n",
      "Scaled KL Loss is: 0.041249461472034454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355454991364209\n",
      "NLL Loss is: 1.4579192308467548\n",
      "Scaled KL Loss is: 0.04062284901738167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4985420798641365\n",
      "NLL Loss is: 1.4910517864126416\n",
      "Scaled KL Loss is: 0.03469439968466759\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5257461860973092\n",
      "NLL Loss is: 1.4306398293368694\n",
      "Scaled KL Loss is: 0.035714805126190186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4663546344630596\n",
      "NLL Loss is: 1.3542839539674139\n",
      "Scaled KL Loss is: 0.04108082503080368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3953647789982175\n",
      "NLL Loss is: 1.281133155795743\n",
      "Scaled KL Loss is: 0.036916058510541916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318049214306285\n",
      "NLL Loss is: 1.4545147468656432\n",
      "Scaled KL Loss is: 0.03697548806667328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4914902349323165\n",
      "NLL Loss is: 1.3599349184437974\n",
      "Scaled KL Loss is: 0.03773178905248642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3976667074962839\n",
      "NLL Loss is: 1.7090027105908643\n",
      "Scaled KL Loss is: 0.030267229303717613\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.739269939894582\n",
      "NLL Loss is: 1.3673975527748512= 1.407; test loss = 1.443\n",
      "Scaled KL Loss is: 0.04048765078186989\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.407885203556721\n",
      "NLL Loss is: 1.422483258973026\n",
      "Scaled KL Loss is: 0.037660978734493256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4601442377075193\n",
      "NLL Loss is: 1.4143526678298153\n",
      "Scaled KL Loss is: 0.0392494723200798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.453602140149895\n",
      "NLL Loss is: 1.464880353198135\n",
      "Scaled KL Loss is: 0.04295959696173668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5078399501598716\n",
      "NLL Loss is: 1.3915595912703547\n",
      "Scaled KL Loss is: 0.034961383789777756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4265209750601324\n",
      "NLL Loss is: 1.450344166977214\n",
      "Scaled KL Loss is: 0.03979383036494255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4901379973421565\n",
      "NLL Loss is: 1.4254211500424534\n",
      "Scaled KL Loss is: 0.03413211181759834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4595532618600517\n",
      "NLL Loss is: 1.3394754746937338\n",
      "Scaled KL Loss is: 0.03654146566987038\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3760169403636042\n",
      "NLL Loss is: 1.4064744072749824\n",
      "Scaled KL Loss is: 0.03588707000017166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.442361477275154\n",
      "NLL Loss is: 1.3119024971087203\n",
      "Scaled KL Loss is: 0.04108935222029686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3529918493290172\n",
      "NLL Loss is: 1.314134063367077\n",
      "Scaled KL Loss is: 0.037362538278102875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35149660164518\n",
      "NLL Loss is: 1.4335563341760877\n",
      "Scaled KL Loss is: 0.03698699548840523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.470543329664493\n",
      "NLL Loss is: 1.3193372843477045\n",
      "Scaled KL Loss is: 0.04010048881173134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3594377731594358\n",
      "NLL Loss is: 1.5252165771364914\n",
      "Scaled KL Loss is: 0.0389997735619545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.564216350698446\n",
      "NLL Loss is: 1.3161207302168114\n",
      "Scaled KL Loss is: 0.038253042846918106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3543737730637295\n",
      "NLL Loss is: 1.4873852824812126\n",
      "Scaled KL Loss is: 0.03866647183895111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5260517543201637\n",
      "NLL Loss is: 1.4343423696083573\n",
      "Scaled KL Loss is: 0.0355382077395916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4698805773479489\n",
      "NLL Loss is: 1.3528013752471832\n",
      "Scaled KL Loss is: 0.03851449862122536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3913158738684086\n",
      "NLL Loss is: 1.3000667413150664\n",
      "Scaled KL Loss is: 0.037322405725717545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.337389147040784\n",
      "NLL Loss is: 1.3806706011108645\n",
      "Scaled KL Loss is: 0.03509123623371124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4157618373445757\n",
      "NLL Loss is: 1.3868363305712998\n",
      "Scaled KL Loss is: 0.03840791806578636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4252442486370862\n",
      "NLL Loss is: 1.4158683164991188\n",
      "Scaled KL Loss is: 0.034504566341638565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4503728828407574\n",
      "NLL Loss is: 1.3242941898328353\n",
      "Scaled KL Loss is: 0.03517124801874161\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359465437851577\n",
      "NLL Loss is: 1.5691414801985673\n",
      "Scaled KL Loss is: 0.040051136165857315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6091926163644246\n",
      "NLL Loss is: 1.200266316537842\n",
      "Scaled KL Loss is: 0.0374470092356205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2377133257734625\n",
      "NLL Loss is: 1.334433849682965\n",
      "Scaled KL Loss is: 0.04071348160505295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375147331288018\n",
      "NLL Loss is: 1.3956756386733735\n",
      "Scaled KL Loss is: 0.04093077406287193\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4366064127362455\n",
      "NLL Loss is: 1.2025371769018465\n",
      "Scaled KL Loss is: 0.03863544017076492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2411726170726114\n",
      "NLL Loss is: 1.3660504232086401\n",
      "Scaled KL Loss is: 0.03858324885368347\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4046336720623236\n",
      "NLL Loss is: 1.2254738493966506\n",
      "Scaled KL Loss is: 0.03887466713786125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2643485165345119\n",
      "NLL Loss is: 1.2332605126238452\n",
      "Scaled KL Loss is: 0.03617860749363899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2694391201174842\n",
      "NLL Loss is: 1.3957714949137607\n",
      "Scaled KL Loss is: 0.038290560245513916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4340620551592747\n",
      "NLL Loss is: 1.4037807904142363\n",
      "Scaled KL Loss is: 0.03715083375573158\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440931624169968\n",
      "NLL Loss is: 1.2981439012875575\n",
      "Scaled KL Loss is: 0.037431810051202774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3355757113387603\n",
      "NLL Loss is: 1.4860797830329762\n",
      "Scaled KL Loss is: 0.03723650053143501\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5233162835644112\n",
      "NLL Loss is: 1.5060893055789324\n",
      "Scaled KL Loss is: 0.03799236938357353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.544081674962506\n",
      "NLL Loss is: 1.2908326652007094\n",
      "Scaled KL Loss is: 0.043539322912693024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3343719881134024\n",
      "NLL Loss is: 1.259154143986943\n",
      "Scaled KL Loss is: 0.03896329924464226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2981174432315852\n",
      "NLL Loss is: 1.4147302032827045\n",
      "Scaled KL Loss is: 0.038176797330379486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.452907000613084\n",
      "NLL Loss is: 1.5070194389043146\n",
      "Scaled KL Loss is: 0.03957194834947586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5465913872537904\n",
      "NLL Loss is: 1.2808137077747157\n",
      "Scaled KL Loss is: 0.039874084293842316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.320687792068558\n",
      "NLL Loss is: 1.2776248326885689\n",
      "Scaled KL Loss is: 0.0351889543235302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.312813787012099\n",
      "NLL Loss is: 1.295351005362918\n",
      "Scaled KL Loss is: 0.037983331829309464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3333343371922275\n",
      "NLL Loss is: 1.292699028394606\n",
      "Scaled KL Loss is: 0.04560285434126854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3383018827358746\n",
      "NLL Loss is: 1.3772014028158432\n",
      "Scaled KL Loss is: 0.037244558334350586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4144459611501938\n",
      "NLL Loss is: 1.2967446446463293\n",
      "Scaled KL Loss is: 0.03950262814760208\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3362472727939314\n",
      "NLL Loss is: 1.3134323585739267\n",
      "Scaled KL Loss is: 0.04134480282664299\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3547771614005697\n",
      "NLL Loss is: 1.2320718613613335\n",
      "Scaled KL Loss is: 0.040341999381780624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2724138607431141\n",
      "NLL Loss is: 1.3223855407903116\n",
      "Scaled KL Loss is: 0.04136361926794052\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363749160058252\n",
      "NLL Loss is: 1.288104851472176\n",
      "Scaled KL Loss is: 0.03926214203238487\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3273669935045609\n",
      "NLL Loss is: 1.3641881691380229\n",
      "Scaled KL Loss is: 0.04000559821724892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4041937673552718\n",
      "NLL Loss is: 1.3640592894512316\n",
      "Scaled KL Loss is: 0.038193006068468094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4022522955196997\n",
      "NLL Loss is: 1.2758034215711902\n",
      "Scaled KL Loss is: 0.041763100773096085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3175665223442863\n",
      "NLL Loss is: 1.3913613039517343\n",
      "Scaled KL Loss is: 0.03597470745444298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4273360114061773\n",
      "NLL Loss is: 1.4267671125986732\n",
      "Scaled KL Loss is: 0.03678368777036667\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4635508003690398\n",
      "NLL Loss is: 1.4410790625738377\n",
      "Scaled KL Loss is: 0.03560725599527359\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4766863185691113\n",
      "NLL Loss is: 1.4473891188111014\n",
      "Scaled KL Loss is: 0.04048562049865723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4878747393097587\n",
      "NLL Loss is: 1.3157223166419487\n",
      "Scaled KL Loss is: 0.03925282135605812\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3549751379980068\n",
      "NLL Loss is: 1.2932678491782945\n",
      "Scaled KL Loss is: 0.0354887992143631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3287566483926576\n",
      "NLL Loss is: 1.2380356797969352\n",
      "Scaled KL Loss is: 0.04211290180683136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2801485816037665\n",
      "NLL Loss is: 1.3353806865752682\n",
      "Scaled KL Loss is: 0.038761407136917114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3741420937121853\n",
      "NLL Loss is: 1.3704524100673172\n",
      "Scaled KL Loss is: 0.039488065987825394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099404760551426\n",
      "NLL Loss is: 1.4342990381581586\n",
      "Scaled KL Loss is: 0.0386853888630867\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4729844270212453\n",
      "NLL Loss is: 1.3257401309362666\n",
      "Scaled KL Loss is: 0.037045758217573166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3627858891538398\n",
      "NLL Loss is: 1.358806932514958\n",
      "Scaled KL Loss is: 0.036678969860076904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395485902375035\n",
      "NLL Loss is: 1.4222448090695756\n",
      "Scaled KL Loss is: 0.037606190890073776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4598509999596494\n",
      "NLL Loss is: 1.4314452185159812\n",
      "Scaled KL Loss is: 0.03801022097468376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.469455439490665\n",
      "NLL Loss is: 1.394808281152121\n",
      "Scaled KL Loss is: 0.03898876905441284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4337970502065338\n",
      "NLL Loss is: 1.3626811183488576\n",
      "Scaled KL Loss is: 0.0421811044216156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4048622227704732\n",
      "NLL Loss is: 1.3400463093419308\n",
      "Scaled KL Loss is: 0.03808264061808586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3781289499600167\n",
      "NLL Loss is: 1.4901472109680016\n",
      "Scaled KL Loss is: 0.03926795721054077\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5294151681785424\n",
      "NLL Loss is: 1.3893254220343507\n",
      "Scaled KL Loss is: 0.035982176661491394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4253075986958421\n",
      "NLL Loss is: 1.405101574462403\n",
      "Scaled KL Loss is: 0.041397999972105026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446499574434508\n",
      "NLL Loss is: 1.3693450266910288\n",
      "Scaled KL Loss is: 0.03866136819124222\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408006394882271\n",
      "NLL Loss is: 1.4684047490676968\n",
      "Scaled KL Loss is: 0.03756079450249672\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5059655435701935\n",
      "NLL Loss is: 1.3144953141335527\n",
      "Scaled KL Loss is: 0.03556982800364494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3500651421371976\n",
      "NLL Loss is: 1.4729408521111071\n",
      "Scaled KL Loss is: 0.038236312568187714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5111771646792949\n",
      "NLL Loss is: 1.4296035136200624\n",
      "Scaled KL Loss is: 0.0363246388733387\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4659281524934011\n",
      "NLL Loss is: 1.3616067626461483\n",
      "Scaled KL Loss is: 0.040746621787548065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4023533844336964\n",
      "NLL Loss is: 1.3251307795502905\n",
      "Scaled KL Loss is: 0.038099486380815506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363230265931106\n",
      "NLL Loss is: 1.4064256677533193\n",
      "Scaled KL Loss is: 0.03714222460985184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4435678923631712\n",
      "NLL Loss is: 1.2948584403399688\n",
      "Scaled KL Loss is: 0.04027732461690903\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3351357649568778\n",
      "NLL Loss is: 1.3791526201073905\n",
      "Scaled KL Loss is: 0.035387322306632996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4145399424140235\n",
      "NLL Loss is: 1.309513852664101\n",
      "Scaled KL Loss is: 0.040694501250982285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3502083539150833\n",
      "NLL Loss is: 1.4524866869933886\n",
      "Scaled KL Loss is: 0.04002191498875618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4925086019821447\n",
      "NLL Loss is: 1.4882731796992803\n",
      "Scaled KL Loss is: 0.03453939035534859\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.522812570054629\n",
      "NLL Loss is: 1.4271661581412673\n",
      "Scaled KL Loss is: 0.03524112328886986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4624072814301372\n",
      "NLL Loss is: 1.3512100560210683\n",
      "Scaled KL Loss is: 0.04052531719207764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3917353732131459\n",
      "NLL Loss is: 1.2801048387707061\n",
      "Scaled KL Loss is: 0.03646377474069595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.316568613511402\n",
      "NLL Loss is: 1.4541812133541356\n",
      "Scaled KL Loss is: 0.03667294979095459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4908541631450902\n",
      "NLL Loss is: 1.3560686087288416\n",
      "Scaled KL Loss is: 0.037410810589790344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393479419318632\n",
      "NLL Loss is: 1.7062570664765426\n",
      "Scaled KL Loss is: 0.02997523732483387\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7362323038013765\n",
      "NLL Loss is: 1.36447916521845s = 1.404; test loss = 1.440\n",
      "Scaled KL Loss is: 0.03998185321688652\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4044610184353366\n",
      "NLL Loss is: 1.4200964760914456\n",
      "Scaled KL Loss is: 0.037129394710063934\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4572258708015096\n",
      "NLL Loss is: 1.4122657271013332\n",
      "Scaled KL Loss is: 0.03876389563083649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4510296227321697\n",
      "NLL Loss is: 1.4601178967336463\n",
      "Scaled KL Loss is: 0.04224057495594025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5023584716895866\n",
      "NLL Loss is: 1.389367062305787\n",
      "Scaled KL Loss is: 0.03454151004552841\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4239085723513154\n",
      "NLL Loss is: 1.4462840575157296\n",
      "Scaled KL Loss is: 0.039332762360572815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4856168198763025\n",
      "NLL Loss is: 1.4235657428005353\n",
      "Scaled KL Loss is: 0.03374180570244789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4573075485029832\n",
      "NLL Loss is: 1.339659509313012\n",
      "Scaled KL Loss is: 0.03594040870666504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375599918019677\n",
      "NLL Loss is: 1.4060853840176986\n",
      "Scaled KL Loss is: 0.035328902304172516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441414286321871\n",
      "NLL Loss is: 1.3106084771157935\n",
      "Scaled KL Loss is: 0.04056466370820999\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3511731408240035\n",
      "NLL Loss is: 1.3132574631382974\n",
      "Scaled KL Loss is: 0.03661179915070534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3498692622890027\n",
      "NLL Loss is: 1.4320434215741487\n",
      "Scaled KL Loss is: 0.03662896156311035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.468672383137259\n",
      "NLL Loss is: 1.3174055229568815\n",
      "Scaled KL Loss is: 0.039759378880262375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571649018371439\n",
      "NLL Loss is: 1.521320954927189\n",
      "Scaled KL Loss is: 0.038545411080121994\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.559866366007311\n",
      "NLL Loss is: 1.315547228347048\n",
      "Scaled KL Loss is: 0.03765864670276642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3532058750498144\n",
      "NLL Loss is: 1.484314887558246\n",
      "Scaled KL Loss is: 0.038500119000673294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5228150065589192\n",
      "NLL Loss is: 1.4314293935104567\n",
      "Scaled KL Loss is: 0.035362135618925095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4667915291293818\n",
      "NLL Loss is: 1.3513267517793701\n",
      "Scaled KL Loss is: 0.03808645159006119\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3894132033694313\n",
      "NLL Loss is: 1.296619626081083\n",
      "Scaled KL Loss is: 0.036999545991420746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336191720725037\n",
      "NLL Loss is: 1.3785017406521478\n",
      "Scaled KL Loss is: 0.034853745251894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4133554859040418\n",
      "NLL Loss is: 1.3823341212380549\n",
      "Scaled KL Loss is: 0.037814266979694366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4201483882177492\n",
      "NLL Loss is: 1.4124294717880743\n",
      "Scaled KL Loss is: 0.034279607236385345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4467090790244597\n",
      "NLL Loss is: 1.3227143267628099\n",
      "Scaled KL Loss is: 0.0349610261619091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.357675352924719\n",
      "NLL Loss is: 1.5681810800337106\n",
      "Scaled KL Loss is: 0.039606139063835144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6077872190975457\n",
      "NLL Loss is: 1.2002582774537591\n",
      "Scaled KL Loss is: 0.03703119978308678\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237289477236846\n",
      "NLL Loss is: 1.3324409422750394\n",
      "Scaled KL Loss is: 0.040393393486738205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3728343357617776\n",
      "NLL Loss is: 1.3932220362834138\n",
      "Scaled KL Loss is: 0.0406779870390892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.433900023322503\n",
      "NLL Loss is: 1.1992649291463353\n",
      "Scaled KL Loss is: 0.038428809493780136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2376937386401154\n",
      "NLL Loss is: 1.3638260339424608\n",
      "Scaled KL Loss is: 0.0382220596075058\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4020480935499666\n",
      "NLL Loss is: 1.222961416628504\n",
      "Scaled KL Loss is: 0.03848457336425781\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.261445989992762\n",
      "NLL Loss is: 1.2305300184402774\n",
      "Scaled KL Loss is: 0.035684168338775635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.266214186779053\n",
      "NLL Loss is: 1.3916691063597282\n",
      "Scaled KL Loss is: 0.03786783292889595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4295369392886241\n",
      "NLL Loss is: 1.3997173320629668\n",
      "Scaled KL Loss is: 0.03660682961344719\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.436324161676414\n",
      "NLL Loss is: 1.2951459868974087\n",
      "Scaled KL Loss is: 0.03695349022746086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3320994771248695\n",
      "NLL Loss is: 1.4819286961973\n",
      "Scaled KL Loss is: 0.03689076378941536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5188194599867153\n",
      "NLL Loss is: 1.5024011336905818\n",
      "Scaled KL Loss is: 0.037481535226106644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5398826689166885\n",
      "NLL Loss is: 1.288378025185955\n",
      "Scaled KL Loss is: 0.043133895844221115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.331511921030176\n",
      "NLL Loss is: 1.257906338607749\n",
      "Scaled KL Loss is: 0.038722071796655655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2966284104044046\n",
      "NLL Loss is: 1.4112210958417057\n",
      "Scaled KL Loss is: 0.03778683394193649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4490079297836422\n",
      "NLL Loss is: 1.5046908163765735\n",
      "Scaled KL Loss is: 0.03909069299697876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5437815093735523\n",
      "NLL Loss is: 1.2752382187776172\n",
      "Scaled KL Loss is: 0.03936943784356117\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146076566211784\n",
      "NLL Loss is: 1.2736051764663268\n",
      "Scaled KL Loss is: 0.034762006253004074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3083671827193308\n",
      "NLL Loss is: 1.2921207370051846\n",
      "Scaled KL Loss is: 0.03776262700557709\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3298833640107617\n",
      "NLL Loss is: 1.2883909521146308\n",
      "Scaled KL Loss is: 0.0450911745429039\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3334821266575347\n",
      "NLL Loss is: 1.3743888589661288\n",
      "Scaled KL Loss is: 0.03676101937890053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4111498783450294\n",
      "NLL Loss is: 1.2950219109467183\n",
      "Scaled KL Loss is: 0.03917325660586357\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3341951675525818\n",
      "NLL Loss is: 1.312169156093519\n",
      "Scaled KL Loss is: 0.04096582159399986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3531349776875188\n",
      "NLL Loss is: 1.228759501903138\n",
      "Scaled KL Loss is: 0.04021463170647621\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2689741336096143\n",
      "NLL Loss is: 1.3200332087512014\n",
      "Scaled KL Loss is: 0.0409025177359581\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3609357264871595\n",
      "NLL Loss is: 1.2847483428984734\n",
      "Scaled KL Loss is: 0.038851674646139145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3236000175446125\n",
      "NLL Loss is: 1.361642471098615\n",
      "Scaled KL Loss is: 0.03966034948825836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4013028205868734\n",
      "NLL Loss is: 1.3617628925246958\n",
      "Scaled KL Loss is: 0.037696029990911484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3994589225156073\n",
      "NLL Loss is: 1.273121714391748\n",
      "Scaled KL Loss is: 0.04118771478533745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3143094291770854\n",
      "NLL Loss is: 1.389406113616853\n",
      "Scaled KL Loss is: 0.03569333627820015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425099449895053\n",
      "NLL Loss is: 1.424794652994029\n",
      "Scaled KL Loss is: 0.03642316907644272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4612178220704717\n",
      "NLL Loss is: 1.4382755348919847\n",
      "Scaled KL Loss is: 0.03523670509457588\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4735122399865606\n",
      "NLL Loss is: 1.4452244858255903\n",
      "Scaled KL Loss is: 0.040056079626083374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4852805654516736\n",
      "NLL Loss is: 1.3141300123791892\n",
      "Scaled KL Loss is: 0.03868076577782631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3528107781570156\n",
      "NLL Loss is: 1.292076823515386\n",
      "Scaled KL Loss is: 0.03517980873584747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3272566322512336\n",
      "NLL Loss is: 1.235032798499215\n",
      "Scaled KL Loss is: 0.04153822362422943\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2765710221234445\n",
      "NLL Loss is: 1.332954250175897\n",
      "Scaled KL Loss is: 0.03843362629413605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3713878764700331\n",
      "NLL Loss is: 1.3662958600959365\n",
      "Scaled KL Loss is: 0.03896655887365341\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40526241896959\n",
      "NLL Loss is: 1.431564459584765\n",
      "Scaled KL Loss is: 0.03821731358766556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4697817731724305\n",
      "NLL Loss is: 1.3239832923991748\n",
      "Scaled KL Loss is: 0.03682950511574745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3608127975149222\n",
      "NLL Loss is: 1.3563936460597181\n",
      "Scaled KL Loss is: 0.03624962642788887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.392643272487607\n",
      "NLL Loss is: 1.4207404166828224\n",
      "Scaled KL Loss is: 0.037249285727739334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4579897024105617\n",
      "NLL Loss is: 1.4292537574249096\n",
      "Scaled KL Loss is: 0.03772860765457153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.466982365079481\n",
      "NLL Loss is: 1.3925548185470191\n",
      "Scaled KL Loss is: 0.03846855089068413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4310233694377033\n",
      "NLL Loss is: 1.360153423105549\n",
      "Scaled KL Loss is: 0.04171443730592728\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4018678604114763\n",
      "NLL Loss is: 1.337094296109095\n",
      "Scaled KL Loss is: 0.03766237571835518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3747566718274502\n",
      "NLL Loss is: 1.4876362817776385\n",
      "Scaled KL Loss is: 0.03885355964303017\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5264898414206687\n",
      "NLL Loss is: 1.387066123108909\n",
      "Scaled KL Loss is: 0.03561996668577194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.422686089794681\n",
      "NLL Loss is: 1.4007562768160657\n",
      "Scaled KL Loss is: 0.04097887873649597\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4417351555525617\n",
      "NLL Loss is: 1.3677825700177524\n",
      "Scaled KL Loss is: 0.03833652287721634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4061190928949687\n",
      "NLL Loss is: 1.4669365092755005\n",
      "Scaled KL Loss is: 0.03719865530729294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5041351645827934\n",
      "NLL Loss is: 1.3128298694003724\n",
      "Scaled KL Loss is: 0.035142481327056885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3479723507274293\n",
      "NLL Loss is: 1.4704119178298731\n",
      "Scaled KL Loss is: 0.03765055909752846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5080624769274016\n",
      "NLL Loss is: 1.4256292375817226\n",
      "Scaled KL Loss is: 0.03606986999511719\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4616991075768397\n",
      "NLL Loss is: 1.3609493743189327\n",
      "Scaled KL Loss is: 0.040023740381002426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4009731146999351\n",
      "NLL Loss is: 1.3222774857443125\n",
      "Scaled KL Loss is: 0.037487778812646866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3597652645569593\n",
      "NLL Loss is: 1.4036612530113404\n",
      "Scaled KL Loss is: 0.03673061728477478\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4403918702961152\n",
      "NLL Loss is: 1.2913241396394801\n",
      "Scaled KL Loss is: 0.03978949785232544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3311136374918056\n",
      "NLL Loss is: 1.3781388918293505\n",
      "Scaled KL Loss is: 0.03492605686187744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.413064948691228\n",
      "NLL Loss is: 1.3048831167469712\n",
      "Scaled KL Loss is: 0.04020519182085991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3450883085678311\n",
      "NLL Loss is: 1.4471842152909853\n",
      "Scaled KL Loss is: 0.03948986530303955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4866740805940248\n",
      "NLL Loss is: 1.48558177534893\n",
      "Scaled KL Loss is: 0.03445122018456459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5200329955334946\n",
      "NLL Loss is: 1.423694538314593\n",
      "Scaled KL Loss is: 0.034827884286642075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.458522422601235\n",
      "NLL Loss is: 1.3480717714928954\n",
      "Scaled KL Loss is: 0.040042996406555176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3881147678994505\n",
      "NLL Loss is: 1.2787830808224454\n",
      "Scaled KL Loss is: 0.03608521819114685\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3148682990135923\n",
      "NLL Loss is: 1.4537772107935254\n",
      "Scaled KL Loss is: 0.0364440493285656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.490221260122091\n",
      "NLL Loss is: 1.3521583722210226\n",
      "Scaled KL Loss is: 0.03715576231479645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.389314134535819\n",
      "NLL Loss is: 1.7031486649887473\n",
      "Scaled KL Loss is: 0.02974451705813408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7328931820468814\n",
      "NLL Loss is: 1.361659195137261 = 1.401; test loss = 1.437\n",
      "Scaled KL Loss is: 0.039540357887744904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4011995530250059\n",
      "NLL Loss is: 1.4177266733473854\n",
      "Scaled KL Loss is: 0.03666381537914276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4543904887265282\n",
      "NLL Loss is: 1.4104325600528598\n",
      "Scaled KL Loss is: 0.03835311532020569\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4487856753730655\n",
      "NLL Loss is: 1.4556675303915778\n",
      "Scaled KL Loss is: 0.04159621149301529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.497263741884593\n",
      "NLL Loss is: 1.3872929348347214\n",
      "Scaled KL Loss is: 0.034191228449344635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.421484163284066\n",
      "NLL Loss is: 1.4415306941399535\n",
      "Scaled KL Loss is: 0.03893148899078369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4804621831307372\n",
      "NLL Loss is: 1.4217400057623846\n",
      "Scaled KL Loss is: 0.033414166420698166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4551541721830827\n",
      "NLL Loss is: 1.3397109376922485\n",
      "Scaled KL Loss is: 0.03539561480283737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3751065524950858\n",
      "NLL Loss is: 1.405275622817456\n",
      "Scaled KL Loss is: 0.034827131778001785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440102754595458\n",
      "NLL Loss is: 1.3094815989992323\n",
      "Scaled KL Loss is: 0.040105435997247696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34958703499648\n",
      "NLL Loss is: 1.3124470128915988\n",
      "Scaled KL Loss is: 0.03592073917388916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348367752065488\n",
      "NLL Loss is: 1.4305720879304191\n",
      "Scaled KL Loss is: 0.03633098304271698\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.466903070973136\n",
      "NLL Loss is: 1.314733976451316\n",
      "Scaled KL Loss is: 0.03949665650725365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3542306329585696\n",
      "NLL Loss is: 1.518196631178786\n",
      "Scaled KL Loss is: 0.038135822862386703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5563324540411727\n",
      "NLL Loss is: 1.3146043670875107\n",
      "Scaled KL Loss is: 0.0371335931122303\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351737960199741\n",
      "NLL Loss is: 1.4822539835228912\n",
      "Scaled KL Loss is: 0.03840542212128639\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5206594056441776\n",
      "NLL Loss is: 1.4279670896278327\n",
      "Scaled KL Loss is: 0.03525378927588463\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4632208789037173\n",
      "NLL Loss is: 1.3504540252995958\n",
      "Scaled KL Loss is: 0.037708401679992676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3881624269795885\n",
      "NLL Loss is: 1.2951292793884783\n",
      "Scaled KL Loss is: 0.0367468036711216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3318760830596\n",
      "NLL Loss is: 1.3775297033704488\n",
      "Scaled KL Loss is: 0.03467404469847679\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4122037480689256\n",
      "NLL Loss is: 1.3772748312649659\n",
      "Scaled KL Loss is: 0.0372738353908062\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414548666655772\n",
      "NLL Loss is: 1.408943997045169\n",
      "Scaled KL Loss is: 0.03411300852894783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4430570055741168\n",
      "NLL Loss is: 1.3208753014719525\n",
      "Scaled KL Loss is: 0.03481116145849228\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3556864629304448\n",
      "NLL Loss is: 1.5678813984602238\n",
      "Scaled KL Loss is: 0.03922542184591293\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6071068203061367\n",
      "NLL Loss is: 1.199890865212962\n",
      "Scaled KL Loss is: 0.036688078194856644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2365789434078187\n",
      "NLL Loss is: 1.3303872779553665\n",
      "Scaled KL Loss is: 0.040147870779037476\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370535148734404\n",
      "NLL Loss is: 1.391026140633396\n",
      "Scaled KL Loss is: 0.04049154371023178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4315176843436277\n",
      "NLL Loss is: 1.1959689408982443\n",
      "Scaled KL Loss is: 0.03830453008413315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2342734709823775\n",
      "NLL Loss is: 1.3615924157199857\n",
      "Scaled KL Loss is: 0.03794143721461296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3995338529345986\n",
      "NLL Loss is: 1.22020483786279\n",
      "Scaled KL Loss is: 0.03817621245980263\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2583810503225927\n",
      "NLL Loss is: 1.2280546546354179\n",
      "Scaled KL Loss is: 0.03527116775512695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2633258223905448\n",
      "NLL Loss is: 1.3875997587770923\n",
      "Scaled KL Loss is: 0.03753097355365753\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4251307323307498\n",
      "NLL Loss is: 1.3958618160721614\n",
      "Scaled KL Loss is: 0.03614963963627815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4320114557084396\n",
      "NLL Loss is: 1.2926639321691773\n",
      "Scaled KL Loss is: 0.03656025230884552\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3292241844780228\n",
      "NLL Loss is: 1.4782945731717\n",
      "Scaled KL Loss is: 0.036622632294893265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5149172054665934\n",
      "NLL Loss is: 1.4984560610659399\n",
      "Scaled KL Loss is: 0.03705362230539322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.535509683371333\n",
      "NLL Loss is: 1.2866062688560311\n",
      "Scaled KL Loss is: 0.042811498045921326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3294177669019525\n",
      "NLL Loss is: 1.2569223541676058\n",
      "Scaled KL Loss is: 0.03855079412460327\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.295473148292209\n",
      "NLL Loss is: 1.4072011607426413\n",
      "Scaled KL Loss is: 0.037473712116479874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4446748728591212\n",
      "NLL Loss is: 1.5019690667656442\n",
      "Scaled KL Loss is: 0.03869021683931351\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5406592836049577\n",
      "NLL Loss is: 1.2699805733845948\n",
      "Scaled KL Loss is: 0.038941968232393265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.308922541616988\n",
      "NLL Loss is: 1.2691818343892616\n",
      "Scaled KL Loss is: 0.03441711887717247\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303598953266434\n",
      "NLL Loss is: 1.2893360009992438\n",
      "Scaled KL Loss is: 0.03761640191078186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3269524029100257\n",
      "NLL Loss is: 1.2846538319354714\n",
      "Scaled KL Loss is: 0.0446508452296257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3293046771650971\n",
      "NLL Loss is: 1.370880149525421\n",
      "Scaled KL Loss is: 0.03634537383913994\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.407225523364561\n",
      "NLL Loss is: 1.2933702856531044\n",
      "Scaled KL Loss is: 0.03891420364379883\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3322844892969032\n",
      "NLL Loss is: 1.31087656517677\n",
      "Scaled KL Loss is: 0.04065621271729469\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515327778940647\n",
      "NLL Loss is: 1.225400783397425\n",
      "Scaled KL Loss is: 0.04015481472015381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2655555981175788\n",
      "NLL Loss is: 1.3178297805463337\n",
      "Scaled KL Loss is: 0.040526412427425385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358356192973759\n",
      "NLL Loss is: 1.2814445408386146\n",
      "Scaled KL Loss is: 0.03851955756545067\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3199640984040653\n",
      "NLL Loss is: 1.3598631968816652\n",
      "Scaled KL Loss is: 0.03938593715429306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3992491340359583\n",
      "NLL Loss is: 1.359343060410753\n",
      "Scaled KL Loss is: 0.03727531060576439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3966183710165174\n",
      "NLL Loss is: 1.271275510170978\n",
      "Scaled KL Loss is: 0.040701985359191895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.31197749553017\n",
      "NLL Loss is: 1.3874684808278248\n",
      "Scaled KL Loss is: 0.03547393158078194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4229424124086067\n",
      "NLL Loss is: 1.4246365384270485\n",
      "Scaled KL Loss is: 0.03614301234483719\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4607795507718857\n",
      "NLL Loss is: 1.4357235061608449\n",
      "Scaled KL Loss is: 0.03492970019578934\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4706532063566342\n",
      "NLL Loss is: 1.4433510391145739\n",
      "Scaled KL Loss is: 0.03969557583332062\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4830466149478945\n",
      "NLL Loss is: 1.3122363930925838\n",
      "Scaled KL Loss is: 0.038175247609615326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.350411640702199\n",
      "NLL Loss is: 1.2907274305654317\n",
      "Scaled KL Loss is: 0.03493702411651611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3256644546819478\n",
      "NLL Loss is: 1.232054376767748\n",
      "Scaled KL Loss is: 0.04103222116827965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2730865979360277\n",
      "NLL Loss is: 1.3302835796278025\n",
      "Scaled KL Loss is: 0.038170795887708664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3684543755155112\n",
      "NLL Loss is: 1.3620033164729641\n",
      "Scaled KL Loss is: 0.038510389626026154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4005137060989903\n",
      "NLL Loss is: 1.42877185090833\n",
      "Scaled KL Loss is: 0.03781634941697121\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4665882003253012\n",
      "NLL Loss is: 1.322560857683207\n",
      "Scaled KL Loss is: 0.03668073192238808\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3592415896055952\n",
      "NLL Loss is: 1.3539542216450877\n",
      "Scaled KL Loss is: 0.035890743136405945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3898449647814937\n",
      "NLL Loss is: 1.4187675032340552\n",
      "Scaled KL Loss is: 0.03695651516318321\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4557240183972384\n",
      "NLL Loss is: 1.4270991932414416\n",
      "Scaled KL Loss is: 0.03752054646611214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4646197397075538\n",
      "NLL Loss is: 1.3904038666767207\n",
      "Scaled KL Loss is: 0.03802184388041496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4284257105571356\n",
      "NLL Loss is: 1.357697778143013\n",
      "Scaled KL Loss is: 0.041322868317365646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3990206464603787\n",
      "NLL Loss is: 1.3340494646729473\n",
      "Scaled KL Loss is: 0.037315867841243744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371365332514191\n",
      "NLL Loss is: 1.4853431956306344\n",
      "Scaled KL Loss is: 0.038517266511917114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5238604621425516\n",
      "NLL Loss is: 1.3850084968120029\n",
      "Scaled KL Loss is: 0.03533446788787842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4203429646998813\n",
      "NLL Loss is: 1.3966592243744005\n",
      "Scaled KL Loss is: 0.040630705654621124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4372899300290216\n",
      "NLL Loss is: 1.3661433770285232\n",
      "Scaled KL Loss is: 0.03808363527059555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4042270122991187\n",
      "NLL Loss is: 1.4656267171266584\n",
      "Scaled KL Loss is: 0.03690800443291664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.502534721559575\n",
      "NLL Loss is: 1.3114478081167973\n",
      "Scaled KL Loss is: 0.03479700908064842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3462448171974457\n",
      "NLL Loss is: 1.4679847963374109\n",
      "Scaled KL Loss is: 0.03714757412672043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5051323704641313\n",
      "NLL Loss is: 1.4221726557377155\n",
      "Scaled KL Loss is: 0.03589142858982086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4580640843275363\n",
      "NLL Loss is: 1.3605776649576364\n",
      "Scaled KL Loss is: 0.039386216551065445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3999638815087019\n",
      "NLL Loss is: 1.3193966021189087\n",
      "Scaled KL Loss is: 0.03696054592728615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356357148046195\n",
      "NLL Loss is: 1.4009562928002086\n",
      "Scaled KL Loss is: 0.03639296442270279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4373492572229114\n",
      "NLL Loss is: 1.2878803102358725\n",
      "Scaled KL Loss is: 0.039382148534059525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.327262458769932\n",
      "NLL Loss is: 1.3770813811057798\n",
      "Scaled KL Loss is: 0.0345422588288784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4116236399346582\n",
      "NLL Loss is: 1.300666831252961\n",
      "Scaled KL Loss is: 0.0397934652864933\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3404602965394543\n",
      "NLL Loss is: 1.442048601219175\n",
      "Scaled KL Loss is: 0.03903675451874733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4810853557379224\n",
      "NLL Loss is: 1.48285843757617\n",
      "Scaled KL Loss is: 0.034429263323545456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5172877008997154\n",
      "NLL Loss is: 1.4201113944899462\n",
      "Scaled KL Loss is: 0.03448808565735817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4545994801473043\n",
      "NLL Loss is: 1.34521828044708\n",
      "Scaled KL Loss is: 0.03963598608970642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3848542665367864\n",
      "NLL Loss is: 1.2776640234517727\n",
      "Scaled KL Loss is: 0.03578466922044754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3134486926722202\n",
      "NLL Loss is: 1.4532074199021268\n",
      "Scaled KL Loss is: 0.036285385489463806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4894928053915906\n",
      "NLL Loss is: 1.3485499186378511\n",
      "Scaled KL Loss is: 0.036971498280763626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3855214169186147\n",
      "NLL Loss is: 1.7005863960559802\n",
      "Scaled KL Loss is: 0.029579129070043564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7301655251260237\n",
      "NLL Loss is: 1.359023245946765 = 1.398; test loss = 1.434\n",
      "Scaled KL Loss is: 0.03916846960783005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.398191715554595\n",
      "NLL Loss is: 1.4155407862084681\n",
      "Scaled KL Loss is: 0.036271832883358\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4518126190918261\n",
      "NLL Loss is: 1.4086269700923522\n",
      "Scaled KL Loss is: 0.038018133491277695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4466451035836299\n",
      "NLL Loss is: 1.4512880681772382\n",
      "Scaled KL Loss is: 0.04103429615497589\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.492322364332214\n",
      "NLL Loss is: 1.385081374812325\n",
      "Scaled KL Loss is: 0.0339161679148674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4189975427271924\n",
      "NLL Loss is: 1.4373533759711774\n",
      "Scaled KL Loss is: 0.03859792277216911\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4759512987433465\n",
      "NLL Loss is: 1.4198957826676781\n",
      "Scaled KL Loss is: 0.03315985947847366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4530556421461518\n",
      "NLL Loss is: 1.3399000412470017\n",
      "Scaled KL Loss is: 0.03492763638496399\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3748276776319657\n",
      "NLL Loss is: 1.4046332230602303\n",
      "Scaled KL Loss is: 0.03440495580434799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4390381788645783\n",
      "NLL Loss is: 1.3082734055123921\n",
      "Scaled KL Loss is: 0.039723239839076996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3479966453514691\n",
      "NLL Loss is: 1.3116003357602357\n",
      "Scaled KL Loss is: 0.03530885651707649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3469091922773122\n",
      "NLL Loss is: 1.4291044107292965\n",
      "Scaled KL Loss is: 0.036097072064876556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.465201482794173\n",
      "NLL Loss is: 1.3118834880068704\n",
      "Scaled KL Loss is: 0.039305999875068665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351189487881939\n",
      "NLL Loss is: 1.5153849463649556\n",
      "Scaled KL Loss is: 0.03778602555394173\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5531709719188973\n",
      "NLL Loss is: 1.3134533258315122\n",
      "Scaled KL Loss is: 0.036684274673461914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3501376005049741\n",
      "NLL Loss is: 1.4804917657284227\n",
      "Scaled KL Loss is: 0.03839053958654404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5188823053149667\n",
      "NLL Loss is: 1.4243852940033452\n",
      "Scaled KL Loss is: 0.035205330699682236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4595906247030275\n",
      "NLL Loss is: 1.3500137819984592\n",
      "Scaled KL Loss is: 0.037384212017059326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3873979940155186\n",
      "NLL Loss is: 1.29412842246293\n",
      "Scaled KL Loss is: 0.03655778989195824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3306862123548882\n",
      "NLL Loss is: 1.3769428983575653\n",
      "Scaled KL Loss is: 0.03455151244997978\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4114944108075451\n",
      "NLL Loss is: 1.3717643258654806\n",
      "Scaled KL Loss is: 0.036788057535886765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4085523834013673\n",
      "NLL Loss is: 1.4055788690152229\n",
      "Scaled KL Loss is: 0.034000080078840256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4395789490940631\n",
      "NLL Loss is: 1.3188193425074692\n",
      "Scaled KL Loss is: 0.0347171314060688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353536473913538\n",
      "NLL Loss is: 1.5681951387265096\n",
      "Scaled KL Loss is: 0.038893308490514755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6070884472170244\n",
      "NLL Loss is: 1.1992338181288693\n",
      "Scaled KL Loss is: 0.03640180453658104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2356356226654504\n",
      "NLL Loss is: 1.3283441070727773\n",
      "Scaled KL Loss is: 0.03995449095964432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3682985980324216\n",
      "NLL Loss is: 1.3888881596789657\n",
      "Scaled KL Loss is: 0.04035525396466255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4292434136436283\n",
      "NLL Loss is: 1.1922853641207691\n",
      "Scaled KL Loss is: 0.038237564265728\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2305229283864971\n",
      "NLL Loss is: 1.3593154892687727\n",
      "Scaled KL Loss is: 0.03771282732486725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.39702831659364\n",
      "NLL Loss is: 1.2173545844013658\n",
      "Scaled KL Loss is: 0.03792504593729973\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2552796303386655\n",
      "NLL Loss is: 1.225360892758919\n",
      "Scaled KL Loss is: 0.03491564095020294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260276533709122\n",
      "NLL Loss is: 1.383593808531939\n",
      "Scaled KL Loss is: 0.03725018352270126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4208439920546403\n",
      "NLL Loss is: 1.3920883523241492\n",
      "Scaled KL Loss is: 0.0357520692050457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4278404215291949\n",
      "NLL Loss is: 1.29018573727974\n",
      "Scaled KL Loss is: 0.03622618690133095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.326411924181071\n",
      "NLL Loss is: 1.4746741076601813\n",
      "Scaled KL Loss is: 0.036410924047231674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.511085031707413\n",
      "NLL Loss is: 1.4948076326114679\n",
      "Scaled KL Loss is: 0.036692045629024506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5314996782404924\n",
      "NLL Loss is: 1.2846804265044003\n",
      "Scaled KL Loss is: 0.0425458699464798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32722629645088\n",
      "NLL Loss is: 1.255924423475717\n",
      "Scaled KL Loss is: 0.03843466565012932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943590891258463\n",
      "NLL Loss is: 1.403271779329387\n",
      "Scaled KL Loss is: 0.03722088411450386\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4404926634438908\n",
      "NLL Loss is: 1.4994814933715959\n",
      "Scaled KL Loss is: 0.03835199400782585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5378334873794217\n",
      "NLL Loss is: 1.264818379707699\n",
      "Scaled KL Loss is: 0.03857873007655144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3033971097842505\n",
      "NLL Loss is: 1.2647909122827174\n",
      "Scaled KL Loss is: 0.03413451462984085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2989254269125583\n",
      "NLL Loss is: 1.2864997676630556\n",
      "Scaled KL Loss is: 0.037527527660131454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.324027295323187\n",
      "NLL Loss is: 1.28090783385171\n",
      "Scaled KL Loss is: 0.044267408549785614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3251752424014955\n",
      "NLL Loss is: 1.3672843742858611\n",
      "Scaled KL Loss is: 0.035988278687000275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4032726529728614\n",
      "NLL Loss is: 1.2918167166553907\n",
      "Scaled KL Loss is: 0.03871176391839981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3305284805737905\n",
      "NLL Loss is: 1.3095870428854428\n",
      "Scaled KL Loss is: 0.04040230065584183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3499893435412846\n",
      "NLL Loss is: 1.2219932985621178\n",
      "Scaled KL Loss is: 0.040140118449926376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2621334170120442\n",
      "NLL Loss is: 1.3157025397302626\n",
      "Scaled KL Loss is: 0.040198516100645065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3559010558309077\n",
      "NLL Loss is: 1.2780383634363333\n",
      "Scaled KL Loss is: 0.038223911076784134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3162622745131174\n",
      "NLL Loss is: 1.3569481062378437\n",
      "Scaled KL Loss is: 0.039156582206487656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3961046884443313\n",
      "NLL Loss is: 1.3576061212962258\n",
      "Scaled KL Loss is: 0.03690202534198761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3945081466382134\n",
      "NLL Loss is: 1.2684674445493371\n",
      "Scaled KL Loss is: 0.04025549441576004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3087229389650972\n",
      "NLL Loss is: 1.385439772067415\n",
      "Scaled KL Loss is: 0.0353068970143795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4207466690817945\n",
      "NLL Loss is: 1.4224146888689757\n",
      "Scaled KL Loss is: 0.035911303013563156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4583259918825389\n",
      "NLL Loss is: 1.4330263223364026\n",
      "Scaled KL Loss is: 0.0346858836710453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.467712206007448\n",
      "NLL Loss is: 1.4413017046709737\n",
      "Scaled KL Loss is: 0.03939978405833244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4807014887293062\n",
      "NLL Loss is: 1.3106547871710676\n",
      "Scaled KL Loss is: 0.03773652762174606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3483913147928137\n",
      "NLL Loss is: 1.2892616081571089\n",
      "Scaled KL Loss is: 0.03475967422127724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3240212823783861\n",
      "NLL Loss is: 1.2292019331984219\n",
      "Scaled KL Loss is: 0.04059530049562454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2697972336940464\n",
      "NLL Loss is: 1.3276013037777292\n",
      "Scaled KL Loss is: 0.03797008842229843\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3655713922000277\n",
      "NLL Loss is: 1.3576558526396503\n",
      "Scaled KL Loss is: 0.038118306547403336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3957741591870536\n",
      "NLL Loss is: 1.4261117086634585\n",
      "Scaled KL Loss is: 0.037474025040864944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4635857337043234\n",
      "NLL Loss is: 1.3211058118698409\n",
      "Scaled KL Loss is: 0.036586929112672806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3576927409825137\n",
      "NLL Loss is: 1.3514191523963397\n",
      "Scaled KL Loss is: 0.03558606654405594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3870052189403956\n",
      "NLL Loss is: 1.4174394999148803\n",
      "Scaled KL Loss is: 0.03671989217400551\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4541593920888858\n",
      "NLL Loss is: 1.4249025163035298\n",
      "Scaled KL Loss is: 0.037372760474681854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4622752767782117\n",
      "NLL Loss is: 1.388165006213805\n",
      "Scaled KL Loss is: 0.037629034370183945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4257940405839888\n",
      "NLL Loss is: 1.3552244912314502\n",
      "Scaled KL Loss is: 0.04098911210894585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.396213603340396\n",
      "NLL Loss is: 1.3311675998590675\n",
      "Scaled KL Loss is: 0.037014663219451904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3681822630785194\n",
      "NLL Loss is: 1.4830019264292489\n",
      "Scaled KL Loss is: 0.038229942321777344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5212318687510262\n",
      "NLL Loss is: 1.3827840477650917\n",
      "Scaled KL Loss is: 0.03510182350873947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4178858712738311\n",
      "NLL Loss is: 1.3924901499220383\n",
      "Scaled KL Loss is: 0.040334299206733704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432824449128772\n",
      "NLL Loss is: 1.3645398259924324\n",
      "Scaled KL Loss is: 0.037883780896663666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402423606889096\n",
      "NLL Loss is: 1.464509181256882\n",
      "Scaled KL Loss is: 0.036674052476882935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.501183233733765\n",
      "NLL Loss is: 1.3098377449069865\n",
      "Scaled KL Loss is: 0.03450354188680649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344341286793793\n",
      "NLL Loss is: 1.4655240842743884\n",
      "Scaled KL Loss is: 0.03669409826397896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5022181825383674\n",
      "NLL Loss is: 1.419168196969992\n",
      "Scaled KL Loss is: 0.03576741740107536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4549356143710674\n",
      "NLL Loss is: 1.3599945019331068\n",
      "Scaled KL Loss is: 0.038807015866041183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.398801517799148\n",
      "NLL Loss is: 1.3166018416312986\n",
      "Scaled KL Loss is: 0.036498699337244034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3531005409685426\n",
      "NLL Loss is: 1.398324256054442\n",
      "Scaled KL Loss is: 0.036106109619140625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4344303656735826\n",
      "NLL Loss is: 1.2845478611305592\n",
      "Scaled KL Loss is: 0.039034780114889145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3235826412454483\n",
      "NLL Loss is: 1.376103024271485\n",
      "Scaled KL Loss is: 0.03420937806367874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4103124023351636\n",
      "NLL Loss is: 1.296374654301156\n",
      "Scaled KL Loss is: 0.03942789137363434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3358025456747904\n",
      "NLL Loss is: 1.4370582349861567\n",
      "Scaled KL Loss is: 0.03863167017698288\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4756899051631396\n",
      "NLL Loss is: 1.4803037996608117\n",
      "Scaled KL Loss is: 0.034454211592674255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.514758011253486\n",
      "NLL Loss is: 1.4166435564449074\n",
      "Scaled KL Loss is: 0.03419126197695732\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4508348184218647\n",
      "NLL Loss is: 1.342326921853612\n",
      "Scaled KL Loss is: 0.039286985993385315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3816139078469973\n",
      "NLL Loss is: 1.2762090839646807\n",
      "Scaled KL Loss is: 0.03554193675518036\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.311751020719861\n",
      "NLL Loss is: 1.4526383666784204\n",
      "Scaled KL Loss is: 0.0361795648932457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.488817931571666\n",
      "NLL Loss is: 1.3448760705760474\n",
      "Scaled KL Loss is: 0.0368344783782959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3817105489543433\n",
      "NLL Loss is: 1.6976639804022953\n",
      "Scaled KL Loss is: 0.029460391029715538\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7271243714320108\n",
      "NLL Loss is: 1.3564899120240788= 1.395; test loss = 1.431\n",
      "Scaled KL Loss is: 0.038843996822834015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3953339088469128\n",
      "NLL Loss is: 1.4131146954295486\n",
      "Scaled KL Loss is: 0.035934507846832275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4490492032763809\n",
      "NLL Loss is: 1.40697301716553\n",
      "Scaled KL Loss is: 0.03773878887295723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4447118060384871\n",
      "NLL Loss is: 1.4471905065575965\n",
      "Scaled KL Loss is: 0.040526822209358215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4877173287669547\n",
      "NLL Loss is: 1.3829040042762033\n",
      "Scaled KL Loss is: 0.03369517624378204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4165991805199853\n",
      "NLL Loss is: 1.4333161332186477\n",
      "Scaled KL Loss is: 0.03831780329346657\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4716339365121143\n",
      "NLL Loss is: 1.4181889342961442\n",
      "Scaled KL Loss is: 0.03295927867293358\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4511482129690778\n",
      "NLL Loss is: 1.340132620886276\n",
      "Scaled KL Loss is: 0.034514933824539185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3746475547108152\n",
      "NLL Loss is: 1.4039622803008152\n",
      "Scaled KL Loss is: 0.03404286131262779\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.438005141613443\n",
      "NLL Loss is: 1.3066789353556043\n",
      "Scaled KL Loss is: 0.03939688578248024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3460758211380845\n",
      "NLL Loss is: 1.3106836027220023\n",
      "Scaled KL Loss is: 0.03476683050394058\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.345450433225943\n",
      "NLL Loss is: 1.42762306876397\n",
      "Scaled KL Loss is: 0.03592321649193764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4635462852559076\n",
      "NLL Loss is: 1.309205900964594\n",
      "Scaled KL Loss is: 0.039173368364572525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3483792693291665\n",
      "NLL Loss is: 1.5123467103795047\n",
      "Scaled KL Loss is: 0.03750004991889\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5498467602983947\n",
      "NLL Loss is: 1.3122659369640124\n",
      "Scaled KL Loss is: 0.03631022945046425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3485761664144766\n",
      "NLL Loss is: 1.4782570697092052\n",
      "Scaled KL Loss is: 0.038421884179115295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5166789538883205\n",
      "NLL Loss is: 1.4210872845302789\n",
      "Scaled KL Loss is: 0.035215821117162704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4563031056474416\n",
      "NLL Loss is: 1.3492265749084935\n",
      "Scaled KL Loss is: 0.03713741898536682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3863639938938603\n",
      "NLL Loss is: 1.2924234379650028\n",
      "Scaled KL Loss is: 0.0364360585808754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3288594965458782\n",
      "NLL Loss is: 1.3758624062038791\n",
      "Scaled KL Loss is: 0.03449954092502594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410361947128905\n",
      "NLL Loss is: 1.366893640223319\n",
      "Scaled KL Loss is: 0.036383409053087234\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4032770492764062\n",
      "NLL Loss is: 1.4023758721369297\n",
      "Scaled KL Loss is: 0.03395314887166023\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.43632902100859\n",
      "NLL Loss is: 1.3168917521765433\n",
      "Scaled KL Loss is: 0.03469222038984299\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515839725663863\n",
      "NLL Loss is: 1.5680557088057827\n",
      "Scaled KL Loss is: 0.03864122927188873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6066969380776714\n",
      "NLL Loss is: 1.1986983517798522\n",
      "Scaled KL Loss is: 0.03619644045829773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.23489479223815\n",
      "NLL Loss is: 1.3265695922210528\n",
      "Scaled KL Loss is: 0.039830636233091354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.366400228454144\n",
      "NLL Loss is: 1.3868100579199893\n",
      "Scaled KL Loss is: 0.040285877883434296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4270959358034236\n",
      "NLL Loss is: 1.1891735704427584\n",
      "Scaled KL Loss is: 0.038230471312999725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2274040417557581\n",
      "NLL Loss is: 1.3571607805839756\n",
      "Scaled KL Loss is: 0.03755662962794304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3947174102119186\n",
      "NLL Loss is: 1.2144932584364385\n",
      "Scaled KL Loss is: 0.037749335169792175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2522425936062307\n",
      "NLL Loss is: 1.222953390591334\n",
      "Scaled KL Loss is: 0.03463871404528618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.25759210463662\n",
      "NLL Loss is: 1.379731410257849\n",
      "Scaled KL Loss is: 0.03704501688480377\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4167764271426528\n",
      "NLL Loss is: 1.3885677166640606\n",
      "Scaled KL Loss is: 0.03543436899781227\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.424002085661873\n",
      "NLL Loss is: 1.2879559998521222\n",
      "Scaled KL Loss is: 0.035967323929071426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3239233237811936\n",
      "NLL Loss is: 1.471250344362901\n",
      "Scaled KL Loss is: 0.03626847267150879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5075188170344098\n",
      "NLL Loss is: 1.4911567218174338\n",
      "Scaled KL Loss is: 0.03640984371304512\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5275665655304789\n",
      "NLL Loss is: 1.2829544553870338\n",
      "Scaled KL Loss is: 0.04235250502824783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3253069604152816\n",
      "NLL Loss is: 1.2549505938526533\n",
      "Scaled KL Loss is: 0.03838388994336128\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2933344837960146\n",
      "NLL Loss is: 1.3992937050994094\n",
      "Scaled KL Loss is: 0.03703918308019638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4363328881796058\n",
      "NLL Loss is: 1.4971203896484326\n",
      "Scaled KL Loss is: 0.03808853402733803\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5352089236757707\n",
      "NLL Loss is: 1.2599053362544708\n",
      "Scaled KL Loss is: 0.03828825429081917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.29819359054529\n",
      "NLL Loss is: 1.2604091384787388\n",
      "Scaled KL Loss is: 0.033926162868738174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.294335301347477\n",
      "NLL Loss is: 1.2836854834627036\n",
      "Scaled KL Loss is: 0.037506721913814545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3211922053765182\n",
      "NLL Loss is: 1.2772029649286423\n",
      "Scaled KL Loss is: 0.043956391513347626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32115935644199\n",
      "NLL Loss is: 1.3637468035957268\n",
      "Scaled KL Loss is: 0.03570520505309105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3994520086488178\n",
      "NLL Loss is: 1.2902213433488345\n",
      "Scaled KL Loss is: 0.03858163580298424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3288029791518188\n",
      "NLL Loss is: 1.3082334274945715\n",
      "Scaled KL Loss is: 0.040219176560640335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3484526040552118\n",
      "NLL Loss is: 1.2186301572673441\n",
      "Scaled KL Loss is: 0.040186356753110886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.258816514020455\n",
      "NLL Loss is: 1.3136954713778415\n",
      "Scaled KL Loss is: 0.03994660824537277\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3536420796232143\n",
      "NLL Loss is: 1.274665249827844\n",
      "Scaled KL Loss is: 0.038000695407390594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3126659452352345\n",
      "NLL Loss is: 1.3541176108254067\n",
      "Scaled KL Loss is: 0.038997478783130646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3931150896085374\n",
      "NLL Loss is: 1.3560114119611983\n",
      "Scaled KL Loss is: 0.03660750389099121\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3926189158521896\n",
      "NLL Loss is: 1.2658077773480445\n",
      "Scaled KL Loss is: 0.03989078104496002\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3056985583930045\n",
      "NLL Loss is: 1.3834247551181007\n",
      "Scaled KL Loss is: 0.03520374000072479\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4186284951188255\n",
      "NLL Loss is: 1.4204316860249373\n",
      "Scaled KL Loss is: 0.03575371578335762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.456185401808295\n",
      "NLL Loss is: 1.430419780989697\n",
      "Scaled KL Loss is: 0.034512244164943695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4649320251546407\n",
      "NLL Loss is: 1.4393614045183971\n",
      "Scaled KL Loss is: 0.03917752578854561\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4785389303069427\n",
      "NLL Loss is: 1.3090725138733796\n",
      "Scaled KL Loss is: 0.03737170994281769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3464442238161973\n",
      "NLL Loss is: 1.2876890854100917\n",
      "Scaled KL Loss is: 0.03465086221694946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3223399476270412\n",
      "NLL Loss is: 1.2264552288228159\n",
      "Scaled KL Loss is: 0.04023554176092148\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2666907705837374\n",
      "NLL Loss is: 1.3248798829449027\n",
      "Scaled KL Loss is: 0.03783763572573662\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3627175186706393\n",
      "NLL Loss is: 1.353265097463146\n",
      "Scaled KL Loss is: 0.037796277552843094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.391061375015989\n",
      "NLL Loss is: 1.4234313462933132\n",
      "Scaled KL Loss is: 0.03720226511359215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4606336114069054\n",
      "NLL Loss is: 1.3197243896500412\n",
      "Scaled KL Loss is: 0.036555491387844086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3562798810378853\n",
      "NLL Loss is: 1.3488181220780973\n",
      "Scaled KL Loss is: 0.035350605845451355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3841687279235486\n",
      "NLL Loss is: 1.4159857028987364\n",
      "Scaled KL Loss is: 0.03654938563704491\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4525350885357813\n",
      "NLL Loss is: 1.422734325989622\n",
      "Scaled KL Loss is: 0.03729132190346718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.460025647893089\n",
      "NLL Loss is: 1.3859246169299768\n",
      "Scaled KL Loss is: 0.03730626031756401\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4232308772475408\n",
      "NLL Loss is: 1.3527749900838526\n",
      "Scaled KL Loss is: 0.04072865471243858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3935036447962912\n",
      "NLL Loss is: 1.3283260492533169\n",
      "Scaled KL Loss is: 0.03677724674344063\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3651032959967575\n",
      "NLL Loss is: 1.480731670344705\n",
      "Scaled KL Loss is: 0.03801163658499718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5187433069297023\n",
      "NLL Loss is: 1.3805900624855234\n",
      "Scaled KL Loss is: 0.0349370576441288\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4155271201296522\n",
      "NLL Loss is: 1.3884221714330391\n",
      "Scaled KL Loss is: 0.04010400176048279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.428526173193522\n",
      "NLL Loss is: 1.3629303100510048\n",
      "Scaled KL Loss is: 0.037748269736766815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4006785797877717\n",
      "NLL Loss is: 1.4635230840636648\n",
      "Scaled KL Loss is: 0.03650733828544617\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.500030422349111\n",
      "NLL Loss is: 1.3082427198444395\n",
      "Scaled KL Loss is: 0.03427831456065178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3425210344050913\n",
      "NLL Loss is: 1.4631018295705596\n",
      "Scaled KL Loss is: 0.03631129488348961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4994131244540492\n",
      "NLL Loss is: 1.416524864027719\n",
      "Scaled KL Loss is: 0.035707827657461166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4522326916851802\n",
      "NLL Loss is: 1.3594427146625145\n",
      "Scaled KL Loss is: 0.03830508887767792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3977478035401925\n",
      "NLL Loss is: 1.3138192271381275\n",
      "Scaled KL Loss is: 0.0361175462603569\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3499367733984844\n",
      "NLL Loss is: 1.3957417838395711\n",
      "Scaled KL Loss is: 0.03588644787669182\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.431628231716263\n",
      "NLL Loss is: 1.2813454672082356\n",
      "Scaled KL Loss is: 0.038760386407375336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.320105853615611\n",
      "NLL Loss is: 1.375157351511756\n",
      "Scaled KL Loss is: 0.033943336457014084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4091006879687702\n",
      "NLL Loss is: 1.2922999210173174\n",
      "Scaled KL Loss is: 0.03912638872861862\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.331426309745936\n",
      "NLL Loss is: 1.4322665665104952\n",
      "Scaled KL Loss is: 0.038293708115816116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4705602746263113\n",
      "NLL Loss is: 1.4778185467250338\n",
      "Scaled KL Loss is: 0.03453411906957626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.51235266579461\n",
      "NLL Loss is: 1.4131896673224873\n",
      "Scaled KL Loss is: 0.03395570069551468\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.447145368018002\n",
      "NLL Loss is: 1.3395332605004342\n",
      "Scaled KL Loss is: 0.039005838334560394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3785390988349946\n",
      "NLL Loss is: 1.274662739917795\n",
      "Scaled KL Loss is: 0.035368662327528\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.310031402245323\n",
      "NLL Loss is: 1.4519989438428775\n",
      "Scaled KL Loss is: 0.03613463044166565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4881335742845432\n",
      "NLL Loss is: 1.3413283136425793\n",
      "Scaled KL Loss is: 0.03675727918744087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3780855928300202\n",
      "NLL Loss is: 1.6948008077767704\n",
      "Scaled KL Loss is: 0.029397282749414444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.724198090526185\n",
      "NLL Loss is: 1.3540844051111622= 1.393; test loss = 1.429\n",
      "Scaled KL Loss is: 0.03858568146824837\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3926700865794106\n",
      "NLL Loss is: 1.410719078000254\n",
      "Scaled KL Loss is: 0.035662151873111725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4463812298733658\n",
      "NLL Loss is: 1.4053842717247886\n",
      "Scaled KL Loss is: 0.037526264786720276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.442910536511509\n",
      "NLL Loss is: 1.4433106470546557\n",
      "Scaled KL Loss is: 0.04009397327899933\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.483404620333655\n",
      "NLL Loss is: 1.380706083522834\n",
      "Scaled KL Loss is: 0.03353974595665932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4142458294794933\n",
      "NLL Loss is: 1.4295157381126038\n",
      "Scaled KL Loss is: 0.038103725761175156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.467619463873779\n",
      "NLL Loss is: 1.4165018490156052\n",
      "Scaled KL Loss is: 0.032824110239744186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4493259592553493\n",
      "NLL Loss is: 1.3403991310522148\n",
      "Scaled KL Loss is: 0.03417351469397545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3745726457461902\n",
      "NLL Loss is: 1.4033299960541876\n",
      "Scaled KL Loss is: 0.033753227442502975\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4370832234966906\n",
      "NLL Loss is: 1.3050511764439114\n",
      "Scaled KL Loss is: 0.03914168104529381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3441928574892053\n",
      "NLL Loss is: 1.3097234160020639\n",
      "Scaled KL Loss is: 0.03430428355932236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3440276995613862\n",
      "NLL Loss is: 1.426149475420929\n",
      "Scaled KL Loss is: 0.03581257164478302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.461962047065712\n",
      "NLL Loss is: 1.306565497043117\n",
      "Scaled KL Loss is: 0.039106063544750214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3456715605878673\n",
      "NLL Loss is: 1.5092463495425434\n",
      "Scaled KL Loss is: 0.0372801274061203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5465264769486637\n",
      "NLL Loss is: 1.3109582032726157\n",
      "Scaled KL Loss is: 0.03601568937301636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346973892645632\n",
      "NLL Loss is: 1.4758933919256583\n",
      "Scaled KL Loss is: 0.03851289674639702\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5144062886720553\n",
      "NLL Loss is: 1.417888050854637\n",
      "Scaled KL Loss is: 0.03528543561697006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.453173486471607\n",
      "NLL Loss is: 1.3484174414315562\n",
      "Scaled KL Loss is: 0.036957986652851105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3853754280844073\n",
      "NLL Loss is: 1.290553436417805\n",
      "Scaled KL Loss is: 0.036379192024469376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3269326284422744\n",
      "NLL Loss is: 1.3746895822325416\n",
      "Scaled KL Loss is: 0.034509897232055664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4091994794645972\n",
      "NLL Loss is: 1.3622759589348958\n",
      "Scaled KL Loss is: 0.03605179488658905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3983277538214849\n",
      "NLL Loss is: 1.3992989241345486\n",
      "Scaled KL Loss is: 0.033965498208999634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4332644223435482\n",
      "NLL Loss is: 1.3149776720100623\n",
      "Scaled KL Loss is: 0.034727878868579865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3497055508786422\n",
      "NLL Loss is: 1.5678747248612075\n",
      "Scaled KL Loss is: 0.038459669798612595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.60633439465982\n",
      "NLL Loss is: 1.198076750215364\n",
      "Scaled KL Loss is: 0.03606041148304939\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2341371616984134\n",
      "NLL Loss is: 1.3249576303916857\n",
      "Scaled KL Loss is: 0.03976799547672272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3647256258684084\n",
      "NLL Loss is: 1.3848283713231775\n",
      "Scaled KL Loss is: 0.04027634859085083\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4251047199140283\n",
      "NLL Loss is: 1.1861824433179031\n",
      "Scaled KL Loss is: 0.038280028849840164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2244624721677433\n",
      "NLL Loss is: 1.3550611043947465\n",
      "Scaled KL Loss is: 0.03746318817138672\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3925242925661332\n",
      "NLL Loss is: 1.2115797457700386\n",
      "Scaled KL Loss is: 0.03764062002301216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2492203657930507\n",
      "NLL Loss is: 1.2205934883387979\n",
      "Scaled KL Loss is: 0.03443076089024544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2550242492290433\n",
      "NLL Loss is: 1.3759987776461264\n",
      "Scaled KL Loss is: 0.0369081050157547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4129068826618811\n",
      "NLL Loss is: 1.385205757686922\n",
      "Scaled KL Loss is: 0.03519100695848465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4203967646454065\n",
      "NLL Loss is: 1.2858169186134234\n",
      "Scaled KL Loss is: 0.035779066383838654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.321595984997262\n",
      "NLL Loss is: 1.467986344844788\n",
      "Scaled KL Loss is: 0.036187734454870224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5041740792996583\n",
      "NLL Loss is: 1.4877413467411795\n",
      "Scaled KL Loss is: 0.036200784146785736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5239421308879653\n",
      "NLL Loss is: 1.2811189835841439\n",
      "Scaled KL Loss is: 0.04222243279218674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3233414163763306\n",
      "NLL Loss is: 1.2539678713276452\n",
      "Scaled KL Loss is: 0.03839448094367981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.292362352271325\n",
      "NLL Loss is: 1.3954949426111278\n",
      "Scaled KL Loss is: 0.03692474216222763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4324196847733555\n",
      "NLL Loss is: 1.4949595360735974\n",
      "Scaled KL Loss is: 0.03789304569363594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5328525817672334\n",
      "NLL Loss is: 1.2550689964779653\n",
      "Scaled KL Loss is: 0.03807105869054794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2931400551685133\n",
      "NLL Loss is: 1.2561530003423858\n",
      "Scaled KL Loss is: 0.03378545120358467\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2899384515459704\n",
      "NLL Loss is: 1.2809088255025882\n",
      "Scaled KL Loss is: 0.037545058876276016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3184538843788642\n",
      "NLL Loss is: 1.2733001871080651\n",
      "Scaled KL Loss is: 0.04371199384331703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3170121809513822\n",
      "NLL Loss is: 1.3602789588136408\n",
      "Scaled KL Loss is: 0.035486578941345215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395765537754986\n",
      "NLL Loss is: 1.2885697317457727\n",
      "Scaled KL Loss is: 0.038517534732818604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3270872664785913\n",
      "NLL Loss is: 1.306834846276468\n",
      "Scaled KL Loss is: 0.04009915888309479\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3469340051595629\n",
      "NLL Loss is: 1.2152739334339442\n",
      "Scaled KL Loss is: 0.04028746858239174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255561402016336\n",
      "NLL Loss is: 1.3117985452981467\n",
      "Scaled KL Loss is: 0.03976083919405937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351559384492206\n",
      "NLL Loss is: 1.2713007940442147\n",
      "Scaled KL Loss is: 0.037840474396944046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3091412684411587\n",
      "NLL Loss is: 1.3511693064838939\n",
      "Scaled KL Loss is: 0.038897983729839325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3900672902137332\n",
      "NLL Loss is: 1.3546516944244822\n",
      "Scaled KL Loss is: 0.03637999668717384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.391031691111656\n",
      "NLL Loss is: 1.2629836548780968\n",
      "Scaled KL Loss is: 0.039595067501068115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.302578722379165\n",
      "NLL Loss is: 1.3813596193785767\n",
      "Scaled KL Loss is: 0.03515690565109253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4165165250296692\n",
      "NLL Loss is: 1.418089456013736\n",
      "Scaled KL Loss is: 0.03565899655222893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.453748452565965\n",
      "NLL Loss is: 1.4278845936507754\n",
      "Scaled KL Loss is: 0.034399908035993576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.462284501686769\n",
      "NLL Loss is: 1.4375219987948753\n",
      "Scaled KL Loss is: 0.03901819512248039\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4765401939173557\n",
      "NLL Loss is: 1.3073852411006999\n",
      "Scaled KL Loss is: 0.03707438334822655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3444596244489264\n",
      "NLL Loss is: 1.285908167673556\n",
      "Scaled KL Loss is: 0.03459768742322922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3205058550967852\n",
      "NLL Loss is: 1.2237430140375087\n",
      "Scaled KL Loss is: 0.03993615135550499\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2636791653930137\n",
      "NLL Loss is: 1.3216603829962765\n",
      "Scaled KL Loss is: 0.03776002675294876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3594204097492253\n",
      "NLL Loss is: 1.3486879622956365\n",
      "Scaled KL Loss is: 0.037527911365032196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3862158736606687\n",
      "NLL Loss is: 1.4209874219822354\n",
      "Scaled KL Loss is: 0.03697573021054268\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.457963152192778\n",
      "NLL Loss is: 1.3182048245691613\n",
      "Scaled KL Loss is: 0.03656884282827377\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354773667397435\n",
      "NLL Loss is: 1.346050437070336\n",
      "Scaled KL Loss is: 0.03515652194619179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3812069590165277\n",
      "NLL Loss is: 1.4153213721511457\n",
      "Scaled KL Loss is: 0.03642325475811958\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4517446269092653\n",
      "NLL Loss is: 1.4205311013565785\n",
      "Scaled KL Loss is: 0.0372561514377594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4577872527943379\n",
      "NLL Loss is: 1.3835464471966485\n",
      "Scaled KL Loss is: 0.03702791780233383\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4205743649989824\n",
      "NLL Loss is: 1.3502533229979545\n",
      "Scaled KL Loss is: 0.04051598161458969\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3907693046125442\n",
      "NLL Loss is: 1.325646605289555\n",
      "Scaled KL Loss is: 0.03657585009932518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3622224553888802\n",
      "NLL Loss is: 1.4784541945987513\n",
      "Scaled KL Loss is: 0.03783606365323067\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.516290258251982\n",
      "NLL Loss is: 1.3783009663683754\n",
      "Scaled KL Loss is: 0.034817133098840714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4131180994672161\n",
      "NLL Loss is: 1.3843397197100908\n",
      "Scaled KL Loss is: 0.03991834446787834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4242580641779692\n",
      "NLL Loss is: 1.361356551067572\n",
      "Scaled KL Loss is: 0.0376560315489769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.399012582616549\n",
      "NLL Loss is: 1.4626238120398662\n",
      "Scaled KL Loss is: 0.0363866426050663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4990104546449325\n",
      "NLL Loss is: 1.3065434332256245\n",
      "Scaled KL Loss is: 0.03409740701317787\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3406408402388024\n",
      "NLL Loss is: 1.4607004329490807\n",
      "Scaled KL Loss is: 0.0359729528427124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.496673385791793\n",
      "NLL Loss is: 1.4142915892664558\n",
      "Scaled KL Loss is: 0.03569195047020912\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.449983539736665\n",
      "NLL Loss is: 1.3588572680249158\n",
      "Scaled KL Loss is: 0.03785596415400505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3967132321789208\n",
      "NLL Loss is: 1.3110931804361794\n",
      "Scaled KL Loss is: 0.03579479083418846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3468879712703679\n",
      "NLL Loss is: 1.3932071923679976\n",
      "Scaled KL Loss is: 0.035711392760276794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4289185851282744\n",
      "NLL Loss is: 1.2782626986973886\n",
      "Scaled KL Loss is: 0.038536570966243744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3167992696636324\n",
      "NLL Loss is: 1.3742669646003565\n",
      "Scaled KL Loss is: 0.03372209519147873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4079890597918352\n",
      "NLL Loss is: 1.28828901652488\n",
      "Scaled KL Loss is: 0.038869500160217285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3271585166850972\n",
      "NLL Loss is: 1.427626807975635\n",
      "Scaled KL Loss is: 0.03799882158637047\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4656256295620054\n",
      "NLL Loss is: 1.4754197428652696\n",
      "Scaled KL Loss is: 0.03464959189295769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5100693347582272\n",
      "NLL Loss is: 1.4098478573772741\n",
      "Scaled KL Loss is: 0.033757422119379044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4436052794966532\n",
      "NLL Loss is: 1.3367602502508809\n",
      "Scaled KL Loss is: 0.038771867752075195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375532118002956\n",
      "NLL Loss is: 1.2728947448108363\n",
      "Scaled KL Loss is: 0.03524206206202507\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3081368068728614\n",
      "NLL Loss is: 1.4513440182751842\n",
      "Scaled KL Loss is: 0.03613194450736046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4874759627825447\n",
      "NLL Loss is: 1.3378142180394048\n",
      "Scaled KL Loss is: 0.036718130111694336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3745323481510991\n",
      "NLL Loss is: 1.6917692188120068\n",
      "Scaled KL Loss is: 0.02937181666493416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.721141035476941\n",
      "NLL Loss is: 1.351770618123603 = 1.390; test loss = 1.426\n",
      "Scaled KL Loss is: 0.038369785994291306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3901404041178944\n",
      "NLL Loss is: 1.408342889152412\n",
      "Scaled KL Loss is: 0.03543394058942795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4437768297418399\n",
      "NLL Loss is: 1.4038960540047944\n",
      "Scaled KL Loss is: 0.03735935688018799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4412554108849824\n",
      "NLL Loss is: 1.4396201648724571\n",
      "Scaled KL Loss is: 0.039712682366371155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4793328472388283\n",
      "NLL Loss is: 1.3785691593930707\n",
      "Scaled KL Loss is: 0.03342955559492111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119987149879918\n",
      "NLL Loss is: 1.4259274999455709\n",
      "Scaled KL Loss is: 0.03793516382575035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4638626637713212\n",
      "NLL Loss is: 1.414885510902605\n",
      "Scaled KL Loss is: 0.032735131680965424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4476206425835705\n",
      "NLL Loss is: 1.3407412828146699\n",
      "Scaled KL Loss is: 0.03388529643416405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.374626579248834\n",
      "NLL Loss is: 1.4028007852527182\n",
      "Scaled KL Loss is: 0.03351748734712601\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4363182725998442\n",
      "NLL Loss is: 1.3034375791779147\n",
      "Scaled KL Loss is: 0.03893802687525749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3423756060531722\n",
      "NLL Loss is: 1.3087644635051896\n",
      "Scaled KL Loss is: 0.03390264883637428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3426671123415639\n",
      "NLL Loss is: 1.4246705449631736\n",
      "Scaled KL Loss is: 0.03574717044830322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4604177154114768\n",
      "NLL Loss is: 1.304039449298016\n",
      "Scaled KL Loss is: 0.03908152878284454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431209780808606\n",
      "NLL Loss is: 1.505914175620278\n",
      "Scaled KL Loss is: 0.03710763528943062\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5430218109097087\n",
      "NLL Loss is: 1.3096133024575243\n",
      "Scaled KL Loss is: 0.035777390003204346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3453906924607286\n",
      "NLL Loss is: 1.473115445370238\n",
      "Scaled KL Loss is: 0.0386388786137104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5117543239839484\n",
      "NLL Loss is: 1.4146396785061024\n",
      "Scaled KL Loss is: 0.03539144992828369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.450031128434386\n",
      "NLL Loss is: 1.3477143642113705\n",
      "Scaled KL Loss is: 0.03682398051023483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3845383447216053\n",
      "NLL Loss is: 1.2887699346411174\n",
      "Scaled KL Loss is: 0.036367133259773254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3251370679008907\n",
      "NLL Loss is: 1.3732963612250628\n",
      "Scaled KL Loss is: 0.03456060215830803\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4078569633833709\n",
      "NLL Loss is: 1.3574008051366058\n",
      "Scaled KL Loss is: 0.035756681114435196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393157486251041\n",
      "NLL Loss is: 1.3963739325791136\n",
      "Scaled KL Loss is: 0.03401101008057594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4303849426596895\n",
      "NLL Loss is: 1.3128336569887589\n",
      "Scaled KL Loss is: 0.03478792682290077\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3476215838116596\n",
      "NLL Loss is: 1.5690235610305785\n",
      "Scaled KL Loss is: 0.038282573223114014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6073061342536925\n",
      "NLL Loss is: 1.1968725873362875\n",
      "Scaled KL Loss is: 0.035946138203144073\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2328187255394316\n",
      "NLL Loss is: 1.3231454540665972\n",
      "Scaled KL Loss is: 0.03971768915653229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3628631432231295\n",
      "NLL Loss is: 1.3830355462171284\n",
      "Scaled KL Loss is: 0.04027989134192467\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423315437559053\n",
      "NLL Loss is: 1.181684126469575\n",
      "Scaled KL Loss is: 0.038362205028533936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.220046331498109\n",
      "NLL Loss is: 1.3526972859436304\n",
      "Scaled KL Loss is: 0.03737186640501022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3900691523486406\n",
      "NLL Loss is: 1.2084518471858554\n",
      "Scaled KL Loss is: 0.03753973916172981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2459915863475852\n",
      "NLL Loss is: 1.217214926999106\n",
      "Scaled KL Loss is: 0.03423192724585533\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2514468542449613\n",
      "NLL Loss is: 1.3721864963938772\n",
      "Scaled KL Loss is: 0.036778610199689865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408965106593567\n",
      "NLL Loss is: 1.3817385218497744\n",
      "Scaled KL Loss is: 0.03495508432388306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4166936061736575\n",
      "NLL Loss is: 1.2828959027218867\n",
      "Scaled KL Loss is: 0.035598114132881165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3184940168547679\n",
      "NLL Loss is: 1.464570258190908\n",
      "Scaled KL Loss is: 0.036113299429416656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5006835576203246\n",
      "NLL Loss is: 1.4857175381200853\n",
      "Scaled KL Loss is: 0.036012109369039536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5217296474891249\n",
      "NLL Loss is: 1.2781709740992375\n",
      "Scaled KL Loss is: 0.04209877550601959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3202697496052571\n",
      "NLL Loss is: 1.2529770235894966\n",
      "Scaled KL Loss is: 0.038425203412771225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2914022270022678\n",
      "NLL Loss is: 1.3924841825091847\n",
      "Scaled KL Loss is: 0.036829572170972824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4293137546801575\n",
      "NLL Loss is: 1.4931126139031772\n",
      "Scaled KL Loss is: 0.03771767392754555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5308302878307227\n",
      "NLL Loss is: 1.2500688587304536\n",
      "Scaled KL Loss is: 0.037877991795539856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2879468505259934\n",
      "NLL Loss is: 1.2525101739962086\n",
      "Scaled KL Loss is: 0.033665794879198074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2861759688754066\n",
      "NLL Loss is: 1.2781272154454606\n",
      "Scaled KL Loss is: 0.03759583458304405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3157230500285046\n",
      "NLL Loss is: 1.2685082340207254\n",
      "Scaled KL Loss is: 0.0434822216629982\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3119904556837236\n",
      "NLL Loss is: 1.3570469367147098\n",
      "Scaled KL Loss is: 0.035280559211969376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3923274959266791\n",
      "NLL Loss is: 1.2864817485420432\n",
      "Scaled KL Loss is: 0.038470830768346786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32495257931039\n",
      "NLL Loss is: 1.3054366178263082\n",
      "Scaled KL Loss is: 0.03999243676662445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3454290545929326\n",
      "NLL Loss is: 1.2124731306360397\n",
      "Scaled KL Loss is: 0.040393732488155365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.252866863124195\n",
      "NLL Loss is: 1.310123584590051\n",
      "Scaled KL Loss is: 0.039593420922756195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3497170055128072\n",
      "NLL Loss is: 1.2683625498326572\n",
      "Scaled KL Loss is: 0.03769076243042946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3060533122630866\n",
      "NLL Loss is: 1.3493372569524553\n",
      "Scaled KL Loss is: 0.038804374635219574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.388141631587675\n",
      "NLL Loss is: 1.3530755441654438\n",
      "Scaled KL Loss is: 0.036160241812467575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3892357859779114\n",
      "NLL Loss is: 1.2607895139615541\n",
      "Scaled KL Loss is: 0.039306238293647766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300095752255202\n",
      "NLL Loss is: 1.379428532242119\n",
      "Scaled KL Loss is: 0.03510452061891556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4145330528610345\n",
      "NLL Loss is: 1.4160635920747098\n",
      "Scaled KL Loss is: 0.035564716905355453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4516283089800652\n",
      "NLL Loss is: 1.4253851979992767\n",
      "Scaled KL Loss is: 0.03428807109594345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.45967326909522\n",
      "NLL Loss is: 1.4354782350828428\n",
      "Scaled KL Loss is: 0.03885994106531143\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4743381761481542\n",
      "NLL Loss is: 1.306314047891464\n",
      "Scaled KL Loss is: 0.03678338974714279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343097437638607\n",
      "NLL Loss is: 1.2843364880464951\n",
      "Scaled KL Loss is: 0.03455277159810066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3188892596445958\n",
      "NLL Loss is: 1.2214576510645534\n",
      "Scaled KL Loss is: 0.03965037316083908\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2611080242253925\n",
      "NLL Loss is: 1.3197052612249416\n",
      "Scaled KL Loss is: 0.03768290579319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3573881670181316\n",
      "NLL Loss is: 1.3446562306275203\n",
      "Scaled KL Loss is: 0.03728359565138817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3819398262789084\n",
      "NLL Loss is: 1.4181289989601171\n",
      "Scaled KL Loss is: 0.03678106144070625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4549100604008234\n",
      "NLL Loss is: 1.3172930354750645\n",
      "Scaled KL Loss is: 0.03660418465733528\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3538972201323998\n",
      "NLL Loss is: 1.343633244577918\n",
      "Scaled KL Loss is: 0.03500453010201454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3786377746799325\n",
      "NLL Loss is: 1.4129801459020102\n",
      "Scaled KL Loss is: 0.03632552921772003\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4493056751197302\n",
      "NLL Loss is: 1.4184795439047466\n",
      "Scaled KL Loss is: 0.037244852632284164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4557243965370308\n",
      "NLL Loss is: 1.381671199954953\n",
      "Scaled KL Loss is: 0.03678712621331215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418458326168265\n",
      "NLL Loss is: 1.3479726938947727\n",
      "Scaled KL Loss is: 0.04033749923110008\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3883101931258728\n",
      "NLL Loss is: 1.3228302685302304\n",
      "Scaled KL Loss is: 0.03641984239220619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3592501109224366\n",
      "NLL Loss is: 1.4764419817949648\n",
      "Scaled KL Loss is: 0.03770092502236366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5141429068173284\n",
      "NLL Loss is: 1.3764783841160197\n",
      "Scaled KL Loss is: 0.034737199544906616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4112155836609264\n",
      "NLL Loss is: 1.3806853197059208\n",
      "Scaled KL Loss is: 0.03976248949766159\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4204478092035824\n",
      "NLL Loss is: 1.3597056954265252\n",
      "Scaled KL Loss is: 0.0375964380800724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3973021335065976\n",
      "NLL Loss is: 1.461836445531378\n",
      "Scaled KL Loss is: 0.03629818931221962\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4981346348435975\n",
      "NLL Loss is: 1.3053688806253851\n",
      "Scaled KL Loss is: 0.03395815193653107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3393270325619162\n",
      "NLL Loss is: 1.4584285808772437\n",
      "Scaled KL Loss is: 0.03568554297089577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4941141238481395\n",
      "NLL Loss is: 1.4117887799334339\n",
      "Scaled KL Loss is: 0.0357058010995388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4474945810329727\n",
      "NLL Loss is: 1.358691155583437\n",
      "Scaled KL Loss is: 0.03745981305837631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3961509686418132\n",
      "NLL Loss is: 1.308377621949357\n",
      "Scaled KL Loss is: 0.03551540896296501\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343893030912322\n",
      "NLL Loss is: 1.3907876939358894\n",
      "Scaled KL Loss is: 0.035573627799749374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4263613217356388\n",
      "NLL Loss is: 1.2752419350677404\n",
      "Scaled KL Loss is: 0.0383501797914505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.313592114859191\n",
      "NLL Loss is: 1.3733836698362365\n",
      "Scaled KL Loss is: 0.033543482422828674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4069271522590652\n",
      "NLL Loss is: 1.2848510470406662\n",
      "Scaled KL Loss is: 0.038654666393995285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3235057134346615\n",
      "NLL Loss is: 1.4231439324896429\n",
      "Scaled KL Loss is: 0.037749018520116806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4608929510097597\n",
      "NLL Loss is: 1.4729560087780698\n",
      "Scaled KL Loss is: 0.03478984907269478\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5077458578507645\n",
      "NLL Loss is: 1.4064073802463173\n",
      "Scaled KL Loss is: 0.03360159322619438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4400089734725117\n",
      "NLL Loss is: 1.3344134208246599\n",
      "Scaled KL Loss is: 0.03857189416885376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3729853149935136\n",
      "NLL Loss is: 1.2715963592833774\n",
      "Scaled KL Loss is: 0.03514401242136955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.306740371704747\n",
      "NLL Loss is: 1.4506200970396315\n",
      "Scaled KL Loss is: 0.036153171211481094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4867732682511126\n",
      "NLL Loss is: 1.334707193488019\n",
      "Scaled KL Loss is: 0.03671110048890114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3714182939769202\n",
      "NLL Loss is: 1.6895904798983987\n",
      "Scaled KL Loss is: 0.029375188052654266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.718965667951053\n",
      "NLL Loss is: 1.3497158381318033= 1.388; test loss = 1.424\n",
      "Scaled KL Loss is: 0.038191210478544235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3879070486103475\n",
      "NLL Loss is: 1.4062847937542937\n",
      "Scaled KL Loss is: 0.03524511680006981\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4415299105543635\n",
      "NLL Loss is: 1.4021697636408852\n",
      "Scaled KL Loss is: 0.037227366119623184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4393971297605084\n",
      "NLL Loss is: 1.435957228430617\n",
      "Scaled KL Loss is: 0.039373017847537994\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.475330246278155\n",
      "NLL Loss is: 1.3763971271334805\n",
      "Scaled KL Loss is: 0.03335476294159889\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4097518900750794\n",
      "NLL Loss is: 1.4226400694866685\n",
      "Scaled KL Loss is: 0.03780011087656021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4604401803632288\n",
      "NLL Loss is: 1.4132938918526088\n",
      "Scaled KL Loss is: 0.03268202394247055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4459759157950793\n",
      "NLL Loss is: 1.3411725690212313\n",
      "Scaled KL Loss is: 0.03363853693008423\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3748111059513155\n",
      "NLL Loss is: 1.4023810404159922\n",
      "Scaled KL Loss is: 0.03332177549600601\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4357028159119982\n",
      "NLL Loss is: 1.3018827712241319\n",
      "Scaled KL Loss is: 0.03877468779683113\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.340657459020963\n",
      "NLL Loss is: 1.307841035673506\n",
      "Scaled KL Loss is: 0.03355034813284874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3413913838063547\n",
      "NLL Loss is: 1.4232202801368499\n",
      "Scaled KL Loss is: 0.03571650758385658\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4589367877207065\n",
      "NLL Loss is: 1.3014623278161732\n",
      "Scaled KL Loss is: 0.039096441119909286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3405587689360825\n",
      "NLL Loss is: 1.5026620514828286\n",
      "Scaled KL Loss is: 0.036972954869270325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.539635006352099\n",
      "NLL Loss is: 1.3081642885244797\n",
      "Scaled KL Loss is: 0.03559345752000809\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3437577460444878\n",
      "NLL Loss is: 1.470467387338967\n",
      "Scaled KL Loss is: 0.03880620375275612\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5092735910917232\n",
      "NLL Loss is: 1.4113884531920349\n",
      "Scaled KL Loss is: 0.035533640533685684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4469220937257206\n",
      "NLL Loss is: 1.3469882853877462\n",
      "Scaled KL Loss is: 0.03673698380589485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.383725269193641\n",
      "NLL Loss is: 1.2871203178494293\n",
      "Scaled KL Loss is: 0.03640005365014076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32352037149957\n",
      "NLL Loss is: 1.371880743775712\n",
      "Scaled KL Loss is: 0.03465352579951286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4065342695752248\n",
      "NLL Loss is: 1.3530789979930506\n",
      "Scaled KL Loss is: 0.035526953637599945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3886059516306506\n",
      "NLL Loss is: 1.3935616586606645\n",
      "Scaled KL Loss is: 0.03410513699054718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4276667956512117\n",
      "NLL Loss is: 1.310866453409135\n",
      "Scaled KL Loss is: 0.034907758235931396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3457742116450664\n",
      "NLL Loss is: 1.5690813940817514\n",
      "Scaled KL Loss is: 0.038192618638277054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6072740127200285\n",
      "NLL Loss is: 1.1960480679151282\n",
      "Scaled KL Loss is: 0.03590942919254303\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2319574971076712\n",
      "NLL Loss is: 1.3217792655790972\n",
      "Scaled KL Loss is: 0.03973620384931564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3615154694284128\n",
      "NLL Loss is: 1.3812798090065315\n",
      "Scaled KL Loss is: 0.040350835770368576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4216306447769\n",
      "NLL Loss is: 1.1788348033743918\n",
      "Scaled KL Loss is: 0.03848811611533165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2173229194897235\n",
      "NLL Loss is: 1.3506497589482154\n",
      "Scaled KL Loss is: 0.03736553713679314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3880152960850085\n",
      "NLL Loss is: 1.2055309144634865\n",
      "Scaled KL Loss is: 0.037524692714214325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2430556071777008\n",
      "NLL Loss is: 1.2149326777098253\n",
      "Scaled KL Loss is: 0.034126535058021545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2490592127678468\n",
      "NLL Loss is: 1.368537644812933\n",
      "Scaled KL Loss is: 0.036740098148584366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4052777429615173\n",
      "NLL Loss is: 1.3787038125936746\n",
      "Scaled KL Loss is: 0.034820716828107834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4135245294217824\n",
      "NLL Loss is: 1.2807837262721455\n",
      "Scaled KL Loss is: 0.03550812229514122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3162918485672868\n",
      "NLL Loss is: 1.4614834660077718\n",
      "Scaled KL Loss is: 0.03611989691853523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.497603362926307\n",
      "NLL Loss is: 1.4829313080728843\n",
      "Scaled KL Loss is: 0.035911962389945984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5188432704628303\n",
      "NLL Loss is: 1.2760908536306625\n",
      "Scaled KL Loss is: 0.04205592721700668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3181467808476692\n",
      "NLL Loss is: 1.251998241932233\n",
      "Scaled KL Loss is: 0.03851877152919769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2905170134614308\n",
      "NLL Loss is: 1.389147011236546\n",
      "Scaled KL Loss is: 0.03681512922048569\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4259621404570317\n",
      "NLL Loss is: 1.4907125051867502\n",
      "Scaled KL Loss is: 0.03762120008468628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5283337052714365\n",
      "NLL Loss is: 1.2454838129534718\n",
      "Scaled KL Loss is: 0.03777133300900459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2832551459624764\n",
      "NLL Loss is: 1.248748364846028\n",
      "Scaled KL Loss is: 0.03362065181136131\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2823690166573893\n",
      "NLL Loss is: 1.2753907114155907\n",
      "Scaled KL Loss is: 0.03771691396832466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3131076253839153\n",
      "NLL Loss is: 1.264612849099903\n",
      "Scaled KL Loss is: 0.043339140713214874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3079519898131178\n",
      "NLL Loss is: 1.3538634538262844\n",
      "Scaled KL Loss is: 0.035160601139068604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.389024054965353\n",
      "NLL Loss is: 1.2847654736425624\n",
      "Scaled KL Loss is: 0.038495905697345734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3232613793399082\n",
      "NLL Loss is: 1.304069060892461\n",
      "Scaled KL Loss is: 0.03995848819613457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3440275490885956\n",
      "NLL Loss is: 1.2093832619797908\n",
      "Scaled KL Loss is: 0.040564365684986115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.249947627664777\n",
      "NLL Loss is: 1.308436541742506\n",
      "Scaled KL Loss is: 0.03950165584683418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34793819758934\n",
      "NLL Loss is: 1.265171597983451\n",
      "Scaled KL Loss is: 0.03762262314558029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3027942211290313\n",
      "NLL Loss is: 1.3465194572874364\n",
      "Scaled KL Loss is: 0.038786791265010834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3853062485524472\n",
      "NLL Loss is: 1.3519720957829349\n",
      "Scaled KL Loss is: 0.036030009388923645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3880021051718585\n",
      "NLL Loss is: 1.2581038930360564\n",
      "Scaled KL Loss is: 0.03910934180021286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2972132348362693\n",
      "NLL Loss is: 1.3774571223339216\n",
      "Scaled KL Loss is: 0.03513466939330101\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4125917917272226\n",
      "NLL Loss is: 1.4135712899666422\n",
      "Scaled KL Loss is: 0.03555447980761528\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4491257697742574\n",
      "NLL Loss is: 1.4229231371196227\n",
      "Scaled KL Loss is: 0.034266501665115356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.457189638784738\n",
      "NLL Loss is: 1.4336033710796223\n",
      "Scaled KL Loss is: 0.03879585862159729\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4723992297012196\n",
      "NLL Loss is: 1.3051065085818925\n",
      "Scaled KL Loss is: 0.03659588471055031\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3417023932924428\n",
      "NLL Loss is: 1.2825287029717145\n",
      "Scaled KL Loss is: 0.03459206596016884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3171207689318833\n",
      "NLL Loss is: 1.219194119471663\n",
      "Scaled KL Loss is: 0.03946499899029732\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2586591184619602\n",
      "NLL Loss is: 1.3173378051841558\n",
      "Scaled KL Loss is: 0.037689898163080215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355027703347236\n",
      "NLL Loss is: 1.3405194746563318\n",
      "Scaled KL Loss is: 0.03713201358914375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3776514882454756\n",
      "NLL Loss is: 1.4154694002917318\n",
      "Scaled KL Loss is: 0.03666931763291359\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4521387179246454\n",
      "NLL Loss is: 1.3160845751168226\n",
      "Scaled KL Loss is: 0.03671310469508171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3527976798119044\n",
      "NLL Loss is: 1.341055078762706\n",
      "Scaled KL Loss is: 0.03492974117398262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3759848199366886\n",
      "NLL Loss is: 1.411345693625845\n",
      "Scaled KL Loss is: 0.03630474954843521\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4476504431742803\n",
      "NLL Loss is: 1.4164585101037865\n",
      "Scaled KL Loss is: 0.03730752691626549\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.453766037020052\n",
      "NLL Loss is: 1.379668916150261\n",
      "Scaled KL Loss is: 0.03662797808647156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4162968942367327\n",
      "NLL Loss is: 1.3457085825217467\n",
      "Scaled KL Loss is: 0.040242329239845276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.385950911761592\n",
      "NLL Loss is: 1.3201609622932364\n",
      "Scaled KL Loss is: 0.036335308104753494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35649627039799\n",
      "NLL Loss is: 1.4743717497174407\n",
      "Scaled KL Loss is: 0.037640344351530075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5120120940689707\n",
      "NLL Loss is: 1.3745353701454692\n",
      "Scaled KL Loss is: 0.03473082184791565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4092661919933849\n",
      "NLL Loss is: 1.377107434855067\n",
      "Scaled KL Loss is: 0.03968523070216179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4167926655572287\n",
      "NLL Loss is: 1.357883299007957\n",
      "Scaled KL Loss is: 0.03760885074734688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395492149755304\n",
      "NLL Loss is: 1.4612013708319682\n",
      "Scaled KL Loss is: 0.03628458082675934\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4974859516587276\n",
      "NLL Loss is: 1.3040564120181386\n",
      "Scaled KL Loss is: 0.03388913720846176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3379455492266004\n",
      "NLL Loss is: 1.4561646894407148\n",
      "Scaled KL Loss is: 0.03547853231430054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4916432217550153\n",
      "NLL Loss is: 1.4093730557133233\n",
      "Scaled KL Loss is: 0.035786449909210205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4451595056225335\n",
      "NLL Loss is: 1.3582288005472634\n",
      "Scaled KL Loss is: 0.03715788945555687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3953866900028202\n",
      "NLL Loss is: 1.3057604937139218\n",
      "Scaled KL Loss is: 0.035328250378370285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341088744092292\n",
      "NLL Loss is: 1.3884489745617217\n",
      "Scaled KL Loss is: 0.03551073372364044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4239597082853621\n",
      "NLL Loss is: 1.2723437733938026\n",
      "Scaled KL Loss is: 0.03824871778488159\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3105924911786841\n",
      "NLL Loss is: 1.3725376850214852\n",
      "Scaled KL Loss is: 0.033440083265304565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4059777682867898\n",
      "NLL Loss is: 1.281553050179919\n",
      "Scaled KL Loss is: 0.038519468158483505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3200725183384026\n",
      "NLL Loss is: 1.418902228753996\n",
      "Scaled KL Loss is: 0.037578023970127106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4564802527241232\n",
      "NLL Loss is: 1.470580596301061\n",
      "Scaled KL Loss is: 0.034986987709999084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.50556758401106\n",
      "NLL Loss is: 1.4030818689977544\n",
      "Scaled KL Loss is: 0.03351505473256111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4365969237303156\n",
      "NLL Loss is: 1.3321015744119822\n",
      "Scaled KL Loss is: 0.03845374658703804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3705553209990202\n",
      "NLL Loss is: 1.2700494389546495\n",
      "Scaled KL Loss is: 0.035124748945236206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3051741878998857\n",
      "NLL Loss is: 1.4498353933567172\n",
      "Scaled KL Loss is: 0.03624042123556137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4860758145922786\n",
      "NLL Loss is: 1.3316767676582981\n",
      "Scaled KL Loss is: 0.036769378930330276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3684461465886284\n",
      "NLL Loss is: 1.687213957942858\n",
      "Scaled KL Loss is: 0.029436999931931496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7166509578747895\n",
      "NLL Loss is: 1.3477723785356255= 1.385; test loss = 1.422\n",
      "Scaled KL Loss is: 0.03808766230940819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3858600408450337\n",
      "NLL Loss is: 1.4040736970371523\n",
      "Scaled KL Loss is: 0.03513554111123085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4392092381483832\n",
      "NLL Loss is: 1.4003681635480805\n",
      "Scaled KL Loss is: 0.037171367555856705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4375395311039372\n",
      "NLL Loss is: 1.4325495573441105\n",
      "Scaled KL Loss is: 0.039121322333812714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4716708796779232\n",
      "NLL Loss is: 1.3742245488346456\n",
      "Scaled KL Loss is: 0.033349186182022095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4075737350166677\n",
      "NLL Loss is: 1.4194836263905897\n",
      "Scaled KL Loss is: 0.037738457322120667\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4572220837127103\n",
      "NLL Loss is: 1.4117468819221712\n",
      "Scaled KL Loss is: 0.032700493931770325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4444473758539416\n",
      "NLL Loss is: 1.3415134682805916\n",
      "Scaled KL Loss is: 0.03347521275281906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3749886810334107\n",
      "NLL Loss is: 1.4019327391568188\n",
      "Scaled KL Loss is: 0.033204086124897\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4351368252817158\n",
      "NLL Loss is: 1.3002078486199158\n",
      "Scaled KL Loss is: 0.03868880495429039\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3388966535742062\n",
      "NLL Loss is: 1.3067937809863839\n",
      "Scaled KL Loss is: 0.03328702971339226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3400808106997761\n",
      "NLL Loss is: 1.4217901364105918\n",
      "Scaled KL Loss is: 0.035749394446611404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4575395308572032\n",
      "NLL Loss is: 1.2989103479037702\n",
      "Scaled KL Loss is: 0.03917383402585983\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.33808418192963\n",
      "NLL Loss is: 1.4995906527424407\n",
      "Scaled KL Loss is: 0.036905936896800995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5364965896392417\n",
      "NLL Loss is: 1.3065370531660399\n",
      "Scaled KL Loss is: 0.035489682108163834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3420267352742037\n",
      "NLL Loss is: 1.4678005062056478\n",
      "Scaled KL Loss is: 0.039025235921144485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5068257421267923\n",
      "NLL Loss is: 1.4082781267815851\n",
      "Scaled KL Loss is: 0.03572877123951912\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4440068980211043\n",
      "NLL Loss is: 1.3463021460123208\n",
      "Scaled KL Loss is: 0.03671589121222496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3830180372245457\n",
      "NLL Loss is: 1.2852901515328015\n",
      "Scaled KL Loss is: 0.03649214282631874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3217822943591202\n",
      "NLL Loss is: 1.370369271231344\n",
      "Scaled KL Loss is: 0.034802019596099854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4051712908274439\n",
      "NLL Loss is: 1.3488750094754751\n",
      "Scaled KL Loss is: 0.03536923974752426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3842442492229994\n",
      "NLL Loss is: 1.3909518355450248\n",
      "Scaled KL Loss is: 0.03425111994147301\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4252029554864978\n",
      "NLL Loss is: 1.30885027482849\n",
      "Scaled KL Loss is: 0.035078808665275574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3439290834937656\n",
      "NLL Loss is: 1.5692225278071306\n",
      "Scaled KL Loss is: 0.038162630051374435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.607385157858505\n",
      "NLL Loss is: 1.1950489132918933\n",
      "Scaled KL Loss is: 0.03593293949961662\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.23098185279151\n",
      "NLL Loss is: 1.3205357670396072\n",
      "Scaled KL Loss is: 0.03980490565299988\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360340672692607\n",
      "NLL Loss is: 1.3795697226678458\n",
      "Scaled KL Loss is: 0.040470972657203674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4200406953250495\n",
      "NLL Loss is: 1.17596800905873\n",
      "Scaled KL Loss is: 0.03865700215101242\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2146250112097423\n",
      "NLL Loss is: 1.3486727603662172\n",
      "Scaled KL Loss is: 0.03740965202450752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3860824123907247\n",
      "NLL Loss is: 1.202636794976985\n",
      "Scaled KL Loss is: 0.03756518289446831\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2402019778714533\n",
      "NLL Loss is: 1.212624856530681\n",
      "Scaled KL Loss is: 0.03408125787973404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246706114410415\n",
      "NLL Loss is: 1.3650722193025677\n",
      "Scaled KL Loss is: 0.036757126450538635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4018293457531064\n",
      "NLL Loss is: 1.3758890857480626\n",
      "Scaled KL Loss is: 0.03475072234869003\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4106398080967526\n",
      "NLL Loss is: 1.2788766164512442\n",
      "Scaled KL Loss is: 0.03547999635338783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.314356612804632\n",
      "NLL Loss is: 1.4586170318212188\n",
      "Scaled KL Loss is: 0.036180708557367325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4947977403785861\n",
      "NLL Loss is: 1.4799680265754247\n",
      "Scaled KL Loss is: 0.035875868052244186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5158438946276689\n",
      "NLL Loss is: 1.2744233009816497\n",
      "Scaled KL Loss is: 0.04207134246826172\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3164946434499114\n",
      "NLL Loss is: 1.251078680615576\n",
      "Scaled KL Loss is: 0.03866010159254074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2897387822081168\n",
      "NLL Loss is: 1.3855341711927003\n",
      "Scaled KL Loss is: 0.036858800798654556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4223929719913548\n",
      "NLL Loss is: 1.4886353257213438\n",
      "Scaled KL Loss is: 0.037588149309158325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5262234750305022\n",
      "NLL Loss is: 1.241303465204439\n",
      "Scaled KL Loss is: 0.03772206977009773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2790255349745367\n",
      "NLL Loss is: 1.2447176052013809\n",
      "Scaled KL Loss is: 0.033635448664426804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2783530538658077\n",
      "NLL Loss is: 1.272724067200988\n",
      "Scaled KL Loss is: 0.03788826987147331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3106123370724614\n",
      "NLL Loss is: 1.2614069182197098\n",
      "Scaled KL Loss is: 0.04325071722269058\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3046576354424004\n",
      "NLL Loss is: 1.3507367790161755\n",
      "Scaled KL Loss is: 0.03510141372680664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3858381927429821\n",
      "NLL Loss is: 1.2831730899537712\n",
      "Scaled KL Loss is: 0.038572028279304504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3217451182330757\n",
      "NLL Loss is: 1.3026924606151749\n",
      "Scaled KL Loss is: 0.03997807577252388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3426705363876987\n",
      "NLL Loss is: 1.2062295560455596\n",
      "Scaled KL Loss is: 0.040775321424007416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.247004877469567\n",
      "NLL Loss is: 1.306794579002215\n",
      "Scaled KL Loss is: 0.03946700692176819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3462615859239833\n",
      "NLL Loss is: 1.2619808715993694\n",
      "Scaled KL Loss is: 0.03761306032538414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2995939319247536\n",
      "NLL Loss is: 1.3435757291913486\n",
      "Scaled KL Loss is: 0.03882453218102455\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3824002613723732\n",
      "NLL Loss is: 1.3509999140569113\n",
      "Scaled KL Loss is: 0.035963382571935654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.386963296628847\n",
      "NLL Loss is: 1.2555167274584773\n",
      "Scaled KL Loss is: 0.0389845073223114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2945012347807887\n",
      "NLL Loss is: 1.3755526030751495\n",
      "Scaled KL Loss is: 0.035216692835092545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410769295910242\n",
      "NLL Loss is: 1.4114156917964369\n",
      "Scaled KL Loss is: 0.035602863878011703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4470185556744486\n",
      "NLL Loss is: 1.420583391378527\n",
      "Scaled KL Loss is: 0.034301288425922394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4548846798044495\n",
      "NLL Loss is: 1.4319469778830802\n",
      "Scaled KL Loss is: 0.038789983838796616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4707369617218768\n",
      "NLL Loss is: 1.3037736661044952\n",
      "Scaled KL Loss is: 0.03647400438785553\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3402476704923507\n",
      "NLL Loss is: 1.2806259926154844\n",
      "Scaled KL Loss is: 0.03468193858861923\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3153079312041036\n",
      "NLL Loss is: 1.2169695933540363\n",
      "Scaled KL Loss is: 0.03934276103973389\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2563123543937702\n",
      "NLL Loss is: 1.3147816895560336\n",
      "Scaled KL Loss is: 0.0377483032643795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.352529992820413\n",
      "NLL Loss is: 1.3363275840188367\n",
      "Scaled KL Loss is: 0.03703887760639191\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3733664616252286\n",
      "NLL Loss is: 1.4129080152462665\n",
      "Scaled KL Loss is: 0.03661046549677849\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.449518480743045\n",
      "NLL Loss is: 1.3147883334911485\n",
      "Scaled KL Loss is: 0.03686603158712387\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3516543650782724\n",
      "NLL Loss is: 1.3384516328716733\n",
      "Scaled KL Loss is: 0.03490603715181351\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3733576700234869\n",
      "NLL Loss is: 1.409905738930891\n",
      "Scaled KL Loss is: 0.03633197396993637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4462377129008275\n",
      "NLL Loss is: 1.4144968051096765\n",
      "Scaled KL Loss is: 0.03741594776511192\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4519127528747884\n",
      "NLL Loss is: 1.3776437309837866\n",
      "Scaled KL Loss is: 0.036523520946502686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4141672519302892\n",
      "NLL Loss is: 1.3435113375797092\n",
      "Scaled KL Loss is: 0.04020201042294502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3837133480026542\n",
      "NLL Loss is: 1.3175719152739398\n",
      "Scaled KL Loss is: 0.03629840165376663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3538703169277064\n",
      "NLL Loss is: 1.4723137961530302\n",
      "Scaled KL Loss is: 0.037629809230566025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5099436053835962\n",
      "NLL Loss is: 1.3726248487893713\n",
      "Scaled KL Loss is: 0.03477367013692856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4073985189262999\n",
      "NLL Loss is: 1.373688531229388\n",
      "Scaled KL Loss is: 0.03965948894619942\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4133480201755875\n",
      "NLL Loss is: 1.356046681749811\n",
      "Scaled KL Loss is: 0.037667982280254364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3937146640300653\n",
      "NLL Loss is: 1.4606821880561927\n",
      "Scaled KL Loss is: 0.03631999343633652\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4970021814925292\n",
      "NLL Loss is: 1.3027585674257947\n",
      "Scaled KL Loss is: 0.033870257437229156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3366288248630238\n",
      "NLL Loss is: 1.453975633367092\n",
      "Scaled KL Loss is: 0.03532877191901207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.489304405286104\n",
      "NLL Loss is: 1.4071008518932056\n",
      "Scaled KL Loss is: 0.035909466445446014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4430103183386516\n",
      "NLL Loss is: 1.3576944926443548\n",
      "Scaled KL Loss is: 0.03692135587334633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3946158485177012\n",
      "NLL Loss is: 1.3031993388715386\n",
      "Scaled KL Loss is: 0.03520433232188225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3384036711934209\n",
      "NLL Loss is: 1.3862074951724128\n",
      "Scaled KL Loss is: 0.035497624427080154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.421705119599493\n",
      "NLL Loss is: 1.2695919374471827\n",
      "Scaled KL Loss is: 0.038204241544008255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307796178991191\n",
      "NLL Loss is: 1.371722323695178\n",
      "Scaled KL Loss is: 0.03338845819234848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4051107818875266\n",
      "NLL Loss is: 1.2783469472121198\n",
      "Scaled KL Loss is: 0.038438405841588974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3167853530537088\n",
      "NLL Loss is: 1.414904975410341\n",
      "Scaled KL Loss is: 0.0374600775539875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4523650529643286\n",
      "NLL Loss is: 1.4683273245887876\n",
      "Scaled KL Loss is: 0.035215113312006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5035424379007936\n",
      "NLL Loss is: 1.3998614702498275\n",
      "Scaled KL Loss is: 0.03347526118159294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4333367314314205\n",
      "NLL Loss is: 1.3298722902324227\n",
      "Scaled KL Loss is: 0.038389287889003754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3682615781214265\n",
      "NLL Loss is: 1.2684052824032528\n",
      "Scaled KL Loss is: 0.03515715152025223\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303562433923505\n",
      "NLL Loss is: 1.449002013409036\n",
      "Scaled KL Loss is: 0.0363684818148613\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4853704952238973\n",
      "NLL Loss is: 1.3288116280778195\n",
      "Scaled KL Loss is: 0.03686917573213577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3656808038099553\n",
      "NLL Loss is: 1.6848793819373202\n",
      "Scaled KL Loss is: 0.029534809291362762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.714414191228683\n",
      "NLL Loss is: 1.3459723116401006= 1.383; test loss = 1.420\n",
      "Scaled KL Loss is: 0.03803456947207451\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.384006881112175\n",
      "NLL Loss is: 1.401881095677198\n",
      "Scaled KL Loss is: 0.03507866710424423\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4369597627814423\n",
      "NLL Loss is: 1.398531311806699\n",
      "Scaled KL Loss is: 0.03716541454195976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4356967263486589\n",
      "NLL Loss is: 1.4293721699798767\n",
      "Scaled KL Loss is: 0.038929879665374756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4683020496452515\n",
      "NLL Loss is: 1.3720767368857105\n",
      "Scaled KL Loss is: 0.03338894620537758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405465683091088\n",
      "NLL Loss is: 1.4165439267855442\n",
      "Scaled KL Loss is: 0.037725675851106644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4542696026366508\n",
      "NLL Loss is: 1.4102180176612031\n",
      "Scaled KL Loss is: 0.03276488184928894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.442982899510492\n",
      "NLL Loss is: 1.3418440973061905\n",
      "Scaled KL Loss is: 0.03336925804615021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3752133553523407\n",
      "NLL Loss is: 1.4015113217141788\n",
      "Scaled KL Loss is: 0.03313981369137764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4346511354055564\n",
      "NLL Loss is: 1.2984935799361625\n",
      "Scaled KL Loss is: 0.038656603544950485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.337150183481113\n",
      "NLL Loss is: 1.3057009566960178\n",
      "Scaled KL Loss is: 0.03308822959661484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3387891862926327\n",
      "NLL Loss is: 1.4203495921982698\n",
      "Scaled KL Loss is: 0.03582680597901344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4561763981772833\n",
      "NLL Loss is: 1.296482867000505\n",
      "Scaled KL Loss is: 0.03929213061928749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3357749976197926\n",
      "NLL Loss is: 1.4962830078957103\n",
      "Scaled KL Loss is: 0.03688761964440346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5331706275401138\n",
      "NLL Loss is: 1.304776204888939\n",
      "Scaled KL Loss is: 0.03544488921761513\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3402210941065542\n",
      "NLL Loss is: 1.4651657052012723\n",
      "Scaled KL Loss is: 0.03927773982286453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5044434450241368\n",
      "NLL Loss is: 1.4053537511331298\n",
      "Scaled KL Loss is: 0.03595656156539917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441310312698529\n",
      "NLL Loss is: 1.3458677836400914\n",
      "Scaled KL Loss is: 0.03673679381608963\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382604577456181\n",
      "NLL Loss is: 1.2836446929451404\n",
      "Scaled KL Loss is: 0.0366218127310276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.320266505676168\n",
      "NLL Loss is: 1.3689062453522487\n",
      "Scaled KL Loss is: 0.034979332238435745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4038855775906844\n",
      "NLL Loss is: 1.3444635983202182\n",
      "Scaled KL Loss is: 0.035254236310720444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3797178346309387\n",
      "NLL Loss is: 1.3885172173745792\n",
      "Scaled KL Loss is: 0.03442792221903801\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4229451395936172\n",
      "NLL Loss is: 1.3067406928445608\n",
      "Scaled KL Loss is: 0.035277657210826874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3420183500553877\n",
      "NLL Loss is: 1.5698606264255466\n",
      "Scaled KL Loss is: 0.03815844655036926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6080190729759158\n",
      "NLL Loss is: 1.193854662938049\n",
      "Scaled KL Loss is: 0.03598863631486893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.229843299252918\n",
      "NLL Loss is: 1.3193191764884011\n",
      "Scaled KL Loss is: 0.039897896349430084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3592170728378312\n",
      "NLL Loss is: 1.3779194777533086\n",
      "Scaled KL Loss is: 0.04061553254723549\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418535010300544\n",
      "NLL Loss is: 1.1728995611671094\n",
      "Scaled KL Loss is: 0.03884820267558098\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2117477638426903\n",
      "NLL Loss is: 1.3467104471150764\n",
      "Scaled KL Loss is: 0.03747852146625519\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3841889685813316\n",
      "NLL Loss is: 1.199781115466477\n",
      "Scaled KL Loss is: 0.037634797394275665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2374159128607527\n",
      "NLL Loss is: 1.2101596826786\n",
      "Scaled KL Loss is: 0.03407048061490059\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2442301632935007\n",
      "NLL Loss is: 1.3617039138281917\n",
      "Scaled KL Loss is: 0.03680362179875374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3985075356269454\n",
      "NLL Loss is: 1.3732070920844675\n",
      "Scaled KL Loss is: 0.03471718356013298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4079242756446004\n",
      "NLL Loss is: 1.2768937924097292\n",
      "Scaled KL Loss is: 0.035483550280332565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3123773426900618\n",
      "NLL Loss is: 1.4557644785982495\n",
      "Scaled KL Loss is: 0.03626656532287598\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4920310439211255\n",
      "NLL Loss is: 1.4774067300278213\n",
      "Scaled KL Loss is: 0.0358758345246315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5132825645524528\n",
      "NLL Loss is: 1.2725241922464932\n",
      "Scaled KL Loss is: 0.04211151972413063\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146357119706238\n",
      "NLL Loss is: 1.2501217335176662\n",
      "Scaled KL Loss is: 0.03882244601845741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2889441795361236\n",
      "NLL Loss is: 1.38223509587337\n",
      "Scaled KL Loss is: 0.03693287447094917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4191679703443192\n",
      "NLL Loss is: 1.4867430890910145\n",
      "Scaled KL Loss is: 0.03758653625845909\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5243296253494736\n",
      "NLL Loss is: 1.2373137025229541\n",
      "Scaled KL Loss is: 0.03770798444747925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2750216869704334\n",
      "NLL Loss is: 1.2410754904518497\n",
      "Scaled KL Loss is: 0.033679183572530746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2747546740243805\n",
      "NLL Loss is: 1.269982442954971\n",
      "Scaled KL Loss is: 0.03808050602674484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.308062948981716\n",
      "NLL Loss is: 1.2580546591501267\n",
      "Scaled KL Loss is: 0.043194618076086044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3012492772262128\n",
      "NLL Loss is: 1.3478301310268486\n",
      "Scaled KL Loss is: 0.035070594400167465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382900725427016\n",
      "NLL Loss is: 1.2816336222050213\n",
      "Scaled KL Loss is: 0.038672734051942825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3203063562569641\n",
      "NLL Loss is: 1.3013350930813494\n",
      "Scaled KL Loss is: 0.040019262582063675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341354355663413\n",
      "NLL Loss is: 1.203307349808079\n",
      "Scaled KL Loss is: 0.04099975898861885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.244307108796698\n",
      "NLL Loss is: 1.3051953499591078\n",
      "Scaled KL Loss is: 0.03945695981383324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344652309772941\n",
      "NLL Loss is: 1.2589444472328577\n",
      "Scaled KL Loss is: 0.03762811794877052\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2965725651816282\n",
      "NLL Loss is: 1.340592807839145\n",
      "Scaled KL Loss is: 0.03888380527496338\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3794766131141083\n",
      "NLL Loss is: 1.3501726649854806\n",
      "Scaled KL Loss is: 0.035924576222896576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3860972412083772\n",
      "NLL Loss is: 1.2530142312728867\n",
      "Scaled KL Loss is: 0.038887910544872284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.291902141817759\n",
      "NLL Loss is: 1.3737081840672476\n",
      "Scaled KL Loss is: 0.03531940281391144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.409027586881159\n",
      "NLL Loss is: 1.4091919791332301\n",
      "Scaled KL Loss is: 0.03566872701048851\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4448607061437186\n",
      "NLL Loss is: 1.4183508559837457\n",
      "Scaled KL Loss is: 0.034360725432634354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.45271158141638\n",
      "NLL Loss is: 1.4303463418110156\n",
      "Scaled KL Loss is: 0.03880912810564041\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.469155469916656\n",
      "NLL Loss is: 1.3026503190818577\n",
      "Scaled KL Loss is: 0.03638094291090965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3390312619927673\n",
      "NLL Loss is: 1.2787173570639092\n",
      "Scaled KL Loss is: 0.034792687743902206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3135100448078114\n",
      "NLL Loss is: 1.2149094715111293\n",
      "Scaled KL Loss is: 0.03925022482872009\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2541596963398494\n",
      "NLL Loss is: 1.3124635624056102\n",
      "Scaled KL Loss is: 0.037825413048267365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3502889754538776\n",
      "NLL Loss is: 1.3323189047729358\n",
      "Scaled KL Loss is: 0.036974597722291946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3692935024952277\n",
      "NLL Loss is: 1.410444930084829\n",
      "Scaled KL Loss is: 0.03657713532447815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4470220654093071\n",
      "NLL Loss is: 1.3135396990757833\n",
      "Scaled KL Loss is: 0.03703904151916504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3505787405949483\n",
      "NLL Loss is: 1.3358906525908147\n",
      "Scaled KL Loss is: 0.03490745648741722\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370798109078232\n",
      "NLL Loss is: 1.4084643242588593\n",
      "Scaled KL Loss is: 0.03637927398085594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4448435982397152\n",
      "NLL Loss is: 1.4125463555433548\n",
      "Scaled KL Loss is: 0.03754466027021408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.450091015813569\n",
      "NLL Loss is: 1.3756569680139703\n",
      "Scaled KL Loss is: 0.036447539925575256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4121045079395456\n",
      "NLL Loss is: 1.3414105527582538\n",
      "Scaled KL Loss is: 0.040187980979681015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3815985337379348\n",
      "NLL Loss is: 1.3150940584896165\n",
      "Scaled KL Loss is: 0.03628535568714142\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3513794141767579\n",
      "NLL Loss is: 1.4702165253984298\n",
      "Scaled KL Loss is: 0.03764423355460167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5078607589530315\n",
      "NLL Loss is: 1.3708355870762055\n",
      "Scaled KL Loss is: 0.03484199568629265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405677582762498\n",
      "NLL Loss is: 1.3704485415512497\n",
      "Scaled KL Loss is: 0.03965921700000763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4101077585512574\n",
      "NLL Loss is: 1.354307952428782\n",
      "Scaled KL Loss is: 0.037750035524368286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3920579879531503\n",
      "NLL Loss is: 1.4602506045088626\n",
      "Scaled KL Loss is: 0.0363796129822731\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4966302174911357\n",
      "NLL Loss is: 1.3015039645614765\n",
      "Scaled KL Loss is: 0.03387833386659622\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3353822984280728\n",
      "NLL Loss is: 1.4517943053342373\n",
      "Scaled KL Loss is: 0.035211607813835144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4870059131480724\n",
      "NLL Loss is: 1.4047673962483733\n",
      "Scaled KL Loss is: 0.036052439361810684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440819835610184\n",
      "NLL Loss is: 1.3571023893687313\n",
      "Scaled KL Loss is: 0.036721933633089066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3938243230018204\n",
      "NLL Loss is: 1.3007169301414883\n",
      "Scaled KL Loss is: 0.03511783108115196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3358347612226402\n",
      "NLL Loss is: 1.3840735370798274\n",
      "Scaled KL Loss is: 0.03550944849848747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4195829855783149\n",
      "NLL Loss is: 1.2669921078729383\n",
      "Scaled KL Loss is: 0.038189616054296494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3051817239272347\n",
      "NLL Loss is: 1.3709759117211298\n",
      "Scaled KL Loss is: 0.033364977687597275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.404340889408727\n",
      "NLL Loss is: 1.2752505896408064\n",
      "Scaled KL Loss is: 0.03838628530502319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3136368749458296\n",
      "NLL Loss is: 1.4110903910468084\n",
      "Scaled KL Loss is: 0.03737042844295502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4484608194897635\n",
      "NLL Loss is: 1.4661302897964645\n",
      "Scaled KL Loss is: 0.03545602411031723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5015863139067818\n",
      "NLL Loss is: 1.396761104318337\n",
      "Scaled KL Loss is: 0.03346120938658714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4302223137049241\n",
      "NLL Loss is: 1.3277343270847946\n",
      "Scaled KL Loss is: 0.03835326433181763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3660875914166122\n",
      "NLL Loss is: 1.2667739591247336\n",
      "Scaled KL Loss is: 0.035215433686971664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3019893928117052\n",
      "NLL Loss is: 1.4481969288400744\n",
      "Scaled KL Loss is: 0.0365135483443737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4847104771844482\n",
      "NLL Loss is: 1.326118744619058\n",
      "Scaled KL Loss is: 0.03698766604065895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363106410659717\n",
      "NLL Loss is: 1.6826984203657882\n",
      "Scaled KL Loss is: 0.029651127755641937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7123495481214301\n",
      "NLL Loss is: 1.3443172593666486= 1.381; test loss = 1.418\n",
      "Scaled KL Loss is: 0.03800734132528305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3823246006919316\n",
      "NLL Loss is: 1.399722803315054\n",
      "Scaled KL Loss is: 0.035050246864557266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4347730501796112\n",
      "NLL Loss is: 1.39662393619035\n",
      "Scaled KL Loss is: 0.03718561679124832\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4338095529815984\n",
      "NLL Loss is: 1.4263613679933653\n",
      "Scaled KL Loss is: 0.038771048188209534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4651324161815749\n",
      "NLL Loss is: 1.3698841051964918\n",
      "Scaled KL Loss is: 0.03345504030585289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4033391455023447\n",
      "NLL Loss is: 1.4136477132250465\n",
      "Scaled KL Loss is: 0.037738997489213943\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4513867107142604\n",
      "NLL Loss is: 1.408812899731697\n",
      "Scaled KL Loss is: 0.03285827860236168\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4416711783340588\n",
      "NLL Loss is: 1.3422544169624444\n",
      "Scaled KL Loss is: 0.03330107778310776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3755554947455522\n",
      "NLL Loss is: 1.4011502772674982\n",
      "Scaled KL Loss is: 0.03311104327440262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4342613205419008\n",
      "NLL Loss is: 1.2967541153527133\n",
      "Scaled KL Loss is: 0.03865647315979004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3354105885125034\n",
      "NLL Loss is: 1.304549781509\n",
      "Scaled KL Loss is: 0.03293329477310181\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3374830762821017\n",
      "NLL Loss is: 1.4189188788202978\n",
      "Scaled KL Loss is: 0.03592928871512413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.454848167535422\n",
      "NLL Loss is: 1.2941218703025366\n",
      "Scaled KL Loss is: 0.039432380348443985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3335542506509805\n",
      "NLL Loss is: 1.4932880404614197\n",
      "Scaled KL Loss is: 0.036894507706165314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.530182548167585\n",
      "NLL Loss is: 1.3029102436104574\n",
      "Scaled KL Loss is: 0.03544025868177414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3383505022922315\n",
      "NLL Loss is: 1.4625721021824747\n",
      "Scaled KL Loss is: 0.039549171924591064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5021212741070658\n",
      "NLL Loss is: 1.4025240546806685\n",
      "Scaled KL Loss is: 0.03620431199669838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.438728366677367\n",
      "NLL Loss is: 1.3454633244860823\n",
      "Scaled KL Loss is: 0.03678927943110466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382252603917187\n",
      "NLL Loss is: 1.2819976800502433\n",
      "Scaled KL Loss is: 0.03677601367235184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3187736937225951\n",
      "NLL Loss is: 1.3674495658501653\n",
      "Scaled KL Loss is: 0.03518259525299072\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402632161103156\n",
      "NLL Loss is: 1.340407088742834\n",
      "Scaled KL Loss is: 0.03518218547105789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375589274213892\n",
      "NLL Loss is: 1.3862015570446642\n",
      "Scaled KL Loss is: 0.03462977334856987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420831330393234\n",
      "NLL Loss is: 1.3046824421597378\n",
      "Scaled KL Loss is: 0.03550267219543457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3401851143551724\n",
      "NLL Loss is: 1.5703331810123122\n",
      "Scaled KL Loss is: 0.0381932407617569\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6085264217740691\n",
      "NLL Loss is: 1.1926763332449297\n",
      "Scaled KL Loss is: 0.036081358790397644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2287576920353274\n",
      "NLL Loss is: 1.3182153940328987\n",
      "Scaled KL Loss is: 0.04002152010798454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3582369141408832\n",
      "NLL Loss is: 1.376354589821721\n",
      "Scaled KL Loss is: 0.04078784957528114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4171424393970022\n",
      "NLL Loss is: 1.1701683553437485\n",
      "Scaled KL Loss is: 0.039061374962329865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2092297303060784\n",
      "NLL Loss is: 1.344842771538999\n",
      "Scaled KL Loss is: 0.03758133575320244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3824241072922014\n",
      "NLL Loss is: 1.1969574961960339\n",
      "Scaled KL Loss is: 0.03774089366197586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2346983898580097\n",
      "NLL Loss is: 1.2078887259858897\n",
      "Scaled KL Loss is: 0.034100428223609924\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2419891542094996\n",
      "NLL Loss is: 1.358567875962193\n",
      "Scaled KL Loss is: 0.03688966855406761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3954575445162607\n",
      "NLL Loss is: 1.3707562906056492\n",
      "Scaled KL Loss is: 0.03472789376974106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4054841843753902\n",
      "NLL Loss is: 1.275123499100085\n",
      "Scaled KL Loss is: 0.035526666790246964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.310650165890332\n",
      "NLL Loss is: 1.4531739580342773\n",
      "Scaled KL Loss is: 0.03638562187552452\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4895595799098018\n",
      "NLL Loss is: 1.4748206216794286\n",
      "Scaled KL Loss is: 0.035916682332754135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5107373040121828\n",
      "NLL Loss is: 1.2708534055096665\n",
      "Scaled KL Loss is: 0.04218650236725807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3130399078769246\n",
      "NLL Loss is: 1.249198328672783\n",
      "Scaled KL Loss is: 0.03901563212275505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.288213960795538\n",
      "NLL Loss is: 1.3788945189391788\n",
      "Scaled KL Loss is: 0.03704378381371498\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4159383027528938\n",
      "NLL Loss is: 1.4850378238869666\n",
      "Scaled KL Loss is: 0.03762451931834221\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5226623432053088\n",
      "NLL Loss is: 1.2335357437395351\n",
      "Scaled KL Loss is: 0.03773419186472893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.271269935604264\n",
      "NLL Loss is: 1.2374359847791323\n",
      "Scaled KL Loss is: 0.03376323729753494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2711992220766672\n",
      "NLL Loss is: 1.267401748946331\n",
      "Scaled KL Loss is: 0.03830458223819733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3057063311845283\n",
      "NLL Loss is: 1.2550683395407\n",
      "Scaled KL Loss is: 0.04317757859826088\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.298245918138961\n",
      "NLL Loss is: 1.34501681568345\n",
      "Scaled KL Loss is: 0.03508193790912628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3800987535925764\n",
      "NLL Loss is: 1.280049146679561\n",
      "Scaled KL Loss is: 0.038809169083833694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3188583157633946\n",
      "NLL Loss is: 1.299971783126432\n",
      "Scaled KL Loss is: 0.04009594768285751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3400677308092894\n",
      "NLL Loss is: 1.2004182232303517\n",
      "Scaled KL Loss is: 0.04125156253576279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2416697857661145\n",
      "NLL Loss is: 1.303703540586622\n",
      "Scaled KL Loss is: 0.039488501846790314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431920424334123\n",
      "NLL Loss is: 1.2559921940425915\n",
      "Scaled KL Loss is: 0.03768597170710564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2936781657496972\n",
      "NLL Loss is: 1.3377165715169133\n",
      "Scaled KL Loss is: 0.03897978365421295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3766963551711262\n",
      "NLL Loss is: 1.349427187508998\n",
      "Scaled KL Loss is: 0.03593246266245842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3853596501714565\n",
      "NLL Loss is: 1.2506265730499637\n",
      "Scaled KL Loss is: 0.03883984312415123\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289466416174115\n",
      "NLL Loss is: 1.3718733056931764\n",
      "Scaled KL Loss is: 0.03545684367418289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4073301493673593\n",
      "NLL Loss is: 1.407045596310693\n",
      "Scaled KL Loss is: 0.03577360510826111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.442819201418954\n",
      "NLL Loss is: 1.4161746410883251\n",
      "Scaled KL Loss is: 0.034456767141819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4506314082301441\n",
      "NLL Loss is: 1.4287804663897798\n",
      "Scaled KL Loss is: 0.03886569291353226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.467646159303312\n",
      "NLL Loss is: 1.3015365950918314\n",
      "Scaled KL Loss is: 0.036336954683065414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3378735497748968\n",
      "NLL Loss is: 1.2767482349462695\n",
      "Scaled KL Loss is: 0.03493572771549225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3116839626617618\n",
      "NLL Loss is: 1.212970646042601\n",
      "Scaled KL Loss is: 0.0392044372856617\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2521750833282628\n",
      "NLL Loss is: 1.3101704063957968\n",
      "Scaled KL Loss is: 0.03793845698237419\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348108863378171\n",
      "NLL Loss is: 1.3284221561561387\n",
      "Scaled KL Loss is: 0.03695761039853096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3653797665546696\n",
      "NLL Loss is: 1.4079924945329707\n",
      "Scaled KL Loss is: 0.03658580780029297\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4445783023332637\n",
      "NLL Loss is: 1.3123449368374056\n",
      "Scaled KL Loss is: 0.037245672196149826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3495906090335554\n",
      "NLL Loss is: 1.333359366516915\n",
      "Scaled KL Loss is: 0.03495076671242714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3683101332293421\n",
      "NLL Loss is: 1.4069896035640463\n",
      "Scaled KL Loss is: 0.036465853452682495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4434554570167288\n",
      "NLL Loss is: 1.4106517333782875\n",
      "Scaled KL Loss is: 0.0377095490694046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4483612824476921\n",
      "NLL Loss is: 1.373732914025261\n",
      "Scaled KL Loss is: 0.03641589358448982\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4101488076097508\n",
      "NLL Loss is: 1.3393714373412349\n",
      "Scaled KL Loss is: 0.04021643102169037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3795878683629252\n",
      "NLL Loss is: 1.3126392091773713\n",
      "Scaled KL Loss is: 0.03631295636296272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348952165540334\n",
      "NLL Loss is: 1.4682122104552493\n",
      "Scaled KL Loss is: 0.03769860789179802\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5059108183470473\n",
      "NLL Loss is: 1.369104239319924\n",
      "Scaled KL Loss is: 0.03494486212730408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.404049101447228\n",
      "NLL Loss is: 1.3673966842381016\n",
      "Scaled KL Loss is: 0.039697933942079544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4070946181801811\n",
      "NLL Loss is: 1.35256750795398\n",
      "Scaled KL Loss is: 0.03786777704954147\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3904352850035215\n",
      "NLL Loss is: 1.45986527203521\n",
      "Scaled KL Loss is: 0.03647701442241669\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4963422864576268\n",
      "NLL Loss is: 1.3003008370240061\n",
      "Scaled KL Loss is: 0.033928319811820984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.334229156835827\n",
      "NLL Loss is: 1.4497218425534306\n",
      "Scaled KL Loss is: 0.035140737891197205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4848625804446278\n",
      "NLL Loss is: 1.4027959344361671\n",
      "Scaled KL Loss is: 0.03622632846236229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4390222628985294\n",
      "NLL Loss is: 1.35658448217469\n",
      "Scaled KL Loss is: 0.036579713225364685\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3931641954000547\n",
      "NLL Loss is: 1.2982686659122349\n",
      "Scaled KL Loss is: 0.03508143499493599\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3333501009071709\n",
      "NLL Loss is: 1.3820163763269329\n",
      "Scaled KL Loss is: 0.035561323165893555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4175776994928264\n",
      "NLL Loss is: 1.264522437290053\n",
      "Scaled KL Loss is: 0.03822026029229164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3027426975823446\n",
      "NLL Loss is: 1.3702033781620024\n",
      "Scaled KL Loss is: 0.03338269516825676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4035860733302592\n",
      "NLL Loss is: 1.2723838024434238\n",
      "Scaled KL Loss is: 0.0383797287940979\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3107635312375217\n",
      "NLL Loss is: 1.4075148552856103\n",
      "Scaled KL Loss is: 0.037324316799640656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444839172085251\n",
      "NLL Loss is: 1.4640145823595236\n",
      "Scaled KL Loss is: 0.035716257989406586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4997308403489302\n",
      "NLL Loss is: 1.3937790496295996\n",
      "Scaled KL Loss is: 0.033484313637018204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4272633632666178\n",
      "NLL Loss is: 1.3257311483976073\n",
      "Scaled KL Loss is: 0.038358379155397415\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3640895275530047\n",
      "NLL Loss is: 1.2651169023596833\n",
      "Scaled KL Loss is: 0.03531470149755478\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300431603857238\n",
      "NLL Loss is: 1.4473110428202267\n",
      "Scaled KL Loss is: 0.036687590181827545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4839986330020543\n",
      "NLL Loss is: 1.3236187464504676\n",
      "Scaled KL Loss is: 0.037135716527700424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360754462978168\n",
      "NLL Loss is: 1.680701313051121\n",
      "Scaled KL Loss is: 0.029787596315145493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7104889093662665\n",
      "NLL Loss is: 1.3427640778855818= 1.379; test loss = 1.416\n",
      "Scaled KL Loss is: 0.03802047669887543\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3807845545844573\n",
      "NLL Loss is: 1.397666739742386\n",
      "Scaled KL Loss is: 0.03506431728601456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4327310570284006\n",
      "NLL Loss is: 1.394786997036907\n",
      "Scaled KL Loss is: 0.03724289685487747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4320298938917844\n",
      "NLL Loss is: 1.4235788351673322\n",
      "Scaled KL Loss is: 0.03866273909807205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4622415742654042\n",
      "NLL Loss is: 1.367719368984663\n",
      "Scaled KL Loss is: 0.03355611488223076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4012754838668937\n",
      "NLL Loss is: 1.4110991775167614\n",
      "Scaled KL Loss is: 0.03779275342822075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4488919309449821\n",
      "NLL Loss is: 1.4074607479224226\n",
      "Scaled KL Loss is: 0.032987330108881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4404480780313036\n",
      "NLL Loss is: 1.3426454045711103\n",
      "Scaled KL Loss is: 0.03328007459640503\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3759254791675153\n",
      "NLL Loss is: 1.4007789666360486\n",
      "Scaled KL Loss is: 0.03312821686267853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4339071834987271\n",
      "NLL Loss is: 1.2949966956813848\n",
      "Scaled KL Loss is: 0.03869778290390968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336944785852944\n",
      "NLL Loss is: 1.3032428350278764\n",
      "Scaled KL Loss is: 0.032831814140081406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3360746491679578\n",
      "NLL Loss is: 1.4174706075515218\n",
      "Scaled KL Loss is: 0.03606630489230156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4535369124438233\n",
      "NLL Loss is: 1.2919142444618492\n",
      "Scaled KL Loss is: 0.03960283845663071\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.33151708291848\n",
      "NLL Loss is: 1.4901244869114096\n",
      "Scaled KL Loss is: 0.03694384917616844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.527068336087578\n",
      "NLL Loss is: 1.3009957920392878\n",
      "Scaled KL Loss is: 0.03548397123813629\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3364797632774241\n",
      "NLL Loss is: 1.4597872598632136\n",
      "Scaled KL Loss is: 0.03983975201845169\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4996270118816653\n",
      "NLL Loss is: 1.3999723619980227\n",
      "Scaled KL Loss is: 0.03647811710834503\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4364504791063677\n",
      "NLL Loss is: 1.3446702413654743\n",
      "Scaled KL Loss is: 0.03688480705022812\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3815550484157024\n",
      "NLL Loss is: 1.2798546938865218\n",
      "Scaled KL Loss is: 0.03696393966674805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.31681863355327\n",
      "NLL Loss is: 1.3658986085157105\n",
      "Scaled KL Loss is: 0.0354185588657856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4013171673814961\n",
      "NLL Loss is: 1.337008137164317\n",
      "Scaled KL Loss is: 0.03516816720366478\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3721763043679818\n",
      "NLL Loss is: 1.3839354863107693\n",
      "Scaled KL Loss is: 0.034865446388721466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4188009326994908\n",
      "NLL Loss is: 1.302700047846434\n",
      "Scaled KL Loss is: 0.03576333075761795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3384633786040518\n",
      "NLL Loss is: 1.5703011298050333\n",
      "Scaled KL Loss is: 0.03828351944684982\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6085846492518832\n",
      "NLL Loss is: 1.191552539898797\n",
      "Scaled KL Loss is: 0.036219529807567596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2277720697063645\n",
      "NLL Loss is: 1.3172527534234724\n",
      "Scaled KL Loss is: 0.040185559540987015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3574383129644594\n",
      "NLL Loss is: 1.3748364166725278\n",
      "Scaled KL Loss is: 0.04099743813276291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4158338548052907\n",
      "NLL Loss is: 1.167820949542281\n",
      "Scaled KL Loss is: 0.039301950484514236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2071229000267953\n",
      "NLL Loss is: 1.3430725649819244\n",
      "Scaled KL Loss is: 0.03772725164890289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3807998166308273\n",
      "NLL Loss is: 1.1941705088208325\n",
      "Scaled KL Loss is: 0.037893056869506836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2320635656903394\n",
      "NLL Loss is: 1.2058358377713376\n",
      "Scaled KL Loss is: 0.034178026020526886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2400138637918645\n",
      "NLL Loss is: 1.3556744519054518\n",
      "Scaled KL Loss is: 0.03702417388558388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3926986257910356\n",
      "NLL Loss is: 1.368483328399779\n",
      "Scaled KL Loss is: 0.03479256480932236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4032758932091014\n",
      "NLL Loss is: 1.27354930997765\n",
      "Scaled KL Loss is: 0.03562018275260925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3091694927302593\n",
      "NLL Loss is: 1.4508404439353177\n",
      "Scaled KL Loss is: 0.036544185131788254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.487384629067106\n",
      "NLL Loss is: 1.4723859327294289\n",
      "Scaled KL Loss is: 0.036005649715662\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5083915824450909\n",
      "NLL Loss is: 1.269222949713987\n",
      "Scaled KL Loss is: 0.04230382665991783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.311526776373905\n",
      "NLL Loss is: 1.248259195919322\n",
      "Scaled KL Loss is: 0.03924619033932686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.287505386258649\n",
      "NLL Loss is: 1.3757076156975416\n",
      "Scaled KL Loss is: 0.03719988092780113\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4129074966253428\n",
      "NLL Loss is: 1.4834878246255752\n",
      "Scaled KL Loss is: 0.03771268576383591\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.521200510389411\n",
      "NLL Loss is: 1.2300031486457927\n",
      "Scaled KL Loss is: 0.03781234100461006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2678154896504028\n",
      "NLL Loss is: 1.2339995180638688\n",
      "Scaled KL Loss is: 0.03389335796236992\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2678928760262387\n",
      "NLL Loss is: 1.2648900834882275\n",
      "Scaled KL Loss is: 0.038565415889024734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3034554993772522\n",
      "NLL Loss is: 1.2519688614300124\n",
      "Scaled KL Loss is: 0.04321449249982834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2951833539298407\n",
      "NLL Loss is: 1.3423028969937725\n",
      "Scaled KL Loss is: 0.035142362117767334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3774452591115398\n",
      "NLL Loss is: 1.2784765520283725\n",
      "Scaled KL Loss is: 0.03898802772164345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.317464579750016\n",
      "NLL Loss is: 1.298601436245454\n",
      "Scaled KL Loss is: 0.040213387459516525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3388148237049706\n",
      "NLL Loss is: 1.1976568448046558\n",
      "Scaled KL Loss is: 0.041534118354320526\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2391909631589764\n",
      "NLL Loss is: 1.3022572504838614\n",
      "Scaled KL Loss is: 0.039566293358802795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3418235438426642\n",
      "NLL Loss is: 1.2531823838901244\n",
      "Scaled KL Loss is: 0.03779017925262451\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2909725631427489\n",
      "NLL Loss is: 1.3349738471310046\n",
      "Scaled KL Loss is: 0.03911726921796799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3740911163489726\n",
      "NLL Loss is: 1.3487333823545504\n",
      "Scaled KL Loss is: 0.03599042445421219\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3847238068087626\n",
      "NLL Loss is: 1.248379926851518\n",
      "Scaled KL Loss is: 0.038847532123327255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2872274589748454\n",
      "NLL Loss is: 1.3700763782312766\n",
      "Scaled KL Loss is: 0.03563160449266434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405707982723941\n",
      "NLL Loss is: 1.4051199071395408\n",
      "Scaled KL Loss is: 0.03591719642281532\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4410371035623561\n",
      "NLL Loss is: 1.4140899209790896\n",
      "Scaled KL Loss is: 0.034590840339660645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4486807613187502\n",
      "NLL Loss is: 1.4273126723203555\n",
      "Scaled KL Loss is: 0.03896200656890869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4662746788892642\n",
      "NLL Loss is: 1.3004013613651926\n",
      "Scaled KL Loss is: 0.03634225204586983\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3367436134110624\n",
      "NLL Loss is: 1.274717440490417\n",
      "Scaled KL Loss is: 0.03511212766170502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.309829568152122\n",
      "NLL Loss is: 1.211101206555736\n",
      "Scaled KL Loss is: 0.03920474275946617\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2503059493152022\n",
      "NLL Loss is: 1.3079237516158224\n",
      "Scaled KL Loss is: 0.0380847193300724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3460084709458948\n",
      "NLL Loss is: 1.3246353007522635\n",
      "Scaled KL Loss is: 0.03698449581861496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3616197965708785\n",
      "NLL Loss is: 1.4055909608495705\n",
      "Scaled KL Loss is: 0.036634791642427444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.442225752491998\n",
      "NLL Loss is: 1.3111482071098595\n",
      "Scaled KL Loss is: 0.037481579929590225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3486297870394497\n",
      "NLL Loss is: 1.3308748945753244\n",
      "Scaled KL Loss is: 0.035032015293836594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.365906909869161\n",
      "NLL Loss is: 1.4054361126805857\n",
      "Scaled KL Loss is: 0.036586564034223557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4420226767148092\n",
      "NLL Loss is: 1.4088691025843667\n",
      "Scaled KL Loss is: 0.037906285375356674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4467753879597234\n",
      "NLL Loss is: 1.3718854294478708\n",
      "Scaled KL Loss is: 0.03642849251627922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40831392196415\n",
      "NLL Loss is: 1.3374406994069938\n",
      "Scaled KL Loss is: 0.040286097675561905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3777267970825557\n",
      "NLL Loss is: 1.3102513445111896\n",
      "Scaled KL Loss is: 0.03638068959116936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346632034102359\n",
      "NLL Loss is: 1.4662906591903198\n",
      "Scaled KL Loss is: 0.03779202327132225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.504082682461642\n",
      "NLL Loss is: 1.3675045155519547\n",
      "Scaled KL Loss is: 0.035082485526800156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402587001078755\n",
      "NLL Loss is: 1.364585885440684\n",
      "Scaled KL Loss is: 0.03977691009640694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.404362795537091\n",
      "NLL Loss is: 1.3508565566201785\n",
      "Scaled KL Loss is: 0.0380190834403038\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3888756400604823\n",
      "NLL Loss is: 1.459554656931231\n",
      "Scaled KL Loss is: 0.036610137671232224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4961647946024632\n",
      "NLL Loss is: 1.2992158446586486\n",
      "Scaled KL Loss is: 0.034017231315374374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.333233075974023\n",
      "NLL Loss is: 1.447702874751681\n",
      "Scaled KL Loss is: 0.0351187102496624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4828215850013433\n",
      "NLL Loss is: 1.4008564616977326\n",
      "Scaled KL Loss is: 0.03642750158905983\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4372839632867924\n",
      "NLL Loss is: 1.3560730274630834\n",
      "Scaled KL Loss is: 0.03649480640888214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3925678338719656\n",
      "NLL Loss is: 1.2958743528808183\n",
      "Scaled KL Loss is: 0.035093553364276886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3309679062450952\n",
      "NLL Loss is: 1.3801125254445703\n",
      "Scaled KL Loss is: 0.03564998134970665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415762506794277\n",
      "NLL Loss is: 1.2621682997353805\n",
      "Scaled KL Loss is: 0.03829416260123253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300462462336613\n",
      "NLL Loss is: 1.3694406018524996\n",
      "Scaled KL Loss is: 0.03344166278839111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4028822646408907\n",
      "NLL Loss is: 1.2698543224981163\n",
      "Scaled KL Loss is: 0.03841833770275116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3082726602008674\n",
      "NLL Loss is: 1.4041893245790051\n",
      "Scaled KL Loss is: 0.03732355311512947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4415128776941346\n",
      "NLL Loss is: 1.4619910802290377\n",
      "Scaled KL Loss is: 0.03599294275045395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4979840229794916\n",
      "NLL Loss is: 1.3908835021804093\n",
      "Scaled KL Loss is: 0.033547066152095795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4244305683325051\n",
      "NLL Loss is: 1.3238897423171572\n",
      "Scaled KL Loss is: 0.03840380162000656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3622935439371637\n",
      "NLL Loss is: 1.2635424775659967\n",
      "Scaled KL Loss is: 0.03544914349913597\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2989916210651327\n",
      "NLL Loss is: 1.4463827476991202\n",
      "Scaled KL Loss is: 0.03688579052686691\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4832685382259871\n",
      "NLL Loss is: 1.321341857644899\n",
      "Scaled KL Loss is: 0.03731391206383705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358655769708736\n",
      "NLL Loss is: 1.6789928994507768\n",
      "Scaled KL Loss is: 0.029945461079478264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.708938360530255\n",
      "NLL Loss is: 1.341355473179803 = 1.377; test loss = 1.414\n",
      "Scaled KL Loss is: 0.03807377442717552\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3794292476069785\n",
      "NLL Loss is: 1.395703142919977\n",
      "Scaled KL Loss is: 0.03512030467391014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4308234475938872\n",
      "NLL Loss is: 1.3928505190474842\n",
      "Scaled KL Loss is: 0.03733622282743454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4301867418749188\n",
      "NLL Loss is: 1.420973203691539\n",
      "Scaled KL Loss is: 0.038601722568273544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4595749262598126\n",
      "NLL Loss is: 1.3655357859347717\n",
      "Scaled KL Loss is: 0.033688344061374664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3992241299961463\n",
      "NLL Loss is: 1.4087701832860102\n",
      "Scaled KL Loss is: 0.037882134318351746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446652317604362\n",
      "NLL Loss is: 1.4061569542810686\n",
      "Scaled KL Loss is: 0.033148251473903656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4393052057549722\n",
      "NLL Loss is: 1.3429527283873492\n",
      "Scaled KL Loss is: 0.03330348804593086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37625621643328\n",
      "NLL Loss is: 1.400389806441479\n",
      "Scaled KL Loss is: 0.033184412866830826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4335742193083099\n",
      "NLL Loss is: 1.2932306028978935\n",
      "Scaled KL Loss is: 0.03877672553062439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3320073284285179\n",
      "NLL Loss is: 1.3018585957699071\n",
      "Scaled KL Loss is: 0.032779086381196976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3346376821511041\n",
      "NLL Loss is: 1.415994407794618\n",
      "Scaled KL Loss is: 0.03623300418257713\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4522274119771952\n",
      "NLL Loss is: 1.2898010356945349\n",
      "Scaled KL Loss is: 0.03979836776852608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.329599403463061\n",
      "NLL Loss is: 1.487114069953845\n",
      "Scaled KL Loss is: 0.037027258425951004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.524141328379796\n",
      "NLL Loss is: 1.298974558322048\n",
      "Scaled KL Loss is: 0.03557102754712105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.334545585869169\n",
      "NLL Loss is: 1.4570516430000797\n",
      "Scaled KL Loss is: 0.04014841467142105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4972000576715008\n",
      "NLL Loss is: 1.3975475001078501\n",
      "Scaled KL Loss is: 0.036771148443222046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4343186485510722\n",
      "NLL Loss is: 1.3438800182250799\n",
      "Scaled KL Loss is: 0.03701208904385567\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3808921072689355\n",
      "NLL Loss is: 1.2774639208138427\n",
      "Scaled KL Loss is: 0.03717594966292381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146398704767666\n",
      "NLL Loss is: 1.3643943362437592\n",
      "Scaled KL Loss is: 0.03567283973097801\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4000671759747372\n",
      "NLL Loss is: 1.3333517108634814\n",
      "Scaled KL Loss is: 0.03518451005220413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3685362209156855\n",
      "NLL Loss is: 1.381860981448614\n",
      "Scaled KL Loss is: 0.035117872059345245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4169788535079593\n",
      "NLL Loss is: 1.3006107433851577\n",
      "Scaled KL Loss is: 0.036031730473041534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3366424738581992\n",
      "NLL Loss is: 1.57142540756428\n",
      "Scaled KL Loss is: 0.038367994129657745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6097934016939377\n",
      "NLL Loss is: 1.1899947186348145\n",
      "Scaled KL Loss is: 0.036367110908031464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.226361829542846\n",
      "NLL Loss is: 1.316102570370244\n",
      "Scaled KL Loss is: 0.040347032248973846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564496026192179\n",
      "NLL Loss is: 1.3734351934036397\n",
      "Scaled KL Loss is: 0.04121076315641403\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4146459565600538\n",
      "NLL Loss is: 1.1644901613605723\n",
      "Scaled KL Loss is: 0.039546627551317215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2040367889118895\n",
      "NLL Loss is: 1.3411087562040924\n",
      "Scaled KL Loss is: 0.03786460682749748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37897336303159\n",
      "NLL Loss is: 1.1913677408941694\n",
      "Scaled KL Loss is: 0.03803807497024536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2294058158644148\n",
      "NLL Loss is: 1.2030064308812483\n",
      "Scaled KL Loss is: 0.034259241074323654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237265671955572\n",
      "NLL Loss is: 1.352503574516905\n",
      "Scaled KL Loss is: 0.03715003654360771\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3896536110605127\n",
      "NLL Loss is: 1.366229622003226\n",
      "Scaled KL Loss is: 0.034857820719480515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4010874427227065\n",
      "NLL Loss is: 1.2714261570168401\n",
      "Scaled KL Loss is: 0.03570670634508133\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3071328633619215\n",
      "NLL Loss is: 1.448283134723645\n",
      "Scaled KL Loss is: 0.0366915762424469\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4849747109660918\n",
      "NLL Loss is: 1.4710774983095332\n",
      "Scaled KL Loss is: 0.03609650954604149\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5071740078555746\n",
      "NLL Loss is: 1.2668952321079963\n",
      "Scaled KL Loss is: 0.04240763932466507\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3093028714326613\n",
      "NLL Loss is: 1.2472720879075805\n",
      "Scaled KL Loss is: 0.03946777805685997\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2867398659644405\n",
      "NLL Loss is: 1.3731379204448952\n",
      "Scaled KL Loss is: 0.03735277056694031\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4104906910118356\n",
      "NLL Loss is: 1.482009190352504\n",
      "Scaled KL Loss is: 0.037796054035425186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.519805244387929\n",
      "NLL Loss is: 1.2266378643197051\n",
      "Scaled KL Loss is: 0.0378887802362442\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2645266445559493\n",
      "NLL Loss is: 1.23093269362115\n",
      "Scaled KL Loss is: 0.034017063677310944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.264949757298461\n",
      "NLL Loss is: 1.2624175387685082\n",
      "Scaled KL Loss is: 0.03881215676665306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3012296955351612\n",
      "NLL Loss is: 1.2492834437712481\n",
      "Scaled KL Loss is: 0.04323501139879227\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2925184551700404\n",
      "NLL Loss is: 1.3397244984274597\n",
      "Scaled KL Loss is: 0.03519364446401596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3749181428914756\n",
      "NLL Loss is: 1.277057146741178\n",
      "Scaled KL Loss is: 0.03914821892976761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3162053656709456\n",
      "NLL Loss is: 1.2973305647000313\n",
      "Scaled KL Loss is: 0.04031277075409889\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3376433354541302\n",
      "NLL Loss is: 1.1948966303861241\n",
      "Scaled KL Loss is: 0.04179065674543381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.236687287131558\n",
      "NLL Loss is: 1.3007708568968661\n",
      "Scaled KL Loss is: 0.03962533548474312\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3403961923816092\n",
      "NLL Loss is: 1.2503662303632637\n",
      "Scaled KL Loss is: 0.03787446394562721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2882406943088909\n",
      "NLL Loss is: 1.3316759660630606\n",
      "Scaled KL Loss is: 0.039234161376953125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3709101274400137\n",
      "NLL Loss is: 1.3483165728057847\n",
      "Scaled KL Loss is: 0.0360352024435997\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3843517752493844\n",
      "NLL Loss is: 1.245945651822649\n",
      "Scaled KL Loss is: 0.03884010389447212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2847857557171212\n",
      "NLL Loss is: 1.3683893305168038\n",
      "Scaled KL Loss is: 0.035793423652648926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4041827541694527\n",
      "NLL Loss is: 1.403050302867282\n",
      "Scaled KL Loss is: 0.0360407717525959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.439091074619878\n",
      "NLL Loss is: 1.4121175746913692\n",
      "Scaled KL Loss is: 0.034713633358478546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4468312080498478\n",
      "NLL Loss is: 1.4259891329596948\n",
      "Scaled KL Loss is: 0.03904281184077263\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4650319448004674\n",
      "NLL Loss is: 1.299407973563251\n",
      "Scaled KL Loss is: 0.03633687645196915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3357448500152203\n",
      "NLL Loss is: 1.272763084846244\n",
      "Scaled KL Loss is: 0.035272955894470215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3080360407407141\n",
      "NLL Loss is: 1.2093292783903704\n",
      "Scaled KL Loss is: 0.0391889326274395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.24851821101781\n",
      "NLL Loss is: 1.305579399616918\n",
      "Scaled KL Loss is: 0.038213182240724564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3437925818576426\n",
      "NLL Loss is: 1.3208900353660238\n",
      "Scaled KL Loss is: 0.03699418157339096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3578842169394147\n",
      "NLL Loss is: 1.4035130917474936\n",
      "Scaled KL Loss is: 0.03666027635335922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4401733681008528\n",
      "NLL Loss is: 1.3097858142634906\n",
      "Scaled KL Loss is: 0.03769650310277939\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34748231736627\n",
      "NLL Loss is: 1.328386495759699\n",
      "Scaled KL Loss is: 0.03509081155061722\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3634773073103161\n",
      "NLL Loss is: 1.4045273093972515\n",
      "Scaled KL Loss is: 0.03668482229113579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4412121316883872\n",
      "NLL Loss is: 1.4071211395263936\n",
      "Scaled KL Loss is: 0.03808122128248215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4452023608088758\n",
      "NLL Loss is: 1.3698667745168394\n",
      "Scaled KL Loss is: 0.03641918674111366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.406285961257953\n",
      "NLL Loss is: 1.3355210769192403\n",
      "Scaled KL Loss is: 0.04033350944519043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3758545863644307\n",
      "NLL Loss is: 1.3081664254621654\n",
      "Scaled KL Loss is: 0.03642027825117111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3445867037133366\n",
      "NLL Loss is: 1.464206851429519\n",
      "Scaled KL Loss is: 0.037863072007894516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5020699234374135\n",
      "NLL Loss is: 1.3658016486936515\n",
      "Scaled KL Loss is: 0.03520246967673302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4010041183703845\n",
      "NLL Loss is: 1.361682034020266\n",
      "Scaled KL Loss is: 0.03983505815267563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4015170921729416\n",
      "NLL Loss is: 1.3493011314899654\n",
      "Scaled KL Loss is: 0.03814929723739624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3874504287273617\n",
      "NLL Loss is: 1.4592217512456613\n",
      "Scaled KL Loss is: 0.036722030490636826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4959437817362982\n",
      "NLL Loss is: 1.2979761486414731\n",
      "Scaled KL Loss is: 0.03408684581518173\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3320629944566549\n",
      "NLL Loss is: 1.4456149439611397\n",
      "Scaled KL Loss is: 0.03507285937666893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4806878033378086\n",
      "NLL Loss is: 1.3990575705335042\n",
      "Scaled KL Loss is: 0.03660915419459343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4356667247280976\n",
      "NLL Loss is: 1.3554476509155693\n",
      "Scaled KL Loss is: 0.036390360444784164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3918380113603535\n",
      "NLL Loss is: 1.2937260595755133\n",
      "Scaled KL Loss is: 0.03509477898478508\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3288208385602984\n",
      "NLL Loss is: 1.3782381589997572\n",
      "Scaled KL Loss is: 0.03572024777531624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4139584067750735\n",
      "NLL Loss is: 1.2599166837154874\n",
      "Scaled KL Loss is: 0.038352180272340775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2982688639878281\n",
      "NLL Loss is: 1.3687782081204467\n",
      "Scaled KL Loss is: 0.03347974643111229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402257954551559\n",
      "NLL Loss is: 1.267130210997245\n",
      "Scaled KL Loss is: 0.0384373664855957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3055675774828408\n",
      "NLL Loss is: 1.4009345764621077\n",
      "Scaled KL Loss is: 0.03729557245969772\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4382301489218055\n",
      "NLL Loss is: 1.460048379915196\n",
      "Scaled KL Loss is: 0.03624739125370979\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4962957711689058\n",
      "NLL Loss is: 1.3882350903598821\n",
      "Scaled KL Loss is: 0.03358647599816322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4218215663580454\n",
      "NLL Loss is: 1.3219480626749123\n",
      "Scaled KL Loss is: 0.03842978924512863\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360377851920041\n",
      "NLL Loss is: 1.2618027573114146\n",
      "Scaled KL Loss is: 0.03556939214468002\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2973721494560946\n",
      "NLL Loss is: 1.4455748939321662\n",
      "Scaled KL Loss is: 0.037064433097839355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4826393270300056\n",
      "NLL Loss is: 1.3189768050700617\n",
      "Scaled KL Loss is: 0.037467896938323975\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564447020083856\n",
      "NLL Loss is: 1.6770675209657762\n",
      "Scaled KL Loss is: 0.03008369356393814\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7071512145297143\n",
      "NLL Loss is: 1.3399541517361175= 1.375; test loss = 1.412\n",
      "Scaled KL Loss is: 0.038103654980659485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.378057806716777\n",
      "NLL Loss is: 1.3935995689575258\n",
      "Scaled KL Loss is: 0.03515586629509926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.428755435252625\n",
      "NLL Loss is: 1.3911671349872123\n",
      "Scaled KL Loss is: 0.03741040453314781\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4285775395203602\n",
      "NLL Loss is: 1.4184774197624441\n",
      "Scaled KL Loss is: 0.03851908817887306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4569965079413172\n",
      "NLL Loss is: 1.3635633346825582\n",
      "Scaled KL Loss is: 0.03380155563354492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3973648903161031\n",
      "NLL Loss is: 1.406269027779747\n",
      "Scaled KL Loss is: 0.03795354440808296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.44422257218783\n",
      "NLL Loss is: 1.4050296245154614\n",
      "Scaled KL Loss is: 0.0332958847284317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4383255092438931\n",
      "NLL Loss is: 1.3433901602223164\n",
      "Scaled KL Loss is: 0.03331894055008888\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3767091007724053\n",
      "NLL Loss is: 1.399999959734564\n",
      "Scaled KL Loss is: 0.03323059901595116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4332305587505152\n",
      "NLL Loss is: 1.2914594681947449\n",
      "Scaled KL Loss is: 0.038840070366859436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3302995385616043\n",
      "NLL Loss is: 1.3005233005599641\n",
      "Scaled KL Loss is: 0.0327228344976902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3332461350576543\n",
      "NLL Loss is: 1.4145319881097778\n",
      "Scaled KL Loss is: 0.036386068910360336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.450918057020138\n",
      "NLL Loss is: 1.287793248589665\n",
      "Scaled KL Loss is: 0.039975836873054504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3277690854627195\n",
      "NLL Loss is: 1.4842177633852163\n",
      "Scaled KL Loss is: 0.03709746524691582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.521315228632132\n",
      "NLL Loss is: 1.2970194042798828\n",
      "Scaled KL Loss is: 0.03565129637718201\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3326707006570648\n",
      "NLL Loss is: 1.454350245074325\n",
      "Scaled KL Loss is: 0.04043518751859665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4947854325929217\n",
      "NLL Loss is: 1.3952417826730967\n",
      "Scaled KL Loss is: 0.03704805672168732\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432289839394784\n",
      "NLL Loss is: 1.3430703283799443\n",
      "Scaled KL Loss is: 0.037129487842321396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3801998162222657\n",
      "NLL Loss is: 1.2750335877877617\n",
      "Scaled KL Loss is: 0.03737468272447586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3124082705122375\n",
      "NLL Loss is: 1.3628074076802748\n",
      "Scaled KL Loss is: 0.03592013940215111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3987275470824259\n",
      "NLL Loss is: 1.330397258811689\n",
      "Scaled KL Loss is: 0.035208817571401596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3656060763830906\n",
      "NLL Loss is: 1.3798063855285148\n",
      "Scaled KL Loss is: 0.03536295145750046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4151693369860152\n",
      "NLL Loss is: 1.2987459107395027\n",
      "Scaled KL Loss is: 0.03630199655890465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3350479072984074\n",
      "NLL Loss is: 1.5712379556633898\n",
      "Scaled KL Loss is: 0.0384821854531765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6097201411165662\n",
      "NLL Loss is: 1.1888555273725145\n",
      "Scaled KL Loss is: 0.0365290641784668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2253845915509813\n",
      "NLL Loss is: 1.3152792592933744\n",
      "Scaled KL Loss is: 0.04052167758345604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3558009368768305\n",
      "NLL Loss is: 1.3720622647268943\n",
      "Scaled KL Loss is: 0.04142792522907257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4134901899559669\n",
      "NLL Loss is: 1.1625097520922527\n",
      "Scaled KL Loss is: 0.03978698328137398\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2022967353736267\n",
      "NLL Loss is: 1.3394486805123296\n",
      "Scaled KL Loss is: 0.038026414811611176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3774750953239407\n",
      "NLL Loss is: 1.1887472606680387\n",
      "Scaled KL Loss is: 0.03821003809571266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2269572987637514\n",
      "NLL Loss is: 1.2011088112347093\n",
      "Scaled KL Loss is: 0.034368958324193954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2354777695589032\n",
      "NLL Loss is: 1.3499153585421368\n",
      "Scaled KL Loss is: 0.03731050714850426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.387225865690641\n",
      "NLL Loss is: 1.3642263589731771\n",
      "Scaled KL Loss is: 0.03496042266488075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3991867816380579\n",
      "NLL Loss is: 1.2699559468121109\n",
      "Scaled KL Loss is: 0.03582840785384178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3057843546659527\n",
      "NLL Loss is: 1.4461505051065178\n",
      "Scaled KL Loss is: 0.036866553127765656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4830170582342834\n",
      "NLL Loss is: 1.468914343612944\n",
      "Scaled KL Loss is: 0.03621700406074524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5051313476736892\n",
      "NLL Loss is: 1.2653630351670027\n",
      "Scaled KL Loss is: 0.042540691792964935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3079037269599676\n",
      "NLL Loss is: 1.246383750767933\n",
      "Scaled KL Loss is: 0.03971047326922417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2860942240371571\n",
      "NLL Loss is: 1.3702940126209273\n",
      "Scaled KL Loss is: 0.037535205483436584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.407829218104364\n",
      "NLL Loss is: 1.480723199385429\n",
      "Scaled KL Loss is: 0.037915002554655075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5186382019400841\n",
      "NLL Loss is: 1.223504770017757\n",
      "Scaled KL Loss is: 0.03800496086478233\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2615097308825394\n",
      "NLL Loss is: 1.2278670433075796\n",
      "Scaled KL Loss is: 0.03417685255408287\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2620438958616624\n",
      "NLL Loss is: 1.2600432880705208\n",
      "Scaled KL Loss is: 0.03908824920654297\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2991315372770638\n",
      "NLL Loss is: 1.246704698158704\n",
      "Scaled KL Loss is: 0.043299656361341476\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2900043545200455\n",
      "NLL Loss is: 1.3373130118911893\n",
      "Scaled KL Loss is: 0.03528887778520584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3726018896763952\n",
      "NLL Loss is: 1.2755088281159803\n",
      "Scaled KL Loss is: 0.03934789076447487\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3148567188804552\n",
      "NLL Loss is: 1.2960051200571365\n",
      "Scaled KL Loss is: 0.0404510498046875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336456169861824\n",
      "NLL Loss is: 1.192386521353299\n",
      "Scaled KL Loss is: 0.042079709470272064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.234466230823571\n",
      "NLL Loss is: 1.2994226445480657\n",
      "Scaled KL Loss is: 0.03973209112882614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3391547356768918\n",
      "NLL Loss is: 1.2477992267367297\n",
      "Scaled KL Loss is: 0.03801378607749939\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.285813012814229\n",
      "NLL Loss is: 1.3290253137218233\n",
      "Scaled KL Loss is: 0.039396174252033234\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3684214879738565\n",
      "NLL Loss is: 1.3477842358423981\n",
      "Scaled KL Loss is: 0.03613179177045822\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3839160276128564\n",
      "NLL Loss is: 1.243874792300617\n",
      "Scaled KL Loss is: 0.038892507553100586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2827672998537176\n",
      "NLL Loss is: 1.3667765487985477\n",
      "Scaled KL Loss is: 0.0359935536980629\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4027701024966106\n",
      "NLL Loss is: 1.4010898243573513\n",
      "Scaled KL Loss is: 0.03620386868715286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4372936930445042\n",
      "NLL Loss is: 1.4101509004852397\n",
      "Scaled KL Loss is: 0.0348769910633564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4450278915485961\n",
      "NLL Loss is: 1.4246117913095202\n",
      "Scaled KL Loss is: 0.039168208837509155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4637800001470294\n",
      "NLL Loss is: 1.2985269254926657\n",
      "Scaled KL Loss is: 0.036390285938978195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3349172114316439\n",
      "NLL Loss is: 1.2708473527092432\n",
      "Scaled KL Loss is: 0.035471390932798386\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3063187436420416\n",
      "NLL Loss is: 1.2077280529271628\n",
      "Scaled KL Loss is: 0.03923342004418373\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2469614729713465\n",
      "NLL Loss is: 1.303722669696488\n",
      "Scaled KL Loss is: 0.03838352486491203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3421061945614001\n",
      "NLL Loss is: 1.3174789041745205\n",
      "Scaled KL Loss is: 0.03706670552492142\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354545609699442\n",
      "NLL Loss is: 1.4012999764877003\n",
      "Scaled KL Loss is: 0.036746714264154434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4380466907518548\n",
      "NLL Loss is: 1.3086082735301436\n",
      "Scaled KL Loss is: 0.03795447573065758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3465627492608012\n",
      "NLL Loss is: 1.3260363851920045\n",
      "Scaled KL Loss is: 0.0352078415453434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361244226737348\n",
      "NLL Loss is: 1.403004944556321\n",
      "Scaled KL Loss is: 0.03683451935648918\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4398394639128103\n",
      "NLL Loss is: 1.4053453682255763\n",
      "Scaled KL Loss is: 0.03830385580658913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4436492240321654\n",
      "NLL Loss is: 1.3680532276111343\n",
      "Scaled KL Loss is: 0.03647186607122421\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4045250936823586\n",
      "NLL Loss is: 1.3337336753645024\n",
      "Scaled KL Loss is: 0.04043642058968544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3741700959541878\n",
      "NLL Loss is: 1.3060669381274042\n",
      "Scaled KL Loss is: 0.036519378423690796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.342586316551095\n",
      "NLL Loss is: 1.4623258403322794\n",
      "Scaled KL Loss is: 0.0379878468811512\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5003136872134306\n",
      "NLL Loss is: 1.364273789376418\n",
      "Scaled KL Loss is: 0.03537021949887276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3996440088752908\n",
      "NLL Loss is: 1.359069545512064\n",
      "Scaled KL Loss is: 0.039948854595422745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3990184001074868\n",
      "NLL Loss is: 1.347715599735906\n",
      "Scaled KL Loss is: 0.03832760080695152\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3860432005428576\n",
      "NLL Loss is: 1.458939344049889\n",
      "Scaled KL Loss is: 0.03688383102416992\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.495823175074059\n",
      "NLL Loss is: 1.2969406067418714\n",
      "Scaled KL Loss is: 0.034210674464702606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.331151281206574\n",
      "NLL Loss is: 1.4436734377520262\n",
      "Scaled KL Loss is: 0.03509441390633583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.478767851658362\n",
      "NLL Loss is: 1.3972505487919296\n",
      "Scaled KL Loss is: 0.03682884946465492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4340793982565845\n",
      "NLL Loss is: 1.3548932251225023\n",
      "Scaled KL Loss is: 0.036363448947668076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3912566740701704\n",
      "NLL Loss is: 1.291597478737395\n",
      "Scaled KL Loss is: 0.035157058387994766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3267545371253897\n",
      "NLL Loss is: 1.3765106774032652\n",
      "Scaled KL Loss is: 0.03584182634949684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.412352503752762\n",
      "NLL Loss is: 1.257791916938518\n",
      "Scaled KL Loss is: 0.03846828639507294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.296260203333591\n",
      "NLL Loss is: 1.3680487046228529\n",
      "Scaled KL Loss is: 0.03357435017824173\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4016230548010946\n",
      "NLL Loss is: 1.26488067674228\n",
      "Scaled KL Loss is: 0.03851902857422829\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3033997053165083\n",
      "NLL Loss is: 1.397961348569861\n",
      "Scaled KL Loss is: 0.0373321995139122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4352935480837732\n",
      "NLL Loss is: 1.4581882973243177\n",
      "Scaled KL Loss is: 0.036527119576931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4947154169012487\n",
      "NLL Loss is: 1.3856577945940345\n",
      "Scaled KL Loss is: 0.033681757748126984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4193395523421615\n",
      "NLL Loss is: 1.3202208796857489\n",
      "Scaled KL Loss is: 0.03851068764925003\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358731567334999\n",
      "NLL Loss is: 1.2602126182878566\n",
      "Scaled KL Loss is: 0.035737309604883194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2959499278927398\n",
      "NLL Loss is: 1.44462101161664\n",
      "Scaled KL Loss is: 0.03727814182639122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4818991534430312\n",
      "NLL Loss is: 1.316926319459246\n",
      "Scaled KL Loss is: 0.037665143609046936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354591463068293\n",
      "NLL Loss is: 1.6755337892170945\n",
      "Scaled KL Loss is: 0.03025403991341591\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7057878291305104\n",
      "NLL Loss is: 1.338681094772868 = 1.374; test loss = 1.411\n",
      "Scaled KL Loss is: 0.03819030523300171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3768714000058697\n",
      "NLL Loss is: 1.3916048705042317\n",
      "Scaled KL Loss is: 0.035250645130872726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4268555156351044\n",
      "NLL Loss is: 1.3893828672539914\n",
      "Scaled KL Loss is: 0.03753546252846718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4269183297824586\n",
      "NLL Loss is: 1.4161697536822957\n",
      "Scaled KL Loss is: 0.03850371018052101\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4546734638628167\n",
      "NLL Loss is: 1.3615144261495964\n",
      "Scaled KL Loss is: 0.0339600071310997\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395474433280696\n",
      "NLL Loss is: 1.4041643037072884\n",
      "Scaled KL Loss is: 0.03807775303721428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4422420567445027\n",
      "NLL Loss is: 1.4038565158396716\n",
      "Scaled KL Loss is: 0.03348856419324875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4373450800329204\n",
      "NLL Loss is: 1.3436889499937315\n",
      "Scaled KL Loss is: 0.033396001905202866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3770849518989343\n",
      "NLL Loss is: 1.3995868637697368\n",
      "Scaled KL Loss is: 0.03333204239606857\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4329189061658054\n",
      "NLL Loss is: 1.2896746986460095\n",
      "Scaled KL Loss is: 0.03895658254623413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3286312811922436\n",
      "NLL Loss is: 1.2990620242488042\n",
      "Scaled KL Loss is: 0.03273085877299309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3317928830217973\n",
      "NLL Loss is: 1.412994516063639\n",
      "Scaled KL Loss is: 0.03658062219619751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4495751382598365\n",
      "NLL Loss is: 1.2858288662355222\n",
      "Scaled KL Loss is: 0.040190499275922775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.326019365511445\n",
      "NLL Loss is: 1.481526357623803\n",
      "Scaled KL Loss is: 0.03721506893634796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5187414265601509\n",
      "NLL Loss is: 1.2948748590120112\n",
      "Scaled KL Loss is: 0.03578770160675049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3306625606187616\n",
      "NLL Loss is: 1.451780895564718\n",
      "Scaled KL Loss is: 0.04074912890791893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.492530024472637\n",
      "NLL Loss is: 1.3929797729663143\n",
      "Scaled KL Loss is: 0.037351276725530624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4303310496918449\n",
      "NLL Loss is: 1.3422998675636981\n",
      "Scaled KL Loss is: 0.03728926181793213\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3795891293816303\n",
      "NLL Loss is: 1.2729037267052516\n",
      "Scaled KL Loss is: 0.037604644894599915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3105083715998516\n",
      "NLL Loss is: 1.361325946725856\n",
      "Scaled KL Loss is: 0.03619099408388138\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3975169408097374\n",
      "NLL Loss is: 1.3274678888639917\n",
      "Scaled KL Loss is: 0.03528129309415817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3627491819581499\n",
      "NLL Loss is: 1.3778556620981397\n",
      "Scaled KL Loss is: 0.03563479334115982\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4134904554392995\n",
      "NLL Loss is: 1.2968692210476451\n",
      "Scaled KL Loss is: 0.03659500181674957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3334642228643947\n",
      "NLL Loss is: 1.5711467747162304\n",
      "Scaled KL Loss is: 0.038631390780210495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.609778165496441\n",
      "NLL Loss is: 1.187561388170621\n",
      "Scaled KL Loss is: 0.03672339394688606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2242847821175071\n",
      "NLL Loss is: 1.3144498032119398\n",
      "Scaled KL Loss is: 0.0407235249876976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3551733281996374\n",
      "NLL Loss is: 1.3707440654977214\n",
      "Scaled KL Loss is: 0.041672129184007645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.412416194681729\n",
      "NLL Loss is: 1.1605901385923614\n",
      "Scaled KL Loss is: 0.04004767909646034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2006378176888217\n",
      "NLL Loss is: 1.3377936222241664\n",
      "Scaled KL Loss is: 0.03821655362844467\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376010175852611\n",
      "NLL Loss is: 1.1861241911764386\n",
      "Scaled KL Loss is: 0.03841346874833107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2245376599247697\n",
      "NLL Loss is: 1.1992652853860784\n",
      "Scaled KL Loss is: 0.03451194986701012\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2337772352530885\n",
      "NLL Loss is: 1.3474987822701956\n",
      "Scaled KL Loss is: 0.03750324994325638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.385002032213452\n",
      "NLL Loss is: 1.3623627235308584\n",
      "Scaled KL Loss is: 0.03510187938809395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3974646029189524\n",
      "NLL Loss is: 1.2686133818149992\n",
      "Scaled KL Loss is: 0.03598278388381004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3045961656988092\n",
      "NLL Loss is: 1.4442069027861562\n",
      "Scaled KL Loss is: 0.037067707628011703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4812746104141679\n",
      "NLL Loss is: 1.4668024361616832\n",
      "Scaled KL Loss is: 0.036367449909448624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5031698860711318\n",
      "NLL Loss is: 1.2639939842340313\n",
      "Scaled KL Loss is: 0.042699750512838364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3066937347468697\n",
      "NLL Loss is: 1.2455221106793544\n",
      "Scaled KL Loss is: 0.039973001927137375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2854951126064917\n",
      "NLL Loss is: 1.3674791997751075\n",
      "Scaled KL Loss is: 0.03774487227201462\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405224072047122\n",
      "NLL Loss is: 1.4795625073999759\n",
      "Scaled KL Loss is: 0.03806399554014206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.517626502940118\n",
      "NLL Loss is: 1.2205722620120618\n",
      "Scaled KL Loss is: 0.03815232217311859\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2587245841851804\n",
      "NLL Loss is: 1.2246402863078922\n",
      "Scaled KL Loss is: 0.03436281532049179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.259003101628384\n",
      "NLL Loss is: 1.2578194866911914\n",
      "Scaled KL Loss is: 0.03938419744372368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297203684134915\n",
      "NLL Loss is: 1.2442183120624042\n",
      "Scaled KL Loss is: 0.04339568689465523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2876139989570594\n",
      "NLL Loss is: 1.3349860593518945\n",
      "Scaled KL Loss is: 0.035412270575761795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3703983299276563\n",
      "NLL Loss is: 1.273948549725433\n",
      "Scaled KL Loss is: 0.039568815380334854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3135173651057679\n",
      "NLL Loss is: 1.2946960848213953\n",
      "Scaled KL Loss is: 0.040609851479530334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3353059363009256\n",
      "NLL Loss is: 1.1899886369475028\n",
      "Scaled KL Loss is: 0.04238246753811836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2323711044856211\n",
      "NLL Loss is: 1.2981690405536614\n",
      "Scaled KL Loss is: 0.03986291214823723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3380319527018987\n",
      "NLL Loss is: 1.2453669480145542\n",
      "Scaled KL Loss is: 0.03818114101886749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2835480890334217\n",
      "NLL Loss is: 1.3266832281359038\n",
      "Scaled KL Loss is: 0.03957810625433922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.366261334390243\n",
      "NLL Loss is: 1.3471874297065936\n",
      "Scaled KL Loss is: 0.03625468537211418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3834421150787077\n",
      "NLL Loss is: 1.2420268143569588\n",
      "Scaled KL Loss is: 0.038976822048425674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2810036364053845\n",
      "NLL Loss is: 1.3651937374832328\n",
      "Scaled KL Loss is: 0.03621003404259682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4014037715258296\n",
      "NLL Loss is: 1.3995245625470563\n",
      "Scaled KL Loss is: 0.03638426586985588\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4359088284169121\n",
      "NLL Loss is: 1.4082738982383771\n",
      "Scaled KL Loss is: 0.035054951906204224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4433288501445813\n",
      "NLL Loss is: 1.4233373706531234\n",
      "Scaled KL Loss is: 0.039314545691013336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4626519163441367\n",
      "NLL Loss is: 1.2975440223506503\n",
      "Scaled KL Loss is: 0.03646776080131531\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3340117831519656\n",
      "NLL Loss is: 1.2689327751015527\n",
      "Scaled KL Loss is: 0.035679493099451065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3046122682010037\n",
      "NLL Loss is: 1.2061763564308947\n",
      "Scaled KL Loss is: 0.03929907828569412\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2454754347165888\n",
      "NLL Loss is: 1.301812813215686\n",
      "Scaled KL Loss is: 0.03856572508811951\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3403785383038056\n",
      "NLL Loss is: 1.3141691399627937\n",
      "Scaled KL Loss is: 0.037159111350774765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3513282513135685\n",
      "NLL Loss is: 1.3991550802627666\n",
      "Scaled KL Loss is: 0.036848701536655426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.436003781799422\n",
      "NLL Loss is: 1.3074294566706568\n",
      "Scaled KL Loss is: 0.03821878507733345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3456482417479902\n",
      "NLL Loss is: 1.3237394558818965\n",
      "Scaled KL Loss is: 0.035339079797267914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3590785356791644\n",
      "NLL Loss is: 1.4016006189889192\n",
      "Scaled KL Loss is: 0.03699667751789093\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4385972965068101\n",
      "NLL Loss is: 1.4036415095354453\n",
      "Scaled KL Loss is: 0.03853513300418854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4421766425396338\n",
      "NLL Loss is: 1.3663398232096446\n",
      "Scaled KL Loss is: 0.036541249603033066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4028810728126777\n",
      "NLL Loss is: 1.332031952088607\n",
      "Scaled KL Loss is: 0.040552448481321335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3725844005699284\n",
      "NLL Loss is: 1.3040066796993495\n",
      "Scaled KL Loss is: 0.036632098257541656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3406387779568911\n",
      "NLL Loss is: 1.4605315569819617\n",
      "Scaled KL Loss is: 0.03812369331717491\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4986552502991366\n",
      "NLL Loss is: 1.3627729720012451\n",
      "Scaled KL Loss is: 0.03554713353514671\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3983201055363919\n",
      "NLL Loss is: 1.3565809379402471\n",
      "Scaled KL Loss is: 0.04007479175925255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3966557296994997\n",
      "NLL Loss is: 1.3461417295417197\n",
      "Scaled KL Loss is: 0.038512345403432846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3846540749451526\n",
      "NLL Loss is: 1.458671354194866\n",
      "Scaled KL Loss is: 0.03705328702926636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4957246412241323\n",
      "NLL Loss is: 1.2959216748355655\n",
      "Scaled KL Loss is: 0.03434491902589798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3302665938614635\n",
      "NLL Loss is: 1.4418685183622628\n",
      "Scaled KL Loss is: 0.03513045236468315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.476998970726946\n",
      "NLL Loss is: 1.3957824193233048\n",
      "Scaled KL Loss is: 0.037051618099212646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4328340374225175\n",
      "NLL Loss is: 1.3543553267497253\n",
      "Scaled KL Loss is: 0.0363592654466629\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3907145921963882\n",
      "NLL Loss is: 1.2895449167298654\n",
      "Scaled KL Loss is: 0.03523598983883858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.324780906568704\n",
      "NLL Loss is: 1.3748382272606567\n",
      "Scaled KL Loss is: 0.03597388416528702\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4108121114259438\n",
      "NLL Loss is: 1.2557521039072048\n",
      "Scaled KL Loss is: 0.038598380982875824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943504848900806\n",
      "NLL Loss is: 1.3673332245100847\n",
      "Scaled KL Loss is: 0.03367963805794716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4010128625680318\n",
      "NLL Loss is: 1.2627871069894692\n",
      "Scaled KL Loss is: 0.03861462324857712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3014017302380463\n",
      "NLL Loss is: 1.3951629795773264\n",
      "Scaled KL Loss is: 0.037380650639534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4325436302168604\n",
      "NLL Loss is: 1.456408759827927\n",
      "Scaled KL Loss is: 0.03679925203323364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4932080118611606\n",
      "NLL Loss is: 1.3832110069310042\n",
      "Scaled KL Loss is: 0.0337868295609951\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4169978364919993\n",
      "NLL Loss is: 1.3185625094365028\n",
      "Scaled KL Loss is: 0.038602523505687714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571650329421905\n",
      "NLL Loss is: 1.258612796014792\n",
      "Scaled KL Loss is: 0.03591466695070267\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2945274629654946\n",
      "NLL Loss is: 1.4436611711935317\n",
      "Scaled KL Loss is: 0.037492312490940094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4811534836844717\n",
      "NLL Loss is: 1.31496905781035\n",
      "Scaled KL Loss is: 0.03786510229110718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.352834160101457\n",
      "NLL Loss is: 1.6740073866300855\n",
      "Scaled KL Loss is: 0.030422033742070198\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7044294203721557\n",
      "NLL Loss is: 1.337483952703465 = 1.372; test loss = 1.409\n",
      "Scaled KL Loss is: 0.03828699141740799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375770944120873\n",
      "NLL Loss is: 1.389663861365487\n",
      "Scaled KL Loss is: 0.03535880148410797\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425022662849595\n",
      "NLL Loss is: 1.38769983034928\n",
      "Scaled KL Loss is: 0.037668194621801376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4253680249710814\n",
      "NLL Loss is: 1.4140365157002295\n",
      "Scaled KL Loss is: 0.03850393742322922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4525404531234587\n",
      "NLL Loss is: 1.3595626003907935\n",
      "Scaled KL Loss is: 0.03412265330553055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393685253696324\n",
      "NLL Loss is: 1.402223948544701\n",
      "Scaled KL Loss is: 0.038210924714803696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4404348732595047\n",
      "NLL Loss is: 1.4027417895037968\n",
      "Scaled KL Loss is: 0.03368755429983139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4364293438036282\n",
      "NLL Loss is: 1.3439429219373809\n",
      "Scaled KL Loss is: 0.033489082008600235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377432003945981\n",
      "NLL Loss is: 1.399109401233534\n",
      "Scaled KL Loss is: 0.03344409167766571\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4325534929111996\n",
      "NLL Loss is: 1.2878954675475185\n",
      "Scaled KL Loss is: 0.03908133506774902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3269768026152675\n",
      "NLL Loss is: 1.297601367324407\n",
      "Scaled KL Loss is: 0.03275767341256142\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3303590407369683\n",
      "NLL Loss is: 1.4114988874492136\n",
      "Scaled KL Loss is: 0.03677840903401375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4482772964832273\n",
      "NLL Loss is: 1.283928665050105\n",
      "Scaled KL Loss is: 0.040405940264463425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3243346053145684\n",
      "NLL Loss is: 1.4790294854125887\n",
      "Scaled KL Loss is: 0.0373384952545166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5163679806671053\n",
      "NLL Loss is: 1.292733502375932\n",
      "Scaled KL Loss is: 0.03593700751662254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3286705098925546\n",
      "NLL Loss is: 1.4493260932334753\n",
      "Scaled KL Loss is: 0.0410563163459301\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4903824095794054\n",
      "NLL Loss is: 1.3908235365640724\n",
      "Scaled KL Loss is: 0.0376490019261837\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4284725384902561\n",
      "NLL Loss is: 1.3415298033930614\n",
      "Scaled KL Loss is: 0.03745406121015549\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3789838646032169\n",
      "NLL Loss is: 1.2708290088283296\n",
      "Scaled KL Loss is: 0.037833910435438156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3086629192637678\n",
      "NLL Loss is: 1.3598400410215379\n",
      "Scaled KL Loss is: 0.03645934909582138\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3962993901173593\n",
      "NLL Loss is: 1.3247415307556116\n",
      "Scaled KL Loss is: 0.03536723181605339\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360108762571665\n",
      "NLL Loss is: 1.376002424067387\n",
      "Scaled KL Loss is: 0.035902973264455795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119053973318427\n",
      "NLL Loss is: 1.2950642979870945\n",
      "Scaled KL Loss is: 0.0368841215968132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3319484195839078\n",
      "NLL Loss is: 1.5709858506909142\n",
      "Scaled KL Loss is: 0.0387868694961071\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6097727201870213\n",
      "NLL Loss is: 1.1862803676573836\n",
      "Scaled KL Loss is: 0.036919914186000824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2232002818433845\n",
      "NLL Loss is: 1.313684652708943\n",
      "Scaled KL Loss is: 0.04092374071478844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3546083934237314\n",
      "NLL Loss is: 1.3694876552851378\n",
      "Scaled KL Loss is: 0.0419132374227047\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4114008927078425\n",
      "NLL Loss is: 1.1588246543252478\n",
      "Scaled KL Loss is: 0.04030085355043411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.199125507875682\n",
      "NLL Loss is: 1.3362385514084627\n",
      "Scaled KL Loss is: 0.03840770572423935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.374646257132702\n",
      "NLL Loss is: 1.1835883088250623\n",
      "Scaled KL Loss is: 0.038620516657829285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2222088254828916\n",
      "NLL Loss is: 1.1975808009469393\n",
      "Scaled KL Loss is: 0.03466123342514038\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2322420343720797\n",
      "NLL Loss is: 1.3452728868460042\n",
      "Scaled KL Loss is: 0.03770146891474724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3829743557607515\n",
      "NLL Loss is: 1.3606238672148823\n",
      "Scaled KL Loss is: 0.03525242581963539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3958762930345177\n",
      "NLL Loss is: 1.2672604321784022\n",
      "Scaled KL Loss is: 0.036138907074928284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3033993392533305\n",
      "NLL Loss is: 1.442302681193176\n",
      "Scaled KL Loss is: 0.03726053610444069\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4795632172976168\n",
      "NLL Loss is: 1.465486141455305\n",
      "Scaled KL Loss is: 0.03651954606175423\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5020056875170593\n",
      "NLL Loss is: 1.2619246087368179\n",
      "Scaled KL Loss is: 0.04284980520606041\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3047744139428783\n",
      "NLL Loss is: 1.244547832119318\n",
      "Scaled KL Loss is: 0.04023083671927452\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2847786688385925\n",
      "NLL Loss is: 1.3657629589575988\n",
      "Scaled KL Loss is: 0.03795139864087105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4037143575984699\n",
      "NLL Loss is: 1.4782961312593412\n",
      "Scaled KL Loss is: 0.03821944072842598\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5165155719877672\n",
      "NLL Loss is: 1.2179007756605622\n",
      "Scaled KL Loss is: 0.038303568959236145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2562043446197984\n",
      "NLL Loss is: 1.2225782500243219\n",
      "Scaled KL Loss is: 0.03454623743891716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.257124487463239\n",
      "NLL Loss is: 1.2554632834595028\n",
      "Scaled KL Loss is: 0.03966672345995903\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2951300069194618\n",
      "NLL Loss is: 1.241459385910408\n",
      "Scaled KL Loss is: 0.04348493367433548\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2849443195847434\n",
      "NLL Loss is: 1.3329442043665376\n",
      "Scaled KL Loss is: 0.03552975878119469\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3684739631477323\n",
      "NLL Loss is: 1.2724110047000727\n",
      "Scaled KL Loss is: 0.03978028520941734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.31219128990949\n",
      "NLL Loss is: 1.2934301722576584\n",
      "Scaled KL Loss is: 0.040755804628133774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3341859768857922\n",
      "NLL Loss is: 1.1877585944818163\n",
      "Scaled KL Loss is: 0.04266592487692833\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2304245193587446\n",
      "NLL Loss is: 1.2969220309585432\n",
      "Scaled KL Loss is: 0.039982207119464874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336904238078008\n",
      "NLL Loss is: 1.2430342536248449\n",
      "Scaled KL Loss is: 0.03833694010972977\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2813711937345746\n",
      "NLL Loss is: 1.3239448086728196\n",
      "Scaled KL Loss is: 0.039745934307575226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3636907429803948\n",
      "NLL Loss is: 1.3468763022006407\n",
      "Scaled KL Loss is: 0.036369118839502335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.383245421040143\n",
      "NLL Loss is: 1.2397762652786113\n",
      "Scaled KL Loss is: 0.03905444219708443\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2788307074756957\n",
      "NLL Loss is: 1.363677808929629\n",
      "Scaled KL Loss is: 0.03641977533698082\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40009758426661\n",
      "NLL Loss is: 1.3973356370715724\n",
      "Scaled KL Loss is: 0.036547258496284485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4338828955678569\n",
      "NLL Loss is: 1.4064436090953816\n",
      "Scaled KL Loss is: 0.035227637737989426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441671246833371\n",
      "NLL Loss is: 1.4219789220629133\n",
      "Scaled KL Loss is: 0.03944914788007736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4614280699429907\n",
      "NLL Loss is: 1.2968398712415108\n",
      "Scaled KL Loss is: 0.036544423550367355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3333842947918781\n",
      "NLL Loss is: 1.2671030826703933\n",
      "Scaled KL Loss is: 0.03587682545185089\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3029799081222442\n",
      "NLL Loss is: 1.204764734757843\n",
      "Scaled KL Loss is: 0.03936176747083664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2441265022286796\n",
      "NLL Loss is: 1.3001384773637172\n",
      "Scaled KL Loss is: 0.038736745715141296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3388752230788585\n",
      "NLL Loss is: 1.3110559642845707\n",
      "Scaled KL Loss is: 0.03724896162748337\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348304925912054\n",
      "NLL Loss is: 1.3971121714035672\n",
      "Scaled KL Loss is: 0.03694497048854828\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4340571418921155\n",
      "NLL Loss is: 1.3062333734138327\n",
      "Scaled KL Loss is: 0.038472745567560196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344706118981393\n",
      "NLL Loss is: 1.3214956334238213\n",
      "Scaled KL Loss is: 0.035464148968458176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569597823922794\n",
      "NLL Loss is: 1.4004255560728576\n",
      "Scaled KL Loss is: 0.03714761137962341\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.437573167452481\n",
      "NLL Loss is: 1.4019893741880591\n",
      "Scaled KL Loss is: 0.03875623643398285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440745610622042\n",
      "NLL Loss is: 1.364598303945484\n",
      "Scaled KL Loss is: 0.03660661727190018\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4012049212173843\n",
      "NLL Loss is: 1.3304161109866612\n",
      "Scaled KL Loss is: 0.04066024348139763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3710763544680589\n",
      "NLL Loss is: 1.3021262808298137\n",
      "Scaled KL Loss is: 0.036736197769641876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3388624785994556\n",
      "NLL Loss is: 1.4586403960345888\n",
      "Scaled KL Loss is: 0.03825207054615021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.496892466580739\n",
      "NLL Loss is: 1.361316917927139\n",
      "Scaled KL Loss is: 0.03571626916527748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3970331870924164\n",
      "NLL Loss is: 1.3541858223163294\n",
      "Scaled KL Loss is: 0.04019469767808914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3943805199944186\n",
      "NLL Loss is: 1.344675395172337\n",
      "Scaled KL Loss is: 0.03868977352976799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.383365168702105\n",
      "NLL Loss is: 1.4583745602398162\n",
      "Scaled KL Loss is: 0.03721585124731064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4955904114871268\n",
      "NLL Loss is: 1.2948659187824896\n",
      "Scaled KL Loss is: 0.034473441541194916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3293393603236845\n",
      "NLL Loss is: 1.4400648192925625\n",
      "Scaled KL Loss is: 0.035164982080459595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.475229801373022\n",
      "NLL Loss is: 1.3941418819951363\n",
      "Scaled KL Loss is: 0.037263136357069016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4314050183522053\n",
      "NLL Loss is: 1.3536924491425772\n",
      "Scaled KL Loss is: 0.03635768964886665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.390050138791444\n",
      "NLL Loss is: 1.2876455861061922\n",
      "Scaled KL Loss is: 0.03531728312373161\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3229628692299238\n",
      "NLL Loss is: 1.3732761144055616\n",
      "Scaled KL Loss is: 0.03609951213002205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4093756265355837\n",
      "NLL Loss is: 1.2538040396757233\n",
      "Scaled KL Loss is: 0.03872600197792053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2925300416536438\n",
      "NLL Loss is: 1.36668788379768\n",
      "Scaled KL Loss is: 0.03378133475780487\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4004692185554848\n",
      "NLL Loss is: 1.2607285093629854\n",
      "Scaled KL Loss is: 0.03870704397559166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.299435553338577\n",
      "NLL Loss is: 1.3924906965636492\n",
      "Scaled KL Loss is: 0.03742394596338272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.429914642527032\n",
      "NLL Loss is: 1.4546902060572586\n",
      "Scaled KL Loss is: 0.03705578297376633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.491745989031025\n",
      "NLL Loss is: 1.380911112938643\n",
      "Scaled KL Loss is: 0.03388749063014984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414798603568793\n",
      "NLL Loss is: 1.3169196859748455\n",
      "Scaled KL Loss is: 0.03869054093956947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355610226914415\n",
      "NLL Loss is: 1.256997216974566\n",
      "Scaled KL Loss is: 0.03608618676662445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2930834037411905\n",
      "NLL Loss is: 1.442788898464351\n",
      "Scaled KL Loss is: 0.037694405764341354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4804833042286925\n",
      "NLL Loss is: 1.3130744512030252\n",
      "Scaled KL Loss is: 0.038054458796978\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3511289100000032\n",
      "NLL Loss is: 1.6725026705047559\n",
      "Scaled KL Loss is: 0.030580589547753334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7030832600525092\n",
      "NLL Loss is: 1.3363480340851757= 1.370; test loss = 1.408\n",
      "Scaled KL Loss is: 0.03837835043668747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3747263845218631\n",
      "NLL Loss is: 1.3877576512473124\n",
      "Scaled KL Loss is: 0.035465117543935776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4232227687912482\n",
      "NLL Loss is: 1.385996515530782\n",
      "Scaled KL Loss is: 0.03779605031013489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423792565840917\n",
      "NLL Loss is: 1.4119624672204487\n",
      "Scaled KL Loss is: 0.03850413113832474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4504665983587735\n",
      "NLL Loss is: 1.3576444830969652\n",
      "Scaled KL Loss is: 0.03428040072321892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.391924883820184\n",
      "NLL Loss is: 1.4002446254803604\n",
      "Scaled KL Loss is: 0.03834060952067375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4385852350010342\n",
      "NLL Loss is: 1.4017027613114856\n",
      "Scaled KL Loss is: 0.033885832875967026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4355885941874527\n",
      "NLL Loss is: 1.3441983392328172\n",
      "Scaled KL Loss is: 0.03359062224626541\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3777889614790826\n",
      "NLL Loss is: 1.3986616074577773\n",
      "Scaled KL Loss is: 0.03355829045176506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4322198979095424\n",
      "NLL Loss is: 1.2861463188949442\n",
      "Scaled KL Loss is: 0.03920536860823631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3253516875031806\n",
      "NLL Loss is: 1.2961107591349055\n",
      "Scaled KL Loss is: 0.03279499337077141\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3289057525056769\n",
      "NLL Loss is: 1.4100179543625515\n",
      "Scaled KL Loss is: 0.03697182238101959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446989776743571\n",
      "NLL Loss is: 1.2821678155112028\n",
      "Scaled KL Loss is: 0.04060989245772362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3227777079689265\n",
      "NLL Loss is: 1.4765602423108044\n",
      "Scaled KL Loss is: 0.03746312856674194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5140233708775463\n",
      "NLL Loss is: 1.2906082306072486\n",
      "Scaled KL Loss is: 0.03609008342027664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3266983140275252\n",
      "NLL Loss is: 1.4468255851476968\n",
      "Scaled KL Loss is: 0.04134957864880562\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4881751637965024\n",
      "NLL Loss is: 1.388837992295793\n",
      "Scaled KL Loss is: 0.03793682903051376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4267748213263067\n",
      "NLL Loss is: 1.3407109827943384\n",
      "Scaled KL Loss is: 0.03761911392211914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3783300967164576\n",
      "NLL Loss is: 1.2686992440735532\n",
      "Scaled KL Loss is: 0.038057856261730194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3067571003352834\n",
      "NLL Loss is: 1.3583502693387672\n",
      "Scaled KL Loss is: 0.03672095760703087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395071226945798\n",
      "NLL Loss is: 1.3222102409661383\n",
      "Scaled KL Loss is: 0.035461824387311935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3576720653534502\n",
      "NLL Loss is: 1.3742344888772007\n",
      "Scaled KL Loss is: 0.03616620972752571\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4104006986047264\n",
      "NLL Loss is: 1.2933045912250145\n",
      "Scaled KL Loss is: 0.037167031317949295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3304716225429638\n",
      "NLL Loss is: 1.5708305419089632\n",
      "Scaled KL Loss is: 0.03894273564219475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.609773277551158\n",
      "NLL Loss is: 1.1849609477779688\n",
      "Scaled KL Loss is: 0.037115029990673065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2220759777686419\n",
      "NLL Loss is: 1.3129190102761925\n",
      "Scaled KL Loss is: 0.04111815243959427\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3540371627157868\n",
      "NLL Loss is: 1.368284230188489\n",
      "Scaled KL Loss is: 0.04214802011847496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410432250306964\n",
      "NLL Loss is: 1.1570843291414605\n",
      "Scaled KL Loss is: 0.040544293820858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1976286229623185\n",
      "NLL Loss is: 1.334725553102344\n",
      "Scaled KL Loss is: 0.03859444707632065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3733200001786647\n",
      "NLL Loss is: 1.1811186045206066\n",
      "Scaled KL Loss is: 0.03882472962141037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.219943334142017\n",
      "NLL Loss is: 1.1958816544195594\n",
      "Scaled KL Loss is: 0.03481244668364525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2306941011032047\n",
      "NLL Loss is: 1.3431218729212822\n",
      "Scaled KL Loss is: 0.03789820149540901\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3810200744166912\n",
      "NLL Loss is: 1.358863179844551\n",
      "Scaled KL Loss is: 0.035406894981861115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.394270074826412\n",
      "NLL Loss is: 1.2660072235740487\n",
      "Scaled KL Loss is: 0.03630032762885094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3023075512028996\n",
      "NLL Loss is: 1.4405935575307978\n",
      "Scaled KL Loss is: 0.037456028163433075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4780495856942308\n",
      "NLL Loss is: 1.4636920627733305\n",
      "Scaled KL Loss is: 0.03667636215686798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5003684249301985\n",
      "NLL Loss is: 1.260507434881944\n",
      "Scaled KL Loss is: 0.04300260916352272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3035100440454668\n",
      "NLL Loss is: 1.2437183541192862\n",
      "Scaled KL Loss is: 0.04048512503504753\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2842034791543337\n",
      "NLL Loss is: 1.363438007836645\n",
      "Scaled KL Loss is: 0.03816293179988861\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4016009396365336\n",
      "NLL Loss is: 1.4772164383550017\n",
      "Scaled KL Loss is: 0.038378339260816574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5155947776158183\n",
      "NLL Loss is: 1.2154322481363815\n",
      "Scaled KL Loss is: 0.03846176713705063\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2538940152734321\n",
      "NLL Loss is: 1.2207720826247808\n",
      "Scaled KL Loss is: 0.03473583236336708\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2555079149881478\n",
      "NLL Loss is: 1.2531940806760844\n",
      "Scaled KL Loss is: 0.03995032608509064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.293144406761175\n",
      "NLL Loss is: 1.238514079210389\n",
      "Scaled KL Loss is: 0.04358707368373871\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2821011528941277\n",
      "NLL Loss is: 1.3312228167180207\n",
      "Scaled KL Loss is: 0.03565415367484093\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3668769703928616\n",
      "NLL Loss is: 1.2706567021593984\n",
      "Scaled KL Loss is: 0.03999731317162514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3106540153310235\n",
      "NLL Loss is: 1.2919564423272423\n",
      "Scaled KL Loss is: 0.04090268909931183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.332859131426554\n",
      "NLL Loss is: 1.1861049454253731\n",
      "Scaled KL Loss is: 0.04295140132308006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2290563467484532\n",
      "NLL Loss is: 1.2960102637067263\n",
      "Scaled KL Loss is: 0.04010002687573433\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3361102905824607\n",
      "NLL Loss is: 1.2412283214422515\n",
      "Scaled KL Loss is: 0.03850298374891281\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2797313051911643\n",
      "NLL Loss is: 1.3228469241457292\n",
      "Scaled KL Loss is: 0.039916008710861206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3627629328565904\n",
      "NLL Loss is: 1.3460176332162044\n",
      "Scaled KL Loss is: 0.036487728357315063\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3825053615735194\n",
      "NLL Loss is: 1.2383779333105425\n",
      "Scaled KL Loss is: 0.03914092108607292\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2775188543966154\n",
      "NLL Loss is: 1.362194936188081\n",
      "Scaled KL Loss is: 0.03662039712071419\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3988153333087952\n",
      "NLL Loss is: 1.395694160809906\n",
      "Scaled KL Loss is: 0.03670656308531761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4324007238952237\n",
      "NLL Loss is: 1.4046752575546202\n",
      "Scaled KL Loss is: 0.035394906997680664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4400701645523009\n",
      "NLL Loss is: 1.4205166061367163\n",
      "Scaled KL Loss is: 0.039582546800374985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4600991529370912\n",
      "NLL Loss is: 1.2964291544645707\n",
      "Scaled KL Loss is: 0.03662991523742676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3330590697019975\n",
      "NLL Loss is: 1.265441678678808\n",
      "Scaled KL Loss is: 0.03607147932052612\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3015131579993342\n",
      "NLL Loss is: 1.203716952254116\n",
      "Scaled KL Loss is: 0.03944120183587074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2431581540899868\n",
      "NLL Loss is: 1.2992659769603059\n",
      "Scaled KL Loss is: 0.03890959173440933\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3381755686947152\n",
      "NLL Loss is: 1.3083735133693484\n",
      "Scaled KL Loss is: 0.03736522048711777\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3457387338564661\n",
      "NLL Loss is: 1.394842885309082\n",
      "Scaled KL Loss is: 0.03707240894436836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4319152942534503\n",
      "NLL Loss is: 1.3055824323976508\n",
      "Scaled KL Loss is: 0.03873782604932785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3443202584469787\n",
      "NLL Loss is: 1.3195802674912007\n",
      "Scaled KL Loss is: 0.03562113642692566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3552014039181264\n",
      "NLL Loss is: 1.398156538844544\n",
      "Scaled KL Loss is: 0.03731989115476608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4354764299993101\n",
      "NLL Loss is: 1.400390772563356\n",
      "Scaled KL Loss is: 0.038999274373054504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4393900469364105\n",
      "NLL Loss is: 1.363445387238328\n",
      "Scaled KL Loss is: 0.036710552871227264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4001559401095554\n",
      "NLL Loss is: 1.328968586590263\n",
      "Scaled KL Loss is: 0.0408017672598362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3697703538500992\n",
      "NLL Loss is: 1.300022257327363\n",
      "Scaled KL Loss is: 0.03688433766365051\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3369065949910135\n",
      "NLL Loss is: 1.4571884631783696\n",
      "Scaled KL Loss is: 0.038413818925619125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4956022821039887\n",
      "NLL Loss is: 1.3602100755663755\n",
      "Scaled KL Loss is: 0.03591030463576317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3961203802021387\n",
      "NLL Loss is: 1.3521547135837446\n",
      "Scaled KL Loss is: 0.040347542613744736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3925022561974894\n",
      "NLL Loss is: 1.343061716943231\n",
      "Scaled KL Loss is: 0.038894303143024445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3819560200862555\n",
      "NLL Loss is: 1.4581096227032058\n",
      "Scaled KL Loss is: 0.037406034767627716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4955156574708335\n",
      "NLL Loss is: 1.2942083024886517\n",
      "Scaled KL Loss is: 0.0346376895904541\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3288459920791058\n",
      "NLL Loss is: 1.4385342023852474\n",
      "Scaled KL Loss is: 0.0352511964738369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4737853988590843\n",
      "NLL Loss is: 1.3924600966309382\n",
      "Scaled KL Loss is: 0.03748998045921326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4299500770901514\n",
      "NLL Loss is: 1.3534344023019094\n",
      "Scaled KL Loss is: 0.036413565278053284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3898479675799627\n",
      "NLL Loss is: 1.285585912710749\n",
      "Scaled KL Loss is: 0.0354330874979496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3210190002086986\n",
      "NLL Loss is: 1.3718446003195999\n",
      "Scaled KL Loss is: 0.0362568199634552\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408101420283055\n",
      "NLL Loss is: 1.2519127927033902\n",
      "Scaled KL Loss is: 0.03888688236474991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.29079967506814\n",
      "NLL Loss is: 1.3659968747995093\n",
      "Scaled KL Loss is: 0.033920977264642715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.399917852064152\n",
      "NLL Loss is: 1.2593127481758608\n",
      "Scaled KL Loss is: 0.03884446248412132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2981572106599821\n",
      "NLL Loss is: 1.3900965825230014\n",
      "Scaled KL Loss is: 0.03751740604639053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.427613988569392\n",
      "NLL Loss is: 1.4529890241735972\n",
      "Scaled KL Loss is: 0.037316132336854935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4903051565104521\n",
      "NLL Loss is: 1.3785234573312968\n",
      "Scaled KL Loss is: 0.03402962535619736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4125530826874941\n",
      "NLL Loss is: 1.315608099393296\n",
      "Scaled KL Loss is: 0.038809146732091904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544172461253878\n",
      "NLL Loss is: 1.2557131800034225\n",
      "Scaled KL Loss is: 0.03628116846084595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2919943484642684\n",
      "NLL Loss is: 1.4417491971394782\n",
      "Scaled KL Loss is: 0.03790903463959694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4796582317790752\n",
      "NLL Loss is: 1.3116045491337376\n",
      "Scaled KL Loss is: 0.038267459720373154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3498720088541107\n",
      "NLL Loss is: 1.6714893498789878\n",
      "Scaled KL Loss is: 0.030750684440135956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7022400343191237\n",
      "NLL Loss is: 1.335456856314285 = 1.369; test loss = 1.407\n",
      "Scaled KL Loss is: 0.03850623965263367\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3739630959669187\n",
      "NLL Loss is: 1.386205049709462\n",
      "Scaled KL Loss is: 0.035612501204013824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4218175509134758\n",
      "NLL Loss is: 1.384115212330808\n",
      "Scaled KL Loss is: 0.03795451298356056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4220697253143686\n",
      "NLL Loss is: 1.4101179414512197\n",
      "Scaled KL Loss is: 0.03855442255735397\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4486723640085737\n",
      "NLL Loss is: 1.3556777013906076\n",
      "Scaled KL Loss is: 0.034464724361896515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3901424257525041\n",
      "NLL Loss is: 1.3987783972692989\n",
      "Scaled KL Loss is: 0.038506124168634415\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4372845214379333\n",
      "NLL Loss is: 1.4005538561515638\n",
      "Scaled KL Loss is: 0.03411288559436798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4346667417459318\n",
      "NLL Loss is: 1.3440722832687249\n",
      "Scaled KL Loss is: 0.03373665735125542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3778089406199803\n",
      "NLL Loss is: 1.3979743048579525\n",
      "Scaled KL Loss is: 0.033702969551086426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.431677274409039\n",
      "NLL Loss is: 1.2842371413196307\n",
      "Scaled KL Loss is: 0.039356779307127\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3235939206267577\n",
      "NLL Loss is: 1.2945495891318786\n",
      "Scaled KL Loss is: 0.032859623432159424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.327409212564038\n",
      "NLL Loss is: 1.4087305634109877\n",
      "Scaled KL Loss is: 0.037183552980422974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4459141163914107\n",
      "NLL Loss is: 1.2800530100276533\n",
      "Scaled KL Loss is: 0.04084618017077446\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3208991901984277\n",
      "NLL Loss is: 1.4763775102511878\n",
      "Scaled KL Loss is: 0.037599965929985046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5139774761811728\n",
      "NLL Loss is: 1.2883202274285113\n",
      "Scaled KL Loss is: 0.03627141937613487\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3245916468046461\n",
      "NLL Loss is: 1.445199152074373\n",
      "Scaled KL Loss is: 0.0416598916053772\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4868590436797502\n",
      "NLL Loss is: 1.3867802770310553\n",
      "Scaled KL Loss is: 0.0382300540804863\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4250103311115416\n",
      "NLL Loss is: 1.3407794823391859\n",
      "Scaled KL Loss is: 0.0377972275018692\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.378576709841055\n",
      "NLL Loss is: 1.2670258211519332\n",
      "Scaled KL Loss is: 0.03828466683626175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.305310487988195\n",
      "NLL Loss is: 1.3569756278804948\n",
      "Scaled KL Loss is: 0.03697415813803673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3939497860185315\n",
      "NLL Loss is: 1.3192708695207604\n",
      "Scaled KL Loss is: 0.035562578588724136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3548334481094846\n",
      "NLL Loss is: 1.372728246769042\n",
      "Scaled KL Loss is: 0.036417894065380096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4091461408344221\n",
      "NLL Loss is: 1.2915969272862111\n",
      "Scaled KL Loss is: 0.037442758679389954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.329039685965601\n",
      "NLL Loss is: 1.5707694603472064\n",
      "Scaled KL Loss is: 0.03909842297434807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6098678833215545\n",
      "NLL Loss is: 1.1836916552894083\n",
      "Scaled KL Loss is: 0.03730427473783493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2209959300272433\n",
      "NLL Loss is: 1.312219945649473\n",
      "Scaled KL Loss is: 0.04130985587835312\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353529801527826\n",
      "NLL Loss is: 1.3671059600701465\n",
      "Scaled KL Loss is: 0.04237659275531769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4094825528254642\n",
      "NLL Loss is: 1.155779753427401\n",
      "Scaled KL Loss is: 0.040773093700408936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.19655284712781\n",
      "NLL Loss is: 1.3333954608764151\n",
      "Scaled KL Loss is: 0.03878098726272583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.372176448139141\n",
      "NLL Loss is: 1.1788114013087125\n",
      "Scaled KL Loss is: 0.03903334587812424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2178447471868368\n",
      "NLL Loss is: 1.194573276559682\n",
      "Scaled KL Loss is: 0.03496597334742546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2295392499071074\n",
      "NLL Loss is: 1.3413780896924163\n",
      "Scaled KL Loss is: 0.038101159036159515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3794792487285759\n",
      "NLL Loss is: 1.357511996708534\n",
      "Scaled KL Loss is: 0.03555862605571747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3930706227642515\n",
      "NLL Loss is: 1.2652543360880428\n",
      "Scaled KL Loss is: 0.03646383062005043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3017181667080933\n",
      "NLL Loss is: 1.4392035440937598\n",
      "Scaled KL Loss is: 0.037654340267181396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4768578843609412\n",
      "NLL Loss is: 1.461068965721972\n",
      "Scaled KL Loss is: 0.036829832941293716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4978987986632657\n",
      "NLL Loss is: 1.2598732857370252\n",
      "Scaled KL Loss is: 0.043152034282684326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3030253200197095\n",
      "NLL Loss is: 1.2430530662687875\n",
      "Scaled KL Loss is: 0.04072732478380203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2837803910525896\n",
      "NLL Loss is: 1.360739853109345\n",
      "Scaled KL Loss is: 0.03836992755532265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3991097806646677\n",
      "NLL Loss is: 1.4763916291528514\n",
      "Scaled KL Loss is: 0.03853018581867218\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5149218149715236\n",
      "NLL Loss is: 1.213031731131576\n",
      "Scaled KL Loss is: 0.03861185908317566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2516435902147516\n",
      "NLL Loss is: 1.2169186530983551\n",
      "Scaled KL Loss is: 0.034925419837236404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2518440729355915\n",
      "NLL Loss is: 1.2511551540493486\n",
      "Scaled KL Loss is: 0.040232717990875244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2913878720402239\n",
      "NLL Loss is: 1.2371765888361224\n",
      "Scaled KL Loss is: 0.04368925094604492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2808658397821673\n",
      "NLL Loss is: 1.3289179711690673\n",
      "Scaled KL Loss is: 0.03579919412732124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3647171652963885\n",
      "NLL Loss is: 1.269484151409502\n",
      "Scaled KL Loss is: 0.04020816832780838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3096923197373105\n",
      "NLL Loss is: 1.2909270658165874\n",
      "Scaled KL Loss is: 0.041062917560338974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3319899833769264\n",
      "NLL Loss is: 1.183810015904276\n",
      "Scaled KL Loss is: 0.043234847486019135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.227044863390295\n",
      "NLL Loss is: 1.2948566027049748\n",
      "Scaled KL Loss is: 0.0402459092438221\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.335102511948797\n",
      "NLL Loss is: 1.2390874626816109\n",
      "Scaled KL Loss is: 0.038694899529218674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2777823622108295\n",
      "NLL Loss is: 1.3205251053517884\n",
      "Scaled KL Loss is: 0.04010974243283272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360634847784621\n",
      "NLL Loss is: 1.345520178740964\n",
      "Scaled KL Loss is: 0.03664158657193184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382161765312896\n",
      "NLL Loss is: 1.2365969533979868\n",
      "Scaled KL Loss is: 0.039277058094739914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2758740114927267\n",
      "NLL Loss is: 1.3608148950732317\n",
      "Scaled KL Loss is: 0.03685100004076958\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3976658951140013\n",
      "NLL Loss is: 1.3948417573402265\n",
      "Scaled KL Loss is: 0.03689774125814438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.431739498598371\n",
      "NLL Loss is: 1.4030882501762312\n",
      "Scaled KL Loss is: 0.03558697551488876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.43867522569112\n",
      "NLL Loss is: 1.4193361483068483\n",
      "Scaled KL Loss is: 0.03974252939224243\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4590786776990907\n",
      "NLL Loss is: 1.2951027250890876\n",
      "Scaled KL Loss is: 0.036740392446517944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3318431175356056\n",
      "NLL Loss is: 1.2635990300333164\n",
      "Scaled KL Loss is: 0.036271799355745316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2998708293890617\n",
      "NLL Loss is: 1.2021789261489009\n",
      "Scaled KL Loss is: 0.03953498601913452\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2417139121680354\n",
      "NLL Loss is: 1.2972683237433111\n",
      "Scaled KL Loss is: 0.039094675332307816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336362999075619\n",
      "NLL Loss is: 1.3053033293873524\n",
      "Scaled KL Loss is: 0.037477005273103714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.342780334660456\n",
      "NLL Loss is: 1.3930226351957287\n",
      "Scaled KL Loss is: 0.03718499466776848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4302076298634971\n",
      "NLL Loss is: 1.304381936493253\n",
      "Scaled KL Loss is: 0.038990575820207596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3433725123134606\n",
      "NLL Loss is: 1.3173714351993864\n",
      "Scaled KL Loss is: 0.035764411091804504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3531358462911909\n",
      "NLL Loss is: 1.3972749896472998\n",
      "Scaled KL Loss is: 0.03747320920228958\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4347481988495894\n",
      "NLL Loss is: 1.3986877428479048\n",
      "Scaled KL Loss is: 0.03922927752137184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4379170203692766\n",
      "NLL Loss is: 1.3617474269570962\n",
      "Scaled KL Loss is: 0.036797668784856796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.398545095741953\n",
      "NLL Loss is: 1.3274715306269622\n",
      "Scaled KL Loss is: 0.040928151458501816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.368399682085464\n",
      "NLL Loss is: 1.2983198770342699\n",
      "Scaled KL Loss is: 0.03700517117977142\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3353250482140413\n",
      "NLL Loss is: 1.4553454590510462\n",
      "Scaled KL Loss is: 0.03855869919061661\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4939041582416628\n",
      "NLL Loss is: 1.3585571183226919\n",
      "Scaled KL Loss is: 0.036079343408346176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.394636461731038\n",
      "NLL Loss is: 1.3499991241117568\n",
      "Scaled KL Loss is: 0.04048102721571922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.390480151327476\n",
      "NLL Loss is: 1.3415916431714674\n",
      "Scaled KL Loss is: 0.0390821173787117\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.380673760550179\n",
      "NLL Loss is: 1.4574295162375808\n",
      "Scaled KL Loss is: 0.037571247667074203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.495000763904655\n",
      "NLL Loss is: 1.29328131515822\n",
      "Scaled KL Loss is: 0.03478409722447395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.328065412382694\n",
      "NLL Loss is: 1.437021217718833\n",
      "Scaled KL Loss is: 0.035312335938215256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4723335536570483\n",
      "NLL Loss is: 1.3910349797405206\n",
      "Scaled KL Loss is: 0.037695832550525665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4287308122910463\n",
      "NLL Loss is: 1.3528960656051265\n",
      "Scaled KL Loss is: 0.03645169734954834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3893477629546749\n",
      "NLL Loss is: 1.2838050087148931\n",
      "Scaled KL Loss is: 0.035539403557777405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3193444122726705\n",
      "NLL Loss is: 1.3701123043843288\n",
      "Scaled KL Loss is: 0.0363958366215229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4065081410058518\n",
      "NLL Loss is: 1.2500398734586933\n",
      "Scaled KL Loss is: 0.03903145715594292\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2890713306146362\n",
      "NLL Loss is: 1.3655815913005902\n",
      "Scaled KL Loss is: 0.034031227231025696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.399612818531616\n",
      "NLL Loss is: 1.257644697365792\n",
      "Scaled KL Loss is: 0.03896547853946686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2966101759052588\n",
      "NLL Loss is: 1.3877786581953746\n",
      "Scaled KL Loss is: 0.037587281316518784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4253659395118934\n",
      "NLL Loss is: 1.4514068132225697\n",
      "Scaled KL Loss is: 0.0375535786151886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4889603918377583\n",
      "NLL Loss is: 1.3764932732330089\n",
      "Scaled KL Loss is: 0.034145452082157135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410638725315166\n",
      "NLL Loss is: 1.3140465541457147\n",
      "Scaled KL Loss is: 0.038905296474695206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35295185062041\n",
      "NLL Loss is: 1.2541822401705034\n",
      "Scaled KL Loss is: 0.036461684852838516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.290643925023342\n",
      "NLL Loss is: 1.440841923969457\n",
      "Scaled KL Loss is: 0.038106437772512436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4789483617419694\n",
      "NLL Loss is: 1.3101531851677155\n",
      "Scaled KL Loss is: 0.03845656290650368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3486097480742192\n",
      "NLL Loss is: 1.670171260697415\n",
      "Scaled KL Loss is: 0.030903318896889687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7010745795943047\n",
      "NLL Loss is: 1.3345644578732845= 1.368; test loss = 1.405\n",
      "Scaled KL Loss is: 0.03861436992883682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3731788278021213\n",
      "NLL Loss is: 1.384603785706573\n",
      "Scaled KL Loss is: 0.03573549538850784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4203392810950808\n",
      "NLL Loss is: 1.3824353803341736\n",
      "Scaled KL Loss is: 0.03809032216668129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4205257025008549\n",
      "NLL Loss is: 1.4083733084985135\n",
      "Scaled KL Loss is: 0.03857896849513054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446952276993644\n",
      "NLL Loss is: 1.353842117916129\n",
      "Scaled KL Loss is: 0.034626029431819916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.388468147347949\n",
      "NLL Loss is: 1.3968387692061728\n",
      "Scaled KL Loss is: 0.03865035995841026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.435489129164583\n",
      "NLL Loss is: 1.399532085957591\n",
      "Scaled KL Loss is: 0.03430964797735214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4338417339349432\n",
      "NLL Loss is: 1.3439443739034735\n",
      "Scaled KL Loss is: 0.03386969491839409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3778140688218676\n",
      "NLL Loss is: 1.3975424113237935\n",
      "Scaled KL Loss is: 0.033835358917713165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4313777702415067\n",
      "NLL Loss is: 1.2816996158898488\n",
      "Scaled KL Loss is: 0.03948128968477249\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3211809055746213\n",
      "NLL Loss is: 1.2928136333136013\n",
      "Scaled KL Loss is: 0.032919470220804214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3257331035344055\n",
      "NLL Loss is: 1.407295385123947\n",
      "Scaled KL Loss is: 0.037357449531555176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444652834655502\n",
      "NLL Loss is: 1.277353985284036\n",
      "Scaled KL Loss is: 0.04102509841322899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318379083697265\n",
      "NLL Loss is: 1.4739868236864988\n",
      "Scaled KL Loss is: 0.03773009032011032\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5117169140066091\n",
      "NLL Loss is: 1.2861501867620957\n",
      "Scaled KL Loss is: 0.03643646091222763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3225866476743233\n",
      "NLL Loss is: 1.4430179333048485\n",
      "Scaled KL Loss is: 0.04192579165101051\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.484943724955859\n",
      "NLL Loss is: 1.3843263679501228\n",
      "Scaled KL Loss is: 0.03849213570356369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4228185036536865\n",
      "NLL Loss is: 1.3399922538477194\n",
      "Scaled KL Loss is: 0.03794272243976593\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3779349762874853\n",
      "NLL Loss is: 1.2652695954495177\n",
      "Scaled KL Loss is: 0.03848154470324516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3037511401527628\n",
      "NLL Loss is: 1.3545934289913715\n",
      "Scaled KL Loss is: 0.037192318588495255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3917857475798667\n",
      "NLL Loss is: 1.316857412964855\n",
      "Scaled KL Loss is: 0.03565334901213646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3525107619769914\n",
      "NLL Loss is: 1.3716509462735809\n",
      "Scaled KL Loss is: 0.03662940114736557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4082803474209464\n",
      "NLL Loss is: 1.2898287425110113\n",
      "Scaled KL Loss is: 0.037672001868486404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3275007443794977\n",
      "NLL Loss is: 1.570939537683655\n",
      "Scaled KL Loss is: 0.03921467438340187\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.610154212067057\n",
      "NLL Loss is: 1.1819506485900524\n",
      "Scaled KL Loss is: 0.037446584552526474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2193972331425789\n",
      "NLL Loss is: 1.3100754787852955\n",
      "Scaled KL Loss is: 0.04145234823226929\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515278270175648\n",
      "NLL Loss is: 1.3650038762610301\n",
      "Scaled KL Loss is: 0.04252689331769943\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4075307695787296\n",
      "NLL Loss is: 1.154479134102388\n",
      "Scaled KL Loss is: 0.04091716557741165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1953962996797995\n",
      "NLL Loss is: 1.3298695556579707\n",
      "Scaled KL Loss is: 0.038880202919244766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3687497585772155\n",
      "NLL Loss is: 1.1758622751499432\n",
      "Scaled KL Loss is: 0.03913275524973869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.214995030399682\n",
      "NLL Loss is: 1.1917408386589108\n",
      "Scaled KL Loss is: 0.03498384729027748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2267246859491883\n",
      "NLL Loss is: 1.3403931124127615\n",
      "Scaled KL Loss is: 0.03805418685078621\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3784472992635477\n",
      "NLL Loss is: 1.3512793694785503\n",
      "Scaled KL Loss is: 0.03535732999444008\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3866366994729904\n",
      "NLL Loss is: 1.2550540421278518\n",
      "Scaled KL Loss is: 0.03625959903001785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2913136411578696\n",
      "NLL Loss is: 1.430414894694352\n",
      "Scaled KL Loss is: 0.037649307399988174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4680642020943402\n",
      "NLL Loss is: 1.4522271148493795\n",
      "Scaled KL Loss is: 0.03732762858271599\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4895547434320955\n",
      "NLL Loss is: 1.2587475964100927\n",
      "Scaled KL Loss is: 0.04422428458929062\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3029718809993833\n",
      "NLL Loss is: 1.23428051006348\n",
      "Scaled KL Loss is: 0.04212991148233414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276410421545814\n",
      "NLL Loss is: 1.3532195757014427\n",
      "Scaled KL Loss is: 0.04066209867596626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393881674377409\n",
      "NLL Loss is: 1.4654253449157844\n",
      "Scaled KL Loss is: 0.04140467569231987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5068300206081042\n",
      "NLL Loss is: 1.193952296023779\n",
      "Scaled KL Loss is: 0.04179062321782112\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2357429192416\n",
      "NLL Loss is: 1.2101149637664994\n",
      "Scaled KL Loss is: 0.03773894160985947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2478539053763589\n",
      "NLL Loss is: 1.232923089509218\n",
      "Scaled KL Loss is: 0.04258488491177559\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2755079744209936\n",
      "NLL Loss is: 1.2519480638953415\n",
      "Scaled KL Loss is: 0.047674063593149185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2996221274884907\n",
      "NLL Loss is: 1.3073819058308933\n",
      "Scaled KL Loss is: 0.03904935345053673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34643125928143\n",
      "NLL Loss is: 1.2518232598995884\n",
      "Scaled KL Loss is: 0.042632877826690674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.294456137726279\n",
      "NLL Loss is: 1.2754370775827213\n",
      "Scaled KL Loss is: 0.043591130524873734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.319028208107595\n",
      "NLL Loss is: 1.1862176352425893\n",
      "Scaled KL Loss is: 0.04534495621919632\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2315625914617856\n",
      "NLL Loss is: 1.2741618335844627\n",
      "Scaled KL Loss is: 0.042900919914245605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3170627534987083\n",
      "NLL Loss is: 1.21134109232458\n",
      "Scaled KL Loss is: 0.04175717756152153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2530982698861015\n",
      "NLL Loss is: 1.2934564283307852\n",
      "Scaled KL Loss is: 0.04278852418065071\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336244952511436\n",
      "NLL Loss is: 1.3206417282588638\n",
      "Scaled KL Loss is: 0.0395570807158947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3601988089747585\n",
      "NLL Loss is: 1.2215893267282076\n",
      "Scaled KL Loss is: 0.04281150549650192\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2644008322247096\n",
      "NLL Loss is: 1.3367769384032118\n",
      "Scaled KL Loss is: 0.03963707014918327\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376414008552395\n",
      "NLL Loss is: 1.3985645917095735\n",
      "Scaled KL Loss is: 0.039475515484809875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4380401071943834\n",
      "NLL Loss is: 1.3952748303856948\n",
      "Scaled KL Loss is: 0.03844316676259041\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4337179971482852\n",
      "NLL Loss is: 1.401662416117237\n",
      "Scaled KL Loss is: 0.042691830545663834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444354246662901\n",
      "NLL Loss is: 1.2639162060217317\n",
      "Scaled KL Loss is: 0.040363676846027374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304279882867759\n",
      "NLL Loss is: 1.2511516753351646\n",
      "Scaled KL Loss is: 0.03879838064312935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289950055978294\n",
      "NLL Loss is: 1.1835034278640097\n",
      "Scaled KL Loss is: 0.04339827597141266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2269017038354224\n",
      "NLL Loss is: 1.2781027710434387\n",
      "Scaled KL Loss is: 0.04212505742907524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.320227828472514\n",
      "NLL Loss is: 1.2937693386122628\n",
      "Scaled KL Loss is: 0.04145058989524841\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3352199285075113\n",
      "NLL Loss is: 1.3872974231616495\n",
      "Scaled KL Loss is: 0.041017889976501465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.428315313138151\n",
      "NLL Loss is: 1.2918679554319124\n",
      "Scaled KL Loss is: 0.04207190126180649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3339398566937188\n",
      "NLL Loss is: 1.2952875002906992\n",
      "Scaled KL Loss is: 0.039452940225601196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3347404405163004\n",
      "NLL Loss is: 1.3927185966688105\n",
      "Scaled KL Loss is: 0.04100355878472328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4337221554535338\n",
      "NLL Loss is: 1.3942057797299998\n",
      "Scaled KL Loss is: 0.04256802424788475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4367738039778846\n",
      "NLL Loss is: 1.3385968460943003\n",
      "Scaled KL Loss is: 0.04115574434399605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3797525904382963\n",
      "NLL Loss is: 1.3017613802755807\n",
      "Scaled KL Loss is: 0.04494747892022133\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346708859195802\n",
      "NLL Loss is: 1.2798966905813116\n",
      "Scaled KL Loss is: 0.0412813164293766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3211780070106882\n",
      "NLL Loss is: 1.4446348598832066\n",
      "Scaled KL Loss is: 0.04238147661089897\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4870163364941056\n",
      "NLL Loss is: 1.3372595583186566\n",
      "Scaled KL Loss is: 0.0396561436355114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376915701954168\n",
      "NLL Loss is: 1.3113851245044554\n",
      "Scaled KL Loss is: 0.04530530422925949\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356690428733715\n",
      "NLL Loss is: 1.3383613607097076\n",
      "Scaled KL Loss is: 0.0432712584733963\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3816326191831039\n",
      "NLL Loss is: 1.4233722299129932\n",
      "Scaled KL Loss is: 0.04175980016589165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4651320300788848\n",
      "NLL Loss is: 1.278034469166927\n",
      "Scaled KL Loss is: 0.038971055299043655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3170055244659706\n",
      "NLL Loss is: 1.402621755478907\n",
      "Scaled KL Loss is: 0.04018842428922653\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4428101797681336\n",
      "NLL Loss is: 1.3899658213728867\n",
      "Scaled KL Loss is: 0.041078224778175354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.431044046151062\n",
      "NLL Loss is: 1.3396265791813817\n",
      "Scaled KL Loss is: 0.04205998405814171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3816865632395234\n",
      "NLL Loss is: 1.2586971713597237\n",
      "Scaled KL Loss is: 0.04019470140337944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2988918727631031\n",
      "NLL Loss is: 1.3481129670697036\n",
      "Scaled KL Loss is: 0.04077843949198723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3888914065616909\n",
      "NLL Loss is: 1.219171439972244\n",
      "Scaled KL Loss is: 0.04374632239341736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2629177623656613\n",
      "NLL Loss is: 1.3542967356153326\n",
      "Scaled KL Loss is: 0.038407936692237854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3927046723075704\n",
      "NLL Loss is: 1.2121519902055709\n",
      "Scaled KL Loss is: 0.04404567927122116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.256197669476792\n",
      "NLL Loss is: 1.3429332590125227\n",
      "Scaled KL Loss is: 0.04270773008465767\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3856409890971804\n",
      "NLL Loss is: 1.4317944932589917\n",
      "Scaled KL Loss is: 0.040509097278118134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4723035905371098\n",
      "NLL Loss is: 1.3508318906076822\n",
      "Scaled KL Loss is: 0.03862989693880081\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.389461787546483\n",
      "NLL Loss is: 1.2901581806175892\n",
      "Scaled KL Loss is: 0.043624017387628555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3337821980052178\n",
      "NLL Loss is: 1.2424390031073071\n",
      "Scaled KL Loss is: 0.04022936150431633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2826683646116235\n",
      "NLL Loss is: 1.4382423154149484\n",
      "Scaled KL Loss is: 0.041399598121643066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4796419135365915\n",
      "NLL Loss is: 1.2772451663606745\n",
      "Scaled KL Loss is: 0.04240790754556656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.319653073906241\n",
      "NLL Loss is: 1.6720372282531817\n",
      "Scaled KL Loss is: 0.03390558436512947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7059428126183112\n",
      "NLL Loss is: 1.3278008056472663= 1.360; test loss = 1.389\n",
      "Scaled KL Loss is: 0.0434277206659317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371228526313198\n",
      "NLL Loss is: 1.3503239232169812\n",
      "Scaled KL Loss is: 0.04072317108511925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3910470943021005\n",
      "NLL Loss is: 1.3695160034071394\n",
      "Scaled KL Loss is: 0.042805757373571396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4123217607807108\n",
      "NLL Loss is: 1.3761147583285949\n",
      "Scaled KL Loss is: 0.04479461908340454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4209093774119994\n",
      "NLL Loss is: 1.3465325625760223\n",
      "Scaled KL Loss is: 0.039066437631845474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3855990002078677\n",
      "NLL Loss is: 1.3626953426198614\n",
      "Scaled KL Loss is: 0.044118478894233704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.406813821514095\n",
      "NLL Loss is: 1.398407110324286\n",
      "Scaled KL Loss is: 0.03914254158735275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4375496519116389\n",
      "NLL Loss is: 1.337880909337906\n",
      "Scaled KL Loss is: 0.040238674730062485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3781195840679685\n",
      "NLL Loss is: 1.3912483736590295\n",
      "Scaled KL Loss is: 0.03921281173825264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4304611853972822\n",
      "NLL Loss is: 1.2599217705838461\n",
      "Scaled KL Loss is: 0.04535757005214691\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.305279340635993\n",
      "NLL Loss is: 1.2846086021751513\n",
      "Scaled KL Loss is: 0.03939327225089073\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.324001874426042\n",
      "NLL Loss is: 1.407562034261722\n",
      "Scaled KL Loss is: 0.04210673272609711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4496687669878192\n",
      "NLL Loss is: 1.246220029219147\n",
      "Scaled KL Loss is: 0.04535682871937752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2915768579385245\n",
      "NLL Loss is: 1.4460438896047811\n",
      "Scaled KL Loss is: 0.043105822056531906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.489149711661313\n",
      "NLL Loss is: 1.2573239667185632\n",
      "Scaled KL Loss is: 0.04181564599275589\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.299139612711319\n",
      "NLL Loss is: 1.4314813734209317\n",
      "Scaled KL Loss is: 0.04543079808354378\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4769121715044755\n",
      "NLL Loss is: 1.36330017672865\n",
      "Scaled KL Loss is: 0.04214923456311226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4054494112917622\n",
      "NLL Loss is: 1.3188404782762575\n",
      "Scaled KL Loss is: 0.042750902473926544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361591380750184\n",
      "NLL Loss is: 1.2404382923440493\n",
      "Scaled KL Loss is: 0.04255241900682449\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2829907113508738\n",
      "NLL Loss is: 1.344596838317212\n",
      "Scaled KL Loss is: 0.040936291217803955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.385533129535016\n",
      "NLL Loss is: 1.2786029475425977\n",
      "Scaled KL Loss is: 0.041335947811603546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3199388953542013\n",
      "NLL Loss is: 1.35511302332299\n",
      "Scaled KL Loss is: 0.04063116014003754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3957441834630275\n",
      "NLL Loss is: 1.2636544952273843\n",
      "Scaled KL Loss is: 0.041627004742622375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3052814999700066\n",
      "NLL Loss is: 1.5771631120269505\n",
      "Scaled KL Loss is: 0.044942378997802734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6221054910247532\n",
      "NLL Loss is: 1.1567724876774366\n",
      "Scaled KL Loss is: 0.04252273589372635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.199295223571163\n",
      "NLL Loss is: 1.29521174613831\n",
      "Scaled KL Loss is: 0.04631902649998665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3415307726382966\n",
      "NLL Loss is: 1.346356073033368\n",
      "Scaled KL Loss is: 0.04752945154905319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393885524582421\n",
      "NLL Loss is: 1.1357161069913664\n",
      "Scaled KL Loss is: 0.045255936682224274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1809720436735907\n",
      "NLL Loss is: 1.2978168264004295\n",
      "Scaled KL Loss is: 0.0441768504679203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3419936768683498\n",
      "NLL Loss is: 1.1314574343464323\n",
      "Scaled KL Loss is: 0.04469243064522743\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1761498649916597\n",
      "NLL Loss is: 1.1768669004860839\n",
      "Scaled KL Loss is: 0.0407157838344574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2175826843205413\n",
      "NLL Loss is: 1.337040649095369\n",
      "Scaled KL Loss is: 0.044179171323776245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3812198204191453\n",
      "NLL Loss is: 1.343972119178172\n",
      "Scaled KL Loss is: 0.04211891442537308\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.386091033603545\n",
      "NLL Loss is: 1.2398254929296162\n",
      "Scaled KL Loss is: 0.042577531188726425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2824030241183426\n",
      "NLL Loss is: 1.422814477016059\n",
      "Scaled KL Loss is: 0.043378908187150955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4661933852032099\n",
      "NLL Loss is: 1.4409919750899605\n",
      "Scaled KL Loss is: 0.04317864030599594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4841706153959564\n",
      "NLL Loss is: 1.249331510071032\n",
      "Scaled KL Loss is: 0.04975689947605133\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2990884095470834\n",
      "NLL Loss is: 1.2163131780671441\n",
      "Scaled KL Loss is: 0.04648834466934204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2628015227364862\n",
      "NLL Loss is: 1.3359388701398789\n",
      "Scaled KL Loss is: 0.04492943361401558\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3808683037538945\n",
      "NLL Loss is: 1.4545433298851091\n",
      "Scaled KL Loss is: 0.04555680602788925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5001001359129984\n",
      "NLL Loss is: 1.1890328432052966\n",
      "Scaled KL Loss is: 0.04587011784315109\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2349029610484477\n",
      "NLL Loss is: 1.19655874073321\n",
      "Scaled KL Loss is: 0.04123266786336899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2377914085965789\n",
      "NLL Loss is: 1.2217368681474923\n",
      "Scaled KL Loss is: 0.04594043269753456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2676773008450268\n",
      "NLL Loss is: 1.2330213198725537\n",
      "Scaled KL Loss is: 0.05183415114879608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2848554710213498\n",
      "NLL Loss is: 1.3014430104210384\n",
      "Scaled KL Loss is: 0.04291735589504242\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3443603663160808\n",
      "NLL Loss is: 1.2369916440783046\n",
      "Scaled KL Loss is: 0.046586036682128906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2835776807604335\n",
      "NLL Loss is: 1.258408262697829\n",
      "Scaled KL Loss is: 0.04782814905047417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3062364117483032\n",
      "NLL Loss is: 1.1731583706054873\n",
      "Scaled KL Loss is: 0.049253858625888824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2224122292313762\n",
      "NLL Loss is: 1.2635074888402071\n",
      "Scaled KL Loss is: 0.047422196716070175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3109296855562773\n",
      "NLL Loss is: 1.1959003425015553\n",
      "Scaled KL Loss is: 0.0463048592209816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.242205201722537\n",
      "NLL Loss is: 1.278685429439973\n",
      "Scaled KL Loss is: 0.04723372682929039\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3259191562692634\n",
      "NLL Loss is: 1.311541950521256\n",
      "Scaled KL Loss is: 0.0442231111228466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3557650616441026\n",
      "NLL Loss is: 1.2128987880172253\n",
      "Scaled KL Loss is: 0.047839000821113586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2607377888383389\n",
      "NLL Loss is: 1.3261738154089102\n",
      "Scaled KL Loss is: 0.04367685690522194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3698506723141322\n",
      "NLL Loss is: 1.3967294688388636\n",
      "Scaled KL Loss is: 0.04355737566947937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440286844508343\n",
      "NLL Loss is: 1.3877196247999675\n",
      "Scaled KL Loss is: 0.04256235435605049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.430281979156018\n",
      "NLL Loss is: 1.3909990788954545\n",
      "Scaled KL Loss is: 0.04705367609858513\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4380527549940396\n",
      "NLL Loss is: 1.248792079963074\n",
      "Scaled KL Loss is: 0.04503295198082924\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2938250319439033\n",
      "NLL Loss is: 1.2386957588257064\n",
      "Scaled KL Loss is: 0.04255179315805435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2812475519837607\n",
      "NLL Loss is: 1.1709238149640828\n",
      "Scaled KL Loss is: 0.04817572608590126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.219099541049984\n",
      "NLL Loss is: 1.265474441219392\n",
      "Scaled KL Loss is: 0.045977067202329636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3114515084217215\n",
      "NLL Loss is: 1.289552535765968\n",
      "Scaled KL Loss is: 0.045594554394483566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3351470901604516\n",
      "NLL Loss is: 1.3796146459380467\n",
      "Scaled KL Loss is: 0.044966816902160645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4245814628402074\n",
      "NLL Loss is: 1.2819402292867914\n",
      "Scaled KL Loss is: 0.04523429274559021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3271745220323816\n",
      "NLL Loss is: 1.2800255965703133\n",
      "Scaled KL Loss is: 0.042912524193525314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3229381207638387\n",
      "NLL Loss is: 1.385027651102859\n",
      "Scaled KL Loss is: 0.044203389436006546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4292310405388655\n",
      "NLL Loss is: 1.389161673700789\n",
      "Scaled KL Loss is: 0.04559442028403282\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4347560939848218\n",
      "NLL Loss is: 1.3290490708728027\n",
      "Scaled KL Loss is: 0.04466864466667175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3737177155394744\n",
      "NLL Loss is: 1.2938227364962882\n",
      "Scaled KL Loss is: 0.048259835690259933\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3420825721865481\n",
      "NLL Loss is: 1.2755864177504501\n",
      "Scaled KL Loss is: 0.044412363320589066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3199987810710392\n",
      "NLL Loss is: 1.4423587359335874\n",
      "Scaled KL Loss is: 0.04538033902645111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4877390749600385\n",
      "NLL Loss is: 1.3284887909698484\n",
      "Scaled KL Loss is: 0.04241035506129265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370899146031141\n",
      "NLL Loss is: 1.3036190917115742\n",
      "Scaled KL Loss is: 0.04838831350207329\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3520074052136475\n",
      "NLL Loss is: 1.3304039812966255\n",
      "Scaled KL Loss is: 0.045961298048496246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3763652793451218\n",
      "NLL Loss is: 1.4151101305067622\n",
      "Scaled KL Loss is: 0.04436922073364258\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4594793512404047\n",
      "NLL Loss is: 1.2721040921267497\n",
      "Scaled KL Loss is: 0.041543640196323395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.313647732323073\n",
      "NLL Loss is: 1.3970541480550918\n",
      "Scaled KL Loss is: 0.04310807213187218\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.440162220186964\n",
      "NLL Loss is: 1.3913664019377683\n",
      "Scaled KL Loss is: 0.0434725321829319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4348389341207002\n",
      "NLL Loss is: 1.3314586941071027\n",
      "Scaled KL Loss is: 0.045218195766210556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3766768898733133\n",
      "NLL Loss is: 1.253174564596997\n",
      "Scaled KL Loss is: 0.04313249886035919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2963070634573561\n",
      "NLL Loss is: 1.3428556188826917\n",
      "Scaled KL Loss is: 0.04341987892985344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.386275497812545\n",
      "NLL Loss is: 1.2137648746782674\n",
      "Scaled KL Loss is: 0.0466291569173336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260394031595601\n",
      "NLL Loss is: 1.3463078058366849\n",
      "Scaled KL Loss is: 0.041060734540224075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.387368540376909\n",
      "NLL Loss is: 1.2085143645201342\n",
      "Scaled KL Loss is: 0.046904753893613815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255419118413748\n",
      "NLL Loss is: 1.3381948465448026\n",
      "Scaled KL Loss is: 0.04566534236073494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3838601889055375\n",
      "NLL Loss is: 1.424621795110371\n",
      "Scaled KL Loss is: 0.04273303970694542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4673548348173164\n",
      "NLL Loss is: 1.3449322570305124\n",
      "Scaled KL Loss is: 0.04128491133451462\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.386217168365027\n",
      "NLL Loss is: 1.2855613977349571\n",
      "Scaled KL Loss is: 0.046503882855176926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.332065280590134\n",
      "NLL Loss is: 1.235528149200419\n",
      "Scaled KL Loss is: 0.04281076416373253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2783389133641516\n",
      "NLL Loss is: 1.4315082613404035\n",
      "Scaled KL Loss is: 0.04374941810965538\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.475257679450059\n",
      "NLL Loss is: 1.2736158890438285\n",
      "Scaled KL Loss is: 0.04492352902889252\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318539418072721\n",
      "NLL Loss is: 1.667205452528896\n",
      "Scaled KL Loss is: 0.03599152714014053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7031969796690365\n",
      "NLL Loss is: 1.3249744089814781= 1.351; test loss = 1.386\n",
      "Scaled KL Loss is: 0.04627405107021332\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3712484600516914\n",
      "NLL Loss is: 1.338392052068794\n",
      "Scaled KL Loss is: 0.04343181103467941\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3818238631034734\n",
      "NLL Loss is: 1.3610166483225523\n",
      "Scaled KL Loss is: 0.04532213881611824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4063387871386706\n",
      "NLL Loss is: 1.375906160454063\n",
      "Scaled KL Loss is: 0.0475255511701107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4234317116241737\n",
      "NLL Loss is: 1.3390045862919988\n",
      "Scaled KL Loss is: 0.04117627069354057\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3801808569855394\n",
      "NLL Loss is: 1.364502046236002\n",
      "Scaled KL Loss is: 0.046374134719371796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4108761809553738\n",
      "NLL Loss is: 1.3907321059215882\n",
      "Scaled KL Loss is: 0.04113265872001648\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4318647646416047\n",
      "NLL Loss is: 1.3273706754359682\n",
      "Scaled KL Loss is: 0.0423625111579895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3697331865939577\n",
      "NLL Loss is: 1.385732821875037\n",
      "Scaled KL Loss is: 0.04126253351569176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4269953553907289\n",
      "NLL Loss is: 1.2525286823046122\n",
      "Scaled KL Loss is: 0.04758366569876671\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300112348003379\n",
      "NLL Loss is: 1.2730582909342312\n",
      "Scaled KL Loss is: 0.04169454425573349\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3147528351899647\n",
      "NLL Loss is: 1.4033822757874947\n",
      "Scaled KL Loss is: 0.04409459978342056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4474768755709153\n",
      "NLL Loss is: 1.2389684365508769\n",
      "Scaled KL Loss is: 0.047440364956855774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2864088015077326\n",
      "NLL Loss is: 1.4399017856430976\n",
      "Scaled KL Loss is: 0.045330729335546494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.485232514978644\n",
      "NLL Loss is: 1.2462780324752283\n",
      "Scaled KL Loss is: 0.04415113851428032\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2904291709895086\n",
      "NLL Loss is: 1.424889924244603\n",
      "Scaled KL Loss is: 0.04730524867773056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4721951729223335\n",
      "NLL Loss is: 1.3559651933528953\n",
      "Scaled KL Loss is: 0.043959617614746094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3999248109676414\n",
      "NLL Loss is: 1.3100678863206203\n",
      "Scaled KL Loss is: 0.04484143108129501\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3549093174019153\n",
      "NLL Loss is: 1.2333233428590922\n",
      "Scaled KL Loss is: 0.04452630504965782\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27784964790875\n",
      "NLL Loss is: 1.3393350324159072\n",
      "Scaled KL Loss is: 0.04269157722592354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3820266096418308\n",
      "NLL Loss is: 1.2707187854916806\n",
      "Scaled KL Loss is: 0.0436490923166275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.314367877808308\n",
      "NLL Loss is: 1.3482503873763334\n",
      "Scaled KL Loss is: 0.04243551567196846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3906859030483019\n",
      "NLL Loss is: 1.2558764969433553\n",
      "Scaled KL Loss is: 0.0433204248547554\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2991969217981107\n",
      "NLL Loss is: 1.5744872799852514\n",
      "Scaled KL Loss is: 0.046944569796323776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6214318497815752\n",
      "NLL Loss is: 1.148512953106948\n",
      "Scaled KL Loss is: 0.0443156473338604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1928286004408084\n",
      "NLL Loss is: 1.2901867807709297\n",
      "Scaled KL Loss is: 0.048021674156188965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3382084549271187\n",
      "NLL Loss is: 1.3393264216185523\n",
      "Scaled KL Loss is: 0.04940421134233475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.388730632960887\n",
      "NLL Loss is: 1.12948787196749\n",
      "Scaled KL Loss is: 0.04686147719621658\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1763493491637065\n",
      "NLL Loss is: 1.289287457536424\n",
      "Scaled KL Loss is: 0.04591572657227516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.335203184108699\n",
      "NLL Loss is: 1.1226611365105992\n",
      "Scaled KL Loss is: 0.04646953567862511\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1691306721892243\n",
      "NLL Loss is: 1.173804492895272\n",
      "Scaled KL Loss is: 0.04241575300693512\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2162202459022071\n",
      "NLL Loss is: 1.3348292669403572\n",
      "Scaled KL Loss is: 0.04582248628139496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3806517532217522\n",
      "NLL Loss is: 1.3439795408326136\n",
      "Scaled KL Loss is: 0.043836645781993866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3878161866146075\n",
      "NLL Loss is: 1.2392751298301432\n",
      "Scaled KL Loss is: 0.04419650509953499\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2834716349296782\n",
      "NLL Loss is: 1.4209345034692364\n",
      "Scaled KL Loss is: 0.044873397797346115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4658079012665826\n",
      "NLL Loss is: 1.436881026365626\n",
      "Scaled KL Loss is: 0.044754378497600555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4816354048632265\n",
      "NLL Loss is: 1.246522029197416\n",
      "Scaled KL Loss is: 0.05129610374569893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2978181329431149\n",
      "NLL Loss is: 1.2118782851892633\n",
      "Scaled KL Loss is: 0.04789027199149132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2597685571807546\n",
      "NLL Loss is: 1.3313950523971538\n",
      "Scaled KL Loss is: 0.046260442584753036\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3776554949819069\n",
      "NLL Loss is: 1.4500820094985045\n",
      "Scaled KL Loss is: 0.04700217768549919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4970841871840037\n",
      "NLL Loss is: 1.18600963340367\n",
      "Scaled KL Loss is: 0.047352127730846405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2333617611345165\n",
      "NLL Loss is: 1.1909511897179115\n",
      "Scaled KL Loss is: 0.04252408817410469\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2334752778920162\n",
      "NLL Loss is: 1.2196452166063967\n",
      "Scaled KL Loss is: 0.04720447584986687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2668496924562636\n",
      "NLL Loss is: 1.231719074232582\n",
      "Scaled KL Loss is: 0.05322626978158951\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2849453440141716\n",
      "NLL Loss is: 1.2994328668221842\n",
      "Scaled KL Loss is: 0.044232577085494995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3436654439076792\n",
      "NLL Loss is: 1.228437390031028\n",
      "Scaled KL Loss is: 0.04787184298038483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2763092330114127\n",
      "NLL Loss is: 1.2540658516699197\n",
      "Scaled KL Loss is: 0.04913629591464996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3032021475845696\n",
      "NLL Loss is: 1.1682175249150852\n",
      "Scaled KL Loss is: 0.05035779997706413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2185753248921494\n",
      "NLL Loss is: 1.2602710146282374\n",
      "Scaled KL Loss is: 0.04863256961107254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.30890358423931\n",
      "NLL Loss is: 1.189385996389834\n",
      "Scaled KL Loss is: 0.04754340648651123\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2369294028763453\n",
      "NLL Loss is: 1.2739363792286245\n",
      "Scaled KL Loss is: 0.048349812626838684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3222861918554631\n",
      "NLL Loss is: 1.3092124527637787\n",
      "Scaled KL Loss is: 0.04538685828447342\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3545993110482522\n",
      "NLL Loss is: 1.2090550483281062\n",
      "Scaled KL Loss is: 0.048919133841991425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2579741821700976\n",
      "NLL Loss is: 1.3219058644398416\n",
      "Scaled KL Loss is: 0.044730883091688156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3666367475315297\n",
      "NLL Loss is: 1.3904797333281926\n",
      "Scaled KL Loss is: 0.0445924811065197\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4350722144347123\n",
      "NLL Loss is: 1.3834743085747536\n",
      "Scaled KL Loss is: 0.04356265813112259\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4270369667058762\n",
      "NLL Loss is: 1.3872583051836562\n",
      "Scaled KL Loss is: 0.04811503365635872\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.435373338840015\n",
      "NLL Loss is: 1.2456593940031748\n",
      "Scaled KL Loss is: 0.0461149588227272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.291774352825902\n",
      "NLL Loss is: 1.2332676566940282\n",
      "Scaled KL Loss is: 0.04354960471391678\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276817261407945\n",
      "NLL Loss is: 1.1667327233589893\n",
      "Scaled KL Loss is: 0.04934338852763176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.216076111886621\n",
      "NLL Loss is: 1.2622034612807818\n",
      "Scaled KL Loss is: 0.04705258831381798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3092560495945997\n",
      "NLL Loss is: 1.2872729771114972\n",
      "Scaled KL Loss is: 0.046626005321741104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3338989824332383\n",
      "NLL Loss is: 1.374897926001848\n",
      "Scaled KL Loss is: 0.04602259397506714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420920519976915\n",
      "NLL Loss is: 1.278732893637117\n",
      "Scaled KL Loss is: 0.046233005821704865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3249658994588218\n",
      "NLL Loss is: 1.2741232617124951\n",
      "Scaled KL Loss is: 0.043922245502471924\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318045507214967\n",
      "NLL Loss is: 1.3805359319889212\n",
      "Scaled KL Loss is: 0.04518530145287514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4257212334417964\n",
      "NLL Loss is: 1.3863938013568224\n",
      "Scaled KL Loss is: 0.04660238325595856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432996184612781\n",
      "NLL Loss is: 1.3252097283341089\n",
      "Scaled KL Loss is: 0.04577230289578438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3709820312298933\n",
      "NLL Loss is: 1.2892268602969583\n",
      "Scaled KL Loss is: 0.04934093356132507\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3385677938582834\n",
      "NLL Loss is: 1.2730550965411027\n",
      "Scaled KL Loss is: 0.04543081298470497\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3184859095258077\n",
      "NLL Loss is: 1.4408037012537918\n",
      "Scaled KL Loss is: 0.04638871178030968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4871924130341014\n",
      "NLL Loss is: 1.3241391275670904\n",
      "Scaled KL Loss is: 0.04334518313407898\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3674843107011694\n",
      "NLL Loss is: 1.2993457481210844\n",
      "Scaled KL Loss is: 0.049465179443359375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3488109275644438\n",
      "NLL Loss is: 1.326903643510247\n",
      "Scaled KL Loss is: 0.046914443373680115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3738180868839271\n",
      "NLL Loss is: 1.4100714974508615\n",
      "Scaled KL Loss is: 0.04530821740627289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4553797148571344\n",
      "NLL Loss is: 1.2687245794604625\n",
      "Scaled KL Loss is: 0.042449235916137695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3111738153766002\n",
      "NLL Loss is: 1.3936130905766846\n",
      "Scaled KL Loss is: 0.04410633072257042\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.437719421299255\n",
      "NLL Loss is: 1.3928847064622483\n",
      "Scaled KL Loss is: 0.044352926313877106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4372376327761254\n",
      "NLL Loss is: 1.329054154941998\n",
      "Scaled KL Loss is: 0.04628453031182289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375338685253821\n",
      "NLL Loss is: 1.2503548336852754\n",
      "Scaled KL Loss is: 0.04414631798863411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2945011516739096\n",
      "NLL Loss is: 1.3392756589860033\n",
      "Scaled KL Loss is: 0.044356074184179306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3836317331701826\n",
      "NLL Loss is: 1.2103698565604448\n",
      "Scaled KL Loss is: 0.047652337700128555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2580221942605734\n",
      "NLL Loss is: 1.3432220615438433\n",
      "Scaled KL Loss is: 0.04196460172533989\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3851866632691832\n",
      "NLL Loss is: 1.2054178481753468\n",
      "Scaled KL Loss is: 0.047896455973386765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2533143041487336\n",
      "NLL Loss is: 1.3341401874708887\n",
      "Scaled KL Loss is: 0.046690501272678375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.380830688743567\n",
      "NLL Loss is: 1.420588775091695\n",
      "Scaled KL Loss is: 0.04352903738617897\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.464117812477874\n",
      "NLL Loss is: 1.3417150659054835\n",
      "Scaled KL Loss is: 0.04222011938691139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.383935185292395\n",
      "NLL Loss is: 1.281099227923017\n",
      "Scaled KL Loss is: 0.04749610275030136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3285953306733183\n",
      "NLL Loss is: 1.2320372903187746\n",
      "Scaled KL Loss is: 0.043734531849622726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2757718221683974\n",
      "NLL Loss is: 1.4288006149615717\n",
      "Scaled KL Loss is: 0.04460825026035309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4734088652219248\n",
      "NLL Loss is: 1.2704179854315343\n",
      "Scaled KL Loss is: 0.04582514613866806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3162431315702023\n",
      "NLL Loss is: 1.664982896767324\n",
      "Scaled KL Loss is: 0.03672187402844429\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7017047707957682\n",
      "NLL Loss is: 1.3239917997039945= 1.348; test loss = 1.384\n",
      "Scaled KL Loss is: 0.04725610092282295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3712479006268175\n",
      "NLL Loss is: 1.3329140817374432\n",
      "Scaled KL Loss is: 0.04438808187842369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3773021636158669\n",
      "NLL Loss is: 1.3562650195998858\n",
      "Scaled KL Loss is: 0.04620491340756416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40246993300745\n",
      "NLL Loss is: 1.374890595170043\n",
      "Scaled KL Loss is: 0.04851050674915314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423401101919196\n",
      "NLL Loss is: 1.3358778996146359\n",
      "Scaled KL Loss is: 0.041968416422605515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3778463160372414\n",
      "NLL Loss is: 1.3629872212283607\n",
      "Scaled KL Loss is: 0.047261323779821396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410248545008182\n",
      "NLL Loss is: 1.3878272408698225\n",
      "Scaled KL Loss is: 0.041938699781894684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4297659406517171\n",
      "NLL Loss is: 1.3237942808089105\n",
      "Scaled KL Loss is: 0.0432019978761673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3669962786850778\n",
      "NLL Loss is: 1.383480304156177\n",
      "Scaled KL Loss is: 0.04209141805768013\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425571722213857\n",
      "NLL Loss is: 1.2490729994798713\n",
      "Scaled KL Loss is: 0.048482853919267654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297555853399139\n",
      "NLL Loss is: 1.268582514143286\n",
      "Scaled KL Loss is: 0.042589832097291946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.311172346240578\n",
      "NLL Loss is: 1.4020208172591333\n",
      "Scaled KL Loss is: 0.044863056391477585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4468838736506109\n",
      "NLL Loss is: 1.234907722087716\n",
      "Scaled KL Loss is: 0.04830440506339073\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2832121271511068\n",
      "NLL Loss is: 1.4363450111185976\n",
      "Scaled KL Loss is: 0.046174004673957825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4825190157925554\n",
      "NLL Loss is: 1.2415347996964843\n",
      "Scaled KL Loss is: 0.04505326598882675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.286588065685311\n",
      "NLL Loss is: 1.421696473521845\n",
      "Scaled KL Loss is: 0.04811232537031174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4698087988921567\n",
      "NLL Loss is: 1.3507637323597652\n",
      "Scaled KL Loss is: 0.04471307620406151\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3954768085638267\n",
      "NLL Loss is: 1.3059121981399584\n",
      "Scaled KL Loss is: 0.045658815652132034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515710137920904\n",
      "NLL Loss is: 1.2303079883566392\n",
      "Scaled KL Loss is: 0.045336391776800156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2756443801334394\n",
      "NLL Loss is: 1.3366177827374441\n",
      "Scaled KL Loss is: 0.04337398335337639\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3799917660908205\n",
      "NLL Loss is: 1.2666502038277043\n",
      "Scaled KL Loss is: 0.044461458921432495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3111116627491368\n",
      "NLL Loss is: 1.3444037232204809\n",
      "Scaled KL Loss is: 0.04316914454102516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.387572867761506\n",
      "NLL Loss is: 1.252104703376138\n",
      "Scaled KL Loss is: 0.043963588774204254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2960682921503424\n",
      "NLL Loss is: 1.5704486293113897\n",
      "Scaled KL Loss is: 0.047644469887018204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.618093099198408\n",
      "NLL Loss is: 1.1443228868916533\n",
      "Scaled KL Loss is: 0.04497138038277626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1892942672744296\n",
      "NLL Loss is: 1.2849701738506645\n",
      "Scaled KL Loss is: 0.04863535612821579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336055299788803\n",
      "NLL Loss is: 1.3363385257343805\n",
      "Scaled KL Loss is: 0.05009900778532028\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3864375335197008\n",
      "NLL Loss is: 1.1263093717420465\n",
      "Scaled KL Loss is: 0.04750901460647583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1738183863485223\n",
      "NLL Loss is: 1.2853054917441726\n",
      "Scaled KL Loss is: 0.04648935794830322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3317948496924759\n",
      "NLL Loss is: 1.1184611982176473\n",
      "Scaled KL Loss is: 0.047065019607543945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1655262178251913\n",
      "NLL Loss is: 1.1708428658388685\n",
      "Scaled KL Loss is: 0.04292255640029907\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2137654222391676\n",
      "NLL Loss is: 1.331449284329276\n",
      "Scaled KL Loss is: 0.046327270567417145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3777765548966932\n",
      "NLL Loss is: 1.3431007274144915\n",
      "Scaled KL Loss is: 0.04431438446044922\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3874151118749407\n",
      "NLL Loss is: 1.2387849180928465\n",
      "Scaled KL Loss is: 0.04466291144490242\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.283447829537749\n",
      "NLL Loss is: 1.4200745302680793\n",
      "Scaled KL Loss is: 0.04531276598572731\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4653872962538066\n",
      "NLL Loss is: 1.4338403571610656\n",
      "Scaled KL Loss is: 0.045157354325056076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4789977114861217\n",
      "NLL Loss is: 1.2441156315946786\n",
      "Scaled KL Loss is: 0.051719821989536285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.295835453584215\n",
      "NLL Loss is: 1.2101724810372234\n",
      "Scaled KL Loss is: 0.04832671582698822\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2584991968642116\n",
      "NLL Loss is: 1.327830289484215\n",
      "Scaled KL Loss is: 0.04667738452553749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3745076740097526\n",
      "NLL Loss is: 1.4478467656308118\n",
      "Scaled KL Loss is: 0.04740205779671669\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4952488234275285\n",
      "NLL Loss is: 1.183584231508191\n",
      "Scaled KL Loss is: 0.047798171639442444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2313824031476335\n",
      "NLL Loss is: 1.1876383784795896\n",
      "Scaled KL Loss is: 0.04292421415448189\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2305625926340715\n",
      "NLL Loss is: 1.2177912715272337\n",
      "Scaled KL Loss is: 0.04766812175512314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2654593932823568\n",
      "NLL Loss is: 1.2286796111180818\n",
      "Scaled KL Loss is: 0.05369991064071655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2823795217587983\n",
      "NLL Loss is: 1.2975373794368121\n",
      "Scaled KL Loss is: 0.04466767981648445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3422050592532966\n",
      "NLL Loss is: 1.2252384254827613\n",
      "Scaled KL Loss is: 0.04837436601519585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2736127914979571\n",
      "NLL Loss is: 1.251781669062254\n",
      "Scaled KL Loss is: 0.04963105544447899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.301412724506733\n",
      "NLL Loss is: 1.1651411302382237\n",
      "Scaled KL Loss is: 0.050902195274829865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2160433255130536\n",
      "NLL Loss is: 1.2580227164231867\n",
      "Scaled KL Loss is: 0.04914040118455887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3071631176077456\n",
      "NLL Loss is: 1.1858283883559388\n",
      "Scaled KL Loss is: 0.04808948561549187\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2339178739714307\n",
      "NLL Loss is: 1.271184738390454\n",
      "Scaled KL Loss is: 0.04886629804968834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3200510364401423\n",
      "NLL Loss is: 1.3066421757960862\n",
      "Scaled KL Loss is: 0.04591696336865425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3525591391647405\n",
      "NLL Loss is: 1.2074512452264528\n",
      "Scaled KL Loss is: 0.049447160214185715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2568984054406385\n",
      "NLL Loss is: 1.3189788258296704\n",
      "Scaled KL Loss is: 0.04525631666183472\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3642351424915051\n",
      "NLL Loss is: 1.388630367270157\n",
      "Scaled KL Loss is: 0.04508190229535103\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.433712269565508\n",
      "NLL Loss is: 1.3806219073321955\n",
      "Scaled KL Loss is: 0.044062208384275436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.424684115716471\n",
      "NLL Loss is: 1.3851413892648707\n",
      "Scaled KL Loss is: 0.04862793907523155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4337693283401023\n",
      "NLL Loss is: 1.2436592407803537\n",
      "Scaled KL Loss is: 0.04665776714682579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2903170079271795\n",
      "NLL Loss is: 1.2298802746810251\n",
      "Scaled KL Loss is: 0.044049572199583054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2739298468806082\n",
      "NLL Loss is: 1.16401870317319\n",
      "Scaled KL Loss is: 0.04991227388381958\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2139309770570095\n",
      "NLL Loss is: 1.259576991208987\n",
      "Scaled KL Loss is: 0.04758315533399582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3071601465429827\n",
      "NLL Loss is: 1.2848724462712129\n",
      "Scaled KL Loss is: 0.04715162515640259\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3320240714276155\n",
      "NLL Loss is: 1.3721415276180446\n",
      "Scaled KL Loss is: 0.046550095081329346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418691622699374\n",
      "NLL Loss is: 1.2769333663325677\n",
      "Scaled KL Loss is: 0.04674428328871727\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.323677649621285\n",
      "NLL Loss is: 1.2702681439323442\n",
      "Scaled KL Loss is: 0.044425200670957565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146933446033018\n",
      "NLL Loss is: 1.3781734962510694\n",
      "Scaled KL Loss is: 0.04566263407468796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4238361303257574\n",
      "NLL Loss is: 1.3845638743690907\n",
      "Scaled KL Loss is: 0.04712185636162758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4316857307307183\n",
      "NLL Loss is: 1.3226646643030364\n",
      "Scaled KL Loss is: 0.04626860469579697\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3689332689988334\n",
      "NLL Loss is: 1.2859892299942948\n",
      "Scaled KL Loss is: 0.049867741763591766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3358569717578865\n",
      "NLL Loss is: 1.2707240741131602\n",
      "Scaled KL Loss is: 0.04591089114546776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.316634965258628\n",
      "NLL Loss is: 1.4390909049770406\n",
      "Scaled KL Loss is: 0.04687236621975899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4859632711967996\n",
      "NLL Loss is: 1.3210809137807353\n",
      "Scaled KL Loss is: 0.04380065202713013\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3648815658078655\n",
      "NLL Loss is: 1.2963029186364405\n",
      "Scaled KL Loss is: 0.04999478533864021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3462977039750808\n",
      "NLL Loss is: 1.3248408291522251\n",
      "Scaled KL Loss is: 0.047391414642333984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.372232243794559\n",
      "NLL Loss is: 1.4064003135057717\n",
      "Scaled KL Loss is: 0.04577772691845894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4521780404242306\n",
      "NLL Loss is: 1.2664592829956662\n",
      "Scaled KL Loss is: 0.04288503900170326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3093443219973695\n",
      "NLL Loss is: 1.3910907197140374\n",
      "Scaled KL Loss is: 0.04457125440239906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4356619741164365\n",
      "NLL Loss is: 1.3926868473402032\n",
      "Scaled KL Loss is: 0.04480031877756119\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4374871661177644\n",
      "NLL Loss is: 1.3279231595724084\n",
      "Scaled KL Loss is: 0.046770837157964706\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.374693996730373\n",
      "NLL Loss is: 1.2481725215416024\n",
      "Scaled KL Loss is: 0.04461728781461716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2927898093562196\n",
      "NLL Loss is: 1.3363953468161618\n",
      "Scaled KL Loss is: 0.04481039568781853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3812057425039803\n",
      "NLL Loss is: 1.2074294644539523\n",
      "Scaled KL Loss is: 0.048144739121198654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255574203575151\n",
      "NLL Loss is: 1.3413186919932494\n",
      "Scaled KL Loss is: 0.04238905757665634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3837077495699057\n",
      "NLL Loss is: 1.2026393521450647\n",
      "Scaled KL Loss is: 0.048377975821495056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2510173279665597\n",
      "NLL Loss is: 1.3305133686344601\n",
      "Scaled KL Loss is: 0.04718161001801491\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377694978652475\n",
      "NLL Loss is: 1.4174255876516377\n",
      "Scaled KL Loss is: 0.043943341821432114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4613689294730698\n",
      "NLL Loss is: 1.3392533267481903\n",
      "Scaled KL Loss is: 0.04267783463001251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3819311613782028\n",
      "NLL Loss is: 1.2775391765268405\n",
      "Scaled KL Loss is: 0.047980502247810364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3255196787746508\n",
      "NLL Loss is: 1.2298477287147314\n",
      "Scaled KL Loss is: 0.04419657960534096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2740443083200723\n",
      "NLL Loss is: 1.4270431072511263\n",
      "Scaled KL Loss is: 0.04503989592194557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4720830031730718\n",
      "NLL Loss is: 1.267741267045481\n",
      "Scaled KL Loss is: 0.04628068953752518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3140219565830062\n",
      "NLL Loss is: 1.6641151316630345\n",
      "Scaled KL Loss is: 0.03709288686513901\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7012080185281735\n",
      "NLL Loss is: 1.3233130443933399= 1.345; test loss = 1.382\n",
      "Scaled KL Loss is: 0.04772010073065758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3710331451239974\n",
      "NLL Loss is: 1.3295054582552428\n",
      "Scaled KL Loss is: 0.04484420642256737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3743496646778102\n",
      "NLL Loss is: 1.3529609404192058\n",
      "Scaled KL Loss is: 0.046639584004879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3996005244240848\n",
      "NLL Loss is: 1.373643134994478\n",
      "Scaled KL Loss is: 0.0489310622215271\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.422574197216005\n",
      "NLL Loss is: 1.3334018830208954\n",
      "Scaled KL Loss is: 0.04233318194746971\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.375735064968365\n",
      "NLL Loss is: 1.3617660223135504\n",
      "Scaled KL Loss is: 0.04764944314956665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.409415465463117\n",
      "NLL Loss is: 1.3853670795774855\n",
      "Scaled KL Loss is: 0.042300429195165634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4276675087726511\n",
      "NLL Loss is: 1.3214158023065026\n",
      "Scaled KL Loss is: 0.04353788122534752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.36495368353185\n",
      "NLL Loss is: 1.3821272741857988\n",
      "Scaled KL Loss is: 0.04239198938012123\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.42451926356592\n",
      "NLL Loss is: 1.2466368736845561\n",
      "Scaled KL Loss is: 0.048826057463884354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2954629311484405\n",
      "NLL Loss is: 1.2649617123645882\n",
      "Scaled KL Loss is: 0.04289231821894646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3078540305835347\n",
      "NLL Loss is: 1.400060018056621\n",
      "Scaled KL Loss is: 0.04520091414451599\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.445260932201137\n",
      "NLL Loss is: 1.2322412703277075\n",
      "Scaled KL Loss is: 0.04867856949567795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2809198398233854\n",
      "NLL Loss is: 1.4338879912600262\n",
      "Scaled KL Loss is: 0.04651591181755066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4804039030775769\n",
      "NLL Loss is: 1.238639941497788\n",
      "Scaled KL Loss is: 0.0454191155731678\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840590570709558\n",
      "NLL Loss is: 1.4192144290117212\n",
      "Scaled KL Loss is: 0.0485302209854126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4677446499971338\n",
      "NLL Loss is: 1.3477987353708079\n",
      "Scaled KL Loss is: 0.04510675370693207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.39290548907774\n",
      "NLL Loss is: 1.3035299777536704\n",
      "Scaled KL Loss is: 0.04602639004588127\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3495563677995517\n",
      "NLL Loss is: 1.2278921667161913\n",
      "Scaled KL Loss is: 0.04572606831789017\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2736182350340814\n",
      "NLL Loss is: 1.3343300399823892\n",
      "Scaled KL Loss is: 0.04373475909233093\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3780647990747201\n",
      "NLL Loss is: 1.2639124344336947\n",
      "Scaled KL Loss is: 0.04481206834316254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3087245027768573\n",
      "NLL Loss is: 1.3415769879806823\n",
      "Scaled KL Loss is: 0.043558672070503235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3851356600511855\n",
      "NLL Loss is: 1.249388118807509\n",
      "Scaled KL Loss is: 0.044343508780002594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2937316275875117\n",
      "NLL Loss is: 1.5689879568325182\n",
      "Scaled KL Loss is: 0.047980859875679016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6169688167081973\n",
      "NLL Loss is: 1.1420123066040255\n",
      "Scaled KL Loss is: 0.04529733210802078\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1873096387120463\n",
      "NLL Loss is: 1.2827696842517542\n",
      "Scaled KL Loss is: 0.04896404966711998\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3317337339188742\n",
      "NLL Loss is: 1.3345116737046174\n",
      "Scaled KL Loss is: 0.05045761540532112\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3849692891099386\n",
      "NLL Loss is: 1.1238069903516514\n",
      "Scaled KL Loss is: 0.04785759747028351\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.171664587821935\n",
      "NLL Loss is: 1.2822739082719066\n",
      "Scaled KL Loss is: 0.04682100564241409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3290949139143207\n",
      "NLL Loss is: 1.1151451199498252\n",
      "Scaled KL Loss is: 0.04738767445087433\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1625327944006996\n",
      "NLL Loss is: 1.1683610423069262\n",
      "Scaled KL Loss is: 0.04318828135728836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2115493236642145\n",
      "NLL Loss is: 1.3289651704381618\n",
      "Scaled KL Loss is: 0.04660870507359505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3755738755117568\n",
      "NLL Loss is: 1.3419978778530213\n",
      "Scaled KL Loss is: 0.044575996696949005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3865738745499703\n",
      "NLL Loss is: 1.2377533882140626\n",
      "Scaled KL Loss is: 0.044933661818504333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2826870500325669\n",
      "NLL Loss is: 1.4190174289160902\n",
      "Scaled KL Loss is: 0.04557451233267784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.464591941248768\n",
      "NLL Loss is: 1.4310471766774049\n",
      "Scaled KL Loss is: 0.045402076095342636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4764492527727475\n",
      "NLL Loss is: 1.2423947407014222\n",
      "Scaled KL Loss is: 0.051978979259729385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943737199611516\n",
      "NLL Loss is: 1.2089130263899492\n",
      "Scaled KL Loss is: 0.048616938292980194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2575299646829294\n",
      "NLL Loss is: 1.325447298197752\n",
      "Scaled KL Loss is: 0.046957459300756454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3724047574985085\n",
      "NLL Loss is: 1.4462434451434365\n",
      "Scaled KL Loss is: 0.04764309898018837\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4938865441236249\n",
      "NLL Loss is: 1.1811456255848298\n",
      "Scaled KL Loss is: 0.04807886853814125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.229224494122971\n",
      "NLL Loss is: 1.184943462563708\n",
      "Scaled KL Loss is: 0.04318159446120262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2281250570249107\n",
      "NLL Loss is: 1.2161824139263515\n",
      "Scaled KL Loss is: 0.04796956107020378\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2641519749965553\n",
      "NLL Loss is: 1.226545529585069\n",
      "Scaled KL Loss is: 0.05397304520010948\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2805185747851784\n",
      "NLL Loss is: 1.295811240467616\n",
      "Scaled KL Loss is: 0.04491058364510536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3407218241127214\n",
      "NLL Loss is: 1.223085962420702\n",
      "Scaled KL Loss is: 0.04868245869874954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2717684211194515\n",
      "NLL Loss is: 1.2501104533331275\n",
      "Scaled KL Loss is: 0.04990992322564125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3000203765587688\n",
      "NLL Loss is: 1.1628008052822019\n",
      "Scaled KL Loss is: 0.051241710782051086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.214042516064253\n",
      "NLL Loss is: 1.2562632938078848\n",
      "Scaled KL Loss is: 0.04940333589911461\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3056666297069994\n",
      "NLL Loss is: 1.1833578174224237\n",
      "Scaled KL Loss is: 0.048378486186265945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2317363036086897\n",
      "NLL Loss is: 1.2691311700077248\n",
      "Scaled KL Loss is: 0.04915216937661171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3182833393843365\n",
      "NLL Loss is: 1.3045952913943097\n",
      "Scaled KL Loss is: 0.04616710543632507\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3507623968306348\n",
      "NLL Loss is: 1.205985072874161\n",
      "Scaled KL Loss is: 0.04969353973865509\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255678612612816\n",
      "NLL Loss is: 1.316706182358464\n",
      "Scaled KL Loss is: 0.045554351061582565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3622605334200466\n",
      "NLL Loss is: 1.3866963359261768\n",
      "Scaled KL Loss is: 0.0453144796192646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4320108155454414\n",
      "NLL Loss is: 1.3780134429985624\n",
      "Scaled KL Loss is: 0.044313132762908936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4223265757614714\n",
      "NLL Loss is: 1.3835537632366894\n",
      "Scaled KL Loss is: 0.048861708492040634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.43241547172873\n",
      "NLL Loss is: 1.242273620990823\n",
      "Scaled KL Loss is: 0.04689813032746315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289171751318286\n",
      "NLL Loss is: 1.2269493690584587\n",
      "Scaled KL Loss is: 0.04430397227406502\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2712533413325238\n",
      "NLL Loss is: 1.1621288611831366\n",
      "Scaled KL Loss is: 0.05016189441084862\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2122907555939852\n",
      "NLL Loss is: 1.2576902338914193\n",
      "Scaled KL Loss is: 0.047862857580184937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3055530914716043\n",
      "NLL Loss is: 1.2826458558518241\n",
      "Scaled KL Loss is: 0.0474005825817585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3300464384335826\n",
      "NLL Loss is: 1.369552142889486\n",
      "Scaled KL Loss is: 0.0467986986041069\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4163508414935928\n",
      "NLL Loss is: 1.2755295542223952\n",
      "Scaled KL Loss is: 0.04702889174222946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3225584459646247\n",
      "NLL Loss is: 1.2674435293989688\n",
      "Scaled KL Loss is: 0.044669557362794876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3121130867617636\n",
      "NLL Loss is: 1.3762029846721635\n",
      "Scaled KL Loss is: 0.04589816927909851\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.422101153951262\n",
      "NLL Loss is: 1.3828691570577591\n",
      "Scaled KL Loss is: 0.04742574691772461\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4302949039754838\n",
      "NLL Loss is: 1.3206580151129328\n",
      "Scaled KL Loss is: 0.046511419117450714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3671694342303835\n",
      "NLL Loss is: 1.2835187795523364\n",
      "Scaled KL Loss is: 0.050135400146245956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336541796985824\n",
      "NLL Loss is: 1.2684985834511557\n",
      "Scaled KL Loss is: 0.04617037996649742\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146689634176532\n",
      "NLL Loss is: 1.4373788055034453\n",
      "Scaled KL Loss is: 0.04713047295808792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4845092784615332\n",
      "NLL Loss is: 1.3185865939701826\n",
      "Scaled KL Loss is: 0.044061750173568726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3626483441437514\n",
      "NLL Loss is: 1.2942115735149706\n",
      "Scaled KL Loss is: 0.05028408765792847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344495661172899\n",
      "NLL Loss is: 1.3232657375712165\n",
      "Scaled KL Loss is: 0.04766209051012993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3709278280813464\n",
      "NLL Loss is: 1.403597777899916\n",
      "Scaled KL Loss is: 0.04604968801140785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4496474659113239\n",
      "NLL Loss is: 1.2645595658414834\n",
      "Scaled KL Loss is: 0.04313178360462189\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3076913494461053\n",
      "NLL Loss is: 1.389162181399655\n",
      "Scaled KL Loss is: 0.044811852276325226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4339740336759803\n",
      "NLL Loss is: 1.3919592511535697\n",
      "Scaled KL Loss is: 0.04506845399737358\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4370277051509432\n",
      "NLL Loss is: 1.3272079702127244\n",
      "Scaled KL Loss is: 0.047003988176584244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3742119583893087\n",
      "NLL Loss is: 1.2462879625020575\n",
      "Scaled KL Loss is: 0.04486612230539322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2911540848074508\n",
      "NLL Loss is: 1.3340682619381545\n",
      "Scaled KL Loss is: 0.045068006962537766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3791362689006923\n",
      "NLL Loss is: 1.2050301284972917\n",
      "Scaled KL Loss is: 0.048417508602142334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.253447637099434\n",
      "NLL Loss is: 1.3398279961221657\n",
      "Scaled KL Loss is: 0.04261220991611481\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3824402060382806\n",
      "NLL Loss is: 1.200556150073038\n",
      "Scaled KL Loss is: 0.048634808510541916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2491909585835799\n",
      "NLL Loss is: 1.3275968603853305\n",
      "Scaled KL Loss is: 0.04743863642215729\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3750354968074878\n",
      "NLL Loss is: 1.4148306976828025\n",
      "Scaled KL Loss is: 0.0442010723054409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4590317699882434\n",
      "NLL Loss is: 1.3373150896287513\n",
      "Scaled KL Loss is: 0.04290507361292839\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3802201632416797\n",
      "NLL Loss is: 1.2745765651255831\n",
      "Scaled KL Loss is: 0.048244621604681015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3228211867302642\n",
      "NLL Loss is: 1.2281404060764007\n",
      "Scaled KL Loss is: 0.044472794979810715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2726132010562115\n",
      "NLL Loss is: 1.4255808890258992\n",
      "Scaled KL Loss is: 0.045298147946596146\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4708790369724953\n",
      "NLL Loss is: 1.265584470486663\n",
      "Scaled KL Loss is: 0.04654335230588913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3121278227925521\n",
      "NLL Loss is: 1.6636147274066995\n",
      "Scaled KL Loss is: 0.037315208464860916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7009299358715604\n",
      "NLL Loss is: 1.3225927162262594= 1.343; test loss = 1.380\n",
      "Scaled KL Loss is: 0.047976408153772354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3705691243800318\n",
      "NLL Loss is: 1.3270001627262606\n",
      "Scaled KL Loss is: 0.04510461539030075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3721047781165614\n",
      "NLL Loss is: 1.3505809965323037\n",
      "Scaled KL Loss is: 0.046894609928131104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3974756064604348\n",
      "NLL Loss is: 1.3724161663196421\n",
      "Scaled KL Loss is: 0.04915683716535568\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4215730034849978\n",
      "NLL Loss is: 1.3313759516021773\n",
      "Scaled KL Loss is: 0.04255639389157295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3739323454937502\n",
      "NLL Loss is: 1.3601883754862865\n",
      "Scaled KL Loss is: 0.047890424728393555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40807880021468\n",
      "NLL Loss is: 1.383493310906083\n",
      "Scaled KL Loss is: 0.04253893718123436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4260322480873173\n",
      "NLL Loss is: 1.3197746248661417\n",
      "Scaled KL Loss is: 0.04374632239341736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363520947259559\n",
      "NLL Loss is: 1.3811724145627833\n",
      "Scaled KL Loss is: 0.04257303476333618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4237454493261195\n",
      "NLL Loss is: 1.2447561659222222\n",
      "Scaled KL Loss is: 0.049039795994758606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2937959619169808\n",
      "NLL Loss is: 1.2623226825434337\n",
      "Scaled KL Loss is: 0.043069977313280106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3053926598567138\n",
      "NLL Loss is: 1.398622925881759\n",
      "Scaled KL Loss is: 0.045425932854413986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444048858736173\n",
      "NLL Loss is: 1.2300466950021631\n",
      "Scaled KL Loss is: 0.04893232882022858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2789790238223917\n",
      "NLL Loss is: 1.4318299699285624\n",
      "Scaled KL Loss is: 0.04672939330339432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4785593632319567\n",
      "NLL Loss is: 1.236639594106007\n",
      "Scaled KL Loss is: 0.04565808176994324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2822976758759503\n",
      "NLL Loss is: 1.4172847397331498\n",
      "Scaled KL Loss is: 0.04883255064487457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4661172903780244\n",
      "NLL Loss is: 1.3449423060538186\n",
      "Scaled KL Loss is: 0.045391544699668884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3903338507534875\n",
      "NLL Loss is: 1.3014166435529106\n",
      "Scaled KL Loss is: 0.04626720771193504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3476838512648457\n",
      "NLL Loss is: 1.2257422223473422\n",
      "Scaled KL Loss is: 0.046001601964235306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2717438243115775\n",
      "NLL Loss is: 1.3321760854738485\n",
      "Scaled KL Loss is: 0.04399218037724495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3761682658510934\n",
      "NLL Loss is: 1.261167633627941\n",
      "Scaled KL Loss is: 0.045036766678094864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3062044003060358\n",
      "NLL Loss is: 1.3389557553199436\n",
      "Scaled KL Loss is: 0.04384882375597954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3828045790759231\n",
      "NLL Loss is: 1.24673792750217\n",
      "Scaled KL Loss is: 0.04462317377328873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2913611012754587\n",
      "NLL Loss is: 1.5678582387064455\n",
      "Scaled KL Loss is: 0.048212263733148575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.616070502439594\n",
      "NLL Loss is: 1.140198566149773\n",
      "Scaled KL Loss is: 0.04553289711475372\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1857314632645268\n",
      "NLL Loss is: 1.2805502192556562\n",
      "Scaled KL Loss is: 0.04920350760221481\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.329753726857871\n",
      "NLL Loss is: 1.3326050430611158\n",
      "Scaled KL Loss is: 0.050725385546684265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3833304286078\n",
      "NLL Loss is: 1.1215607429065009\n",
      "Scaled KL Loss is: 0.04812689498066902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.16968763788717\n",
      "NLL Loss is: 1.2795335821708897\n",
      "Scaled KL Loss is: 0.047064829617738724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3265984117886285\n",
      "NLL Loss is: 1.1123358244106063\n",
      "Scaled KL Loss is: 0.04763089865446091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1599667230650672\n",
      "NLL Loss is: 1.1663551865868846\n",
      "Scaled KL Loss is: 0.04339243844151497\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2097476250283996\n",
      "NLL Loss is: 1.327124418163698\n",
      "Scaled KL Loss is: 0.04682372510433197\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37394814326803\n",
      "NLL Loss is: 1.3409036901533204\n",
      "Scaled KL Loss is: 0.044776156544685364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3856798466980058\n",
      "NLL Loss is: 1.2367445840298255\n",
      "Scaled KL Loss is: 0.045139048248529434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.281883632278355\n",
      "NLL Loss is: 1.4179278690123716\n",
      "Scaled KL Loss is: 0.04577235132455826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4637002203369298\n",
      "NLL Loss is: 1.428457987725741\n",
      "Scaled KL Loss is: 0.04558820649981499\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.474046194225556\n",
      "NLL Loss is: 1.2410281233850826\n",
      "Scaled KL Loss is: 0.05216687172651291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2931949951115955\n",
      "NLL Loss is: 1.2078067001634627\n",
      "Scaled KL Loss is: 0.048843950033187866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2566506501966506\n",
      "NLL Loss is: 1.3236937071815817\n",
      "Scaled KL Loss is: 0.04715990275144577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3708536099330275\n",
      "NLL Loss is: 1.4447985621810289\n",
      "Scaled KL Loss is: 0.0478120781481266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4926106403291555\n",
      "NLL Loss is: 1.1789873335374506\n",
      "Scaled KL Loss is: 0.04827694222331047\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.227264275760761\n",
      "NLL Loss is: 1.1825770019632191\n",
      "Scaled KL Loss is: 0.043373771011829376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2259507729750485\n",
      "NLL Loss is: 1.2147454403878544\n",
      "Scaled KL Loss is: 0.04819273203611374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.262938172423968\n",
      "NLL Loss is: 1.224702590220546\n",
      "Scaled KL Loss is: 0.05414639413356781\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2788489843541138\n",
      "NLL Loss is: 1.2943087550264862\n",
      "Scaled KL Loss is: 0.045064959675073624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3393737147015599\n",
      "NLL Loss is: 1.2212258584955618\n",
      "Scaled KL Loss is: 0.04889978468418121\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270125643179743\n",
      "NLL Loss is: 1.2487475561174117\n",
      "Scaled KL Loss is: 0.050095461308956146\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2988430174263679\n",
      "NLL Loss is: 1.16077483347615\n",
      "Scaled KL Loss is: 0.05149693414568901\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.212271767621839\n",
      "NLL Loss is: 1.2548224200963944\n",
      "Scaled KL Loss is: 0.049567483365535736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3043899034619302\n",
      "NLL Loss is: 1.1813402541688667\n",
      "Scaled KL Loss is: 0.048569563776254654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2299098179451213\n",
      "NLL Loss is: 1.2675045376578986\n",
      "Scaled KL Loss is: 0.04934310168027878\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3168476393381774\n",
      "NLL Loss is: 1.302752839774023\n",
      "Scaled KL Loss is: 0.04631185904145241\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3490646988154753\n",
      "NLL Loss is: 1.2045823494991816\n",
      "Scaled KL Loss is: 0.049823541194200516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2544058906933822\n",
      "NLL Loss is: 1.314777001261134\n",
      "Scaled KL Loss is: 0.04576430842280388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3605413096839378\n",
      "NLL Loss is: 1.3849482534408744\n",
      "Scaled KL Loss is: 0.04545829817652702\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4304065516174014\n",
      "NLL Loss is: 1.375670414311428\n",
      "Scaled KL Loss is: 0.044470805674791336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4201412199862193\n",
      "NLL Loss is: 1.3822372046424465\n",
      "Scaled KL Loss is: 0.04899529740214348\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.43123250204459\n",
      "NLL Loss is: 1.2410838959127382\n",
      "Scaled KL Loss is: 0.0470263697206974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2881102656334356\n",
      "NLL Loss is: 1.22427622750143\n",
      "Scaled KL Loss is: 0.044468849897384644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2687450773988147\n",
      "NLL Loss is: 1.1605538718268038\n",
      "Scaled KL Loss is: 0.05029296875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2108468405768038\n",
      "NLL Loss is: 1.256093795834636\n",
      "Scaled KL Loss is: 0.04804975911974907\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3041435549543852\n",
      "NLL Loss is: 1.2805588239752819\n",
      "Scaled KL Loss is: 0.047543447464704514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3281022714399864\n",
      "NLL Loss is: 1.3670980908630455\n",
      "Scaled KL Loss is: 0.04694146662950516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4140395574925506\n",
      "NLL Loss is: 1.2742428465772209\n",
      "Scaled KL Loss is: 0.04723180830478668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3214746548820075\n",
      "NLL Loss is: 1.2651034269672912\n",
      "Scaled KL Loss is: 0.04481092467904091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.309914351646332\n",
      "NLL Loss is: 1.3744564303746762\n",
      "Scaled KL Loss is: 0.04603834077715874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420494771151835\n",
      "NLL Loss is: 1.3813304704545755\n",
      "Scaled KL Loss is: 0.047632887959480286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4289633584140558\n",
      "NLL Loss is: 1.3189090717528313\n",
      "Scaled KL Loss is: 0.04665215685963631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3655612286124676\n",
      "NLL Loss is: 1.2814103785675603\n",
      "Scaled KL Loss is: 0.05029519274830818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3317055713158685\n",
      "NLL Loss is: 1.266304830965687\n",
      "Scaled KL Loss is: 0.046334315091371536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3126391460570586\n",
      "NLL Loss is: 1.4357307996479134\n",
      "Scaled KL Loss is: 0.047293152660131454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4830239523080448\n",
      "NLL Loss is: 1.3164183499652324\n",
      "Scaled KL Loss is: 0.04423876106739044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3606571110326229\n",
      "NLL Loss is: 1.2926727218909204\n",
      "Scaled KL Loss is: 0.05047161132097244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431443332118929\n",
      "NLL Loss is: 1.3218669888242283\n",
      "Scaled KL Loss is: 0.04784831032156944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3697152991457977\n",
      "NLL Loss is: 1.4013809025091128\n",
      "Scaled KL Loss is: 0.046230752021074295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4476116545301871\n",
      "NLL Loss is: 1.2629153170884404\n",
      "Scaled KL Loss is: 0.043295834213495255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3062111513019357\n",
      "NLL Loss is: 1.3876009833829626\n",
      "Scaled KL Loss is: 0.0449531264603138\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4325541098432764\n",
      "NLL Loss is: 1.3909686754723694\n",
      "Scaled KL Loss is: 0.04525930806994438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4362279835423137\n",
      "NLL Loss is: 1.3265822340604319\n",
      "Scaled KL Loss is: 0.047126371413469315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3737086054739012\n",
      "NLL Loss is: 1.2445766968265877\n",
      "Scaled KL Loss is: 0.04501477628946304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2895914731160507\n",
      "NLL Loss is: 1.3321767015494825\n",
      "Scaled KL Loss is: 0.04523271322250366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3774094147719862\n",
      "NLL Loss is: 1.2029415684457865\n",
      "Scaled KL Loss is: 0.04859137535095215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2515329437967386\n",
      "NLL Loss is: 1.338572839287629\n",
      "Scaled KL Loss is: 0.04274837300181389\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.381321212289443\n",
      "NLL Loss is: 1.1989082024117277\n",
      "Scaled KL Loss is: 0.048799194395542145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2477073968072698\n",
      "NLL Loss is: 1.3251285238822148\n",
      "Scaled KL Loss is: 0.047591038048267365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3727195619304822\n",
      "NLL Loss is: 1.4126352426061228\n",
      "Scaled KL Loss is: 0.04438842833042145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4570236709365443\n",
      "NLL Loss is: 1.3356224735110862\n",
      "Scaled KL Loss is: 0.04306963458657265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3786921080976589\n",
      "NLL Loss is: 1.2719875202309032\n",
      "Scaled KL Loss is: 0.04840902239084244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3203965426217457\n",
      "NLL Loss is: 1.226696004297787\n",
      "Scaled KL Loss is: 0.04466646909713745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2713624733949245\n",
      "NLL Loss is: 1.424218935173192\n",
      "Scaled KL Loss is: 0.04547959193587303\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.469698527109065\n",
      "NLL Loss is: 1.2638064468504684\n",
      "Scaled KL Loss is: 0.04672488570213318\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3105313325526016\n",
      "NLL Loss is: 1.6634046806678933\n",
      "Scaled KL Loss is: 0.03747145086526871\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.700876131533162\n",
      "NLL Loss is: 1.321856388156009 = 1.342; test loss = 1.379\n",
      "Scaled KL Loss is: 0.04814211651682854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3699985046728376\n",
      "NLL Loss is: 1.3250076831836397\n",
      "Scaled KL Loss is: 0.04527778923511505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702854724187548\n",
      "NLL Loss is: 1.3487132863701214\n",
      "Scaled KL Loss is: 0.047066520899534225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3957798072696557\n",
      "NLL Loss is: 1.3712995728749662\n",
      "Scaled KL Loss is: 0.04928136616945267\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4205809390444188\n",
      "NLL Loss is: 1.329526604771348\n",
      "Scaled KL Loss is: 0.04270755499601364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3722341597673617\n",
      "NLL Loss is: 1.3586948577876086\n",
      "Scaled KL Loss is: 0.04804811254143715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4067429703290457\n",
      "NLL Loss is: 1.3817620374672088\n",
      "Scaled KL Loss is: 0.04270949214696884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4244715296141777\n",
      "NLL Loss is: 1.318348607281112\n",
      "Scaled KL Loss is: 0.04387367144227028\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3622222787233822\n",
      "NLL Loss is: 1.380331682853167\n",
      "Scaled KL Loss is: 0.04267561808228493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423007300935452\n",
      "NLL Loss is: 1.2431262437156854\n",
      "Scaled KL Loss is: 0.049168508499860764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2922947522155461\n",
      "NLL Loss is: 1.260116948646183\n",
      "Scaled KL Loss is: 0.04315105453133583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3032680031775188\n",
      "NLL Loss is: 1.3972754337105076\n",
      "Scaled KL Loss is: 0.04557930305600166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4428547367665092\n",
      "NLL Loss is: 1.228238484497472\n",
      "Scaled KL Loss is: 0.0491030290722847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2773415135697568\n",
      "NLL Loss is: 1.4300842924222588\n",
      "Scaled KL Loss is: 0.046856727451086044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4769410198733448\n",
      "NLL Loss is: 1.2350538787235135\n",
      "Scaled KL Loss is: 0.04580071195960045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.280854590683114\n",
      "NLL Loss is: 1.4156002264722785\n",
      "Scaled KL Loss is: 0.04906168952584267\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4646619159981211\n",
      "NLL Loss is: 1.3424967604621663\n",
      "Scaled KL Loss is: 0.04560164362192154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3880984040840878\n",
      "NLL Loss is: 1.299529756156612\n",
      "Scaled KL Loss is: 0.0464177206158638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3459474767724757\n",
      "NLL Loss is: 1.2237889829650614\n",
      "Scaled KL Loss is: 0.04618879780173302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2699777807667945\n",
      "NLL Loss is: 1.3301263526784732\n",
      "Scaled KL Loss is: 0.04417547211050987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.374301824788983\n",
      "NLL Loss is: 1.258972900931837\n",
      "Scaled KL Loss is: 0.045153044164180756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3041259450960176\n",
      "NLL Loss is: 1.3366580390302403\n",
      "Scaled KL Loss is: 0.04405767843127251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3807157174615128\n",
      "NLL Loss is: 1.2444713813619044\n",
      "Scaled KL Loss is: 0.044827211648225784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2892985930101302\n",
      "NLL Loss is: 1.5667026372861605\n",
      "Scaled KL Loss is: 0.048347000032663345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.615049637318824\n",
      "NLL Loss is: 1.1387596259965003\n",
      "Scaled KL Loss is: 0.04568013921380043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1844397652103007\n",
      "NLL Loss is: 1.278771961669876\n",
      "Scaled KL Loss is: 0.04935668408870697\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.328128645758583\n",
      "NLL Loss is: 1.330921943026611\n",
      "Scaled KL Loss is: 0.050903551280498505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3818254943071095\n",
      "NLL Loss is: 1.119723304553466\n",
      "Scaled KL Loss is: 0.04831479862332344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1680381031767895\n",
      "NLL Loss is: 1.2771938600823076\n",
      "Scaled KL Loss is: 0.04722923785448074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3244230979367884\n",
      "NLL Loss is: 1.1100102063525243\n",
      "Scaled KL Loss is: 0.0477868877351284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1577970940876527\n",
      "NLL Loss is: 1.1645741596663401\n",
      "Scaled KL Loss is: 0.04351571947336197\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2080898791397021\n",
      "NLL Loss is: 1.3254728667300584\n",
      "Scaled KL Loss is: 0.04695684462785721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3724297113579156\n",
      "NLL Loss is: 1.339765846332768\n",
      "Scaled KL Loss is: 0.044890038669109344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3846558850018773\n",
      "NLL Loss is: 1.2357878348399083\n",
      "Scaled KL Loss is: 0.04526244103908539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2810502758789937\n",
      "NLL Loss is: 1.416900595881449\n",
      "Scaled KL Loss is: 0.04589911177754402\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.462799707658993\n",
      "NLL Loss is: 1.4259460194572509\n",
      "Scaled KL Loss is: 0.045692384243011475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4716384037002623\n",
      "NLL Loss is: 1.239838236436495\n",
      "Scaled KL Loss is: 0.05226677283644676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2921050092729418\n",
      "NLL Loss is: 1.2069017056756415\n",
      "Scaled KL Loss is: 0.048996176570653915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2558978822462954\n",
      "NLL Loss is: 1.32216569925823\n",
      "Scaled KL Loss is: 0.047281116247177124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3694468155054071\n",
      "NLL Loss is: 1.443497460384642\n",
      "Scaled KL Loss is: 0.04789735749363899\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.491394817878281\n",
      "NLL Loss is: 1.1770147672550753\n",
      "Scaled KL Loss is: 0.04838719218969345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2254019594447687\n",
      "NLL Loss is: 1.1804826775052626\n",
      "Scaled KL Loss is: 0.04348975047469139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.223972427979954\n",
      "NLL Loss is: 1.213452308840693\n",
      "Scaled KL Loss is: 0.04834778979420662\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2618000986348996\n",
      "NLL Loss is: 1.2230094992534104\n",
      "Scaled KL Loss is: 0.054233331233263016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2772428304866734\n",
      "NLL Loss is: 1.2929122578260206\n",
      "Scaled KL Loss is: 0.04514600709080696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3380582649168276\n",
      "NLL Loss is: 1.2197220707034442\n",
      "Scaled KL Loss is: 0.04904922842979431\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2687712991332385\n",
      "NLL Loss is: 1.2476525279593107\n",
      "Scaled KL Loss is: 0.050211094319820404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297863622279131\n",
      "NLL Loss is: 1.1589675007012021\n",
      "Scaled KL Loss is: 0.05169086158275604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2106583622839582\n",
      "NLL Loss is: 1.253562105672849\n",
      "Scaled KL Loss is: 0.04966377094388008\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303225876616729\n",
      "NLL Loss is: 1.1795834300401287\n",
      "Scaled KL Loss is: 0.048696503043174744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2282799330833034\n",
      "NLL Loss is: 1.266101270776416\n",
      "Scaled KL Loss is: 0.04947122558951378\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3155724963659299\n",
      "NLL Loss is: 1.3009620913466111\n",
      "Scaled KL Loss is: 0.046402134001255035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3473642253478662\n",
      "NLL Loss is: 1.203278919168112\n",
      "Scaled KL Loss is: 0.04990188032388687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2531807994919988\n",
      "NLL Loss is: 1.3130014769916516\n",
      "Scaled KL Loss is: 0.045932989567518234\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3589344665591698\n",
      "NLL Loss is: 1.3834666267718427\n",
      "Scaled KL Loss is: 0.04556695744395256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4290335842157953\n",
      "NLL Loss is: 1.3735492964775062\n",
      "Scaled KL Loss is: 0.04459836706519127\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4181476635426975\n",
      "NLL Loss is: 1.3810222093069036\n",
      "Scaled KL Loss is: 0.049094635993242264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4301168453001458\n",
      "NLL Loss is: 1.2400477351376562\n",
      "Scaled KL Loss is: 0.04711935296654701\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2871670881042032\n",
      "NLL Loss is: 1.221931991426291\n",
      "Scaled KL Loss is: 0.044605355709791183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2665373471360821\n",
      "NLL Loss is: 1.159053067238143\n",
      "Scaled KL Loss is: 0.050387099385261536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2094401666234045\n",
      "NLL Loss is: 1.2546431586532094\n",
      "Scaled KL Loss is: 0.048197872936725616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.302841031589935\n",
      "NLL Loss is: 1.2786160006567946\n",
      "Scaled KL Loss is: 0.04764961078763008\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3262656114444247\n",
      "NLL Loss is: 1.3648764192231906\n",
      "Scaled KL Loss is: 0.047051530331373215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119279495545638\n",
      "NLL Loss is: 1.2731277434347035\n",
      "Scaled KL Loss is: 0.04740250110626221\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3205302445409657\n",
      "NLL Loss is: 1.2630116385191896\n",
      "Scaled KL Loss is: 0.04492174834012985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3079333868593195\n",
      "NLL Loss is: 1.372756090021383\n",
      "Scaled KL Loss is: 0.046147670596838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418903760618221\n",
      "NLL Loss is: 1.3799894787053117\n",
      "Scaled KL Loss is: 0.047801483422517776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4277909621278295\n",
      "NLL Loss is: 1.3173761007626692\n",
      "Scaled KL Loss is: 0.04674377664923668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3641198774119059\n",
      "NLL Loss is: 1.279379384735233\n",
      "Scaled KL Loss is: 0.05040799081325531\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3297873755484884\n",
      "NLL Loss is: 1.26421970711973\n",
      "Scaled KL Loss is: 0.04644448310136795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.310664190221098\n",
      "NLL Loss is: 1.4342172501768102\n",
      "Scaled KL Loss is: 0.04741224646568298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4816294966424932\n",
      "NLL Loss is: 1.314446841736657\n",
      "Scaled KL Loss is: 0.04437234252691269\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3588191842635697\n",
      "NLL Loss is: 1.2913516461485757\n",
      "Scaled KL Loss is: 0.05060405284166336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341955698990239\n",
      "NLL Loss is: 1.3205135354458013\n",
      "Scaled KL Loss is: 0.047983989119529724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.368497524565331\n",
      "NLL Loss is: 1.3993428138685633\n",
      "Scaled KL Loss is: 0.046363867819309235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4457066816878725\n",
      "NLL Loss is: 1.2614170690018809\n",
      "Scaled KL Loss is: 0.04341201111674309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304829080118624\n",
      "NLL Loss is: 1.3861894277197278\n",
      "Scaled KL Loss is: 0.04503803327679634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.431227460996524\n",
      "NLL Loss is: 1.3899022775370906\n",
      "Scaled KL Loss is: 0.0454099103808403\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.435312187917931\n",
      "NLL Loss is: 1.3260464929333673\n",
      "Scaled KL Loss is: 0.0471901036798954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3732365966132627\n",
      "NLL Loss is: 1.2429666665309178\n",
      "Scaled KL Loss is: 0.04510931298136711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.288075979512285\n",
      "NLL Loss is: 1.3305094275683198\n",
      "Scaled KL Loss is: 0.04534854739904404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3758579749673638\n",
      "NLL Loss is: 1.2011069525086335\n",
      "Scaled KL Loss is: 0.048714812844991684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2498217653536252\n",
      "NLL Loss is: 1.3374699638436822\n",
      "Scaled KL Loss is: 0.04283832386136055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3803082877050428\n",
      "NLL Loss is: 1.1975301781552912\n",
      "Scaled KL Loss is: 0.04890367016196251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2464338483172537\n",
      "NLL Loss is: 1.3229065598901173\n",
      "Scaled KL Loss is: 0.0476873517036438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370593911593761\n",
      "NLL Loss is: 1.41065253066216\n",
      "Scaled KL Loss is: 0.04453735798597336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4551898886481334\n",
      "NLL Loss is: 1.3341051212192423\n",
      "Scaled KL Loss is: 0.0431840643286705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3772891855479128\n",
      "NLL Loss is: 1.2695283257737784\n",
      "Scaled KL Loss is: 0.048520278185606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3180486039593844\n",
      "NLL Loss is: 1.225346688879477\n",
      "Scaled KL Loss is: 0.044809725135564804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2701564140150419\n",
      "NLL Loss is: 1.4229734001192773\n",
      "Scaled KL Loss is: 0.04562037065625191\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4685937707755292\n",
      "NLL Loss is: 1.2622426896824799\n",
      "Scaled KL Loss is: 0.046857673674821854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3091003633573017\n",
      "NLL Loss is: 1.6633250925907164\n",
      "Scaled KL Loss is: 0.03758830577135086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7009133983620672\n",
      "NLL Loss is: 1.3212088650789964= 1.340; test loss = 1.377\n",
      "Scaled KL Loss is: 0.048252660781145096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3694615258601415\n",
      "NLL Loss is: 1.3232894142365186\n",
      "Scaled KL Loss is: 0.04539906978607178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3686884840225904\n",
      "NLL Loss is: 1.3468117127110235\n",
      "Scaled KL Loss is: 0.04718805104494095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3939997637559645\n",
      "NLL Loss is: 1.3703195154930388\n",
      "Scaled KL Loss is: 0.04933810979127884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4196576252843176\n",
      "NLL Loss is: 1.3277403275742616\n",
      "Scaled KL Loss is: 0.04280881956219673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3705491471364584\n",
      "NLL Loss is: 1.3574285827967998\n",
      "Scaled KL Loss is: 0.04814710468053818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405575687477338\n",
      "NLL Loss is: 1.3800683113273857\n",
      "Scaled KL Loss is: 0.04282870143651962\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4228970127639053\n",
      "NLL Loss is: 1.316940568589656\n",
      "Scaled KL Loss is: 0.04393942281603813\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3608799914056942\n",
      "NLL Loss is: 1.3795125488637925\n",
      "Scaled KL Loss is: 0.04271841049194336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4222309593557358\n",
      "NLL Loss is: 1.2416681938664431\n",
      "Scaled KL Loss is: 0.0492284893989563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2908966832653994\n",
      "NLL Loss is: 1.2579574489303549\n",
      "Scaled KL Loss is: 0.043154992163181305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3011124410935362\n",
      "NLL Loss is: 1.395871745142067\n",
      "Scaled KL Loss is: 0.04567845165729523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4415501967993622\n",
      "NLL Loss is: 1.2266798414535491\n",
      "Scaled KL Loss is: 0.049208883196115494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2758887246496646\n",
      "NLL Loss is: 1.4286443139336615\n",
      "Scaled KL Loss is: 0.04691271856427193\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4755570324979335\n",
      "NLL Loss is: 1.233532996108459\n",
      "Scaled KL Loss is: 0.04586482420563698\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2793978203140959\n",
      "NLL Loss is: 1.4140344408300707\n",
      "Scaled KL Loss is: 0.049234788864851\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4632692296949217\n",
      "NLL Loss is: 1.340474700199978\n",
      "Scaled KL Loss is: 0.045748814940452576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3862235151404305\n",
      "NLL Loss is: 1.2978796653743885\n",
      "Scaled KL Loss is: 0.04649002477526665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3443696901496551\n",
      "NLL Loss is: 1.2220549266843188\n",
      "Scaled KL Loss is: 0.046300701797008514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2683556284813273\n",
      "NLL Loss is: 1.32831414698595\n",
      "Scaled KL Loss is: 0.04428940266370773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3726035496496578\n",
      "NLL Loss is: 1.2574059883468296\n",
      "Scaled KL Loss is: 0.04516838118433952\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3025743695311691\n",
      "NLL Loss is: 1.334725908365843\n",
      "Scaled KL Loss is: 0.0441911444067955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3789170527726384\n",
      "NLL Loss is: 1.2427009283706287\n",
      "Scaled KL Loss is: 0.04496389254927635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.287664820919905\n",
      "NLL Loss is: 1.5653685940098216\n",
      "Scaled KL Loss is: 0.048389982432127\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6137585764419486\n",
      "NLL Loss is: 1.1375006925796312\n",
      "Scaled KL Loss is: 0.0457414872944355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1832421798740667\n",
      "NLL Loss is: 1.2772755952994352\n",
      "Scaled KL Loss is: 0.049429409205913544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3267050045053488\n",
      "NLL Loss is: 1.3293775173060147\n",
      "Scaled KL Loss is: 0.05100037157535553\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3803778888813703\n",
      "NLL Loss is: 1.1180440629183306\n",
      "Scaled KL Loss is: 0.04842831566929817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1664723785876288\n",
      "NLL Loss is: 1.2751801913438714\n",
      "Scaled KL Loss is: 0.047315821051597595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.322496012395469\n",
      "NLL Loss is: 1.1081679884553066\n",
      "Scaled KL Loss is: 0.04785410687327385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1560220953285805\n",
      "NLL Loss is: 1.1628821833374658\n",
      "Scaled KL Loss is: 0.04354618862271309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.206428371960179\n",
      "NLL Loss is: 1.3238202312883822\n",
      "Scaled KL Loss is: 0.04700315371155739\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3708233849999396\n",
      "NLL Loss is: 1.3386606889048316\n",
      "Scaled KL Loss is: 0.04490736499428749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.383568053899119\n",
      "NLL Loss is: 1.235003514194493\n",
      "Scaled KL Loss is: 0.045290786772966385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2802943009674594\n",
      "NLL Loss is: 1.4159182302276188\n",
      "Scaled KL Loss is: 0.045939281582832336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.461857511810451\n",
      "NLL Loss is: 1.4236493859838284\n",
      "Scaled KL Loss is: 0.04570319503545761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.469352581019286\n",
      "NLL Loss is: 1.238582510580442\n",
      "Scaled KL Loss is: 0.052273936569690704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2908564471501327\n",
      "NLL Loss is: 1.2061960373788814\n",
      "Scaled KL Loss is: 0.04907740652561188\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2552734439044932\n",
      "NLL Loss is: 1.3208489271263448\n",
      "Scaled KL Loss is: 0.047328442335128784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3681773694614736\n",
      "NLL Loss is: 1.4424074939811034\n",
      "Scaled KL Loss is: 0.04790123924612999\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4903087332272333\n",
      "NLL Loss is: 1.1751357762589512\n",
      "Scaled KL Loss is: 0.04842023923993111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2235560154988823\n",
      "NLL Loss is: 1.1786594503743526\n",
      "Scaled KL Loss is: 0.04353402554988861\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2221934759242412\n",
      "NLL Loss is: 1.2122491886727687\n",
      "Scaled KL Loss is: 0.048443734645843506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2606929233186122\n",
      "NLL Loss is: 1.2213856548000757\n",
      "Scaled KL Loss is: 0.054242074489593506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2756277292896692\n",
      "NLL Loss is: 1.291681044119417\n",
      "Scaled KL Loss is: 0.04515935853123665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3368404026506537\n",
      "NLL Loss is: 1.2184114541541984\n",
      "Scaled KL Loss is: 0.04913487285375595\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2675463270079543\n",
      "NLL Loss is: 1.2467568350170304\n",
      "Scaled KL Loss is: 0.05026078596711159\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297017620984142\n",
      "NLL Loss is: 1.15735129394563\n",
      "Scaled KL Loss is: 0.05182325094938278\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2091745448950129\n",
      "NLL Loss is: 1.252409454245999\n",
      "Scaled KL Loss is: 0.049695875495672226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3021053297416711\n",
      "NLL Loss is: 1.1780461220815988\n",
      "Scaled KL Loss is: 0.04875820875167847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2268043308332772\n",
      "NLL Loss is: 1.2648746223782976\n",
      "Scaled KL Loss is: 0.04954023286700249\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3144148552453\n",
      "NLL Loss is: 1.2992726433410138\n",
      "Scaled KL Loss is: 0.046430330723524094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3457029740645379\n",
      "NLL Loss is: 1.2021228039281244\n",
      "Scaled KL Loss is: 0.04991703853011131\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2520398424582357\n",
      "NLL Loss is: 1.3113756596232673\n",
      "Scaled KL Loss is: 0.046046484261751175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3574221438850185\n",
      "NLL Loss is: 1.382282752437983\n",
      "Scaled KL Loss is: 0.04561954364180565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4279022960797887\n",
      "NLL Loss is: 1.371552127693596\n",
      "Scaled KL Loss is: 0.044669508934020996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416221636627617\n",
      "NLL Loss is: 1.3799497829976561\n",
      "Scaled KL Loss is: 0.0491352453827858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.429085028380442\n",
      "NLL Loss is: 1.239229082186579\n",
      "Scaled KL Loss is: 0.0471525713801384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2863816535667174\n",
      "NLL Loss is: 1.2198244666885056\n",
      "Scaled KL Loss is: 0.04469266161322594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2645171283017316\n",
      "NLL Loss is: 1.1576762707120771\n",
      "Scaled KL Loss is: 0.05042503774166107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2081013084537382\n",
      "NLL Loss is: 1.253288099738515\n",
      "Scaled KL Loss is: 0.04829724505543709\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.301585344793952\n",
      "NLL Loss is: 1.276716480661257\n",
      "Scaled KL Loss is: 0.04770813509821892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.324424615759476\n",
      "NLL Loss is: 1.3628460530239928\n",
      "Scaled KL Loss is: 0.04711468517780304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099607382017958\n",
      "NLL Loss is: 1.2721619261892454\n",
      "Scaled KL Loss is: 0.047529615461826324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3196915416510717\n",
      "NLL Loss is: 1.2611028484834144\n",
      "Scaled KL Loss is: 0.04499003291130066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.306092881394715\n",
      "NLL Loss is: 1.3712235709603933\n",
      "Scaled KL Loss is: 0.04621893912553787\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4174425100859311\n",
      "NLL Loss is: 1.3787654563811347\n",
      "Scaled KL Loss is: 0.04793087765574455\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4266963340368792\n",
      "NLL Loss is: 1.3159864587112449\n",
      "Scaled KL Loss is: 0.04679635912179947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3627828178330443\n",
      "NLL Loss is: 1.2774792850277614\n",
      "Scaled KL Loss is: 0.0504794679582119\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3279587529859733\n",
      "NLL Loss is: 1.2622017627194826\n",
      "Scaled KL Loss is: 0.04651577025651932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.308717532976002\n",
      "NLL Loss is: 1.4327327101659162\n",
      "Scaled KL Loss is: 0.04748891666531563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4802216268312318\n",
      "NLL Loss is: 1.3126700644588183\n",
      "Scaled KL Loss is: 0.04446546360850334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571355280673216\n",
      "NLL Loss is: 1.2901332762746236\n",
      "Scaled KL Loss is: 0.050691794604063034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3408250708786866\n",
      "NLL Loss is: 1.31931884854203\n",
      "Scaled KL Loss is: 0.04807969555258751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3673985440946175\n",
      "NLL Loss is: 1.3974975732780706\n",
      "Scaled KL Loss is: 0.04645543545484543\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.443953008732916\n",
      "NLL Loss is: 1.2600554448762191\n",
      "Scaled KL Loss is: 0.04348872974514961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3035441746213687\n",
      "NLL Loss is: 1.3849274878581468\n",
      "Scaled KL Loss is: 0.04507468640804291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4300021742661897\n",
      "NLL Loss is: 1.3886590424699958\n",
      "Scaled KL Loss is: 0.045520711690187454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4341797541601833\n",
      "NLL Loss is: 1.3256360427793537\n",
      "Scaled KL Loss is: 0.04720667749643326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.372842720275787\n",
      "NLL Loss is: 1.2414968114468763\n",
      "Scaled KL Loss is: 0.04515707492828369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.28665388637516\n",
      "NLL Loss is: 1.3289276412434539\n",
      "Scaled KL Loss is: 0.045423004776239395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3743506460196933\n",
      "NLL Loss is: 1.1993552490052035\n",
      "Scaled KL Loss is: 0.04879288002848625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2481481290336898\n",
      "NLL Loss is: 1.3365008865823251\n",
      "Scaled KL Loss is: 0.04288717731833458\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3793880639006597\n",
      "NLL Loss is: 1.1962811088349692\n",
      "Scaled KL Loss is: 0.04896116629242897\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2452422751273982\n",
      "NLL Loss is: 1.3207664556373349\n",
      "Scaled KL Loss is: 0.04773733392357826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3685037895609131\n",
      "NLL Loss is: 1.4087550217369837\n",
      "Scaled KL Loss is: 0.04464975744485855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4534047791818423\n",
      "NLL Loss is: 1.3327158247363038\n",
      "Scaled KL Loss is: 0.04325917735695839\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3759750020932622\n",
      "NLL Loss is: 1.2672522350850224\n",
      "Scaled KL Loss is: 0.04858538135886192\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3158376164438843\n",
      "NLL Loss is: 1.224165220939793\n",
      "Scaled KL Loss is: 0.04491085931658745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2690760802563805\n",
      "NLL Loss is: 1.4218213836496956\n",
      "Scaled KL Loss is: 0.045721955597400665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4675433392470962\n",
      "NLL Loss is: 1.260775100169667\n",
      "Scaled KL Loss is: 0.046952079981565475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3077271801512325\n",
      "NLL Loss is: 1.663298282766168\n",
      "Scaled KL Loss is: 0.03766763582825661\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7009659185944246\n",
      "NLL Loss is: 1.3205801965724415= 1.339; test loss = 1.376\n",
      "Scaled KL Loss is: 0.04831920936703682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3688994059394783\n",
      "NLL Loss is: 1.3217511950390397\n",
      "Scaled KL Loss is: 0.04547877609729767\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3672299711363374\n",
      "NLL Loss is: 1.3450712630308148\n",
      "Scaled KL Loss is: 0.04726719111204147\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3923384541428563\n",
      "NLL Loss is: 1.369363299530268\n",
      "Scaled KL Loss is: 0.04934491217136383\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4187082117016319\n",
      "NLL Loss is: 1.3260473224100537\n",
      "Scaled KL Loss is: 0.04287732020020485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3689246426102586\n",
      "NLL Loss is: 1.3561332944662667\n",
      "Scaled KL Loss is: 0.04821470007300377\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4043479945392705\n",
      "NLL Loss is: 1.3784837647586274\n",
      "Scaled KL Loss is: 0.042924441397190094\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4214082061558175\n",
      "NLL Loss is: 1.3157395832465522\n",
      "Scaled KL Loss is: 0.04398249462246895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359722077869021\n",
      "NLL Loss is: 1.3787941871534393\n",
      "Scaled KL Loss is: 0.04273999482393265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.421534181977372\n",
      "NLL Loss is: 1.2403322206224394\n",
      "Scaled KL Loss is: 0.04926652833819389\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2895987489606333\n",
      "NLL Loss is: 1.2559912050146516\n",
      "Scaled KL Loss is: 0.04313819855451584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2991294035691674\n",
      "NLL Loss is: 1.3945538821392658\n",
      "Scaled KL Loss is: 0.045756809413433075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4403106915526989\n",
      "NLL Loss is: 1.225259194772704\n",
      "Scaled KL Loss is: 0.049287885427474976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.274547080200179\n",
      "NLL Loss is: 1.427202367418833\n",
      "Scaled KL Loss is: 0.04694434627890587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4741467136977389\n",
      "NLL Loss is: 1.232179485315559\n",
      "Scaled KL Loss is: 0.045906007289886475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2780854926054455\n",
      "NLL Loss is: 1.412557048772939\n",
      "Scaled KL Loss is: 0.04937882348895073\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4619358722618898\n",
      "NLL Loss is: 1.3385870842882464\n",
      "Scaled KL Loss is: 0.045873094350099564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.384460178638346\n",
      "NLL Loss is: 1.2962947497358386\n",
      "Scaled KL Loss is: 0.04654042050242424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3428351702382628\n",
      "NLL Loss is: 1.220372004122031\n",
      "Scaled KL Loss is: 0.04639542102813721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2667674251501682\n",
      "NLL Loss is: 1.326603830715179\n",
      "Scaled KL Loss is: 0.044380366802215576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3709841975173946\n",
      "NLL Loss is: 1.2557818602641702\n",
      "Scaled KL Loss is: 0.04517175629734993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.30095361656152\n",
      "NLL Loss is: 1.3328783711738934\n",
      "Scaled KL Loss is: 0.04431435465812683\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3771927258320202\n",
      "NLL Loss is: 1.2409390225097965\n",
      "Scaled KL Loss is: 0.0450863391160965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.286025361625893\n",
      "NLL Loss is: 1.5642788039180777\n",
      "Scaled KL Loss is: 0.04841864854097366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6126974524590514\n",
      "NLL Loss is: 1.136447372889359\n",
      "Scaled KL Loss is: 0.04578837752342224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1822357504127812\n",
      "NLL Loss is: 1.2758364365800523\n",
      "Scaled KL Loss is: 0.0494907982647419\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3253272348447942\n",
      "NLL Loss is: 1.3278590769747396\n",
      "Scaled KL Loss is: 0.05108194053173065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3789410175064702\n",
      "NLL Loss is: 1.116056567118023\n",
      "Scaled KL Loss is: 0.048524219542741776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1645807866607647\n",
      "NLL Loss is: 1.2733507970331686\n",
      "Scaled KL Loss is: 0.04738733172416687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3207381287573354\n",
      "NLL Loss is: 1.106424576820646\n",
      "Scaled KL Loss is: 0.04791455715894699\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.154339133979593\n",
      "NLL Loss is: 1.1613834055024845\n",
      "Scaled KL Loss is: 0.043572451919317245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2049558574218018\n",
      "NLL Loss is: 1.3225775601005103\n",
      "Scaled KL Loss is: 0.04703591763973236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3696134777402427\n",
      "NLL Loss is: 1.3371116800012495\n",
      "Scaled KL Loss is: 0.044923294335603714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3820349743368532\n",
      "NLL Loss is: 1.2345487267980024\n",
      "Scaled KL Loss is: 0.04532543197274208\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2798741587707445\n",
      "NLL Loss is: 1.4153631236989208\n",
      "Scaled KL Loss is: 0.045976925641298294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.461340049340219\n",
      "NLL Loss is: 1.4214798728242994\n",
      "Scaled KL Loss is: 0.045716479420661926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4671963522449614\n",
      "NLL Loss is: 1.2372200162576978\n",
      "Scaled KL Loss is: 0.05228370055556297\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2895037168132608\n",
      "NLL Loss is: 1.2057308617312683\n",
      "Scaled KL Loss is: 0.04915974661707878\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.254890608348347\n",
      "NLL Loss is: 1.3198199554598455\n",
      "Scaled KL Loss is: 0.04738232120871544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367202276668561\n",
      "NLL Loss is: 1.441227557434338\n",
      "Scaled KL Loss is: 0.04789755120873451\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4891251086430726\n",
      "NLL Loss is: 1.1732949145621512\n",
      "Scaled KL Loss is: 0.048468563705682755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.221763478267834\n",
      "NLL Loss is: 1.1769603663375015\n",
      "Scaled KL Loss is: 0.0435904823243618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2205508486618633\n",
      "NLL Loss is: 1.2110625085974194\n",
      "Scaled KL Loss is: 0.048552993685007095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2596155022824265\n",
      "NLL Loss is: 1.2194796205177403\n",
      "Scaled KL Loss is: 0.0542694516479969\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2737490721657372\n",
      "NLL Loss is: 1.2900831799520243\n",
      "Scaled KL Loss is: 0.04518818110227585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3352713610543\n",
      "NLL Loss is: 1.2175902597075605\n",
      "Scaled KL Loss is: 0.04921974241733551\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.266810002124896\n",
      "NLL Loss is: 1.2462114996655906\n",
      "Scaled KL Loss is: 0.05031879246234894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2965302921279396\n",
      "NLL Loss is: 1.1559484141388858\n",
      "Scaled KL Loss is: 0.051960237324237823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2079086514631237\n",
      "NLL Loss is: 1.2510920759124138\n",
      "Scaled KL Loss is: 0.04975152015686035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3008435960692741\n",
      "NLL Loss is: 1.1766716065996161\n",
      "Scaled KL Loss is: 0.04882508143782616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2254966880374423\n",
      "NLL Loss is: 1.264728868199741\n",
      "Scaled KL Loss is: 0.04961166903376579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3143405372335069\n",
      "NLL Loss is: 1.2974809033964438\n",
      "Scaled KL Loss is: 0.046469658613204956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3439505620096488\n",
      "NLL Loss is: 1.2015866150763899\n",
      "Scaled KL Loss is: 0.04995374754071236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2515403626171022\n",
      "NLL Loss is: 1.3099537953135936\n",
      "Scaled KL Loss is: 0.04616039991378784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3561141952273814\n",
      "NLL Loss is: 1.3834219029782522\n",
      "Scaled KL Loss is: 0.045676518231630325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4290984212098825\n",
      "NLL Loss is: 1.3702943425591565\n",
      "Scaled KL Loss is: 0.04474658891558647\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415040931474743\n",
      "NLL Loss is: 1.3793229942505736\n",
      "Scaled KL Loss is: 0.04918034002184868\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4285033342724223\n",
      "NLL Loss is: 1.23793626105002\n",
      "Scaled KL Loss is: 0.04718392714858055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2851201881986005\n",
      "NLL Loss is: 1.2175046765827215\n",
      "Scaled KL Loss is: 0.04477374628186226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2622784228645838\n",
      "NLL Loss is: 1.15634064470347\n",
      "Scaled KL Loss is: 0.050452928990125656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2067935736935957\n",
      "NLL Loss is: 1.251236911888064\n",
      "Scaled KL Loss is: 0.04839438199996948\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2996312938880334\n",
      "NLL Loss is: 1.2752602412830008\n",
      "Scaled KL Loss is: 0.047734908759593964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3229951500425947\n",
      "NLL Loss is: 1.361437249286778\n",
      "Scaled KL Loss is: 0.047148339450359344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4085855887371372\n",
      "NLL Loss is: 1.2711974861399578\n",
      "Scaled KL Loss is: 0.04763287305831909\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3188303591982768\n",
      "NLL Loss is: 1.259304341123386\n",
      "Scaled KL Loss is: 0.045029181987047195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3043335231104332\n",
      "NLL Loss is: 1.3706967391435854\n",
      "Scaled KL Loss is: 0.04626305401325226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4169597931568376\n",
      "NLL Loss is: 1.3774299760653823\n",
      "Scaled KL Loss is: 0.048028621822595596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425458597887978\n",
      "NLL Loss is: 1.3144369811046033\n",
      "Scaled KL Loss is: 0.046815209090709686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361252190195313\n",
      "NLL Loss is: 1.2754663032770681\n",
      "Scaled KL Loss is: 0.05051794275641441\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3259842460334825\n",
      "NLL Loss is: 1.2604869463215511\n",
      "Scaled KL Loss is: 0.04655595123767853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3070428975592296\n",
      "NLL Loss is: 1.431246764008526\n",
      "Scaled KL Loss is: 0.04753375053405762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4787805145425836\n",
      "NLL Loss is: 1.31118658972986\n",
      "Scaled KL Loss is: 0.0445227175951004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3557093073249604\n",
      "NLL Loss is: 1.2891617217387719\n",
      "Scaled KL Loss is: 0.05074722319841385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3399089449371857\n",
      "NLL Loss is: 1.318019629713898\n",
      "Scaled KL Loss is: 0.04814444109797478\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3661640708118727\n",
      "NLL Loss is: 1.3957813196689666\n",
      "Scaled KL Loss is: 0.04652192071080208\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4423032403797686\n",
      "NLL Loss is: 1.2586721264012277\n",
      "Scaled KL Loss is: 0.043538898229599\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3022110246308267\n",
      "NLL Loss is: 1.3837088463678444\n",
      "Scaled KL Loss is: 0.045076481997966766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4287853283658112\n",
      "NLL Loss is: 1.3872935283691752\n",
      "Scaled KL Loss is: 0.04560520499944687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432898733368622\n",
      "NLL Loss is: 1.3252368820521587\n",
      "Scaled KL Loss is: 0.04718071222305298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3724175942752117\n",
      "NLL Loss is: 1.2401450068919806\n",
      "Scaled KL Loss is: 0.04517790302634239\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.285322909918323\n",
      "NLL Loss is: 1.32779638678587\n",
      "Scaled KL Loss is: 0.04545673355460167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3732531203404716\n",
      "NLL Loss is: 1.1976968121987872\n",
      "Scaled KL Loss is: 0.04884456470608711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2465413769048743\n",
      "NLL Loss is: 1.335714730722336\n",
      "Scaled KL Loss is: 0.04290797561407089\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.378622706336407\n",
      "NLL Loss is: 1.195047494044006\n",
      "Scaled KL Loss is: 0.048975493758916855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2440229878029228\n",
      "NLL Loss is: 1.3188070680145256\n",
      "Scaled KL Loss is: 0.047754354774951935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3665614227894776\n",
      "NLL Loss is: 1.4072256494015818\n",
      "Scaled KL Loss is: 0.04473106935620308\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4519567187577849\n",
      "NLL Loss is: 1.3315036527624513\n",
      "Scaled KL Loss is: 0.04330073669552803\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3748043894579793\n",
      "NLL Loss is: 1.2649071063867594\n",
      "Scaled KL Loss is: 0.048622339963912964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3135294463506724\n",
      "NLL Loss is: 1.2228756519163644\n",
      "Scaled KL Loss is: 0.04498375207185745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2678594039882218\n",
      "NLL Loss is: 1.4207997627448927\n",
      "Scaled KL Loss is: 0.04580080509185791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4666005678367506\n",
      "NLL Loss is: 1.2593816168024055\n",
      "Scaled KL Loss is: 0.04702237993478775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3064039967371932\n",
      "NLL Loss is: 1.6632494568605158\n",
      "Scaled KL Loss is: 0.037724561989307404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7009740188498232\n",
      "NLL Loss is: 1.320015801090065 = 1.338; test loss = 1.375\n",
      "Scaled KL Loss is: 0.04835177958011627\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3683675806701814\n",
      "NLL Loss is: 1.3203729317456248\n",
      "Scaled KL Loss is: 0.04553160071372986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3659045324593546\n",
      "NLL Loss is: 1.3433035409456795\n",
      "Scaled KL Loss is: 0.04732183367013931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3906253746158188\n",
      "NLL Loss is: 1.368391976646102\n",
      "Scaled KL Loss is: 0.04932611435651779\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4177180910026197\n",
      "NLL Loss is: 1.324451209013767\n",
      "Scaled KL Loss is: 0.04292628541588783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3673774944296548\n",
      "NLL Loss is: 1.354782185084755\n",
      "Scaled KL Loss is: 0.04825888201594353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4030410671006985\n",
      "NLL Loss is: 1.3770288059653426\n",
      "Scaled KL Loss is: 0.04300070181488991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4200295077802325\n",
      "NLL Loss is: 1.314698268174106\n",
      "Scaled KL Loss is: 0.044004153460264206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3587024216343702\n",
      "NLL Loss is: 1.3781935798665799\n",
      "Scaled KL Loss is: 0.04274642467498779\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4209400045415677\n",
      "NLL Loss is: 1.2390909662095981\n",
      "Scaled KL Loss is: 0.04928727447986603\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2883782406894642\n",
      "NLL Loss is: 1.2540453265689635\n",
      "Scaled KL Loss is: 0.043110188096761703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2971555146657252\n",
      "NLL Loss is: 1.3933595860574055\n",
      "Scaled KL Loss is: 0.04582248628139496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4391820723388005\n",
      "NLL Loss is: 1.224014263649218\n",
      "Scaled KL Loss is: 0.049357157200574875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2733714208497928\n",
      "NLL Loss is: 1.424624731660632\n",
      "Scaled KL Loss is: 0.04697832465171814\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.47160305631235\n",
      "NLL Loss is: 1.2310958698614298\n",
      "Scaled KL Loss is: 0.045959021896123886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2770548917575537\n",
      "NLL Loss is: 1.4110180202517073\n",
      "Scaled KL Loss is: 0.049515560269355774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.460533580521063\n",
      "NLL Loss is: 1.3366888080693662\n",
      "Scaled KL Loss is: 0.04600264132022858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3826914493895948\n",
      "NLL Loss is: 1.2946598912259055\n",
      "Scaled KL Loss is: 0.046602439135313034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3412623303612186\n",
      "NLL Loss is: 1.218498008420992\n",
      "Scaled KL Loss is: 0.04650488123297691\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265002889653969\n",
      "NLL Loss is: 1.3246441183668691\n",
      "Scaled KL Loss is: 0.04449166730046272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3691357856673319\n",
      "NLL Loss is: 1.2539746280221202\n",
      "Scaled KL Loss is: 0.04520907253026962\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2991837005523899\n",
      "NLL Loss is: 1.3309475636406145\n",
      "Scaled KL Loss is: 0.04445703327655792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3754045969171724\n",
      "NLL Loss is: 1.2390891355774754\n",
      "Scaled KL Loss is: 0.045220788568258286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2843099241457336\n",
      "NLL Loss is: 1.5632207882838396\n",
      "Scaled KL Loss is: 0.04849093779921532\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.611711726083055\n",
      "NLL Loss is: 1.1353250642346566\n",
      "Scaled KL Loss is: 0.045875899493694305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.181200963728351\n",
      "NLL Loss is: 1.2743347443987922\n",
      "Scaled KL Loss is: 0.049577496945858\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3239122413446502\n",
      "NLL Loss is: 1.3263495850724665\n",
      "Scaled KL Loss is: 0.05118877813220024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3775383632046667\n",
      "NLL Loss is: 1.114503805541821\n",
      "Scaled KL Loss is: 0.04864782840013504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.163151633941956\n",
      "NLL Loss is: 1.2714379558070241\n",
      "Scaled KL Loss is: 0.047485727816820145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3189236836238443\n",
      "NLL Loss is: 1.104490336801308\n",
      "Scaled KL Loss is: 0.04801028221845627\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1525006190197642\n",
      "NLL Loss is: 1.1599503143672183\n",
      "Scaled KL Loss is: 0.04363483190536499\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2035851462725833\n",
      "NLL Loss is: 1.321168418227846\n",
      "Scaled KL Loss is: 0.047117628157138824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3682860463849849\n",
      "NLL Loss is: 1.3354348490870505\n",
      "Scaled KL Loss is: 0.04498153179883957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.38041638088589\n",
      "NLL Loss is: 1.2337106475035544\n",
      "Scaled KL Loss is: 0.045389916747808456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2791005642513629\n",
      "NLL Loss is: 1.414501010249017\n",
      "Scaled KL Loss is: 0.046052493155002594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4605535034040196\n",
      "NLL Loss is: 1.4193159772601533\n",
      "Scaled KL Loss is: 0.0457703098654747\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.465086287125628\n",
      "NLL Loss is: 1.236120982886741\n",
      "Scaled KL Loss is: 0.052326444536447525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2884474274231885\n",
      "NLL Loss is: 1.2049090349708853\n",
      "Scaled KL Loss is: 0.04927302151918411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2541820564900694\n",
      "NLL Loss is: 1.3187313340408304\n",
      "Scaled KL Loss is: 0.04746505990624428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3661963939470747\n",
      "NLL Loss is: 1.440199146833157\n",
      "Scaled KL Loss is: 0.047943923622369766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4881430704555267\n",
      "NLL Loss is: 1.1714685711854704\n",
      "Scaled KL Loss is: 0.048541102558374405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2200096737438448\n",
      "NLL Loss is: 1.1752932565662686\n",
      "Scaled KL Loss is: 0.04366305097937584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2189563075456444\n",
      "NLL Loss is: 1.2098920649518277\n",
      "Scaled KL Loss is: 0.04867362976074219\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2585656947125698\n",
      "NLL Loss is: 1.2181197056932918\n",
      "Scaled KL Loss is: 0.05429929494857788\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2724190006418696\n",
      "NLL Loss is: 1.2887381174487407\n",
      "Scaled KL Loss is: 0.04522235691547394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3339604743642146\n",
      "NLL Loss is: 1.2163511304592867\n",
      "Scaled KL Loss is: 0.04930892959237099\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2656600600516577\n",
      "NLL Loss is: 1.2453776697344585\n",
      "Scaled KL Loss is: 0.05037481337785721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2957524831123157\n",
      "NLL Loss is: 1.1544206660799112\n",
      "Scaled KL Loss is: 0.0520978644490242\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2065185305289354\n",
      "NLL Loss is: 1.250155388853053\n",
      "Scaled KL Loss is: 0.04978114366531372\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2999365325183667\n",
      "NLL Loss is: 1.1753105050924786\n",
      "Scaled KL Loss is: 0.04888525977730751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.224195764869786\n",
      "NLL Loss is: 1.2636695492273227\n",
      "Scaled KL Loss is: 0.04967772960662842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.313347278833951\n",
      "NLL Loss is: 1.2961252799469631\n",
      "Scaled KL Loss is: 0.0464869886636734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3426122686106365\n",
      "NLL Loss is: 1.2003686380385354\n",
      "Scaled KL Loss is: 0.049958858639001846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2503274966775373\n",
      "NLL Loss is: 1.3086398158932064\n",
      "Scaled KL Loss is: 0.046257562935352325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3548973788285588\n",
      "NLL Loss is: 1.38219053134556\n",
      "Scaled KL Loss is: 0.045713670551776886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.427904201897337\n",
      "NLL Loss is: 1.3684617598676374\n",
      "Scaled KL Loss is: 0.04480348154902458\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.413265241416662\n",
      "NLL Loss is: 1.3783975496694785\n",
      "Scaled KL Loss is: 0.0492006354033947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4275981850728732\n",
      "NLL Loss is: 1.2369845843448284\n",
      "Scaled KL Loss is: 0.047192156314849854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2841767406596782\n",
      "NLL Loss is: 1.2154483761038757\n",
      "Scaled KL Loss is: 0.04484633728861809\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2602947133924938\n",
      "NLL Loss is: 1.1551220259292534\n",
      "Scaled KL Loss is: 0.0504663921892643\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2055884181185177\n",
      "NLL Loss is: 1.2500867457331213\n",
      "Scaled KL Loss is: 0.04847269132733345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2985594370604547\n",
      "NLL Loss is: 1.273655567288865\n",
      "Scaled KL Loss is: 0.0477740578353405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3214296251242055\n",
      "NLL Loss is: 1.3594059646499046\n",
      "Scaled KL Loss is: 0.04719078913331032\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.406596753783215\n",
      "NLL Loss is: 1.2703257643292074\n",
      "Scaled KL Loss is: 0.047750648111104965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3180764124403124\n",
      "NLL Loss is: 1.2576189707528374\n",
      "Scaled KL Loss is: 0.04508417844772339\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3027031492005607\n",
      "NLL Loss is: 1.369293890666997\n",
      "Scaled KL Loss is: 0.046324603259563446\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4156184939265604\n",
      "NLL Loss is: 1.3763436192184786\n",
      "Scaled KL Loss is: 0.048138976097106934\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4244825953155855\n",
      "NLL Loss is: 1.3131096842945817\n",
      "Scaled KL Loss is: 0.046858515590429306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359968199885011\n",
      "NLL Loss is: 1.2737306097440335\n",
      "Scaled KL Loss is: 0.05057740956544876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3243080193094823\n",
      "NLL Loss is: 1.258583249420739\n",
      "Scaled KL Loss is: 0.046625375747680664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3052086251684196\n",
      "NLL Loss is: 1.4299143040377504\n",
      "Scaled KL Loss is: 0.047606486827135086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4775207908648855\n",
      "NLL Loss is: 1.3097830760415496\n",
      "Scaled KL Loss is: 0.04461026191711426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354393337958664\n",
      "NLL Loss is: 1.2881156710733357\n",
      "Scaled KL Loss is: 0.05083874240517616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3389544134785119\n",
      "NLL Loss is: 1.316839237398222\n",
      "Scaled KL Loss is: 0.04824477434158325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3650840117398053\n",
      "NLL Loss is: 1.3940528170029154\n",
      "Scaled KL Loss is: 0.04661286622285843\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4406656832257738\n",
      "NLL Loss is: 1.2574387201318622\n",
      "Scaled KL Loss is: 0.0436217300593853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3010604501912475\n",
      "NLL Loss is: 1.3825766761836866\n",
      "Scaled KL Loss is: 0.0451199896633625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4276966658470491\n",
      "NLL Loss is: 1.385948801525963\n",
      "Scaled KL Loss is: 0.045717790722846985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4316665922488099\n",
      "NLL Loss is: 1.324930404293939\n",
      "Scaled KL Loss is: 0.04720202460885048\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3721324289027894\n",
      "NLL Loss is: 1.2387772277691993\n",
      "Scaled KL Loss is: 0.045233555138111115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840107829073104\n",
      "NLL Loss is: 1.3264210617053265\n",
      "Scaled KL Loss is: 0.04553064703941345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37195170874474\n",
      "NLL Loss is: 1.1960295354640027\n",
      "Scaled KL Loss is: 0.04893157258629799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2449611080503007\n",
      "NLL Loss is: 1.334900432187149\n",
      "Scaled KL Loss is: 0.04296364262700081\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3778640748141497\n",
      "NLL Loss is: 1.1938498037934193\n",
      "Scaled KL Loss is: 0.04903656244277954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2428863662361989\n",
      "NLL Loss is: 1.3168457405174916\n",
      "Scaled KL Loss is: 0.047810882329940796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3646566228474324\n",
      "NLL Loss is: 1.4055905677413705\n",
      "Scaled KL Loss is: 0.04483900964260101\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4504295773839715\n",
      "NLL Loss is: 1.3302824009877878\n",
      "Scaled KL Loss is: 0.04338006302714348\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3736624640149313\n",
      "NLL Loss is: 1.2626947459460327\n",
      "Scaled KL Loss is: 0.04869197681546211\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3113867227614948\n",
      "NLL Loss is: 1.2217370329353963\n",
      "Scaled KL Loss is: 0.04508502408862114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2668220570240174\n",
      "NLL Loss is: 1.4198363655851332\n",
      "Scaled KL Loss is: 0.045903339982032776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.465739705567166\n",
      "NLL Loss is: 1.2580445274180962\n",
      "Scaled KL Loss is: 0.04712000861763954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3051645360357358\n",
      "NLL Loss is: 1.6633698213321868\n",
      "Scaled KL Loss is: 0.03780241310596466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7011722344381515\n",
      "NLL Loss is: 1.3193282763801193= 1.336; test loss = 1.374\n",
      "Scaled KL Loss is: 0.0484180711209774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3677463475010967\n",
      "NLL Loss is: 1.3190347051335614\n",
      "Scaled KL Loss is: 0.04561854898929596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3646532541228573\n",
      "NLL Loss is: 1.3416172232107126\n",
      "Scaled KL Loss is: 0.04740951955318451\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3890267427638971\n",
      "NLL Loss is: 1.3674212117295812\n",
      "Scaled KL Loss is: 0.04935171455144882\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.41677292628103\n",
      "NLL Loss is: 1.3229446927351194\n",
      "Scaled KL Loss is: 0.04300539940595627\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3659500921410757\n",
      "NLL Loss is: 1.3534082498379252\n",
      "Scaled KL Loss is: 0.04834182187914848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4017500717170737\n",
      "NLL Loss is: 1.37566693630646\n",
      "Scaled KL Loss is: 0.04311163350939751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4187785698158575\n",
      "NLL Loss is: 1.3136866451589742\n",
      "Scaled KL Loss is: 0.04406819865107536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3577548438100495\n",
      "NLL Loss is: 1.3775275322814562\n",
      "Scaled KL Loss is: 0.042793385684490204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4203209179659464\n",
      "NLL Loss is: 1.2378918300015243\n",
      "Scaled KL Loss is: 0.049347296357154846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.287239126358679\n",
      "NLL Loss is: 1.2521943805633051\n",
      "Scaled KL Loss is: 0.04312587529420853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2953202558575136\n",
      "NLL Loss is: 1.392333566667888\n",
      "Scaled KL Loss is: 0.045914020389318466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4382475870572065\n",
      "NLL Loss is: 1.2227013354187648\n",
      "Scaled KL Loss is: 0.04945741593837738\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2721587513571422\n",
      "NLL Loss is: 1.4223799471119007\n",
      "Scaled KL Loss is: 0.04704516381025314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4694251109221539\n",
      "NLL Loss is: 1.2299464998599061\n",
      "Scaled KL Loss is: 0.0460507906973362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2759972905572423\n",
      "NLL Loss is: 1.409635479335431\n",
      "Scaled KL Loss is: 0.04967528581619263\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4593107651516237\n",
      "NLL Loss is: 1.3347848799834572\n",
      "Scaled KL Loss is: 0.04615209996700287\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.38093697995046\n",
      "NLL Loss is: 1.293085379188382\n",
      "Scaled KL Loss is: 0.04669013246893883\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.339775511657321\n",
      "NLL Loss is: 1.2168261761396142\n",
      "Scaled KL Loss is: 0.046633217483758926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2634593936233731\n",
      "NLL Loss is: 1.32296302430207\n",
      "Scaled KL Loss is: 0.04461400955915451\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3675770338612245\n",
      "NLL Loss is: 1.2520194045054738\n",
      "Scaled KL Loss is: 0.04526885226368904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2972882567691628\n",
      "NLL Loss is: 1.3290757961428428\n",
      "Scaled KL Loss is: 0.04461528733372688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3736910834765697\n",
      "NLL Loss is: 1.237223987418737\n",
      "Scaled KL Loss is: 0.045370038598775864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2825940260175128\n",
      "NLL Loss is: 1.5623521414920183\n",
      "Scaled KL Loss is: 0.04857216402888298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6109243055209013\n",
      "NLL Loss is: 1.1342137229359621\n",
      "Scaled KL Loss is: 0.0459723062813282\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1801860292172903\n",
      "NLL Loss is: 1.2729443714590594\n",
      "Scaled KL Loss is: 0.049675729125738144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3226201005847975\n",
      "NLL Loss is: 1.3249179416036514\n",
      "Scaled KL Loss is: 0.05130640044808388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3762243420517353\n",
      "NLL Loss is: 1.112631492582228\n",
      "Scaled KL Loss is: 0.04877389967441559\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1614053922566436\n",
      "NLL Loss is: 1.2697289417693929\n",
      "Scaled KL Loss is: 0.04758948087692261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3173184226463155\n",
      "NLL Loss is: 1.1026760995799236\n",
      "Scaled KL Loss is: 0.04811260104179382\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1507887006217175\n",
      "NLL Loss is: 1.1585710236217208\n",
      "Scaled KL Loss is: 0.04370025172829628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.202271275350017\n",
      "NLL Loss is: 1.320024673222001\n",
      "Scaled KL Loss is: 0.04718964174389839\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3672143149658993\n",
      "NLL Loss is: 1.3332157953130952\n",
      "Scaled KL Loss is: 0.04503844678401947\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3782542420971147\n",
      "NLL Loss is: 1.2330786231538287\n",
      "Scaled KL Loss is: 0.04545260965824127\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27853123281207\n",
      "NLL Loss is: 1.4138642186973698\n",
      "Scaled KL Loss is: 0.04611578956246376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4599800082598335\n",
      "NLL Loss is: 1.4173083962886728\n",
      "Scaled KL Loss is: 0.045806314796209335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4631147110848821\n",
      "NLL Loss is: 1.234931099150418\n",
      "Scaled KL Loss is: 0.05234618857502937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2872772877254475\n",
      "NLL Loss is: 1.2042223897713091\n",
      "Scaled KL Loss is: 0.04936615377664566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2535885435479548\n",
      "NLL Loss is: 1.3177212000486112\n",
      "Scaled KL Loss is: 0.04752287268638611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3652440727349973\n",
      "NLL Loss is: 1.4392259212057161\n",
      "Scaled KL Loss is: 0.047959472984075546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4871853941897917\n",
      "NLL Loss is: 1.1699219737237743\n",
      "Scaled KL Loss is: 0.048579152673482895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2185011263972572\n",
      "NLL Loss is: 1.1737709222355017\n",
      "Scaled KL Loss is: 0.04370735585689545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2174782780923972\n",
      "NLL Loss is: 1.2088094672063001\n",
      "Scaled KL Loss is: 0.048772066831588745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2575815340378889\n",
      "NLL Loss is: 1.2165532427626289\n",
      "Scaled KL Loss is: 0.05429358780384064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2708468305664695\n",
      "NLL Loss is: 1.2875334225573567\n",
      "Scaled KL Loss is: 0.04522396996617317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3327573925235299\n",
      "NLL Loss is: 1.2153018932288435\n",
      "Scaled KL Loss is: 0.049369633197784424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.264671526426628\n",
      "NLL Loss is: 1.2446168471333534\n",
      "Scaled KL Loss is: 0.05039830505847931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2950151521918327\n",
      "NLL Loss is: 1.1529203563543284\n",
      "Scaled KL Loss is: 0.05221208930015564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.205132445654484\n",
      "NLL Loss is: 1.249393507092403\n",
      "Scaled KL Loss is: 0.049781445413827896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2991749525062308\n",
      "NLL Loss is: 1.1741136955816558\n",
      "Scaled KL Loss is: 0.04891715571284294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2230308512944987\n",
      "NLL Loss is: 1.2626613753289713\n",
      "Scaled KL Loss is: 0.04971972852945328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3123811038584245\n",
      "NLL Loss is: 1.2949493598784574\n",
      "Scaled KL Loss is: 0.04647280275821686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3414221626366742\n",
      "NLL Loss is: 1.1992706648474032\n",
      "Scaled KL Loss is: 0.04994242638349533\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2492130912308985\n",
      "NLL Loss is: 1.3074515110304619\n",
      "Scaled KL Loss is: 0.046337418258190155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353788929288652\n",
      "NLL Loss is: 1.3810894345268747\n",
      "Scaled KL Loss is: 0.04573352634906769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4268229608759424\n",
      "NLL Loss is: 1.36670800453757\n",
      "Scaled KL Loss is: 0.044836971908807755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4115449764463777\n",
      "NLL Loss is: 1.3776537150122703\n",
      "Scaled KL Loss is: 0.04920176789164543\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4268554829039157\n",
      "NLL Loss is: 1.2362681157705646\n",
      "Scaled KL Loss is: 0.04718112200498581\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2834492377755504\n",
      "NLL Loss is: 1.2135570907861928\n",
      "Scaled KL Loss is: 0.04489494860172272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2584520393879155\n",
      "NLL Loss is: 1.1539514339464514\n",
      "Scaled KL Loss is: 0.05044960230588913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2044010362523405\n",
      "NLL Loss is: 1.2489046128365409\n",
      "Scaled KL Loss is: 0.04852600768208504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297430620518626\n",
      "NLL Loss is: 1.2718440454120974\n",
      "Scaled KL Loss is: 0.04777964577078819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3196236911828856\n",
      "NLL Loss is: 1.3574371267608287\n",
      "Scaled KL Loss is: 0.04720437526702881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4046415020278575\n",
      "NLL Loss is: 1.2694551775179017\n",
      "Scaled KL Loss is: 0.04783860221505165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3172937797329534\n",
      "NLL Loss is: 1.2560509557760289\n",
      "Scaled KL Loss is: 0.045097801834344864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3011487576103737\n",
      "NLL Loss is: 1.3681167776269223\n",
      "Scaled KL Loss is: 0.046351637691259384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4144684153181817\n",
      "NLL Loss is: 1.3752155894945304\n",
      "Scaled KL Loss is: 0.04823087900876999\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4234464685033004\n",
      "NLL Loss is: 1.3118970213087204\n",
      "Scaled KL Loss is: 0.0468624047935009\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3587594261022213\n",
      "NLL Loss is: 1.2721728722667605\n",
      "Scaled KL Loss is: 0.050596173852682114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3227690461194426\n",
      "NLL Loss is: 1.2567447723708915\n",
      "Scaled KL Loss is: 0.04665389284491539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303398665215807\n",
      "NLL Loss is: 1.4284251087475157\n",
      "Scaled KL Loss is: 0.0476468950510025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4760720037985182\n",
      "NLL Loss is: 1.3083441292274305\n",
      "Scaled KL Loss is: 0.04466280713677406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3530069363642045\n",
      "NLL Loss is: 1.287200371421852\n",
      "Scaled KL Loss is: 0.05088600143790245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3380863728597545\n",
      "NLL Loss is: 1.3157544015583482\n",
      "Scaled KL Loss is: 0.04830707982182503\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3640614813801732\n",
      "NLL Loss is: 1.3926387364726764\n",
      "Scaled KL Loss is: 0.04666630178689957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.439305038259576\n",
      "NLL Loss is: 1.2563156262035753\n",
      "Scaled KL Loss is: 0.04366740956902504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2999830357726003\n",
      "NLL Loss is: 1.3816171987966819\n",
      "Scaled KL Loss is: 0.04512065276503563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4267378515617175\n",
      "NLL Loss is: 1.3845885534434585\n",
      "Scaled KL Loss is: 0.04579640179872513\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4303849552421837\n",
      "NLL Loss is: 1.3246836481677469\n",
      "Scaled KL Loss is: 0.047179508954286575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3718631571220334\n",
      "NLL Loss is: 1.2374481432087812\n",
      "Scaled KL Loss is: 0.04524620249867439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2826943457074556\n",
      "NLL Loss is: 1.324961398426308\n",
      "Scaled KL Loss is: 0.04557028040289879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3705316788292068\n",
      "NLL Loss is: 1.1944594815638183\n",
      "Scaled KL Loss is: 0.04897654429078102\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2434360258545993\n",
      "NLL Loss is: 1.334156036501205\n",
      "Scaled KL Loss is: 0.04297918826341629\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3771352247646214\n",
      "NLL Loss is: 1.192899042183634\n",
      "Scaled KL Loss is: 0.04906180128455162\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2419608434681857\n",
      "NLL Loss is: 1.3150160832239361\n",
      "Scaled KL Loss is: 0.047822006046772\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3628380892707082\n",
      "NLL Loss is: 1.4038290481512474\n",
      "Scaled KL Loss is: 0.04492028057575226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4487493287269997\n",
      "NLL Loss is: 1.3290528619449464\n",
      "Scaled KL Loss is: 0.04342801123857498\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3724808731835214\n",
      "NLL Loss is: 1.2607510091804046\n",
      "Scaled KL Loss is: 0.04871594160795212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3094669507883567\n",
      "NLL Loss is: 1.2207699991248568\n",
      "Scaled KL Loss is: 0.04515146464109421\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265921463765951\n",
      "NLL Loss is: 1.4189091101247107\n",
      "Scaled KL Loss is: 0.045968931168317795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4648780412930285\n",
      "NLL Loss is: 1.256840345765919\n",
      "Scaled KL Loss is: 0.04718128219246864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3040216279583876\n",
      "NLL Loss is: 1.663352140368183\n",
      "Scaled KL Loss is: 0.037846095860004425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7011982362281874\n",
      "NLL Loss is: 1.3186696983414294= 1.335; test loss = 1.373\n",
      "Scaled KL Loss is: 0.048444584012031555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367114282353461\n",
      "NLL Loss is: 1.3178421416770107\n",
      "Scaled KL Loss is: 0.04566735774278641\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3635094994197972\n",
      "NLL Loss is: 1.3401443235858854\n",
      "Scaled KL Loss is: 0.047455742955207825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3876000665410932\n",
      "NLL Loss is: 1.3664732543345297\n",
      "Scaled KL Loss is: 0.04933660849928856\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4158098628338183\n",
      "NLL Loss is: 1.3214751139983232\n",
      "Scaled KL Loss is: 0.043055541813373566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3645306558116967\n",
      "NLL Loss is: 1.3520144941235674\n",
      "Scaled KL Loss is: 0.048397719860076904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4004122139836443\n",
      "NLL Loss is: 1.3743470650251126\n",
      "Scaled KL Loss is: 0.04320330545306206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4175503704781747\n",
      "NLL Loss is: 1.3128188957323277\n",
      "Scaled KL Loss is: 0.04411051794886589\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569294136811936\n",
      "NLL Loss is: 1.3769388769810558\n",
      "Scaled KL Loss is: 0.0428164042532444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4197552812343002\n",
      "NLL Loss is: 1.2367692660152414\n",
      "Scaled KL Loss is: 0.04938197880983353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.286151244825075\n",
      "NLL Loss is: 1.2506667079342557\n",
      "Scaled KL Loss is: 0.04311870411038399\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2937854120446397\n",
      "NLL Loss is: 1.3913545448995044\n",
      "Scaled KL Loss is: 0.04598380997776985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4373383548772742\n",
      "NLL Loss is: 1.2214636142474198\n",
      "Scaled KL Loss is: 0.04953032732009888\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2709939415675187\n",
      "NLL Loss is: 1.4206632695566666\n",
      "Scaled KL Loss is: 0.0470849834382534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.46774825299492\n",
      "NLL Loss is: 1.2289262604207922\n",
      "Scaled KL Loss is: 0.046114563941955566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2750408243627478\n",
      "NLL Loss is: 1.4083612956571043\n",
      "Scaled KL Loss is: 0.04980786144733429\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4581691571044386\n",
      "NLL Loss is: 1.3329652276413142\n",
      "Scaled KL Loss is: 0.04627599939703941\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3792412270383536\n",
      "NLL Loss is: 1.2916893338330382\n",
      "Scaled KL Loss is: 0.046750862151384354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3384401959844225\n",
      "NLL Loss is: 1.2152425430222176\n",
      "Scaled KL Loss is: 0.04672936722636223\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2619719102485798\n",
      "NLL Loss is: 1.3213010355295591\n",
      "Scaled KL Loss is: 0.04471283033490181\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.366013865864461\n",
      "NLL Loss is: 1.2502930221651842\n",
      "Scaled KL Loss is: 0.045295294374227524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2955883165394118\n",
      "NLL Loss is: 1.3272881845768694\n",
      "Scaled KL Loss is: 0.04474303498864174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.372031219565511\n",
      "NLL Loss is: 1.2355711116201658\n",
      "Scaled KL Loss is: 0.045488569885492325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.281059681505658\n",
      "NLL Loss is: 1.5613644729039686\n",
      "Scaled KL Loss is: 0.04861508682370186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6099795597276705\n",
      "NLL Loss is: 1.133154524138059\n",
      "Scaled KL Loss is: 0.04603286460042\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.179187388738479\n",
      "NLL Loss is: 1.271704610400639\n",
      "Scaled KL Loss is: 0.049732331186532974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.321436941587172\n",
      "NLL Loss is: 1.3235842382602794\n",
      "Scaled KL Loss is: 0.05138382315635681\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3749680614166362\n",
      "NLL Loss is: 1.1110966072524204\n",
      "Scaled KL Loss is: 0.04886366426944733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1599602715218678\n",
      "NLL Loss is: 1.2681493036252725\n",
      "Scaled KL Loss is: 0.04765642434358597\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3158057279688584\n",
      "NLL Loss is: 1.101074429487288\n",
      "Scaled KL Loss is: 0.048174899071455\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.149249328558743\n",
      "NLL Loss is: 1.1572040289857213\n",
      "Scaled KL Loss is: 0.043720681220293045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2009247102060143\n",
      "NLL Loss is: 1.318733218589622\n",
      "Scaled KL Loss is: 0.04722520709037781\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3659584256799997\n",
      "NLL Loss is: 1.3314974101520474\n",
      "Scaled KL Loss is: 0.04504361003637314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3765410201884205\n",
      "NLL Loss is: 1.2324284493296327\n",
      "Scaled KL Loss is: 0.0454658679664135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2778943172960462\n",
      "NLL Loss is: 1.4131737293586841\n",
      "Scaled KL Loss is: 0.04613565653562546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4593093858943096\n",
      "NLL Loss is: 1.415503529691767\n",
      "Scaled KL Loss is: 0.045799996703863144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4613035263956302\n",
      "NLL Loss is: 1.2335217234723665\n",
      "Scaled KL Loss is: 0.05231305956840515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2858347830407717\n",
      "NLL Loss is: 1.2036741003124025\n",
      "Scaled KL Loss is: 0.04942138493061066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2530954852430132\n",
      "NLL Loss is: 1.3170704417228882\n",
      "Scaled KL Loss is: 0.04754815995693207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3646186016798203\n",
      "NLL Loss is: 1.438499805909277\n",
      "Scaled KL Loss is: 0.047939661890268326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4864394677995454\n",
      "NLL Loss is: 1.168206866459572\n",
      "Scaled KL Loss is: 0.04858756810426712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.216794434563839\n",
      "NLL Loss is: 1.172510183810598\n",
      "Scaled KL Loss is: 0.04372384399175644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2162340278023545\n",
      "NLL Loss is: 1.2076296601898695\n",
      "Scaled KL Loss is: 0.048846423625946045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2564760838158155\n",
      "NLL Loss is: 1.214676471040852\n",
      "Scaled KL Loss is: 0.05425821244716644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2689346834880184\n",
      "NLL Loss is: 1.2862843516707003\n",
      "Scaled KL Loss is: 0.04520166665315628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3314860183238566\n",
      "NLL Loss is: 1.214241604283437\n",
      "Scaled KL Loss is: 0.049408044666051865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2636496489494888\n",
      "NLL Loss is: 1.244011929165156\n",
      "Scaled KL Loss is: 0.050389956682920456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2944018858480764\n",
      "NLL Loss is: 1.1515187099639648\n",
      "Scaled KL Loss is: 0.052303969860076904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2038226798240417\n",
      "NLL Loss is: 1.2486913304663818\n",
      "Scaled KL Loss is: 0.049758180975914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2984495114422958\n",
      "NLL Loss is: 1.1729846423906656\n",
      "Scaled KL Loss is: 0.04892680048942566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2219114428800912\n",
      "NLL Loss is: 1.2619754955779594\n",
      "Scaled KL Loss is: 0.04973552003502846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3117110156129879\n",
      "NLL Loss is: 1.2936813635785251\n",
      "Scaled KL Loss is: 0.0464349165558815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3401162801344066\n",
      "NLL Loss is: 1.19824435707558\n",
      "Scaled KL Loss is: 0.04990195482969284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.248146311905273\n",
      "NLL Loss is: 1.3062589246104885\n",
      "Scaled KL Loss is: 0.046391069889068604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3526499944995571\n",
      "NLL Loss is: 1.379982507808365\n",
      "Scaled KL Loss is: 0.045730385929346085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425712893737711\n",
      "NLL Loss is: 1.3650204602194171\n",
      "Scaled KL Loss is: 0.04485148936510086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.409871949584518\n",
      "NLL Loss is: 1.3767665542886807\n",
      "Scaled KL Loss is: 0.049180448055267334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425947002343948\n",
      "NLL Loss is: 1.235667198915812\n",
      "Scaled KL Loss is: 0.04714842140674591\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2828156203225578\n",
      "NLL Loss is: 1.2117681158309421\n",
      "Scaled KL Loss is: 0.044926051050424576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2566941668813667\n",
      "NLL Loss is: 1.152876464336436\n",
      "Scaled KL Loss is: 0.05041283369064331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2032892980270793\n",
      "NLL Loss is: 1.248062133217699\n",
      "Scaled KL Loss is: 0.048556502908468246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2966186361261673\n",
      "NLL Loss is: 1.2702654402054947\n",
      "Scaled KL Loss is: 0.04776718467473984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3180326248802345\n",
      "NLL Loss is: 1.3554140896565292\n",
      "Scaled KL Loss is: 0.04720202833414078\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40261611799067\n",
      "NLL Loss is: 1.26880469346733\n",
      "Scaled KL Loss is: 0.04791100695729256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3167157004246226\n",
      "NLL Loss is: 1.2545965512508692\n",
      "Scaled KL Loss is: 0.04510180279612541\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2996983540469946\n",
      "NLL Loss is: 1.3666270496778958\n",
      "Scaled KL Loss is: 0.04636046662926674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4129875163071626\n",
      "NLL Loss is: 1.3741082416746537\n",
      "Scaled KL Loss is: 0.04829614609479904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4224043877694528\n",
      "NLL Loss is: 1.3108013381338894\n",
      "Scaled KL Loss is: 0.04684620723128319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3576475453651726\n",
      "NLL Loss is: 1.2706459935461372\n",
      "Scaled KL Loss is: 0.050591763108968735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.321237756655106\n",
      "NLL Loss is: 1.254912334412037\n",
      "Scaled KL Loss is: 0.046666402369737625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3015787367817746\n",
      "NLL Loss is: 1.4271026190048488\n",
      "Scaled KL Loss is: 0.04766537621617317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.474767995221022\n",
      "NLL Loss is: 1.307101438707395\n",
      "Scaled KL Loss is: 0.04469350352883339\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3517949422362283\n",
      "NLL Loss is: 1.2864260348717147\n",
      "Scaled KL Loss is: 0.050913017243146896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3373390521148616\n",
      "NLL Loss is: 1.3146304477275816\n",
      "Scaled KL Loss is: 0.04834955185651779\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3629799995840994\n",
      "NLL Loss is: 1.3913149025915608\n",
      "Scaled KL Loss is: 0.046698879450559616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4380137820421204\n",
      "NLL Loss is: 1.255332491382587\n",
      "Scaled KL Loss is: 0.04369354620575905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.299026037588346\n",
      "NLL Loss is: 1.3807054312282248\n",
      "Scaled KL Loss is: 0.045101191848516464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4258066230767412\n",
      "NLL Loss is: 1.3831765769829383\n",
      "Scaled KL Loss is: 0.045856308192014694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.429032885174953\n",
      "NLL Loss is: 1.3245147935655341\n",
      "Scaled KL Loss is: 0.047134265303611755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371649058869146\n",
      "NLL Loss is: 1.2361809430909891\n",
      "Scaled KL Loss is: 0.04523627832531929\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2814172214163084\n",
      "NLL Loss is: 1.3236998039489063\n",
      "Scaled KL Loss is: 0.045587241649627686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.369287045598534\n",
      "NLL Loss is: 1.1929433478145044\n",
      "Scaled KL Loss is: 0.049001116305589676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.241944464120094\n",
      "NLL Loss is: 1.333466081832089\n",
      "Scaled KL Loss is: 0.04297585040330887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3764419322353978\n",
      "NLL Loss is: 1.19214912375733\n",
      "Scaled KL Loss is: 0.04906240850687027\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2412115322642003\n",
      "NLL Loss is: 1.3133451610537423\n",
      "Scaled KL Loss is: 0.04781210422515869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361157265278901\n",
      "NLL Loss is: 1.4022792964349882\n",
      "Scaled KL Loss is: 0.04497833549976349\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4472576319347517\n",
      "NLL Loss is: 1.3278955698174832\n",
      "Scaled KL Loss is: 0.043452437967061996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3713480077845452\n",
      "NLL Loss is: 1.2588701312991113\n",
      "Scaled KL Loss is: 0.04871854558587074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307588676884982\n",
      "NLL Loss is: 1.2198160970015908\n",
      "Scaled KL Loss is: 0.04519934207201004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2650154390736008\n",
      "NLL Loss is: 1.417954380541165\n",
      "Scaled KL Loss is: 0.04601706564426422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4639714461854292\n",
      "NLL Loss is: 1.255757145703269\n",
      "Scaled KL Loss is: 0.04722399637103081\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3029811420742998\n",
      "NLL Loss is: 1.6634426118207126\n",
      "Scaled KL Loss is: 0.037867236882448196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7013098487031608\n",
      "NLL Loss is: 1.3180178411063104= 1.334; test loss = 1.371\n",
      "Scaled KL Loss is: 0.048447370529174805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3664652116354852\n",
      "NLL Loss is: 1.3167447024299272\n",
      "Scaled KL Loss is: 0.04569627344608307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3624409758760103\n",
      "NLL Loss is: 1.3386529988863771\n",
      "Scaled KL Loss is: 0.04748237133026123\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3861353702166384\n",
      "NLL Loss is: 1.3656009738426418\n",
      "Scaled KL Loss is: 0.04929647967219353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4148974535148353\n",
      "NLL Loss is: 1.3200470948262524\n",
      "Scaled KL Loss is: 0.04308520630002022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3631323011262726\n",
      "NLL Loss is: 1.3508029593339301\n",
      "Scaled KL Loss is: 0.048430655151605606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3992336144855357\n",
      "NLL Loss is: 1.3730566267326854\n",
      "Scaled KL Loss is: 0.04327629134058952\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4163329180732749\n",
      "NLL Loss is: 1.3118865174889\n",
      "Scaled KL Loss is: 0.044131312519311905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356017830008212\n",
      "NLL Loss is: 1.376315070356784\n",
      "Scaled KL Loss is: 0.042821209877729416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4191362802345133\n",
      "NLL Loss is: 1.2356806756155572\n",
      "Scaled KL Loss is: 0.04939529299736023\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2850759686129174\n",
      "NLL Loss is: 1.249115834858534\n",
      "Scaled KL Loss is: 0.04308584704995155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2922016819084856\n",
      "NLL Loss is: 1.3903769684249356\n",
      "Scaled KL Loss is: 0.04603027552366257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4364072439485982\n",
      "NLL Loss is: 1.2203020284037205\n",
      "Scaled KL Loss is: 0.049581874161958694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2698839025656792\n",
      "NLL Loss is: 1.4190798824122572\n",
      "Scaled KL Loss is: 0.04709785059094429\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4661777330032015\n",
      "NLL Loss is: 1.2278612326357505\n",
      "Scaled KL Loss is: 0.0461505725979805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.274011805233731\n",
      "NLL Loss is: 1.407090826241032\n",
      "Scaled KL Loss is: 0.049920063465833664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4570108897068657\n",
      "NLL Loss is: 1.3312107495124892\n",
      "Scaled KL Loss is: 0.04637717455625534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3775879240687445\n",
      "NLL Loss is: 1.2905461532996947\n",
      "Scaled KL Loss is: 0.046774379909038544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3373205332087332\n",
      "NLL Loss is: 1.2141149361897083\n",
      "Scaled KL Loss is: 0.046794626861810684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260909563051519\n",
      "NLL Loss is: 1.3201040251697587\n",
      "Scaled KL Loss is: 0.04478088393807411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3648849091078328\n",
      "NLL Loss is: 1.2482825788134433\n",
      "Scaled KL Loss is: 0.0452793724834919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2935619512969352\n",
      "NLL Loss is: 1.325607959855009\n",
      "Scaled KL Loss is: 0.04484023526310921\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3704481951181182\n",
      "NLL Loss is: 1.2339462032387727\n",
      "Scaled KL Loss is: 0.04557320103049278\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2795194042692655\n",
      "NLL Loss is: 1.5608256568620178\n",
      "Scaled KL Loss is: 0.048605311661958694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6094309685239765\n",
      "NLL Loss is: 1.1318917248594904\n",
      "Scaled KL Loss is: 0.04605399817228317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1779457230317736\n",
      "NLL Loss is: 1.2703545517302315\n",
      "Scaled KL Loss is: 0.04975060001015663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3201051517403881\n",
      "NLL Loss is: 1.322219001834564\n",
      "Scaled KL Loss is: 0.05142926052212715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3736482623566912\n",
      "NLL Loss is: 1.109114251827499\n",
      "Scaled KL Loss is: 0.04893218353390694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.158046435361406\n",
      "NLL Loss is: 1.2664682168056343\n",
      "Scaled KL Loss is: 0.04768404737114906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3141522641767833\n",
      "NLL Loss is: 1.0994814101581478\n",
      "Scaled KL Loss is: 0.04820527136325836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1476866815214062\n",
      "NLL Loss is: 1.15545384664689\n",
      "Scaled KL Loss is: 0.043706540018320084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.19916038666521\n",
      "NLL Loss is: 1.3170729273646131\n",
      "Scaled KL Loss is: 0.047228164970874786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.364301092335488\n",
      "NLL Loss is: 1.3302840868361918\n",
      "Scaled KL Loss is: 0.04501596838235855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3753000552185504\n",
      "NLL Loss is: 1.2314867901070425\n",
      "Scaled KL Loss is: 0.04544641077518463\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2769332008822272\n",
      "NLL Loss is: 1.4122094479809761\n",
      "Scaled KL Loss is: 0.046132124960422516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4583415729413987\n",
      "NLL Loss is: 1.4138631826592063\n",
      "Scaled KL Loss is: 0.04576870799064636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4596318906498527\n",
      "NLL Loss is: 1.2320886881585635\n",
      "Scaled KL Loss is: 0.05224739387631416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2843360820348777\n",
      "NLL Loss is: 1.2031232097825986\n",
      "Scaled KL Loss is: 0.049453675746917725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2525768855295163\n",
      "NLL Loss is: 1.3164418688750736\n",
      "Scaled KL Loss is: 0.04755076393485069\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3639926328099243\n",
      "NLL Loss is: 1.437784910486258\n",
      "Scaled KL Loss is: 0.0478949248790741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.485679835365332\n",
      "NLL Loss is: 1.166513515998372\n",
      "Scaled KL Loss is: 0.04857493191957474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2150884479179467\n",
      "NLL Loss is: 1.1711644068367397\n",
      "Scaled KL Loss is: 0.04372016340494156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2148845702416813\n",
      "NLL Loss is: 1.2065944773729889\n",
      "Scaled KL Loss is: 0.0489010289311409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2554955063041298\n",
      "NLL Loss is: 1.2133950545342131\n",
      "Scaled KL Loss is: 0.05419811233878136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2675931668729945\n",
      "NLL Loss is: 1.2850849655558085\n",
      "Scaled KL Loss is: 0.045159269124269485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.330244234680078\n",
      "NLL Loss is: 1.2132757000974719\n",
      "Scaled KL Loss is: 0.049425262957811356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2627009630552832\n",
      "NLL Loss is: 1.243519533586835\n",
      "Scaled KL Loss is: 0.05036265403032303\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.293882187617158\n",
      "NLL Loss is: 1.1501755032226824\n",
      "Scaled KL Loss is: 0.052378520369529724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.202554023592212\n",
      "NLL Loss is: 1.248010757322411\n",
      "Scaled KL Loss is: 0.049712974578142166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2977237319005532\n",
      "NLL Loss is: 1.1717827312403508\n",
      "Scaled KL Loss is: 0.04892731085419655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2207100420945474\n",
      "NLL Loss is: 1.2610483832721178\n",
      "Scaled KL Loss is: 0.04974057152867317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.310788954800791\n",
      "NLL Loss is: 1.2924792725848955\n",
      "Scaled KL Loss is: 0.046394698321819305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3388739709067148\n",
      "NLL Loss is: 1.1970318159319933\n",
      "Scaled KL Loss is: 0.04985702037811279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246888836310106\n",
      "NLL Loss is: 1.3050962350409305\n",
      "Scaled KL Loss is: 0.04643985629081726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515360913317478\n",
      "NLL Loss is: 1.3786714177829575\n",
      "Scaled KL Loss is: 0.04572536051273346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.424396778295691\n",
      "NLL Loss is: 1.3633676847972698\n",
      "Scaled KL Loss is: 0.04486655071377754\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4082342355110473\n",
      "NLL Loss is: 1.3758593818105556\n",
      "Scaled KL Loss is: 0.04916081950068474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4250202013112403\n",
      "NLL Loss is: 1.2352323923485482\n",
      "Scaled KL Loss is: 0.047118958085775375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2823513504343236\n",
      "NLL Loss is: 1.2101340733648576\n",
      "Scaled KL Loss is: 0.04495740309357643\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255091476458434\n",
      "NLL Loss is: 1.1518101327167525\n",
      "Scaled KL Loss is: 0.0503837950527668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2021939277695193\n",
      "NLL Loss is: 1.2471393778593132\n",
      "Scaled KL Loss is: 0.048594750463962555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2957341283232757\n",
      "NLL Loss is: 1.2686101921044826\n",
      "Scaled KL Loss is: 0.047767698764801025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3163778908692836\n",
      "NLL Loss is: 1.3536703988176273\n",
      "Scaled KL Loss is: 0.04721309617161751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4008834949892448\n",
      "NLL Loss is: 1.2681159045493269\n",
      "Scaled KL Loss is: 0.047991979867219925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3161078844165468\n",
      "NLL Loss is: 1.25314721186853\n",
      "Scaled KL Loss is: 0.045118119567632675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2982653314361627\n",
      "NLL Loss is: 1.3655311650848403\n",
      "Scaled KL Loss is: 0.04638691619038582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119180812752261\n",
      "NLL Loss is: 1.3730488686485274\n",
      "Scaled KL Loss is: 0.048376988619565964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4214258572680933\n",
      "NLL Loss is: 1.3096776409354256\n",
      "Scaled KL Loss is: 0.04684961214661598\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3565272530820416\n",
      "NLL Loss is: 1.2691032756755494\n",
      "Scaled KL Loss is: 0.05060821771621704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3197114933917664\n",
      "NLL Loss is: 1.2532026216705532\n",
      "Scaled KL Loss is: 0.046695493161678314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2998981148322315\n",
      "NLL Loss is: 1.4258117394971601\n",
      "Scaled KL Loss is: 0.04770473763346672\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4735164771306268\n",
      "NLL Loss is: 1.3057487928882605\n",
      "Scaled KL Loss is: 0.044745855033397675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3504946479216582\n",
      "NLL Loss is: 1.2853674616161728\n",
      "Scaled KL Loss is: 0.05096883326768875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3363362948838615\n",
      "NLL Loss is: 1.3135683201209036\n",
      "Scaled KL Loss is: 0.04841603338718414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3619843535080878\n",
      "NLL Loss is: 1.3897632088448502\n",
      "Scaled KL Loss is: 0.04675561934709549\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4365188281919457\n",
      "NLL Loss is: 1.2542636038556332\n",
      "Scaled KL Loss is: 0.04374159127473831\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2980051951303715\n",
      "NLL Loss is: 1.3796850159101268\n",
      "Scaled KL Loss is: 0.04511020705103874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4247952229611656\n",
      "NLL Loss is: 1.3819879353584519\n",
      "Scaled KL Loss is: 0.04593551158905029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4279234469475022\n",
      "NLL Loss is: 1.3244267374428567\n",
      "Scaled KL Loss is: 0.047121815383434296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371548552826291\n",
      "NLL Loss is: 1.234895498850164\n",
      "Scaled KL Loss is: 0.04525964707136154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2801551459215255\n",
      "NLL Loss is: 1.3223023186052212\n",
      "Scaled KL Loss is: 0.045631736516952515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3679340551221737\n",
      "NLL Loss is: 1.191336962372945\n",
      "Scaled KL Loss is: 0.04905369505286217\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2403906574258072\n",
      "NLL Loss is: 1.3328140794021632\n",
      "Scaled KL Loss is: 0.0429985336959362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3758126130980994\n",
      "NLL Loss is: 1.1910518119236644\n",
      "Scaled KL Loss is: 0.04909421503543854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.240146026959103\n",
      "NLL Loss is: 1.3115454504622297\n",
      "Scaled KL Loss is: 0.04782910272479057\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3593745531870203\n",
      "NLL Loss is: 1.400651395011778\n",
      "Scaled KL Loss is: 0.045052338391542435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4457037334033205\n",
      "NLL Loss is: 1.3267843757549205\n",
      "Scaled KL Loss is: 0.04350047931075096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702848550656714\n",
      "NLL Loss is: 1.2568348376307938\n",
      "Scaled KL Loss is: 0.04874948039650917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.305584318027303\n",
      "NLL Loss is: 1.2187885166382746\n",
      "Scaled KL Loss is: 0.04526885971426964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2640573763525442\n",
      "NLL Loss is: 1.417140814071195\n",
      "Scaled KL Loss is: 0.046084243804216385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4632250578754114\n",
      "NLL Loss is: 1.2544580123760836\n",
      "Scaled KL Loss is: 0.0472867414355278\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3017447538116114\n",
      "NLL Loss is: 1.6634474051497183\n",
      "Scaled KL Loss is: 0.037909336388111115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7013567415378295\n",
      "NLL Loss is: 1.317441466325196 = 1.333; test loss = 1.370\n",
      "Scaled KL Loss is: 0.04847757890820503\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3659190452334011\n",
      "NLL Loss is: 1.3155590750675987\n",
      "Scaled KL Loss is: 0.04575071856379509\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3613097936313938\n",
      "NLL Loss is: 1.3372593890034883\n",
      "Scaled KL Loss is: 0.04753395542502403\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3847933444285123\n",
      "NLL Loss is: 1.3646750970654429\n",
      "Scaled KL Loss is: 0.049290671944618225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.413965769010061\n",
      "NLL Loss is: 1.3187551333279421\n",
      "Scaled KL Loss is: 0.04313531145453453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3618904447824767\n",
      "NLL Loss is: 1.3494097090097568\n",
      "Scaled KL Loss is: 0.04848918691277504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3978988959225318\n",
      "NLL Loss is: 1.3718373698599884\n",
      "Scaled KL Loss is: 0.04337255284190178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4152099227018902\n",
      "NLL Loss is: 1.3109233502258026\n",
      "Scaled KL Loss is: 0.044177912175655365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355101262401458\n",
      "NLL Loss is: 1.3756824827065914\n",
      "Scaled KL Loss is: 0.0428495928645134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4185320755711048\n",
      "NLL Loss is: 1.2346099539971909\n",
      "Scaled KL Loss is: 0.04943186044692993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840418144441208\n",
      "NLL Loss is: 1.2476790227889156\n",
      "Scaled KL Loss is: 0.04308462142944336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.290763644218359\n",
      "NLL Loss is: 1.389452585365725\n",
      "Scaled KL Loss is: 0.046098385006189346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4355509703719143\n",
      "NLL Loss is: 1.219167295796359\n",
      "Scaled KL Loss is: 0.04965155944228172\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2688188552386408\n",
      "NLL Loss is: 1.4175392410959988\n",
      "Scaled KL Loss is: 0.04713595658540726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.464675197681406\n",
      "NLL Loss is: 1.226850183813947\n",
      "Scaled KL Loss is: 0.04621642455458641\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2730666083685334\n",
      "NLL Loss is: 1.4058471279089286\n",
      "Scaled KL Loss is: 0.05004972219467163\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4558968501036003\n",
      "NLL Loss is: 1.3294939213249237\n",
      "Scaled KL Loss is: 0.04649877920746803\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3759927005323918\n",
      "NLL Loss is: 1.289224498218116\n",
      "Scaled KL Loss is: 0.04683208838105202\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336056586599168\n",
      "NLL Loss is: 1.2126784926870617\n",
      "Scaled KL Loss is: 0.04688931256532669\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2595678052523884\n",
      "NLL Loss is: 1.3186230331329905\n",
      "Scaled KL Loss is: 0.04487977549433708\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3635028086273275\n",
      "NLL Loss is: 1.2466730426931578\n",
      "Scaled KL Loss is: 0.045314934104681015\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2919879767978388\n",
      "NLL Loss is: 1.3239425132768077\n",
      "Scaled KL Loss is: 0.04497271403670311\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3689152273135108\n",
      "NLL Loss is: 1.2323405110478938\n",
      "Scaled KL Loss is: 0.04569743573665619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27803794678455\n",
      "NLL Loss is: 1.5598228956142508\n",
      "Scaled KL Loss is: 0.04865879938006401\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6084816949943148\n",
      "NLL Loss is: 1.130812780356048\n",
      "Scaled KL Loss is: 0.04612768068909645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1769404610451444\n",
      "NLL Loss is: 1.2691639705349136\n",
      "Scaled KL Loss is: 0.049814000725746155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3189779712606597\n",
      "NLL Loss is: 1.3208985842882595\n",
      "Scaled KL Loss is: 0.051518648862838745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3724172331510982\n",
      "NLL Loss is: 1.107763690236299\n",
      "Scaled KL Loss is: 0.04903154820203781\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1567952384383369\n",
      "NLL Loss is: 1.2649393701674072\n",
      "Scaled KL Loss is: 0.04776199534535408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3127013655127613\n",
      "NLL Loss is: 1.0978050245093363\n",
      "Scaled KL Loss is: 0.04829384386539459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1460988683747309\n",
      "NLL Loss is: 1.1542068266596146\n",
      "Scaled KL Loss is: 0.04375918209552765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1979660087551423\n",
      "NLL Loss is: 1.3158285175436115\n",
      "Scaled KL Loss is: 0.04729936644434929\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3631278839879608\n",
      "NLL Loss is: 1.329038394221116\n",
      "Scaled KL Loss is: 0.045073412358760834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3741118065798767\n",
      "NLL Loss is: 1.2307736939567433\n",
      "Scaled KL Loss is: 0.04550890251994133\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2762825964766846\n",
      "NLL Loss is: 1.4114673602980563\n",
      "Scaled KL Loss is: 0.046203725039958954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4576710853380153\n",
      "NLL Loss is: 1.411926759047234\n",
      "Scaled KL Loss is: 0.045824240893125534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4577509999403595\n",
      "NLL Loss is: 1.2311821073196092\n",
      "Scaled KL Loss is: 0.052278533577919006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2834606408975282\n",
      "NLL Loss is: 1.2025564197094534\n",
      "Scaled KL Loss is: 0.04955695569515228\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2521133754046057\n",
      "NLL Loss is: 1.3155167671411323\n",
      "Scaled KL Loss is: 0.04764128103852272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363158048179655\n",
      "NLL Loss is: 1.4368432945812109\n",
      "Scaled KL Loss is: 0.04794321954250336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4847865141237142\n",
      "NLL Loss is: 1.1649165983526506\n",
      "Scaled KL Loss is: 0.04865425080060959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2135708491532602\n",
      "NLL Loss is: 1.1696518384492616\n",
      "Scaled KL Loss is: 0.04379816725850105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2134500057077626\n",
      "NLL Loss is: 1.2054950424381368\n",
      "Scaled KL Loss is: 0.0490267314016819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2545217738398187\n",
      "NLL Loss is: 1.2123862001132781\n",
      "Scaled KL Loss is: 0.054230913519859314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2666171136331374\n",
      "NLL Loss is: 1.2838639539503003\n",
      "Scaled KL Loss is: 0.04519779235124588\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3290617463015462\n",
      "NLL Loss is: 1.212273640772071\n",
      "Scaled KL Loss is: 0.0495118647813797\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2617855055534506\n",
      "NLL Loss is: 1.24288747987712\n",
      "Scaled KL Loss is: 0.05040775611996651\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2932952359970864\n",
      "NLL Loss is: 1.148840028581086\n",
      "Scaled KL Loss is: 0.052507493644952774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2013475222260388\n",
      "NLL Loss is: 1.2473388377263295\n",
      "Scaled KL Loss is: 0.04973211511969566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2970709528460251\n",
      "NLL Loss is: 1.1706201116348622\n",
      "Scaled KL Loss is: 0.04898552969098091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2196056413258431\n",
      "NLL Loss is: 1.260137854284537\n",
      "Scaled KL Loss is: 0.04980006068944931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3099379149739863\n",
      "NLL Loss is: 1.2913593134943364\n",
      "Scaled KL Loss is: 0.04640702158212662\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.337766335076463\n",
      "NLL Loss is: 1.195803213587342\n",
      "Scaled KL Loss is: 0.04986713454127312\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.245670348128615\n",
      "NLL Loss is: 1.303943193462464\n",
      "Scaled KL Loss is: 0.046531181782484055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.350474375244948\n",
      "NLL Loss is: 1.3774645087031823\n",
      "Scaled KL Loss is: 0.04576439410448074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423228902807663\n",
      "NLL Loss is: 1.361779549458909\n",
      "Scaled KL Loss is: 0.04491959139704704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4066991408559562\n",
      "NLL Loss is: 1.375043253992718\n",
      "Scaled KL Loss is: 0.04918402060866356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4242272746013815\n",
      "NLL Loss is: 1.2345598550847692\n",
      "Scaled KL Loss is: 0.047129563987255096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2816894190720243\n",
      "NLL Loss is: 1.2083827790117243\n",
      "Scaled KL Loss is: 0.04502334073185921\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2534061197435835\n",
      "NLL Loss is: 1.150721000627092\n",
      "Scaled KL Loss is: 0.05039477348327637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2011157741103684\n",
      "NLL Loss is: 1.2462033413861713\n",
      "Scaled KL Loss is: 0.048663701862096786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.294867043248268\n",
      "NLL Loss is: 1.2670879025969537\n",
      "Scaled KL Loss is: 0.04779839888215065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3148863014791043\n",
      "NLL Loss is: 1.3518884662707782\n",
      "Scaled KL Loss is: 0.04724914953112602\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3991376158019042\n",
      "NLL Loss is: 1.2673680435237786\n",
      "Scaled KL Loss is: 0.04809802770614624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3154660712299249\n",
      "NLL Loss is: 1.2516933911493786\n",
      "Scaled KL Loss is: 0.045158252120018005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2968516432693966\n",
      "NLL Loss is: 1.3644671317924946\n",
      "Scaled KL Loss is: 0.04643639922142029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4109035310139149\n",
      "NLL Loss is: 1.3719336550224681\n",
      "Scaled KL Loss is: 0.048478201031684875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420411856054153\n",
      "NLL Loss is: 1.308490333593088\n",
      "Scaled KL Loss is: 0.046874016523361206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3553643501164492\n",
      "NLL Loss is: 1.2675921238622652\n",
      "Scaled KL Loss is: 0.050644420087337494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3182365439496027\n",
      "NLL Loss is: 1.251561664914144\n",
      "Scaled KL Loss is: 0.04674074053764343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2983024054517873\n",
      "NLL Loss is: 1.4245606283288992\n",
      "Scaled KL Loss is: 0.04776068404316902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4723213123720682\n",
      "NLL Loss is: 1.3044742562284137\n",
      "Scaled KL Loss is: 0.04481014236807823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.349284398596492\n",
      "NLL Loss is: 1.2845630794391143\n",
      "Scaled KL Loss is: 0.05103667080402374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.335599750243138\n",
      "NLL Loss is: 1.3124494603027423\n",
      "Scaled KL Loss is: 0.0484943762421608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3609438365449031\n",
      "NLL Loss is: 1.388426303432781\n",
      "Scaled KL Loss is: 0.0468238964676857\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4352501999004668\n",
      "NLL Loss is: 1.2532713754956806\n",
      "Scaled KL Loss is: 0.04379846528172493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2970698407774055\n",
      "NLL Loss is: 1.3787772736170134\n",
      "Scaled KL Loss is: 0.04513208195567131\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4239093555726847\n",
      "NLL Loss is: 1.3807780704164887\n",
      "Scaled KL Loss is: 0.046024173498153687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4268022439146424\n",
      "NLL Loss is: 1.3242170571996843\n",
      "Scaled KL Loss is: 0.04712304100394249\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3713400982036268\n",
      "NLL Loss is: 1.233669716665334\n",
      "Scaled KL Loss is: 0.04529561474919319\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2789653314145273\n",
      "NLL Loss is: 1.3210896552755522\n",
      "Scaled KL Loss is: 0.0456862673163414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3667759225918936\n",
      "NLL Loss is: 1.1898793136713721\n",
      "Scaled KL Loss is: 0.04911999776959419\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2389993114409663\n",
      "NLL Loss is: 1.3321318558769333\n",
      "Scaled KL Loss is: 0.043032772839069366\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3751646287160026\n",
      "NLL Loss is: 1.1902455075300997\n",
      "Scaled KL Loss is: 0.04913771525025368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2393832227803534\n",
      "NLL Loss is: 1.30999550598675\n",
      "Scaled KL Loss is: 0.04785798862576485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.357853494612515\n",
      "NLL Loss is: 1.3991902998667158\n",
      "Scaled KL Loss is: 0.04513390362262726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.444324203489343\n",
      "NLL Loss is: 1.3257470188571236\n",
      "Scaled KL Loss is: 0.04355872422456741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.369305743081691\n",
      "NLL Loss is: 1.2549664940616707\n",
      "Scaled KL Loss is: 0.048788249492645264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303754743554316\n",
      "NLL Loss is: 1.2177762015398148\n",
      "Scaled KL Loss is: 0.04535314440727234\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2631293459470871\n",
      "NLL Loss is: 1.4162271152421664\n",
      "Scaled KL Loss is: 0.046162161976099014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4623892772182654\n",
      "NLL Loss is: 1.253392842759498\n",
      "Scaled KL Loss is: 0.04736011475324631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3007529575127443\n",
      "NLL Loss is: 1.6634895782901775\n",
      "Scaled KL Loss is: 0.037956636399030685\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7014462146892082\n",
      "NLL Loss is: 1.3168085926942632= 1.331; test loss = 1.369\n",
      "Scaled KL Loss is: 0.04851780831813812\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3653264010124013\n",
      "NLL Loss is: 1.3144049152515334\n",
      "Scaled KL Loss is: 0.045816678553819656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360221593805353\n",
      "NLL Loss is: 1.3358133755841464\n",
      "Scaled KL Loss is: 0.047596223652362823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3834095992365092\n",
      "NLL Loss is: 1.3638432780457117\n",
      "Scaled KL Loss is: 0.04929523915052414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4131385171962358\n",
      "NLL Loss is: 1.3173890068499505\n",
      "Scaled KL Loss is: 0.043195486068725586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3605844929186761\n",
      "NLL Loss is: 1.3482430989007654\n",
      "Scaled KL Loss is: 0.04855657368898392\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3967996725897494\n",
      "NLL Loss is: 1.370570539179552\n",
      "Scaled KL Loss is: 0.04347838833928108\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414048927518833\n",
      "NLL Loss is: 1.3098851960823492\n",
      "Scaled KL Loss is: 0.04423613101243973\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354121327094789\n",
      "NLL Loss is: 1.3750747633297409\n",
      "Scaled KL Loss is: 0.04288767650723457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4179624398369755\n",
      "NLL Loss is: 1.2335245901483851\n",
      "Scaled KL Loss is: 0.04947740584611893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.283001995994504\n",
      "NLL Loss is: 1.2461963710113164\n",
      "Scaled KL Loss is: 0.04309309273958206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2892894637508985\n",
      "NLL Loss is: 1.3884979423472632\n",
      "Scaled KL Loss is: 0.0461733378469944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4346712801942576\n",
      "NLL Loss is: 1.2181399616683837\n",
      "Scaled KL Loss is: 0.04972303286194801\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2678629945303317\n",
      "NLL Loss is: 1.4160695978568727\n",
      "Scaled KL Loss is: 0.04718102514743805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4632506230043107\n",
      "NLL Loss is: 1.2258073012645203\n",
      "Scaled KL Loss is: 0.046291183680295944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2720984849448163\n",
      "NLL Loss is: 1.4045975890285574\n",
      "Scaled KL Loss is: 0.050182029604911804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4547796186334692\n",
      "NLL Loss is: 1.3278390922566197\n",
      "Scaled KL Loss is: 0.046624068170785904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3744631604274056\n",
      "NLL Loss is: 1.2879214246574628\n",
      "Scaled KL Loss is: 0.046895675361156464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3348171000186193\n",
      "NLL Loss is: 1.2112871659977278\n",
      "Scaled KL Loss is: 0.04698854312300682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2582757091207346\n",
      "NLL Loss is: 1.31718058320513\n",
      "Scaled KL Loss is: 0.04498086869716644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3621614519022964\n",
      "NLL Loss is: 1.245055094719346\n",
      "Scaled KL Loss is: 0.0453568771481514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2904119718674973\n",
      "NLL Loss is: 1.3222806361707404\n",
      "Scaled KL Loss is: 0.04510848969221115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3673891258629516\n",
      "NLL Loss is: 1.230745065560779\n",
      "Scaled KL Loss is: 0.045821864157915115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2765669297186941\n",
      "NLL Loss is: 1.558911961903061\n",
      "Scaled KL Loss is: 0.04871753603219986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6076294979352608\n",
      "NLL Loss is: 1.1297230676875838\n",
      "Scaled KL Loss is: 0.04620734602212906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1759304137097129\n",
      "NLL Loss is: 1.26793576012183\n",
      "Scaled KL Loss is: 0.049884069710969925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3178198298327999\n",
      "NLL Loss is: 1.3195769300762146\n",
      "Scaled KL Loss is: 0.05161420628428459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3711911363604992\n",
      "NLL Loss is: 1.1063374203820735\n",
      "Scaled KL Loss is: 0.04913640394806862\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1554738243301421\n",
      "NLL Loss is: 1.2634192431050486\n",
      "Scaled KL Loss is: 0.04784071445465088\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3112599575596995\n",
      "NLL Loss is: 1.096129099804749\n",
      "Scaled KL Loss is: 0.04838712885975838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1445162286645074\n",
      "NLL Loss is: 1.15296637964385\n",
      "Scaled KL Loss is: 0.043815065175294876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.196781444819145\n",
      "NLL Loss is: 1.3146331627183536\n",
      "Scaled KL Loss is: 0.04736897349357605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3620021362119297\n",
      "NLL Loss is: 1.3278850093737185\n",
      "Scaled KL Loss is: 0.04512908309698105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3730140924706995\n",
      "NLL Loss is: 1.2300365271540934\n",
      "Scaled KL Loss is: 0.045565828680992126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2756023558350855\n",
      "NLL Loss is: 1.4107197514611516\n",
      "Scaled KL Loss is: 0.04626807942986488\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4569878308910165\n",
      "NLL Loss is: 1.4101111590971482\n",
      "Scaled KL Loss is: 0.04587169364094734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4559828527380956\n",
      "NLL Loss is: 1.2302236110653777\n",
      "Scaled KL Loss is: 0.05229569971561432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.282519310780992\n",
      "NLL Loss is: 1.2019625061812387\n",
      "Scaled KL Loss is: 0.04965099319815636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.251613499379395\n",
      "NLL Loss is: 1.3146336922776585\n",
      "Scaled KL Loss is: 0.04771868512034416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3623523773980026\n",
      "NLL Loss is: 1.4359908789394336\n",
      "Scaled KL Loss is: 0.047976989299058914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4839678682384925\n",
      "NLL Loss is: 1.16341487406052\n",
      "Scaled KL Loss is: 0.04871806502342224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2121329390839422\n",
      "NLL Loss is: 1.1682302403673797\n",
      "Scaled KL Loss is: 0.043862417340278625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2120926577076583\n",
      "NLL Loss is: 1.2044175331172293\n",
      "Scaled KL Loss is: 0.04914069548249245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2535582285997218\n",
      "NLL Loss is: 1.2113215791686816\n",
      "Scaled KL Loss is: 0.05424519255757332\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2655667717262549\n",
      "NLL Loss is: 1.2827196370180147\n",
      "Scaled KL Loss is: 0.0452202633023262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.327939900320341\n",
      "NLL Loss is: 1.2113134423556682\n",
      "Scaled KL Loss is: 0.049584634602069855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260898076957738\n",
      "NLL Loss is: 1.242267904905561\n",
      "Scaled KL Loss is: 0.05043475329875946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2927026582043204\n",
      "NLL Loss is: 1.1475081872509716\n",
      "Scaled KL Loss is: 0.05262114107608795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2001293283270595\n",
      "NLL Loss is: 1.246701188255932\n",
      "Scaled KL Loss is: 0.04973525553941727\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2964364437953493\n",
      "NLL Loss is: 1.169480079503777\n",
      "Scaled KL Loss is: 0.0490330271422863\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2185131066460633\n",
      "NLL Loss is: 1.259242113465348\n",
      "Scaled KL Loss is: 0.04984697327017784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3090890867355258\n",
      "NLL Loss is: 1.2902922699885584\n",
      "Scaled KL Loss is: 0.0464061014354229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3366983714239813\n",
      "NLL Loss is: 1.1946265070768645\n",
      "Scaled KL Loss is: 0.049864090979099274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2444905980559637\n",
      "NLL Loss is: 1.3028601527820398\n",
      "Scaled KL Loss is: 0.04661146178841591\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3494716145704557\n",
      "NLL Loss is: 1.376206981049569\n",
      "Scaled KL Loss is: 0.04578852653503418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4219955075846031\n",
      "NLL Loss is: 1.3602142628966498\n",
      "Scaled KL Loss is: 0.04495682194828987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4051710848449397\n",
      "NLL Loss is: 1.3742703098626359\n",
      "Scaled KL Loss is: 0.049191515892744064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.42346182575538\n",
      "NLL Loss is: 1.2340155452853394\n",
      "Scaled KL Loss is: 0.047123897820711136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2811394431060505\n",
      "NLL Loss is: 1.2066950015045466\n",
      "Scaled KL Loss is: 0.045073527842760086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2517685293473066\n",
      "NLL Loss is: 1.1496833673278832\n",
      "Scaled KL Loss is: 0.05038614198565483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.200069509313538\n",
      "NLL Loss is: 1.2453794057734942\n",
      "Scaled KL Loss is: 0.0487111359834671\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2940905417569613\n",
      "NLL Loss is: 1.2655720435935058\n",
      "Scaled KL Loss is: 0.04781144857406616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.313383492167572\n",
      "NLL Loss is: 1.3501341911323208\n",
      "Scaled KL Loss is: 0.04726339131593704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3973975824482578\n",
      "NLL Loss is: 1.266643933663018\n",
      "Scaled KL Loss is: 0.04818909242749214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3148330260905101\n",
      "NLL Loss is: 1.2503171031262499\n",
      "Scaled KL Loss is: 0.04517722129821777\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2954943244244677\n",
      "NLL Loss is: 1.3634448370698287\n",
      "Scaled KL Loss is: 0.046466927975416183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099117650452448\n",
      "NLL Loss is: 1.3708367307426232\n",
      "Scaled KL Loss is: 0.048563528805971146\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4194002595485944\n",
      "NLL Loss is: 1.3073577315332403\n",
      "Scaled KL Loss is: 0.04688164219260216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3542393737258425\n",
      "NLL Loss is: 1.2661538969192008\n",
      "Scaled KL Loss is: 0.05066554993391037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3168194468531111\n",
      "NLL Loss is: 1.2499508622573388\n",
      "Scaled KL Loss is: 0.04677313566207886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2967239979194176\n",
      "NLL Loss is: 1.423293832400471\n",
      "Scaled KL Loss is: 0.04780500382184982\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4710988362223207\n",
      "NLL Loss is: 1.3032310575104842\n",
      "Scaled KL Loss is: 0.044864483177661896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348095540688146\n",
      "NLL Loss is: 1.2837309005634738\n",
      "Scaled KL Loss is: 0.05109625682234764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3348271573858215\n",
      "NLL Loss is: 1.3113916747633596\n",
      "Scaled KL Loss is: 0.048565156757831573\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3599568315211912\n",
      "NLL Loss is: 1.3870905724591285\n",
      "Scaled KL Loss is: 0.046883754432201385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4339743268913299\n",
      "NLL Loss is: 1.252262057870576\n",
      "Scaled KL Loss is: 0.04384719207882881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.296109249949405\n",
      "NLL Loss is: 1.377873739806192\n",
      "Scaled KL Loss is: 0.04514573514461517\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4230194749508072\n",
      "NLL Loss is: 1.3796544384258675\n",
      "Scaled KL Loss is: 0.04610390216112137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.425758340586989\n",
      "NLL Loss is: 1.324059988759365\n",
      "Scaled KL Loss is: 0.0471152663230896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3711752550824545\n",
      "NLL Loss is: 1.2324806229469598\n",
      "Scaled KL Loss is: 0.04532477632164955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2778053992686094\n",
      "NLL Loss is: 1.3198800228833483\n",
      "Scaled KL Loss is: 0.04573352634906769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.365613549232416\n",
      "NLL Loss is: 1.188394942138568\n",
      "Scaled KL Loss is: 0.04917753487825394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237572477016822\n",
      "NLL Loss is: 1.3314975140798218\n",
      "Scaled KL Loss is: 0.04305930435657501\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3745568184363968\n",
      "NLL Loss is: 1.1893373129734888\n",
      "Scaled KL Loss is: 0.049174580723047256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.238511893696536\n",
      "NLL Loss is: 1.3084358554937596\n",
      "Scaled KL Loss is: 0.04787785932421684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3563137148179765\n",
      "NLL Loss is: 1.3977312218122757\n",
      "Scaled KL Loss is: 0.04520605131983757\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4429372731321133\n",
      "NLL Loss is: 1.3247538503860907\n",
      "Scaled KL Loss is: 0.04360895976424217\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.368362810150333\n",
      "NLL Loss is: 1.2531040239029156\n",
      "Scaled KL Loss is: 0.0488194040954113\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.301923427998327\n",
      "NLL Loss is: 1.2167572862594946\n",
      "Scaled KL Loss is: 0.04542941972613335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.262186705985628\n",
      "NLL Loss is: 1.415380616577286\n",
      "Scaled KL Loss is: 0.046230707317590714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4616113238948767\n",
      "NLL Loss is: 1.2522858780109773\n",
      "Scaled KL Loss is: 0.04742484539747238\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2997107234084497\n",
      "NLL Loss is: 1.6634981644382534\n",
      "Scaled KL Loss is: 0.03799568861722946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7014938530554828\n",
      "NLL Loss is: 1.3162014442832923= 1.330; test loss = 1.368\n",
      "Scaled KL Loss is: 0.04855014756321907\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3647515918465114\n",
      "NLL Loss is: 1.313277849815904\n",
      "Scaled KL Loss is: 0.045875899493694305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3591537493095982\n",
      "NLL Loss is: 1.3344638816891665\n",
      "Scaled KL Loss is: 0.04765240475535393\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3821162864445204\n",
      "NLL Loss is: 1.3630094932983343\n",
      "Scaled KL Loss is: 0.04929658770561218\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4123060810039465\n",
      "NLL Loss is: 1.316111512134497\n",
      "Scaled KL Loss is: 0.043250683695077896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359362195829575\n",
      "NLL Loss is: 1.3469505733625962\n",
      "Scaled KL Loss is: 0.04862089827656746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3955714716391636\n",
      "NLL Loss is: 1.3694149404688178\n",
      "Scaled KL Loss is: 0.04358166083693504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4129966013057529\n",
      "NLL Loss is: 1.3089166494013358\n",
      "Scaled KL Loss is: 0.04429449513554573\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3532111445368815\n",
      "NLL Loss is: 1.3744365318941294\n",
      "Scaled KL Loss is: 0.042926445603370667\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4173629774975\n",
      "NLL Loss is: 1.232492176252637\n",
      "Scaled KL Loss is: 0.0495217964053154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2820139726579525\n",
      "NLL Loss is: 1.2448106367067187\n",
      "Scaled KL Loss is: 0.04310533404350281\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2879159707502215\n",
      "NLL Loss is: 1.3876364333768052\n",
      "Scaled KL Loss is: 0.046245869249105453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4338823026259107\n",
      "NLL Loss is: 1.2171013316043189\n",
      "Scaled KL Loss is: 0.049791913479566574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2668932450838855\n",
      "NLL Loss is: 1.4146304338920397\n",
      "Scaled KL Loss is: 0.047224272042512894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4618547059345526\n",
      "NLL Loss is: 1.2248086506035556\n",
      "Scaled KL Loss is: 0.046365950256586075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2711746008601417\n",
      "NLL Loss is: 1.4033945453957246\n",
      "Scaled KL Loss is: 0.05030813068151474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4537026760772394\n",
      "NLL Loss is: 1.3262118223755675\n",
      "Scaled KL Loss is: 0.04674205556511879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3729538779406862\n",
      "NLL Loss is: 1.2866831364423676\n",
      "Scaled KL Loss is: 0.04695262014865875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3336357565910264\n",
      "NLL Loss is: 1.2099474838636306\n",
      "Scaled KL Loss is: 0.04707973822951317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2570272220931438\n",
      "NLL Loss is: 1.3157619646214953\n",
      "Scaled KL Loss is: 0.04507499933242798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3608369639539233\n",
      "NLL Loss is: 1.2435113542395093\n",
      "Scaled KL Loss is: 0.0453907810151577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.288902135254667\n",
      "NLL Loss is: 1.3206865752832784\n",
      "Scaled KL Loss is: 0.04523533582687378\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3659219111101522\n",
      "NLL Loss is: 1.2292146654919995\n",
      "Scaled KL Loss is: 0.045938700437545776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2751533659295453\n",
      "NLL Loss is: 1.5579441351193513\n",
      "Scaled KL Loss is: 0.048766255378723145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6067103904980744\n",
      "NLL Loss is: 1.1286855829117228\n",
      "Scaled KL Loss is: 0.046277645975351334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1749632288870742\n",
      "NLL Loss is: 1.2667865224389008\n",
      "Scaled KL Loss is: 0.04994261637330055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3167291388122013\n",
      "NLL Loss is: 1.3183136734559069\n",
      "Scaled KL Loss is: 0.0516982302069664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3700119036628733\n",
      "NLL Loss is: 1.1050293036597045\n",
      "Scaled KL Loss is: 0.04922771453857422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1542570181982788\n",
      "NLL Loss is: 1.2619999618970383\n",
      "Scaled KL Loss is: 0.04790831357240677\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.309908275469445\n",
      "NLL Loss is: 1.0945753203891144\n",
      "Scaled KL Loss is: 0.04846688732504845\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1430422077141629\n",
      "NLL Loss is: 1.1518166607975693\n",
      "Scaled KL Loss is: 0.04386008530855179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.195676746106121\n",
      "NLL Loss is: 1.3135067019657753\n",
      "Scaled KL Loss is: 0.04742663726210594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3609333392278813\n",
      "NLL Loss is: 1.3267194951186585\n",
      "Scaled KL Loss is: 0.045174553990364075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3718940491090226\n",
      "NLL Loss is: 1.229412927069783\n",
      "Scaled KL Loss is: 0.045612361282110214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275025288351893\n",
      "NLL Loss is: 1.4100376980867304\n",
      "Scaled KL Loss is: 0.046323589980602264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4563612880673327\n",
      "NLL Loss is: 1.4082777399579254\n",
      "Scaled KL Loss is: 0.0459098182618618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4541875582197872\n",
      "NLL Loss is: 1.229372646750663\n",
      "Scaled KL Loss is: 0.052302077412605286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2816747241632682\n",
      "NLL Loss is: 1.2014411415707433\n",
      "Scaled KL Loss is: 0.049735091626644135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2511762331973875\n",
      "NLL Loss is: 1.313728730185003\n",
      "Scaled KL Loss is: 0.047789350152015686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3615180803370186\n",
      "NLL Loss is: 1.4351124393455477\n",
      "Scaled KL Loss is: 0.04800258204340935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.483115021388957\n",
      "NLL Loss is: 1.1620111226671606\n",
      "Scaled KL Loss is: 0.04877422749996185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2107853501671224\n",
      "NLL Loss is: 1.1668141789312971\n",
      "Scaled KL Loss is: 0.04392113909125328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2107353180225504\n",
      "NLL Loss is: 1.203384501616801\n",
      "Scaled KL Loss is: 0.04924941435456276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2526339159713638\n",
      "NLL Loss is: 1.210326662456729\n",
      "Scaled KL Loss is: 0.054253917187452316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2645805796441814\n",
      "NLL Loss is: 1.281582982470229\n",
      "Scaled KL Loss is: 0.04523709788918495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.326820080359414\n",
      "NLL Loss is: 1.2104342041292198\n",
      "Scaled KL Loss is: 0.04965288192033768\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2600870860495574\n",
      "NLL Loss is: 1.241670164886435\n",
      "Scaled KL Loss is: 0.05045612156391144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2921262864503464\n",
      "NLL Loss is: 1.1462190658474367\n",
      "Scaled KL Loss is: 0.05272974818944931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.198948814036886\n",
      "NLL Loss is: 1.2460980089932965\n",
      "Scaled KL Loss is: 0.049732506275177\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2958305152684735\n",
      "NLL Loss is: 1.1684005832169373\n",
      "Scaled KL Loss is: 0.04907453805208206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2174751212690194\n",
      "NLL Loss is: 1.2584102632240777\n",
      "Scaled KL Loss is: 0.0498875193297863\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.308297782553864\n",
      "NLL Loss is: 1.289287291440254\n",
      "Scaled KL Loss is: 0.04639767110347748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3356849625437315\n",
      "NLL Loss is: 1.1935257268944814\n",
      "Scaled KL Loss is: 0.049853380769491196\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2433791076639726\n",
      "NLL Loss is: 1.301816192023719\n",
      "Scaled KL Loss is: 0.046684641391038895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348500833414758\n",
      "NLL Loss is: 1.375103922730666\n",
      "Scaled KL Loss is: 0.04580433666706085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420908259397727\n",
      "NLL Loss is: 1.3586997775080079\n",
      "Scaled KL Loss is: 0.04498569294810295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4036854704561108\n",
      "NLL Loss is: 1.3735635554059507\n",
      "Scaled KL Loss is: 0.049191396683454514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4227549520894052\n",
      "NLL Loss is: 1.2334900280328904\n",
      "Scaled KL Loss is: 0.04711180180311203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2806018298360025\n",
      "NLL Loss is: 1.2050322285713455\n",
      "Scaled KL Loss is: 0.04511784389615059\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.250150072467496\n",
      "NLL Loss is: 1.1486827813526792\n",
      "Scaled KL Loss is: 0.050373733043670654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1990565143963499\n",
      "NLL Loss is: 1.2445561566714891\n",
      "Scaled KL Loss is: 0.04875398427248001\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2933101409439691\n",
      "NLL Loss is: 1.264064981936861\n",
      "Scaled KL Loss is: 0.04782314971089363\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3118881316477546\n",
      "NLL Loss is: 1.3484314111732703\n",
      "Scaled KL Loss is: 0.04727684333920479\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.395708254512475\n",
      "NLL Loss is: 1.2659639703604824\n",
      "Scaled KL Loss is: 0.04827909544110298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3142430658015853\n",
      "NLL Loss is: 1.2489851789541653\n",
      "Scaled KL Loss is: 0.0451967753469944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2941819543011597\n",
      "NLL Loss is: 1.3624527503790762\n",
      "Scaled KL Loss is: 0.0464961901307106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4089489405097868\n",
      "NLL Loss is: 1.3697369984394985\n",
      "Scaled KL Loss is: 0.04864851385354996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4183855122930484\n",
      "NLL Loss is: 1.3062669702434875\n",
      "Scaled KL Loss is: 0.04689136520028114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3531583354437686\n",
      "NLL Loss is: 1.2647600697128842\n",
      "Scaled KL Loss is: 0.05068746581673622\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3154475355296205\n",
      "NLL Loss is: 1.2483598775260938\n",
      "Scaled KL Loss is: 0.046803154051303864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2951630315773976\n",
      "NLL Loss is: 1.422075100149587\n",
      "Scaled KL Loss is: 0.04784776270389557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4699228628534826\n",
      "NLL Loss is: 1.302030441157643\n",
      "Scaled KL Loss is: 0.04491831734776497\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346948758505408\n",
      "NLL Loss is: 1.282904808871475\n",
      "Scaled KL Loss is: 0.0511576272547245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3340624361261995\n",
      "NLL Loss is: 1.3103694473889413\n",
      "Scaled KL Loss is: 0.04863625019788742\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3590056975868288\n",
      "NLL Loss is: 1.3858276290586833\n",
      "Scaled KL Loss is: 0.046942662447690964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4327702915063742\n",
      "NLL Loss is: 1.2513050695427868\n",
      "Scaled KL Loss is: 0.04389739781618118\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.295202467358968\n",
      "NLL Loss is: 1.3770081823528875\n",
      "Scaled KL Loss is: 0.045161694288253784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4221698766411413\n",
      "NLL Loss is: 1.3785890067371545\n",
      "Scaled KL Loss is: 0.046181801706552505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.424770808443707\n",
      "NLL Loss is: 1.3239774071447101\n",
      "Scaled KL Loss is: 0.047110412269830704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3710878194145408\n",
      "NLL Loss is: 1.2312828720542912\n",
      "Scaled KL Loss is: 0.04535505175590515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2766379238101964\n",
      "NLL Loss is: 1.318703648248327\n",
      "Scaled KL Loss is: 0.045781295746564865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3644849439948918\n",
      "NLL Loss is: 1.1869230664832535\n",
      "Scaled KL Loss is: 0.04923538491129875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2361584513945523\n",
      "NLL Loss is: 1.330882753289818\n",
      "Scaled KL Loss is: 0.043086908757686615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3739696620475046\n",
      "NLL Loss is: 1.1884218781063496\n",
      "Scaled KL Loss is: 0.0492158979177475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237637776024097\n",
      "NLL Loss is: 1.3069038168813187\n",
      "Scaled KL Loss is: 0.04789869114756584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3548025080288846\n",
      "NLL Loss is: 1.3962860210921075\n",
      "Scaled KL Loss is: 0.04527429863810539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441560319730213\n",
      "NLL Loss is: 1.3237641387179975\n",
      "Scaled KL Loss is: 0.04366108775138855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367425226469386\n",
      "NLL Loss is: 1.2513445815166742\n",
      "Scaled KL Loss is: 0.04885173216462135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3001963136812955\n",
      "NLL Loss is: 1.2157882488261316\n",
      "Scaled KL Loss is: 0.04550543054938316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2612936793755147\n",
      "NLL Loss is: 1.4145586606642366\n",
      "Scaled KL Loss is: 0.04629639536142349\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4608550560256601\n",
      "NLL Loss is: 1.2512018964415013\n",
      "Scaled KL Loss is: 0.04748978838324547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2986916848247467\n",
      "NLL Loss is: 1.6635375236947367\n",
      "Scaled KL Loss is: 0.03803275525569916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7015702789504359\n",
      "NLL Loss is: 1.3156158886920417= 1.329; test loss = 1.367\n",
      "Scaled KL Loss is: 0.04858445003628731\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.364200338728329\n",
      "NLL Loss is: 1.312197858238079\n",
      "Scaled KL Loss is: 0.0459379181265831\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3581357763646622\n",
      "NLL Loss is: 1.3332132301120923\n",
      "Scaled KL Loss is: 0.047709111124277115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3809223412363694\n",
      "NLL Loss is: 1.3621590119892841\n",
      "Scaled KL Loss is: 0.04930199682712555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4114610088164097\n",
      "NLL Loss is: 1.3148584470991247\n",
      "Scaled KL Loss is: 0.04330794885754585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3581663959566705\n",
      "NLL Loss is: 1.3456670785433065\n",
      "Scaled KL Loss is: 0.048692114651203156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3943591931945096\n",
      "NLL Loss is: 1.3683001710856573\n",
      "Scaled KL Loss is: 0.04369198530912399\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119921563947813\n",
      "NLL Loss is: 1.3079905765055508\n",
      "Scaled KL Loss is: 0.04436580091714859\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3523563774226994\n",
      "NLL Loss is: 1.3738214200198917\n",
      "Scaled KL Loss is: 0.042977213859558105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4167986338794498\n",
      "NLL Loss is: 1.231477550967466\n",
      "Scaled KL Loss is: 0.04957892745733261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2810564784247986\n",
      "NLL Loss is: 1.2435409378170172\n",
      "Scaled KL Loss is: 0.04313630610704422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2866772439240615\n",
      "NLL Loss is: 1.3868132641699231\n",
      "Scaled KL Loss is: 0.046330858021974564\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4331441221918977\n",
      "NLL Loss is: 1.216069587230692\n",
      "Scaled KL Loss is: 0.04987083375453949\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2659404209852314\n",
      "NLL Loss is: 1.413222579461693\n",
      "Scaled KL Loss is: 0.04728367179632187\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.460506251258015\n",
      "NLL Loss is: 1.2238801293202621\n",
      "Scaled KL Loss is: 0.046460650861263275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2703407801815254\n",
      "NLL Loss is: 1.4022193836066459\n",
      "Scaled KL Loss is: 0.05044322833418846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4526626119408343\n",
      "NLL Loss is: 1.3245604129648028\n",
      "Scaled KL Loss is: 0.046872079372406006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3714324923372088\n",
      "NLL Loss is: 1.2854614336353978\n",
      "Scaled KL Loss is: 0.047030966728925705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3324924003643235\n",
      "NLL Loss is: 1.208617658040956\n",
      "Scaled KL Loss is: 0.04718765243887901\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255805310479835\n",
      "NLL Loss is: 1.3143604076462785\n",
      "Scaled KL Loss is: 0.04518496245145798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3595453700977365\n",
      "NLL Loss is: 1.2417848462440026\n",
      "Scaled KL Loss is: 0.04545581340789795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2872406596519006\n",
      "NLL Loss is: 1.3190562302380142\n",
      "Scaled KL Loss is: 0.04538173973560333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3644379699736175\n",
      "NLL Loss is: 1.2275083718613387\n",
      "Scaled KL Loss is: 0.046072881668806076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2735812535301447\n",
      "NLL Loss is: 1.557210774086344\n",
      "Scaled KL Loss is: 0.04884529858827591\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6060560726746198\n",
      "NLL Loss is: 1.1276503861150098\n",
      "Scaled KL Loss is: 0.04637382924556732\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.174024215360577\n",
      "NLL Loss is: 1.2656319651937962\n",
      "Scaled KL Loss is: 0.0500272735953331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3156592387891293\n",
      "NLL Loss is: 1.3170574757222306\n",
      "Scaled KL Loss is: 0.051807355135679245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3688648308579099\n",
      "NLL Loss is: 1.1036759570746726\n",
      "Scaled KL Loss is: 0.049341388046741486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.153017345121414\n",
      "NLL Loss is: 1.2605429839679736\n",
      "Scaled KL Loss is: 0.04800359159708023\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3085465755650538\n",
      "NLL Loss is: 1.0928966722686868\n",
      "Scaled KL Loss is: 0.04857705533504486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1414737276037317\n",
      "NLL Loss is: 1.1506905071721052\n",
      "Scaled KL Loss is: 0.0439373180270195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1946278251991247\n",
      "NLL Loss is: 1.3124450463493622\n",
      "Scaled KL Loss is: 0.047514379024505615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3599594253738678\n",
      "NLL Loss is: 1.3255864687189318\n",
      "Scaled KL Loss is: 0.04525457322597504\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3708410419449069\n",
      "NLL Loss is: 1.2287119130603288\n",
      "Scaled KL Loss is: 0.04568874090909958\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2744006539694284\n",
      "NLL Loss is: 1.4093932181572881\n",
      "Scaled KL Loss is: 0.04640393331646919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4557971514737573\n",
      "NLL Loss is: 1.406515295406185\n",
      "Scaled KL Loss is: 0.04597759619355202\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.452492891599737\n",
      "NLL Loss is: 1.2285000768990486\n",
      "Scaled KL Loss is: 0.05233727768063545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.280837354579684\n",
      "NLL Loss is: 1.2008521257340616\n",
      "Scaled KL Loss is: 0.04984268546104431\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.250694811195106\n",
      "NLL Loss is: 1.3128841404199492\n",
      "Scaled KL Loss is: 0.047887176275253296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3607713166952025\n",
      "NLL Loss is: 1.434234000439788\n",
      "Scaled KL Loss is: 0.04805689677596092\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.482290897215749\n",
      "NLL Loss is: 1.16061189877179\n",
      "Scaled KL Loss is: 0.04885954409837723\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2094714428701672\n",
      "NLL Loss is: 1.1654462864024437\n",
      "Scaled KL Loss is: 0.04400405287742615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.20945033927987\n",
      "NLL Loss is: 1.2023148195026079\n",
      "Scaled KL Loss is: 0.049378931522369385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2516937510249773\n",
      "NLL Loss is: 1.209323375724515\n",
      "Scaled KL Loss is: 0.054290786385536194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2636141621100512\n",
      "NLL Loss is: 1.2804387886227226\n",
      "Scaled KL Loss is: 0.04528123140335083\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3257200200260735\n",
      "NLL Loss is: 1.2095227059000153\n",
      "Scaled KL Loss is: 0.049746617674827576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.259269323574843\n",
      "NLL Loss is: 1.2410127620358529\n",
      "Scaled KL Loss is: 0.05050361528992653\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2915163773257794\n",
      "NLL Loss is: 1.1449824437084883\n",
      "Scaled KL Loss is: 0.052861910313367844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1978443540218562\n",
      "NLL Loss is: 1.2454394157130773\n",
      "Scaled KL Loss is: 0.04976386949419975\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.295203285207277\n",
      "NLL Loss is: 1.1672642558701714\n",
      "Scaled KL Loss is: 0.04915250837802887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2164167642482002\n",
      "NLL Loss is: 1.2575421459237435\n",
      "Scaled KL Loss is: 0.0499628484249115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307504994348655\n",
      "NLL Loss is: 1.288200748532882\n",
      "Scaled KL Loss is: 0.04643396660685539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3346347151397373\n",
      "NLL Loss is: 1.1924102853999567\n",
      "Scaled KL Loss is: 0.049892622977495193\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.242302908377452\n",
      "NLL Loss is: 1.3007274154770458\n",
      "Scaled KL Loss is: 0.04679509624838829\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3475225117254341\n",
      "NLL Loss is: 1.3741304204351166\n",
      "Scaled KL Loss is: 0.045858047902584076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4199884683377006\n",
      "NLL Loss is: 1.3572360523443898\n",
      "Scaled KL Loss is: 0.04505970701575279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4022957593601426\n",
      "NLL Loss is: 1.3728122769010684\n",
      "Scaled KL Loss is: 0.04923652112483978\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4220487980259082\n",
      "NLL Loss is: 1.2328661330996935\n",
      "Scaled KL Loss is: 0.0471532866358757\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2800194197355692\n",
      "NLL Loss is: 1.2034053375841938\n",
      "Scaled KL Loss is: 0.045200709253549576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2486060468377433\n",
      "NLL Loss is: 1.1476254290364303\n",
      "Scaled KL Loss is: 0.05041394755244255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1980393765888728\n",
      "NLL Loss is: 1.2437428812054236\n",
      "Scaled KL Loss is: 0.04883655533194542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.292579436537369\n",
      "NLL Loss is: 1.2625898293687543\n",
      "Scaled KL Loss is: 0.04788171127438545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3104715406431398\n",
      "NLL Loss is: 1.3467639644767095\n",
      "Scaled KL Loss is: 0.0473317913711071\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3940957558478166\n",
      "NLL Loss is: 1.2652574933603407\n",
      "Scaled KL Loss is: 0.04839819297194481\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3136556863322855\n",
      "NLL Loss is: 1.2476412051611017\n",
      "Scaled KL Loss is: 0.045252103358507156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2928933085196088\n",
      "NLL Loss is: 1.3614645669050127\n",
      "Scaled KL Loss is: 0.04655751958489418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408022086489907\n",
      "NLL Loss is: 1.368635216974482\n",
      "Scaled KL Loss is: 0.048760786652565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.417396003627047\n",
      "NLL Loss is: 1.3051570773324996\n",
      "Scaled KL Loss is: 0.04693520814180374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3520922854743034\n",
      "NLL Loss is: 1.2634025542931098\n",
      "Scaled KL Loss is: 0.050740908831357956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3141434631244677\n",
      "NLL Loss is: 1.2467585050100254\n",
      "Scaled KL Loss is: 0.046862032264471054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2936205372744964\n",
      "NLL Loss is: 1.4208775617855844\n",
      "Scaled KL Loss is: 0.0479157529771328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4687933147627172\n",
      "NLL Loss is: 1.3007492966907535\n",
      "Scaled KL Loss is: 0.04499322921037674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3457425259011302\n",
      "NLL Loss is: 1.282148893657906\n",
      "Scaled KL Loss is: 0.05124347656965256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3333923702275585\n",
      "NLL Loss is: 1.3093325035808456\n",
      "Scaled KL Loss is: 0.0487285740673542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3580610776481998\n",
      "NLL Loss is: 1.3846458107914317\n",
      "Scaled KL Loss is: 0.04702268913388252\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4316684999253142\n",
      "NLL Loss is: 1.250349206652433\n",
      "Scaled KL Loss is: 0.04396916180849075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943183684609239\n",
      "NLL Loss is: 1.3761875580612541\n",
      "Scaled KL Loss is: 0.045202311128377914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.421389869189632\n",
      "NLL Loss is: 1.3774632429818194\n",
      "Scaled KL Loss is: 0.04627902805805206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4237422710398715\n",
      "NLL Loss is: 1.3238025381924503\n",
      "Scaled KL Loss is: 0.04713338240981102\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3709359206022613\n",
      "NLL Loss is: 1.230087402112141\n",
      "Scaled KL Loss is: 0.04541033133864403\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275497733450785\n",
      "NLL Loss is: 1.3175811495366174\n",
      "Scaled KL Loss is: 0.045850880444049835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3634320299806673\n",
      "NLL Loss is: 1.1855193819917689\n",
      "Scaled KL Loss is: 0.0493188239634037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2348382059551726\n",
      "NLL Loss is: 1.3302578206824143\n",
      "Scaled KL Loss is: 0.043136581778526306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3733944024609406\n",
      "NLL Loss is: 1.187544422738684\n",
      "Scaled KL Loss is: 0.04928392916917801\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.236828351907862\n",
      "NLL Loss is: 1.3054599972106684\n",
      "Scaled KL Loss is: 0.04794308543205261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353403082642721\n",
      "NLL Loss is: 1.394908679250063\n",
      "Scaled KL Loss is: 0.045356493443250656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4402651726933136\n",
      "NLL Loss is: 1.3228066844285968\n",
      "Scaled KL Loss is: 0.04373490810394287\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3665415925325397\n",
      "NLL Loss is: 1.2496807368553449\n",
      "Scaled KL Loss is: 0.04890875145792961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2985894883132745\n",
      "NLL Loss is: 1.214832014307653\n",
      "Scaled KL Loss is: 0.04560239240527153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2604344067129245\n",
      "NLL Loss is: 1.4137206248120997\n",
      "Scaled KL Loss is: 0.046379316598176956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4600999414102767\n",
      "NLL Loss is: 1.2501725612654042\n",
      "Scaled KL Loss is: 0.04757536202669144\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2977479232920957\n",
      "NLL Loss is: 1.6636188793610813\n",
      "Scaled KL Loss is: 0.03808595612645149\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7017048354875328\n",
      "NLL Loss is: 1.3150069949681051= 1.328; test loss = 1.366\n",
      "Scaled KL Loss is: 0.04864250496029854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3636494999284037\n",
      "NLL Loss is: 1.3111283821638742\n",
      "Scaled KL Loss is: 0.046023257076740265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571516392406144\n",
      "NLL Loss is: 1.332015195972803\n",
      "Scaled KL Loss is: 0.0477852039039135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3798003998767165\n",
      "NLL Loss is: 1.3613523077052856\n",
      "Scaled KL Loss is: 0.049330051988363266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4106823596936489\n",
      "NLL Loss is: 1.3135992391987423\n",
      "Scaled KL Loss is: 0.04338526725769043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569845064564328\n",
      "NLL Loss is: 1.3444085244113892\n",
      "Scaled KL Loss is: 0.04878660663962364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393195131051013\n",
      "NLL Loss is: 1.3671901324276319\n",
      "Scaled KL Loss is: 0.04382392764091492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4110140600685468\n",
      "NLL Loss is: 1.306983056793469\n",
      "Scaled KL Loss is: 0.04446433484554291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351447391639012\n",
      "NLL Loss is: 1.3731695121793477\n",
      "Scaled KL Loss is: 0.04305172711610794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4162212392954556\n",
      "NLL Loss is: 1.2304479987845154\n",
      "Scaled KL Loss is: 0.04965917021036148\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2801071689948769\n",
      "NLL Loss is: 1.24226959734021\n",
      "Scaled KL Loss is: 0.043194349855184555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2854639471953946\n",
      "NLL Loss is: 1.3859914775029387\n",
      "Scaled KL Loss is: 0.04643544927239418\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432426926775333\n",
      "NLL Loss is: 1.2150549123156447\n",
      "Scaled KL Loss is: 0.049965858459472656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2650207707751173\n",
      "NLL Loss is: 1.4119393273814527\n",
      "Scaled KL Loss is: 0.0473623126745224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.459301640055975\n",
      "NLL Loss is: 1.222942968070258\n",
      "Scaled KL Loss is: 0.04657547548413277\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2695184435543907\n",
      "NLL Loss is: 1.4010904789772096\n",
      "Scaled KL Loss is: 0.050589483231306076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4516799622085157\n",
      "NLL Loss is: 1.322930513594362\n",
      "Scaled KL Loss is: 0.04701356217265129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3699440757670134\n",
      "NLL Loss is: 1.2842387799952757\n",
      "Scaled KL Loss is: 0.04712377488613129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.331362554881407\n",
      "NLL Loss is: 1.2073128767173715\n",
      "Scaled KL Loss is: 0.04730396717786789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2546168438952394\n",
      "NLL Loss is: 1.3129695860674033\n",
      "Scaled KL Loss is: 0.04530315846204758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358272744529451\n",
      "NLL Loss is: 1.2401332579845978\n",
      "Scaled KL Loss is: 0.045530498027801514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2856637560123994\n",
      "NLL Loss is: 1.3175196815423738\n",
      "Scaled KL Loss is: 0.045531876385211945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3630515579275857\n",
      "NLL Loss is: 1.2258295426666908\n",
      "Scaled KL Loss is: 0.04621221870183945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2720417613685302\n",
      "NLL Loss is: 1.5564331596462606\n",
      "Scaled KL Loss is: 0.04892875254154205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6053619121878027\n",
      "NLL Loss is: 1.1265802924948756\n",
      "Scaled KL Loss is: 0.04647358879446983\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1730538812893454\n",
      "NLL Loss is: 1.264545057189055\n",
      "Scaled KL Loss is: 0.050111863762140274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3146569209511954\n",
      "NLL Loss is: 1.3158452657419895\n",
      "Scaled KL Loss is: 0.051915936172008514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367761201913998\n",
      "NLL Loss is: 1.1023993888668482\n",
      "Scaled KL Loss is: 0.04945166036486626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1518510492317144\n",
      "NLL Loss is: 1.2591574177687233\n",
      "Scaled KL Loss is: 0.04809793457388878\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307255352342612\n",
      "NLL Loss is: 1.0912934428896566\n",
      "Scaled KL Loss is: 0.048684291541576385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.139977734431233\n",
      "NLL Loss is: 1.149562671497627\n",
      "Scaled KL Loss is: 0.04401319846510887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.193575869962736\n",
      "NLL Loss is: 1.3113783069804301\n",
      "Scaled KL Loss is: 0.04759950190782547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3589778088882556\n",
      "NLL Loss is: 1.3244951910965803\n",
      "Scaled KL Loss is: 0.0453316867351532\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3698268778317335\n",
      "NLL Loss is: 1.2280501939735555\n",
      "Scaled KL Loss is: 0.04576180875301361\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2738120027265691\n",
      "NLL Loss is: 1.4088061145293478\n",
      "Scaled KL Loss is: 0.04648026451468468\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4552863790440325\n",
      "NLL Loss is: 1.4048030014917758\n",
      "Scaled KL Loss is: 0.046041473746299744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4508444752380756\n",
      "NLL Loss is: 1.2276395636698938\n",
      "Scaled KL Loss is: 0.05236464738845825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.280004211058352\n",
      "NLL Loss is: 1.2002730778698227\n",
      "Scaled KL Loss is: 0.04994538798928261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2502184658591053\n",
      "NLL Loss is: 1.3120831479647854\n",
      "Scaled KL Loss is: 0.04798176512122154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.360064913086007\n",
      "NLL Loss is: 1.4333942401718378\n",
      "Scaled KL Loss is: 0.04810594022274017\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.481500180394578\n",
      "NLL Loss is: 1.1592737824593227\n",
      "Scaled KL Loss is: 0.04894011840224266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2082139008615653\n",
      "NLL Loss is: 1.1641503610803623\n",
      "Scaled KL Loss is: 0.044082388281822205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2082327493621845\n",
      "NLL Loss is: 1.2012723703084267\n",
      "Scaled KL Loss is: 0.04950324445962906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2507756147680558\n",
      "NLL Loss is: 1.2082769016871853\n",
      "Scaled KL Loss is: 0.05432073771953583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.262597639406721\n",
      "NLL Loss is: 1.279305474172713\n",
      "Scaled KL Loss is: 0.0453188493847847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3246243235574977\n",
      "NLL Loss is: 1.2086498445965626\n",
      "Scaled KL Loss is: 0.04983370378613472\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2584835483826973\n",
      "NLL Loss is: 1.2403719463150138\n",
      "Scaled KL Loss is: 0.05054168030619621\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.29091362662121\n",
      "NLL Loss is: 1.1437861651692465\n",
      "Scaled KL Loss is: 0.05298557132482529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1967717364940718\n",
      "NLL Loss is: 1.2448352013087574\n",
      "Scaled KL Loss is: 0.049787167459726334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2946223687684837\n",
      "NLL Loss is: 1.1662238406379035\n",
      "Scaled KL Loss is: 0.0492197684943676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2154436091322711\n",
      "NLL Loss is: 1.2567348697639225\n",
      "Scaled KL Loss is: 0.05002840235829353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.306763272122216\n",
      "NLL Loss is: 1.2871664921293922\n",
      "Scaled KL Loss is: 0.04645894840359688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.333625440532989\n",
      "NLL Loss is: 1.1912940074793437\n",
      "Scaled KL Loss is: 0.04991927370429039\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.241213281183634\n",
      "NLL Loss is: 1.2996773373043768\n",
      "Scaled KL Loss is: 0.04689100757241249\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3465683448767893\n",
      "NLL Loss is: 1.3731623356003713\n",
      "Scaled KL Loss is: 0.045894917100667953\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4190572527010392\n",
      "NLL Loss is: 1.3558005805641347\n",
      "Scaled KL Loss is: 0.04511605203151703\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4009166325956517\n",
      "NLL Loss is: 1.3720861017634247\n",
      "Scaled KL Loss is: 0.04926066845655441\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4213467702199791\n",
      "NLL Loss is: 1.232257934357029\n",
      "Scaled KL Loss is: 0.04717037081718445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2794283051742135\n",
      "NLL Loss is: 1.201795819065128\n",
      "Scaled KL Loss is: 0.04526359960436821\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.247059418669496\n",
      "NLL Loss is: 1.1466423438086866\n",
      "Scaled KL Loss is: 0.050427377223968506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.197069721032655\n",
      "NLL Loss is: 1.2429689142931966\n",
      "Scaled KL Loss is: 0.048895809799432755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2918647240926293\n",
      "NLL Loss is: 1.2611288477159306\n",
      "Scaled KL Loss is: 0.047912657260894775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3090415049768254\n",
      "NLL Loss is: 1.3451179722615927\n",
      "Scaled KL Loss is: 0.04735889658331871\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3924768688449114\n",
      "NLL Loss is: 1.2645638617805326\n",
      "Scaled KL Loss is: 0.048492565751075745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3130564275316083\n",
      "NLL Loss is: 1.2463809019889365\n",
      "Scaled KL Loss is: 0.04527689889073372\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2916578008796702\n",
      "NLL Loss is: 1.360584097468123\n",
      "Scaled KL Loss is: 0.04658593609929085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4071700335674138\n",
      "NLL Loss is: 1.3675118775040775\n",
      "Scaled KL Loss is: 0.04884081333875656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416352690842834\n",
      "NLL Loss is: 1.3040799932975558\n",
      "Scaled KL Loss is: 0.0469374917447567\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3510174850423124\n",
      "NLL Loss is: 1.2621070304739752\n",
      "Scaled KL Loss is: 0.050752948969602585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3128599794435778\n",
      "NLL Loss is: 1.2452486630171264\n",
      "Scaled KL Loss is: 0.046877674758434296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2921263377755607\n",
      "NLL Loss is: 1.4196759698975974\n",
      "Scaled KL Loss is: 0.047943294048309326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4676192639459067\n",
      "NLL Loss is: 1.2995013616420226\n",
      "Scaled KL Loss is: 0.045029014348983765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3445303759910063\n",
      "NLL Loss is: 1.2816845302316766\n",
      "Scaled KL Loss is: 0.05128069221973419\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3329652224514108\n",
      "NLL Loss is: 1.3082602278652267\n",
      "Scaled KL Loss is: 0.04877403751015663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3570342653753833\n",
      "NLL Loss is: 1.383763798897302\n",
      "Scaled KL Loss is: 0.047056883573532104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.430820682470834\n",
      "NLL Loss is: 1.24949247904197\n",
      "Scaled KL Loss is: 0.04399369657039642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2934861756123663\n",
      "NLL Loss is: 1.3755323148677252\n",
      "Scaled KL Loss is: 0.04518955945968628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4207218743274115\n",
      "NLL Loss is: 1.3763902928279532\n",
      "Scaled KL Loss is: 0.046334441751241684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.422724734579195\n",
      "NLL Loss is: 1.323598159597717\n",
      "Scaled KL Loss is: 0.04709520563483238\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3706933652325495\n",
      "NLL Loss is: 1.2289803459958077\n",
      "Scaled KL Loss is: 0.04541369155049324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.274394037546301\n",
      "NLL Loss is: 1.3166843792226626\n",
      "Scaled KL Loss is: 0.04587135836482048\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.362555737587483\n",
      "NLL Loss is: 1.1842345225594817\n",
      "Scaled KL Loss is: 0.04935159906744957\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2335861216269313\n",
      "NLL Loss is: 1.329686534892432\n",
      "Scaled KL Loss is: 0.043135713785886765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3728222486783188\n",
      "NLL Loss is: 1.186953943646863\n",
      "Scaled KL Loss is: 0.049299295991659164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2362532396385222\n",
      "NLL Loss is: 1.3042490967572036\n",
      "Scaled KL Loss is: 0.047933340072631836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3521824368298354\n",
      "NLL Loss is: 1.3937422412443652\n",
      "Scaled KL Loss is: 0.04539880529046059\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4391410465348258\n",
      "NLL Loss is: 1.3219136568142167\n",
      "Scaled KL Loss is: 0.04376187548041344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3656755322946301\n",
      "NLL Loss is: 1.248169711654122\n",
      "Scaled KL Loss is: 0.04891030117869377\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2970800128328157\n",
      "NLL Loss is: 1.2138677744207194\n",
      "Scaled KL Loss is: 0.045659635215997696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.259527409636717\n",
      "NLL Loss is: 1.4128066024833286\n",
      "Scaled KL Loss is: 0.04642266780138016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4592292702847087\n",
      "NLL Loss is: 1.2493531749631084\n",
      "Scaled KL Loss is: 0.04761796444654465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.296971139409653\n",
      "NLL Loss is: 1.6636038530633317\n",
      "Scaled KL Loss is: 0.03809744492173195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7017012979850636\n",
      "NLL Loss is: 1.3143544007049526= 1.327; test loss = 1.366\n",
      "Scaled KL Loss is: 0.048648614436388016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3630030151413406\n",
      "NLL Loss is: 1.3101785873981846\n",
      "Scaled KL Loss is: 0.046059299260377884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3562378866585625\n",
      "NLL Loss is: 1.3309036525149036\n",
      "Scaled KL Loss is: 0.047812432050704956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3787160845656086\n",
      "NLL Loss is: 1.3606768155924065\n",
      "Scaled KL Loss is: 0.049290794879198074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099676104716046\n",
      "NLL Loss is: 1.3122770970843975\n",
      "Scaled KL Loss is: 0.04341569170355797\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3556927887879555\n",
      "NLL Loss is: 1.3434318340931413\n",
      "Scaled KL Loss is: 0.048821285367012024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3922531194601533\n",
      "NLL Loss is: 1.3659773443208627\n",
      "Scaled KL Loss is: 0.04390307143330574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4098804157541684\n",
      "NLL Loss is: 1.3059061176809887\n",
      "Scaled KL Loss is: 0.04449837654829025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.350404494229279\n",
      "NLL Loss is: 1.3725453848435125\n",
      "Scaled KL Loss is: 0.04306110367178917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4156064885153017\n",
      "NLL Loss is: 1.2294518417852727\n",
      "Scaled KL Loss is: 0.04966900870203972\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2791208504873124\n",
      "NLL Loss is: 1.240860312445439\n",
      "Scaled KL Loss is: 0.04317007586359978\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840303883090387\n",
      "NLL Loss is: 1.3850086467133809\n",
      "Scaled KL Loss is: 0.04648071154952049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4314893582629014\n",
      "NLL Loss is: 1.2142369184346484\n",
      "Scaled KL Loss is: 0.04999874159693718\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2642356600315856\n",
      "NLL Loss is: 1.4106811029444197\n",
      "Scaled KL Loss is: 0.04737528786063194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4580563908050517\n",
      "NLL Loss is: 1.2220078440522597\n",
      "Scaled KL Loss is: 0.04662151262164116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2686293566739009\n",
      "NLL Loss is: 1.3999293683956318\n",
      "Scaled KL Loss is: 0.050683654844760895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4506130232403927\n",
      "NLL Loss is: 1.3215400716066252\n",
      "Scaled KL Loss is: 0.04710548743605614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3686455590426814\n",
      "NLL Loss is: 1.2830901869508764\n",
      "Scaled KL Loss is: 0.04715720936655998\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3302473963174364\n",
      "NLL Loss is: 1.2060474386202191\n",
      "Scaled KL Loss is: 0.04736846685409546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2534159054743146\n",
      "NLL Loss is: 1.3116208883868858\n",
      "Scaled KL Loss is: 0.04537422955036163\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569951179372475\n",
      "NLL Loss is: 1.2387580245105116\n",
      "Scaled KL Loss is: 0.045545291155576706\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2843033156660884\n",
      "NLL Loss is: 1.3160411782666153\n",
      "Scaled KL Loss is: 0.04563577473163605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3616769529982513\n",
      "NLL Loss is: 1.224365879789658\n",
      "Scaled KL Loss is: 0.046307701617479324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2706735814071373\n",
      "NLL Loss is: 1.5555453978477045\n",
      "Scaled KL Loss is: 0.04895784333348274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6045032411811873\n",
      "NLL Loss is: 1.1256700566321658\n",
      "Scaled KL Loss is: 0.04652319848537445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1721932551175402\n",
      "NLL Loss is: 1.263546825499175\n",
      "Scaled KL Loss is: 0.05014791339635849\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3136947388955336\n",
      "NLL Loss is: 1.3147101598434703\n",
      "Scaled KL Loss is: 0.051979199051856995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3666893588953273\n",
      "NLL Loss is: 1.1012329190556114\n",
      "Scaled KL Loss is: 0.0495181567966938\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1507510758523052\n",
      "NLL Loss is: 1.2578796071166345\n",
      "Scaled KL Loss is: 0.04814906418323517\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3060286712998697\n",
      "NLL Loss is: 1.0898063787347734\n",
      "Scaled KL Loss is: 0.048751771450042725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.138558150184816\n",
      "NLL Loss is: 1.1485712212771995\n",
      "Scaled KL Loss is: 0.04404979571700096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1926210169942004\n",
      "NLL Loss is: 1.3103754303963517\n",
      "Scaled KL Loss is: 0.047645919024944305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358021349421296\n",
      "NLL Loss is: 1.3234320901380325\n",
      "Scaled KL Loss is: 0.04537081718444824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3688029073224808\n",
      "NLL Loss is: 1.227422235449655\n",
      "Scaled KL Loss is: 0.04579944908618927\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2732216845358442\n",
      "NLL Loss is: 1.40817659194045\n",
      "Scaled KL Loss is: 0.0465245246887207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4547011166291708\n",
      "NLL Loss is: 1.403070568034873\n",
      "Scaled KL Loss is: 0.04607366397976875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4491442320146417\n",
      "NLL Loss is: 1.2268438443679943\n",
      "Scaled KL Loss is: 0.05236024409532547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2792040884633198\n",
      "NLL Loss is: 1.1998050635254345\n",
      "Scaled KL Loss is: 0.05001940578222275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2498244693076572\n",
      "NLL Loss is: 1.3113227063636506\n",
      "Scaled KL Loss is: 0.048051055520772934\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3593737618844235\n",
      "NLL Loss is: 1.4325565473648083\n",
      "Scaled KL Loss is: 0.04813017323613167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.48068672060094\n",
      "NLL Loss is: 1.1578829876187866\n",
      "Scaled KL Loss is: 0.048997633159160614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2068806207779472\n",
      "NLL Loss is: 1.162870190253248\n",
      "Scaled KL Loss is: 0.044139232486486435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2070094227397343\n",
      "NLL Loss is: 1.2002397779343148\n",
      "Scaled KL Loss is: 0.04960785433650017\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.249847632270815\n",
      "NLL Loss is: 1.2074184438309903\n",
      "Scaled KL Loss is: 0.054328855127096176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2617472989580865\n",
      "NLL Loss is: 1.278173923782053\n",
      "Scaled KL Loss is: 0.04533849284052849\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3235124166225816\n",
      "NLL Loss is: 1.2077648941136405\n",
      "Scaled KL Loss is: 0.04990331456065178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2576682086742923\n",
      "NLL Loss is: 1.2398278012727812\n",
      "Scaled KL Loss is: 0.05056283250451088\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2903906337772921\n",
      "NLL Loss is: 1.1426722385191408\n",
      "Scaled KL Loss is: 0.05309086665511131\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.195763105174252\n",
      "NLL Loss is: 1.2442395459134945\n",
      "Scaled KL Loss is: 0.04979557916522026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2940351250787148\n",
      "NLL Loss is: 1.1651723757572596\n",
      "Scaled KL Loss is: 0.049274176359176636\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2144465521164363\n",
      "NLL Loss is: 1.2559353763224659\n",
      "Scaled KL Loss is: 0.05007985979318619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.306015236115652\n",
      "NLL Loss is: 1.2861473864749189\n",
      "Scaled KL Loss is: 0.04647233709692955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3326197235718484\n",
      "NLL Loss is: 1.1901308978474077\n",
      "Scaled KL Loss is: 0.04993554949760437\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.240066447345012\n",
      "NLL Loss is: 1.29860522712367\n",
      "Scaled KL Loss is: 0.04697764292359352\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3455828700472636\n",
      "NLL Loss is: 1.3720525420079632\n",
      "Scaled KL Loss is: 0.045922551304101944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4179750933120652\n",
      "NLL Loss is: 1.3543822009523239\n",
      "Scaled KL Loss is: 0.04516651853919029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3995487194915142\n",
      "NLL Loss is: 1.3712928256808785\n",
      "Scaled KL Loss is: 0.049277208745479584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420570034426358\n",
      "NLL Loss is: 1.231780495977412\n",
      "Scaled KL Loss is: 0.0471826009452343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2789630969226462\n",
      "NLL Loss is: 1.200269324342859\n",
      "Scaled KL Loss is: 0.045321762561798096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2455910869046571\n",
      "NLL Loss is: 1.145682718179563\n",
      "Scaled KL Loss is: 0.050438292324543\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.196121010504106\n",
      "NLL Loss is: 1.2422896412471716\n",
      "Scaled KL Loss is: 0.04894954711198807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2912391883591596\n",
      "NLL Loss is: 1.2597091524598119\n",
      "Scaled KL Loss is: 0.04794373735785484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3076528898176667\n",
      "NLL Loss is: 1.3434863088872995\n",
      "Scaled KL Loss is: 0.04738776758313179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3908740764704313\n",
      "NLL Loss is: 1.2639096568446588\n",
      "Scaled KL Loss is: 0.0485871322453022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.312496789089961\n",
      "NLL Loss is: 1.2451355980513135\n",
      "Scaled KL Loss is: 0.04530763998627663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.29044323803759\n",
      "NLL Loss is: 1.3596865787595795\n",
      "Scaled KL Loss is: 0.04662293940782547\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.406309518167405\n",
      "NLL Loss is: 1.3664513409270276\n",
      "Scaled KL Loss is: 0.04892878606915474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4153801269961823\n",
      "NLL Loss is: 1.303059956734334\n",
      "Scaled KL Loss is: 0.046952445060014725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3500124017943487\n",
      "NLL Loss is: 1.2608244026758584\n",
      "Scaled KL Loss is: 0.05077962577342987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3116040284492883\n",
      "NLL Loss is: 1.2437194839680334\n",
      "Scaled KL Loss is: 0.046910252422094345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2906297363901278\n",
      "NLL Loss is: 1.4185209814202289\n",
      "Scaled KL Loss is: 0.04798891767859459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4665098990988235\n",
      "NLL Loss is: 1.2982480582974978\n",
      "Scaled KL Loss is: 0.045081768184900284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343329826482398\n",
      "NLL Loss is: 1.2810023666412476\n",
      "Scaled KL Loss is: 0.05133907496929169\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3323414416105392\n",
      "NLL Loss is: 1.3072270174589233\n",
      "Scaled KL Loss is: 0.04883529990911484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3560623173680382\n",
      "NLL Loss is: 1.3827501356220782\n",
      "Scaled KL Loss is: 0.04710731282830238\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4298574484503805\n",
      "NLL Loss is: 1.2486260056874117\n",
      "Scaled KL Loss is: 0.04403585195541382\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2926618576428255\n",
      "NLL Loss is: 1.3748319877822774\n",
      "Scaled KL Loss is: 0.04519808664917946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420030074431457\n",
      "NLL Loss is: 1.3753934917526527\n",
      "Scaled KL Loss is: 0.04640262573957443\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4217961174922271\n",
      "NLL Loss is: 1.3234544165087658\n",
      "Scaled KL Loss is: 0.04708251729607582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3705369338048417\n",
      "NLL Loss is: 1.2278655656311233\n",
      "Scaled KL Loss is: 0.04543830454349518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2733038701746184\n",
      "NLL Loss is: 1.3157343357202729\n",
      "Scaled KL Loss is: 0.045910246670246124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.361644582390519\n",
      "NLL Loss is: 1.1829032616004556\n",
      "Scaled KL Loss is: 0.04940427094697952\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.232307532547435\n",
      "NLL Loss is: 1.3291165165442513\n",
      "Scaled KL Loss is: 0.043153803795576096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3722703203398274\n",
      "NLL Loss is: 1.186248543664667\n",
      "Scaled KL Loss is: 0.049334414303302765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2355829579679698\n",
      "NLL Loss is: 1.3029812554203133\n",
      "Scaled KL Loss is: 0.04794459789991379\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.350925853320227\n",
      "NLL Loss is: 1.3925294678923745\n",
      "Scaled KL Loss is: 0.04545031487941742\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.437979782771792\n",
      "NLL Loss is: 1.3210176704433763\n",
      "Scaled KL Loss is: 0.04380633682012558\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3648240072635018\n",
      "NLL Loss is: 1.2466029961513139\n",
      "Scaled KL Loss is: 0.04893090948462486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2955339056359387\n",
      "NLL Loss is: 1.2128810850671123\n",
      "Scaled KL Loss is: 0.045729976147413254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2586110612145256\n",
      "NLL Loss is: 1.411973365982342\n",
      "Scaled KL Loss is: 0.04647736996412277\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4584507359464647\n",
      "NLL Loss is: 1.2484634905767042\n",
      "Scaled KL Loss is: 0.047674115747213364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2961376063239176\n",
      "NLL Loss is: 1.663688082352507\n",
      "Scaled KL Loss is: 0.038118861615657806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.701806943968165\n",
      "NLL Loss is: 1.313755269826281 = 1.326; test loss = 1.365\n",
      "Scaled KL Loss is: 0.048673685640096664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3624289554663778\n",
      "NLL Loss is: 1.309224955271164\n",
      "Scaled KL Loss is: 0.0461115725338459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3553365278050098\n",
      "NLL Loss is: 1.3297819131589836\n",
      "Scaled KL Loss is: 0.047851379960775375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.377633293119759\n",
      "NLL Loss is: 1.3600268127087807\n",
      "Scaled KL Loss is: 0.04926420748233795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4092910201911186\n",
      "NLL Loss is: 1.3109780689525443\n",
      "Scaled KL Loss is: 0.0434526763856411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544307453381854\n",
      "NLL Loss is: 1.3425145305979407\n",
      "Scaled KL Loss is: 0.04886142536997795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3913759559679186\n",
      "NLL Loss is: 1.364777506747882\n",
      "Scaled KL Loss is: 0.04398995637893677\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4087674631268188\n",
      "NLL Loss is: 1.304797333072837\n",
      "Scaled KL Loss is: 0.04454202577471733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3493393588475544\n",
      "NLL Loss is: 1.371866755164988\n",
      "Scaled KL Loss is: 0.04308001324534416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414946768410332\n",
      "NLL Loss is: 1.2284523911112004\n",
      "Scaled KL Loss is: 0.04968686029314995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2781392514043504\n",
      "NLL Loss is: 1.239420700923757\n",
      "Scaled KL Loss is: 0.043152812868356705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2825735137921137\n",
      "NLL Loss is: 1.3840318242531249\n",
      "Scaled KL Loss is: 0.046528153121471405\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4305599773745963\n",
      "NLL Loss is: 1.2134466974324156\n",
      "Scaled KL Loss is: 0.05003175139427185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2634784488266875\n",
      "NLL Loss is: 1.4095097602119926\n",
      "Scaled KL Loss is: 0.04738470911979675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4568944693317893\n",
      "NLL Loss is: 1.2210138601208032\n",
      "Scaled KL Loss is: 0.04666485637426376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.267678716495067\n",
      "NLL Loss is: 1.3987915505627477\n",
      "Scaled KL Loss is: 0.0507727675139904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4495643180767381\n",
      "NLL Loss is: 1.3202510083960692\n",
      "Scaled KL Loss is: 0.047192104160785675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367443112556855\n",
      "NLL Loss is: 1.2819428864136067\n",
      "Scaled KL Loss is: 0.04718327522277832\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.329126161636385\n",
      "NLL Loss is: 1.204822393464608\n",
      "Scaled KL Loss is: 0.0474264957010746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2522488891656827\n",
      "NLL Loss is: 1.3103269651229061\n",
      "Scaled KL Loss is: 0.04543936625123024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3557663313741364\n",
      "NLL Loss is: 1.2375659442363296\n",
      "Scaled KL Loss is: 0.04554951190948486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2831154561458145\n",
      "NLL Loss is: 1.3146233207274158\n",
      "Scaled KL Loss is: 0.045732080936431885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3603554016638477\n",
      "NLL Loss is: 1.2230149838783098\n",
      "Scaled KL Loss is: 0.04639499634504318\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.269409980223353\n",
      "NLL Loss is: 1.5545439785483588\n",
      "Scaled KL Loss is: 0.04897424578666687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6035182243350257\n",
      "NLL Loss is: 1.1247581996863867\n",
      "Scaled KL Loss is: 0.04656122624874115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1713194259351278\n",
      "NLL Loss is: 1.2625905747348785\n",
      "Scaled KL Loss is: 0.05017036944627762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.312760944181156\n",
      "NLL Loss is: 1.3135996582754326\n",
      "Scaled KL Loss is: 0.052027907222509384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.365627565497942\n",
      "NLL Loss is: 1.1000743533240098\n",
      "Scaled KL Loss is: 0.0495721809566021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.149646534280612\n",
      "NLL Loss is: 1.2566642510125579\n",
      "Scaled KL Loss is: 0.04818541929125786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3048496703038157\n",
      "NLL Loss is: 1.0884348908097186\n",
      "Scaled KL Loss is: 0.048803310841321945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1372382016510405\n",
      "NLL Loss is: 1.1476193039539426\n",
      "Scaled KL Loss is: 0.04406864196062088\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1916879459145635\n",
      "NLL Loss is: 1.309382249985234\n",
      "Scaled KL Loss is: 0.04767753928899765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3570597892742315\n",
      "NLL Loss is: 1.3223639478757097\n",
      "Scaled KL Loss is: 0.0453970767557621\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3677610246314718\n",
      "NLL Loss is: 1.2268285596880169\n",
      "Scaled KL Loss is: 0.045826200395822525\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2726547600838394\n",
      "NLL Loss is: 1.4075723255346637\n",
      "Scaled KL Loss is: 0.04655807837843895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4541304039131027\n",
      "NLL Loss is: 1.4013941373502417\n",
      "Scaled KL Loss is: 0.04609699919819832\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.44749113654844\n",
      "NLL Loss is: 1.2260246277434015\n",
      "Scaled KL Loss is: 0.05234649032354355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.278371118066945\n",
      "NLL Loss is: 1.199385871924641\n",
      "Scaled KL Loss is: 0.05008544772863388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.249471319653275\n",
      "NLL Loss is: 1.3106109562204744\n",
      "Scaled KL Loss is: 0.04811602830886841\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3587269845293428\n",
      "NLL Loss is: 1.4317094333405274\n",
      "Scaled KL Loss is: 0.04814929887652397\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4798587322170513\n",
      "NLL Loss is: 1.1564568764165772\n",
      "Scaled KL Loss is: 0.049050167202949524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2055070436195268\n",
      "NLL Loss is: 1.161608236644225\n",
      "Scaled KL Loss is: 0.0441916398704052\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2057998765146303\n",
      "NLL Loss is: 1.1992427127215148\n",
      "Scaled KL Loss is: 0.049705345183610916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2489480579051258\n",
      "NLL Loss is: 1.206675844014551\n",
      "Scaled KL Loss is: 0.05432625487446785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.261002098889019\n",
      "NLL Loss is: 1.2770914040985908\n",
      "Scaled KL Loss is: 0.04534701257944107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3224384166780319\n",
      "NLL Loss is: 1.2069370231082923\n",
      "Scaled KL Loss is: 0.04996197670698166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.256898999815274\n",
      "NLL Loss is: 1.2393375391182324\n",
      "Scaled KL Loss is: 0.05056868866086006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2899062277790925\n",
      "NLL Loss is: 1.1415449441677548\n",
      "Scaled KL Loss is: 0.05318158119916916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.194726525366924\n",
      "NLL Loss is: 1.2436776715481968\n",
      "Scaled KL Loss is: 0.049785640090703964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2934633116389007\n",
      "NLL Loss is: 1.1641606828611555\n",
      "Scaled KL Loss is: 0.049311477690935135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2134721605520906\n",
      "NLL Loss is: 1.255127607619695\n",
      "Scaled KL Loss is: 0.050111450254917145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3052390578746123\n",
      "NLL Loss is: 1.2852030105946821\n",
      "Scaled KL Loss is: 0.04646831378340721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3316713243780893\n",
      "NLL Loss is: 1.1889594579532683\n",
      "Scaled KL Loss is: 0.04993433877825737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2388937967315257\n",
      "NLL Loss is: 1.297583318461125\n",
      "Scaled KL Loss is: 0.04705134779214859\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3446346662532735\n",
      "NLL Loss is: 1.3709088795234465\n",
      "Scaled KL Loss is: 0.045938290655612946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4168471701790595\n",
      "NLL Loss is: 1.3529709652227797\n",
      "Scaled KL Loss is: 0.04520599916577339\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.398176964388553\n",
      "NLL Loss is: 1.3705153117276592\n",
      "Scaled KL Loss is: 0.04928532615303993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.419800637880699\n",
      "NLL Loss is: 1.2313749735983026\n",
      "Scaled KL Loss is: 0.04718644544482231\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.278561419043125\n",
      "NLL Loss is: 1.198812455078115\n",
      "Scaled KL Loss is: 0.04537321627140045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2441856713495154\n",
      "NLL Loss is: 1.1447418854650986\n",
      "Scaled KL Loss is: 0.050441525876522064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1951834113416206\n",
      "NLL Loss is: 1.241578338541379\n",
      "Scaled KL Loss is: 0.04899660497903824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2905749435204172\n",
      "NLL Loss is: 1.2583086866581181\n",
      "Scaled KL Loss is: 0.04796775057911873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3062764372372369\n",
      "NLL Loss is: 1.3419499349187356\n",
      "Scaled KL Loss is: 0.04740739241242409\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3893573273311597\n",
      "NLL Loss is: 1.263242690549856\n",
      "Scaled KL Loss is: 0.04867297038435936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3119156609342153\n",
      "NLL Loss is: 1.2439184869780489\n",
      "Scaled KL Loss is: 0.04532669484615326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2892451818242021\n",
      "NLL Loss is: 1.3589590382408727\n",
      "Scaled KL Loss is: 0.046650566160678864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4056096044015516\n",
      "NLL Loss is: 1.3654301668870923\n",
      "Scaled KL Loss is: 0.04900703951716423\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4144372064042565\n",
      "NLL Loss is: 1.3020508789604435\n",
      "Scaled KL Loss is: 0.04695428907871246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.349005168039156\n",
      "NLL Loss is: 1.2595919970514413\n",
      "Scaled KL Loss is: 0.05079057440161705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3103825714530584\n",
      "NLL Loss is: 1.2422814230828372\n",
      "Scaled KL Loss is: 0.04692719504237175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289208618125209\n",
      "NLL Loss is: 1.417370664677951\n",
      "Scaled KL Loss is: 0.048022396862506866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4653930615404578\n",
      "NLL Loss is: 1.2969821928391816\n",
      "Scaled KL Loss is: 0.04512351378798485\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3421057066271664\n",
      "NLL Loss is: 1.280241562890886\n",
      "Scaled KL Loss is: 0.05138092860579491\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.331622491496681\n",
      "NLL Loss is: 1.3062146547406142\n",
      "Scaled KL Loss is: 0.048887234181165695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3551018889217799\n",
      "NLL Loss is: 1.3817025669172163\n",
      "Scaled KL Loss is: 0.04714865982532501\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4288512267425413\n",
      "NLL Loss is: 1.2477186407789551\n",
      "Scaled KL Loss is: 0.04406972602009773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2917883667990528\n",
      "NLL Loss is: 1.3741179789509823\n",
      "Scaled KL Loss is: 0.04519638419151306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4193143631424954\n",
      "NLL Loss is: 1.374506349766032\n",
      "Scaled KL Loss is: 0.04646600782871246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4209723575947444\n",
      "NLL Loss is: 1.32333530088164\n",
      "Scaled KL Loss is: 0.0470583476126194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3703936484942594\n",
      "NLL Loss is: 1.2268026708904616\n",
      "Scaled KL Loss is: 0.045456502586603165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2722591734770647\n",
      "NLL Loss is: 1.3147502175457517\n",
      "Scaled KL Loss is: 0.04594224691390991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3606924644596616\n",
      "NLL Loss is: 1.1816594509229015\n",
      "Scaled KL Loss is: 0.04945308715105057\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.231112538073952\n",
      "NLL Loss is: 1.3285628529336366\n",
      "Scaled KL Loss is: 0.04316268488764763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3717255378212843\n",
      "NLL Loss is: 1.1854727248741184\n",
      "Scaled KL Loss is: 0.04935865476727486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2348313796413932\n",
      "NLL Loss is: 1.3017044646058136\n",
      "Scaled KL Loss is: 0.04794429987668991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3496487644825035\n",
      "NLL Loss is: 1.3912967629979773\n",
      "Scaled KL Loss is: 0.04549382999539375\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.436790592993371\n",
      "NLL Loss is: 1.320158132329114\n",
      "Scaled KL Loss is: 0.04383997991681099\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.363998112245925\n",
      "NLL Loss is: 1.245029348862391\n",
      "Scaled KL Loss is: 0.048946697264909744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2939760461273007\n",
      "NLL Loss is: 1.211877450490917\n",
      "Scaled KL Loss is: 0.045792508870363235\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2576699593612803\n",
      "NLL Loss is: 1.4111946711203274\n",
      "Scaled KL Loss is: 0.046523500233888626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.457718171354216\n",
      "NLL Loss is: 1.2475254723025682\n",
      "Scaled KL Loss is: 0.047719862312078476\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2952453346146466\n",
      "NLL Loss is: 1.6636497842591915\n",
      "Scaled KL Loss is: 0.03813447803258896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7017842622917805\n",
      "NLL Loss is: 1.313197188431101 = 1.325; test loss = 1.364\n",
      "Scaled KL Loss is: 0.0486881285905838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3618853170216847\n",
      "NLL Loss is: 1.3082695372454851\n",
      "Scaled KL Loss is: 0.04615778848528862\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544273257307737\n",
      "NLL Loss is: 1.328637276742012\n",
      "Scaled KL Loss is: 0.04788577929139137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3765230560334034\n",
      "NLL Loss is: 1.3593672642583448\n",
      "Scaled KL Loss is: 0.04923727363348007\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4086045378918248\n",
      "NLL Loss is: 1.3097743009467393\n",
      "Scaled KL Loss is: 0.04348462447524071\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35325892542198\n",
      "NLL Loss is: 1.341483363238471\n",
      "Scaled KL Loss is: 0.04889766499400139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3903810282324724\n",
      "NLL Loss is: 1.363629487676962\n",
      "Scaled KL Loss is: 0.04407217726111412\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.407701664938076\n",
      "NLL Loss is: 1.3037085183179402\n",
      "Scaled KL Loss is: 0.04457975924015045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3482882775580907\n",
      "NLL Loss is: 1.3711304872054138\n",
      "Scaled KL Loss is: 0.04308946058154106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4142199477869548\n",
      "NLL Loss is: 1.2274871586925513\n",
      "Scaled KL Loss is: 0.04969588667154312\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2771830453640944\n",
      "NLL Loss is: 1.2381063088271131\n",
      "Scaled KL Loss is: 0.04312851279973984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.281234821626853\n",
      "NLL Loss is: 1.383076955079797\n",
      "Scaled KL Loss is: 0.04656854644417763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4296455015239746\n",
      "NLL Loss is: 1.2126637262973816\n",
      "Scaled KL Loss is: 0.050057362765073776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2627210890624554\n",
      "NLL Loss is: 1.4084615149195556\n",
      "Scaled KL Loss is: 0.04738643020391464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4558479451234703\n",
      "NLL Loss is: 1.2200549451744913\n",
      "Scaled KL Loss is: 0.04670286551117897\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2667578106856703\n",
      "NLL Loss is: 1.3976819002536727\n",
      "Scaled KL Loss is: 0.050855644047260284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.448537544300933\n",
      "NLL Loss is: 1.3189797724116608\n",
      "Scaled KL Loss is: 0.04727201536297798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3662517877746387\n",
      "NLL Loss is: 1.2808596590213324\n",
      "Scaled KL Loss is: 0.047201234847307205\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3280608938686396\n",
      "NLL Loss is: 1.203659600460391\n",
      "Scaled KL Loss is: 0.04747692868113518\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2511365291415262\n",
      "NLL Loss is: 1.3090621083586313\n",
      "Scaled KL Loss is: 0.0454963855445385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3545584939031698\n",
      "NLL Loss is: 1.2364062076688693\n",
      "Scaled KL Loss is: 0.0455465205013752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2819527281702445\n",
      "NLL Loss is: 1.313241388684371\n",
      "Scaled KL Loss is: 0.045820314437150955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359061703121522\n",
      "NLL Loss is: 1.2217024482470211\n",
      "Scaled KL Loss is: 0.046475786715745926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.268178234962767\n",
      "NLL Loss is: 1.5535504467650114\n",
      "Scaled KL Loss is: 0.04898298159241676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6025334283574282\n",
      "NLL Loss is: 1.1238526217626132\n",
      "Scaled KL Loss is: 0.04659436270594597\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1704469844685592\n",
      "NLL Loss is: 1.2616556201109466\n",
      "Scaled KL Loss is: 0.05018427222967148\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.311839892340618\n",
      "NLL Loss is: 1.3124987434895439\n",
      "Scaled KL Loss is: 0.052070360630750656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3645691041202945\n",
      "NLL Loss is: 1.098972423870694\n",
      "Scaled KL Loss is: 0.04961925372481346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1485916775955074\n",
      "NLL Loss is: 1.255487898687737\n",
      "Scaled KL Loss is: 0.04821407049894333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3037019691866802\n",
      "NLL Loss is: 1.0871062159905123\n",
      "Scaled KL Loss is: 0.04884851351380348\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1359547295043158\n",
      "NLL Loss is: 1.1467271839543365\n",
      "Scaled KL Loss is: 0.04408144950866699\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1908086334630035\n",
      "NLL Loss is: 1.3084070409124664\n",
      "Scaled KL Loss is: 0.04770103469491005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3561080756073765\n",
      "NLL Loss is: 1.3213776337367085\n",
      "Scaled KL Loss is: 0.04541241377592087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3667900475126293\n",
      "NLL Loss is: 1.226293197811918\n",
      "Scaled KL Loss is: 0.04584280773997307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.272136005551891\n",
      "NLL Loss is: 1.4069868909993408\n",
      "Scaled KL Loss is: 0.0465809665620327\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4535678575613735\n",
      "NLL Loss is: 1.3997077419635735\n",
      "Scaled KL Loss is: 0.046108875423669815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4458166173872433\n",
      "NLL Loss is: 1.2252542386700827\n",
      "Scaled KL Loss is: 0.05231759324669838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.277571831916781\n",
      "NLL Loss is: 1.1989953936903328\n",
      "Scaled KL Loss is: 0.05014131963253021\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.249136713322863\n",
      "NLL Loss is: 1.3099234499126668\n",
      "Scaled KL Loss is: 0.048170123249292374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3580935731619592\n",
      "NLL Loss is: 1.4308790127613025\n",
      "Scaled KL Loss is: 0.04815887659788132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4790378893591838\n",
      "NLL Loss is: 1.1550661537225517\n",
      "Scaled KL Loss is: 0.04909495264291763\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2041611063654694\n",
      "NLL Loss is: 1.1603826409181073\n",
      "Scaled KL Loss is: 0.04424109682440758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2046237377425149\n",
      "NLL Loss is: 1.1982261978915962\n",
      "Scaled KL Loss is: 0.04980217665433884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.248028374545935\n",
      "NLL Loss is: 1.2059922137779129\n",
      "Scaled KL Loss is: 0.054332368075847626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2603245818537605\n",
      "NLL Loss is: 1.2759834512578854\n",
      "Scaled KL Loss is: 0.04536626115441322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3213497124122986\n",
      "NLL Loss is: 1.2060547075514618\n",
      "Scaled KL Loss is: 0.05003094673156738\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2560856542830292\n",
      "NLL Loss is: 1.2388565361379633\n",
      "Scaled KL Loss is: 0.05059143900871277\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289447975146676\n",
      "NLL Loss is: 1.1405306510069926\n",
      "Scaled KL Loss is: 0.053284142166376114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1938147931733687\n",
      "NLL Loss is: 1.243067935804342\n",
      "Scaled KL Loss is: 0.04979921132326126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2928671471276032\n",
      "NLL Loss is: 1.1630963770815326\n",
      "Scaled KL Loss is: 0.04937153309583664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2124679101773692\n",
      "NLL Loss is: 1.2543853485269199\n",
      "Scaled KL Loss is: 0.05016661062836647\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3045519591552863\n",
      "NLL Loss is: 1.2841344839681772\n",
      "Scaled KL Loss is: 0.04649392515420914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3306284091223863\n",
      "NLL Loss is: 1.1879008268844342\n",
      "Scaled KL Loss is: 0.04996486008167267\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2378656869661069\n",
      "NLL Loss is: 1.2965125419502648\n",
      "Scaled KL Loss is: 0.047143492847681046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3436560347979458\n",
      "NLL Loss is: 1.3701136955759114\n",
      "Scaled KL Loss is: 0.04597419500350952\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416087890579421\n",
      "NLL Loss is: 1.3516673964570938\n",
      "Scaled KL Loss is: 0.04526709392666817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.396934490383762\n",
      "NLL Loss is: 1.3697554262905052\n",
      "Scaled KL Loss is: 0.049313612282276154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4190690385727813\n",
      "NLL Loss is: 1.230900576423875\n",
      "Scaled KL Loss is: 0.04721369966864586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2781142760925208\n",
      "NLL Loss is: 1.1973800198486304\n",
      "Scaled KL Loss is: 0.04543973505496979\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2428197549036002\n",
      "NLL Loss is: 1.1437838682485322\n",
      "Scaled KL Loss is: 0.050467099994421005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1942509682429532\n",
      "NLL Loss is: 1.2408738427234531\n",
      "Scaled KL Loss is: 0.04905959963798523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2899334423614384\n",
      "NLL Loss is: 1.2569730291789287\n",
      "Scaled KL Loss is: 0.048010267317295074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3049832964962238\n",
      "NLL Loss is: 1.3404285851031823\n",
      "Scaled KL Loss is: 0.04744729772210121\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3878758828252835\n",
      "NLL Loss is: 1.2625746548974268\n",
      "Scaled KL Loss is: 0.048771847039461136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.311346501936888\n",
      "NLL Loss is: 1.242696772373475\n",
      "Scaled KL Loss is: 0.04536675289273262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2880635252662076\n",
      "NLL Loss is: 1.3581727445783138\n",
      "Scaled KL Loss is: 0.04669533297419548\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4048680775525093\n",
      "NLL Loss is: 1.3644021688893178\n",
      "Scaled KL Loss is: 0.0491010807454586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4135032496347764\n",
      "NLL Loss is: 1.3010456276305729\n",
      "Scaled KL Loss is: 0.04698052629828453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3480261539288574\n",
      "NLL Loss is: 1.2583826137932417\n",
      "Scaled KL Loss is: 0.05082570016384125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.309208313957083\n",
      "NLL Loss is: 1.240832983865382\n",
      "Scaled KL Loss is: 0.04696983844041824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2878028223058002\n",
      "NLL Loss is: 1.4162458346494873\n",
      "Scaled KL Loss is: 0.04807859659194946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4643244312414367\n",
      "NLL Loss is: 1.2957540521998336\n",
      "Scaled KL Loss is: 0.0451853983104229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3409394505102565\n",
      "NLL Loss is: 1.2794526463795244\n",
      "Scaled KL Loss is: 0.05145084112882614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3309034875083505\n",
      "NLL Loss is: 1.305243799850907\n",
      "Scaled KL Loss is: 0.048963602632284164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3542074024831912\n",
      "NLL Loss is: 1.3806091196158718\n",
      "Scaled KL Loss is: 0.047213807702064514\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4278229273179364\n",
      "NLL Loss is: 1.24683529467207\n",
      "Scaled KL Loss is: 0.04412823170423508\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.290963526376305\n",
      "NLL Loss is: 1.3733581756420181\n",
      "Scaled KL Loss is: 0.045224957168102264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4185831328101204\n",
      "NLL Loss is: 1.3734575824542339\n",
      "Scaled KL Loss is: 0.04654606804251671\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4200036504967506\n",
      "NLL Loss is: 1.3232007384953983\n",
      "Scaled KL Loss is: 0.04706990718841553\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702706456838138\n",
      "NLL Loss is: 1.225730669537713\n",
      "Scaled KL Loss is: 0.04550347849726677\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2712341480349798\n",
      "NLL Loss is: 1.3137760011326316\n",
      "Scaled KL Loss is: 0.04599830508232117\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3597743062149528\n",
      "NLL Loss is: 1.1803013380448517\n",
      "Scaled KL Loss is: 0.04952597990632057\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2298273179511723\n",
      "NLL Loss is: 1.3280087651471706\n",
      "Scaled KL Loss is: 0.04319867491722107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3712074400643917\n",
      "NLL Loss is: 1.184640358343974\n",
      "Scaled KL Loss is: 0.04941403865814209\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.234054397002116\n",
      "NLL Loss is: 1.300439910356302\n",
      "Scaled KL Loss is: 0.047972582280635834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3484124926369379\n",
      "NLL Loss is: 1.3900614137284366\n",
      "Scaled KL Loss is: 0.04555336385965347\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.43561477758809\n",
      "NLL Loss is: 1.3193043281594317\n",
      "Scaled KL Loss is: 0.043900515884160995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3632048440435927\n",
      "NLL Loss is: 1.2434554294565112\n",
      "Scaled KL Loss is: 0.04898899048566818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2924444199421794\n",
      "NLL Loss is: 1.2108950286072346\n",
      "Scaled KL Loss is: 0.04587646946310997\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2567714980703446\n",
      "NLL Loss is: 1.4104560870871887\n",
      "Scaled KL Loss is: 0.04658873751759529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.457044824604784\n",
      "NLL Loss is: 1.2465746810614795\n",
      "Scaled KL Loss is: 0.047788430005311966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943631110667915\n",
      "NLL Loss is: 1.663755669211964\n",
      "Scaled KL Loss is: 0.03816768899559975\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7019233582075637\n",
      "NLL Loss is: 1.3126495866443364= 1.324; test loss = 1.363\n",
      "Scaled KL Loss is: 0.04873102158308029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3613806082274167\n",
      "NLL Loss is: 1.3072731817075662\n",
      "Scaled KL Loss is: 0.04623343423008919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3535066159376554\n",
      "NLL Loss is: 1.3274768056470825\n",
      "Scaled KL Loss is: 0.047946322709321976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3754231283564045\n",
      "NLL Loss is: 1.3586469133188894\n",
      "Scaled KL Loss is: 0.04925186187028885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4078987751891783\n",
      "NLL Loss is: 1.3085897808305822\n",
      "Scaled KL Loss is: 0.04354802891612053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3521378097467027\n",
      "NLL Loss is: 1.3403089051593424\n",
      "Scaled KL Loss is: 0.04897438362240791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3892832887817503\n",
      "NLL Loss is: 1.3625890290850697\n",
      "Scaled KL Loss is: 0.044191453605890274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.40678048269096\n",
      "NLL Loss is: 1.3026823296360743\n",
      "Scaled KL Loss is: 0.044666871428489685\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.347349201064564\n",
      "NLL Loss is: 1.370424541358792\n",
      "Scaled KL Loss is: 0.04314621537923813\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4135707567380302\n",
      "NLL Loss is: 1.226513510087578\n",
      "Scaled KL Loss is: 0.049754634499549866\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2762681445871278\n",
      "NLL Loss is: 1.2368717023142153\n",
      "Scaled KL Loss is: 0.04316713660955429\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2800388389237696\n",
      "NLL Loss is: 1.3822432578072006\n",
      "Scaled KL Loss is: 0.04665183275938034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.428895090566581\n",
      "NLL Loss is: 1.2117962347252924\n",
      "Scaled KL Loss is: 0.05012457072734833\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2619208054526407\n",
      "NLL Loss is: 1.4073234446892247\n",
      "Scaled KL Loss is: 0.047439634799957275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.454763079489182\n",
      "NLL Loss is: 1.2191112336300038\n",
      "Scaled KL Loss is: 0.046795088797807693\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2659063224278115\n",
      "NLL Loss is: 1.3965750112629107\n",
      "Scaled KL Loss is: 0.050971053540706635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4475460648036174\n",
      "NLL Loss is: 1.31763017001392\n",
      "Scaled KL Loss is: 0.04738572984933853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3650158998632584\n",
      "NLL Loss is: 1.2797727555277485\n",
      "Scaled KL Loss is: 0.04726706072688103\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3270398162546295\n",
      "NLL Loss is: 1.202431002874556\n",
      "Scaled KL Loss is: 0.04756535589694977\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2499963587715057\n",
      "NLL Loss is: 1.3077738069434701\n",
      "Scaled KL Loss is: 0.04558839276432991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3533621997078\n",
      "NLL Loss is: 1.235045775028847\n",
      "Scaled KL Loss is: 0.04559981822967529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2806455932585223\n",
      "NLL Loss is: 1.3118329045734953\n",
      "Scaled KL Loss is: 0.045945122838020325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3577780274115157\n",
      "NLL Loss is: 1.2202487304263678\n",
      "Scaled KL Loss is: 0.04659193754196167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2668406679683295\n",
      "NLL Loss is: 1.5526883130094062\n",
      "Scaled KL Loss is: 0.04904172196984291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6017300349792492\n",
      "NLL Loss is: 1.1228897576564534\n",
      "Scaled KL Loss is: 0.046670101583004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1695598592394574\n",
      "NLL Loss is: 1.2607246301513042\n",
      "Scaled KL Loss is: 0.0502389557659626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3109635859172668\n",
      "NLL Loss is: 1.3114105682261052\n",
      "Scaled KL Loss is: 0.05215103551745415\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3635616037435594\n",
      "NLL Loss is: 1.097863721950747\n",
      "Scaled KL Loss is: 0.04969745874404907\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.147561180694796\n",
      "NLL Loss is: 1.254289715862332\n",
      "Scaled KL Loss is: 0.048280294984579086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3025700108469112\n",
      "NLL Loss is: 1.0857102913514531\n",
      "Scaled KL Loss is: 0.04892926290631294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.134639554257766\n",
      "NLL Loss is: 1.1458034017683862\n",
      "Scaled KL Loss is: 0.04413251951336861\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1899359212817548\n",
      "NLL Loss is: 1.307438076665397\n",
      "Scaled KL Loss is: 0.04776238650083542\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3552004631662324\n",
      "NLL Loss is: 1.3204304935072344\n",
      "Scaled KL Loss is: 0.04546830430626869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.365898797813503\n",
      "NLL Loss is: 1.2257315437157876\n",
      "Scaled KL Loss is: 0.045895904302597046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2716274480183847\n",
      "NLL Loss is: 1.4064503838427833\n",
      "Scaled KL Loss is: 0.046633925288915634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.453084309131699\n",
      "NLL Loss is: 1.3980869069019395\n",
      "Scaled KL Loss is: 0.04615456610918045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.44424147301112\n",
      "NLL Loss is: 1.2244766722846772\n",
      "Scaled KL Loss is: 0.052320294082164764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276796966366842\n",
      "NLL Loss is: 1.1985291348045661\n",
      "Scaled KL Loss is: 0.05022318661212921\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2487523214166953\n",
      "NLL Loss is: 1.3092482999919914\n",
      "Scaled KL Loss is: 0.04824577271938324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3574940727113747\n",
      "NLL Loss is: 1.4300243555323016\n",
      "Scaled KL Loss is: 0.04819141700863838\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.47821577254094\n",
      "NLL Loss is: 1.153691006762615\n",
      "Scaled KL Loss is: 0.04915632680058479\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2028473335631997\n",
      "NLL Loss is: 1.1595377893143868\n",
      "Scaled KL Loss is: 0.044300422072410583\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2038382113867974\n",
      "NLL Loss is: 1.1970194357461148\n",
      "Scaled KL Loss is: 0.049900177866220474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2469196136123353\n",
      "NLL Loss is: 1.204006300893541\n",
      "Scaled KL Loss is: 0.054331474006175995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.258337774899717\n",
      "NLL Loss is: 1.2751436618600442\n",
      "Scaled KL Loss is: 0.045360881835222244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3205045436952665\n",
      "NLL Loss is: 1.20484399205165\n",
      "Scaled KL Loss is: 0.05009198561310768\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2549359776647577\n",
      "NLL Loss is: 1.2382875412165795\n",
      "Scaled KL Loss is: 0.05058175325393677\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2888692944705162\n",
      "NLL Loss is: 1.1398314664595932\n",
      "Scaled KL Loss is: 0.05336262285709381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.193194089316687\n",
      "NLL Loss is: 1.2427044459178092\n",
      "Scaled KL Loss is: 0.049787115305662155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2924915612234713\n",
      "NLL Loss is: 1.1624256131310853\n",
      "Scaled KL Loss is: 0.049389202147722244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2118148152788075\n",
      "NLL Loss is: 1.255204955148031\n",
      "Scaled KL Loss is: 0.05018021538853645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3053851705365676\n",
      "NLL Loss is: 1.2826629930049847\n",
      "Scaled KL Loss is: 0.04645323008298874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3291162230879734\n",
      "NLL Loss is: 1.1884963027836355\n",
      "Scaled KL Loss is: 0.049931734800338745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2384280375839742\n",
      "NLL Loss is: 1.2958022903333823\n",
      "Scaled KL Loss is: 0.047171201556921005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3429734918903034\n",
      "NLL Loss is: 1.3709953368054102\n",
      "Scaled KL Loss is: 0.04594222456216812\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4169375613675783\n",
      "NLL Loss is: 1.3505491817481112\n",
      "Scaled KL Loss is: 0.04524322971701622\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3957924114651274\n",
      "NLL Loss is: 1.3694688485331934\n",
      "Scaled KL Loss is: 0.04925604164600372\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4187248901791971\n",
      "NLL Loss is: 1.2306466962994258\n",
      "Scaled KL Loss is: 0.04713637754321098\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2777830738426368\n",
      "NLL Loss is: 1.1959125203605814\n",
      "Scaled KL Loss is: 0.04542715474963188\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2413396751102133\n",
      "NLL Loss is: 1.143093363642165\n",
      "Scaled KL Loss is: 0.05038046836853027\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1934738320106952\n",
      "NLL Loss is: 1.2408406806602996\n",
      "Scaled KL Loss is: 0.04902225360274315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2898629342630428\n",
      "NLL Loss is: 1.2558415804084908\n",
      "Scaled KL Loss is: 0.047951750457286835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3037933308657776\n",
      "NLL Loss is: 1.3384337483380762\n",
      "Scaled KL Loss is: 0.04739673435688019\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3858304826949563\n",
      "NLL Loss is: 1.2622266954302737\n",
      "Scaled KL Loss is: 0.04879975691437721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3110264523446509\n",
      "NLL Loss is: 1.241786615618399\n",
      "Scaled KL Loss is: 0.0453316904604435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2871183060788425\n",
      "NLL Loss is: 1.3561925331797244\n",
      "Scaled KL Loss is: 0.046660006046295166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4028525392260196\n",
      "NLL Loss is: 1.3634349733074222\n",
      "Scaled KL Loss is: 0.04912349954247475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.412558472849897\n",
      "NLL Loss is: 1.3005164154814555\n",
      "Scaled KL Loss is: 0.046923812478780746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3474402279602362\n",
      "NLL Loss is: 1.2573779039053223\n",
      "Scaled KL Loss is: 0.05078399181365967\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.308161895718982\n",
      "NLL Loss is: 1.23904584211678\n",
      "Scaled KL Loss is: 0.04695199429988861\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2859978364166686\n",
      "NLL Loss is: 1.4151721548749494\n",
      "Scaled KL Loss is: 0.04807068407535553\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.463242838950305\n",
      "NLL Loss is: 1.2950702504898592\n",
      "Scaled KL Loss is: 0.04518288001418114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3402531305040404\n",
      "NLL Loss is: 1.2792346341857783\n",
      "Scaled KL Loss is: 0.05144562944769859\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.330680263633477\n",
      "NLL Loss is: 1.3044610568560113\n",
      "Scaled KL Loss is: 0.04897691681981087\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3534379736758222\n",
      "NLL Loss is: 1.3798329193548158\n",
      "Scaled KL Loss is: 0.04721652716398239\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4270494465187982\n",
      "NLL Loss is: 1.246551068453678\n",
      "Scaled KL Loss is: 0.04412854090332985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2906796093570079\n",
      "NLL Loss is: 1.3727662440240016\n",
      "Scaled KL Loss is: 0.045191843062639236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4179580870866408\n",
      "NLL Loss is: 1.3712563334790848\n",
      "Scaled KL Loss is: 0.04656646028161049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4178227937606953\n",
      "NLL Loss is: 1.3234308083139044\n",
      "Scaled KL Loss is: 0.04701549559831619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3704463039122206\n",
      "NLL Loss is: 1.224602454508524\n",
      "Scaled KL Loss is: 0.04546891152858734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2700713660371112\n",
      "NLL Loss is: 1.3129343802212277\n",
      "Scaled KL Loss is: 0.04598495736718178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3589193375884094\n",
      "NLL Loss is: 1.1789514562743\n",
      "Scaled KL Loss is: 0.04952310398221016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2284745602565101\n",
      "NLL Loss is: 1.3275637480713027\n",
      "Scaled KL Loss is: 0.04317779839038849\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3707415464616912\n",
      "NLL Loss is: 1.184655554927634\n",
      "Scaled KL Loss is: 0.04940939322113991\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.234064948148774\n",
      "NLL Loss is: 1.2994012488167481\n",
      "Scaled KL Loss is: 0.04794147238135338\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3473427211981015\n",
      "NLL Loss is: 1.3887957205304806\n",
      "Scaled KL Loss is: 0.04556002467870712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4343557452091877\n",
      "NLL Loss is: 1.3183567475503033\n",
      "Scaled KL Loss is: 0.04391050711274147\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3622672546630448\n",
      "NLL Loss is: 1.242515755590652\n",
      "Scaled KL Loss is: 0.048955392092466354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2914711476831184\n",
      "NLL Loss is: 1.2104766460111387\n",
      "Scaled KL Loss is: 0.045894742012023926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2563713880231626\n",
      "NLL Loss is: 1.409651906695012\n",
      "Scaled KL Loss is: 0.04659203067421913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.456243937369231\n",
      "NLL Loss is: 1.2460489790320926\n",
      "Scaled KL Loss is: 0.04780120402574539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.293850183057838\n",
      "NLL Loss is: 1.6645388974264541\n",
      "Scaled KL Loss is: 0.038150958716869354\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7026898561433235\n",
      "NLL Loss is: 1.31223230954004s = 1.323; test loss = 1.362\n",
      "Scaled KL Loss is: 0.04870932176709175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3609416313071319\n",
      "NLL Loss is: 1.3066981956198913\n",
      "Scaled KL Loss is: 0.04625123366713524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3529494292870266\n",
      "NLL Loss is: 1.3261571588830647\n",
      "Scaled KL Loss is: 0.04794291779398918\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.374100076677054\n",
      "NLL Loss is: 1.357808422861731\n",
      "Scaled KL Loss is: 0.04919223114848137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4070006540102125\n",
      "NLL Loss is: 1.3071923716232094\n",
      "Scaled KL Loss is: 0.04356328025460243\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3507556518778119\n",
      "NLL Loss is: 1.3395063140727559\n",
      "Scaled KL Loss is: 0.04899450019001961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3885008142627755\n",
      "NLL Loss is: 1.3615286349003464\n",
      "Scaled KL Loss is: 0.04426386579871178\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4057925006990581\n",
      "NLL Loss is: 1.3018615974311132\n",
      "Scaled KL Loss is: 0.044702816754579544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3465644141856927\n",
      "NLL Loss is: 1.3699972561001073\n",
      "Scaled KL Loss is: 0.04315122589468956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4131484819947968\n",
      "NLL Loss is: 1.2255895387338391\n",
      "Scaled KL Loss is: 0.049760445952415466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2753499846862546\n",
      "NLL Loss is: 1.2356498062681442\n",
      "Scaled KL Loss is: 0.04315133020281792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2788011364709622\n",
      "NLL Loss is: 1.381346594751559\n",
      "Scaled KL Loss is: 0.04669419676065445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4280407915122135\n",
      "NLL Loss is: 1.2110593346006877\n",
      "Scaled KL Loss is: 0.050147704780101776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2612070393807895\n",
      "NLL Loss is: 1.406185871665191\n",
      "Scaled KL Loss is: 0.047451142221689224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4536370138868802\n",
      "NLL Loss is: 1.2182452132347434\n",
      "Scaled KL Loss is: 0.04684608802199364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265091301256737\n",
      "NLL Loss is: 1.3954832140589204\n",
      "Scaled KL Loss is: 0.05105156451463699\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4465347785735574\n",
      "NLL Loss is: 1.3163436673534123\n",
      "Scaled KL Loss is: 0.047470882534980774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3638145498883931\n",
      "NLL Loss is: 1.2788401808159904\n",
      "Scaled KL Loss is: 0.047302283346652985\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3261424641626434\n",
      "NLL Loss is: 1.2013696160163598\n",
      "Scaled KL Loss is: 0.04762691259384155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2489965286102014\n",
      "NLL Loss is: 1.3065905878644033\n",
      "Scaled KL Loss is: 0.045657671988010406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3522482598524137\n",
      "NLL Loss is: 1.2334923762429546\n",
      "Scaled KL Loss is: 0.045627154409885406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27911953065284\n",
      "NLL Loss is: 1.3104446313388285\n",
      "Scaled KL Loss is: 0.04605031758546829\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564949489242968\n",
      "NLL Loss is: 1.2187231103073393\n",
      "Scaled KL Loss is: 0.046689338982105255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2654124492894445\n",
      "NLL Loss is: 1.552150224285583\n",
      "Scaled KL Loss is: 0.049078892916440964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6012291172020239\n",
      "NLL Loss is: 1.1219139014070694\n",
      "Scaled KL Loss is: 0.046731241047382355\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1686451424544517\n",
      "NLL Loss is: 1.259722021927206\n",
      "Scaled KL Loss is: 0.050282079726457596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3100041016536637\n",
      "NLL Loss is: 1.31029788412537\n",
      "Scaled KL Loss is: 0.05222300440073013\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3625208885261002\n",
      "NLL Loss is: 1.0965458608806156\n",
      "Scaled KL Loss is: 0.04977172240614891\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1463175832867645\n",
      "NLL Loss is: 1.2530157687660641\n",
      "Scaled KL Loss is: 0.04833953455090523\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3013553033169694\n",
      "NLL Loss is: 1.084229503471482\n",
      "Scaled KL Loss is: 0.049008674919605255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1332381783910872\n",
      "NLL Loss is: 1.144793765782974\n",
      "Scaled KL Loss is: 0.044185664504766464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1889794302877406\n",
      "NLL Loss is: 1.3064451587163632\n",
      "Scaled KL Loss is: 0.0478244312107563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3542695899271195\n",
      "NLL Loss is: 1.319567005030334\n",
      "Scaled KL Loss is: 0.04552886262536049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3650958676556946\n",
      "NLL Loss is: 1.2249378119940595\n",
      "Scaled KL Loss is: 0.04594926908612251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270887081080182\n",
      "NLL Loss is: 1.405794600527556\n",
      "Scaled KL Loss is: 0.04668894782662392\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4524835483541798\n",
      "NLL Loss is: 1.3965971772266206\n",
      "Scaled KL Loss is: 0.046207692474126816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4428048697007474\n",
      "NLL Loss is: 1.2235864554672853\n",
      "Scaled KL Loss is: 0.05233224853873253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2759187040060178\n",
      "NLL Loss is: 1.197992217689921\n",
      "Scaled KL Loss is: 0.05031007155776024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2483022892476812\n",
      "NLL Loss is: 1.3086631207150095\n",
      "Scaled KL Loss is: 0.04832868650555611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3569918072205656\n",
      "NLL Loss is: 1.429053973145785\n",
      "Scaled KL Loss is: 0.048235706984996796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4772896801307818\n",
      "NLL Loss is: 1.1523454893000595\n",
      "Scaled KL Loss is: 0.049236465245485306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2015819545455448\n",
      "NLL Loss is: 1.158416693847286\n",
      "Scaled KL Loss is: 0.044377077370882034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.202793771218168\n",
      "NLL Loss is: 1.1959599942107935\n",
      "Scaled KL Loss is: 0.05001712590456009\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2459771201153536\n",
      "NLL Loss is: 1.2032363627994884\n",
      "Scaled KL Loss is: 0.05436380207538605\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2576001648748745\n",
      "NLL Loss is: 1.274144159664359\n",
      "Scaled KL Loss is: 0.04539778083562851\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3195419404999875\n",
      "NLL Loss is: 1.2039863775540705\n",
      "Scaled KL Loss is: 0.05017414316534996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2541605207194204\n",
      "NLL Loss is: 1.2377495845186117\n",
      "Scaled KL Loss is: 0.0506153367459774\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2883649212645891\n",
      "NLL Loss is: 1.1388574327325847\n",
      "Scaled KL Loss is: 0.05347288027405739\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.192330313006642\n",
      "NLL Loss is: 1.2421257752608292\n",
      "Scaled KL Loss is: 0.04980987310409546\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2919356483649247\n",
      "NLL Loss is: 1.1614488181083606\n",
      "Scaled KL Loss is: 0.049458663910627365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.210907482018988\n",
      "NLL Loss is: 1.254480639347087\n",
      "Scaled KL Loss is: 0.05024401471018791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304724654057275\n",
      "NLL Loss is: 1.2817057024332628\n",
      "Scaled KL Loss is: 0.046485502272844315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.328191204706107\n",
      "NLL Loss is: 1.1875031605187472\n",
      "Scaled KL Loss is: 0.04997115954756737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2374743200663145\n",
      "NLL Loss is: 1.2947873880576382\n",
      "Scaled KL Loss is: 0.04727036878466606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3420577568423042\n",
      "NLL Loss is: 1.3701334426479577\n",
      "Scaled KL Loss is: 0.04598018527030945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4161136279182671\n",
      "NLL Loss is: 1.349270558582053\n",
      "Scaled KL Loss is: 0.0453060008585453\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3945765594405983\n",
      "NLL Loss is: 1.3687814701754053\n",
      "Scaled KL Loss is: 0.049288757145404816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4180702273208101\n",
      "NLL Loss is: 1.230180088166389\n",
      "Scaled KL Loss is: 0.04716842249035835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2773485106567473\n",
      "NLL Loss is: 1.1944871676962876\n",
      "Scaled KL Loss is: 0.04549577087163925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2399829385679269\n",
      "NLL Loss is: 1.1421852330872275\n",
      "Scaled KL Loss is: 0.05040841922163963\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1925936523088672\n",
      "NLL Loss is: 1.2402067153649061\n",
      "Scaled KL Loss is: 0.049084536731243134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2892912520961493\n",
      "NLL Loss is: 1.2546042683650698\n",
      "Scaled KL Loss is: 0.04799641668796539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3026006850530352\n",
      "NLL Loss is: 1.3369102110123041\n",
      "Scaled KL Loss is: 0.04743635654449463\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3843465675567987\n",
      "NLL Loss is: 1.2615856770656648\n",
      "Scaled KL Loss is: 0.04889767989516258\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3104833569608274\n",
      "NLL Loss is: 1.2406065638201489\n",
      "Scaled KL Loss is: 0.045371826738119125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.285978390558268\n",
      "NLL Loss is: 1.3554853701968788\n",
      "Scaled KL Loss is: 0.04670247063040733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402187840827286\n",
      "NLL Loss is: 1.3624112554695502\n",
      "Scaled KL Loss is: 0.04921450465917587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.411625760128726\n",
      "NLL Loss is: 1.2995113696297858\n",
      "Scaled KL Loss is: 0.04694654792547226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346457917555258\n",
      "NLL Loss is: 1.2562428369637653\n",
      "Scaled KL Loss is: 0.050813186913728714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307056023877494\n",
      "NLL Loss is: 1.2376500512178383\n",
      "Scaled KL Loss is: 0.0469890721142292\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2846391233320675\n",
      "NLL Loss is: 1.4140337182865803\n",
      "Scaled KL Loss is: 0.04811917990446091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4621528981910412\n",
      "NLL Loss is: 1.2939376867601795\n",
      "Scaled KL Loss is: 0.04523652046918869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3391742072293682\n",
      "NLL Loss is: 1.2786361413398484\n",
      "Scaled KL Loss is: 0.05150175839662552\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.330137899736474\n",
      "NLL Loss is: 1.3035309992112039\n",
      "Scaled KL Loss is: 0.04904067516326904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.352571674374473\n",
      "NLL Loss is: 1.3788904963190292\n",
      "Scaled KL Loss is: 0.04726933687925339\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4261598331982825\n",
      "NLL Loss is: 1.2457343605542959\n",
      "Scaled KL Loss is: 0.04417632892727852\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2899106894815744\n",
      "NLL Loss is: 1.3720997977921343\n",
      "Scaled KL Loss is: 0.045209646224975586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.41730944401711\n",
      "NLL Loss is: 1.3703264049175925\n",
      "Scaled KL Loss is: 0.04663574695587158\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416962151873464\n",
      "NLL Loss is: 1.323302282160679\n",
      "Scaled KL Loss is: 0.04701592028141022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3703182024420892\n",
      "NLL Loss is: 1.2235969285225685\n",
      "Scaled KL Loss is: 0.04550451040267944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.269101438925248\n",
      "NLL Loss is: 1.3120861008935878\n",
      "Scaled KL Loss is: 0.04602630436420441\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3581124052577922\n",
      "NLL Loss is: 1.1776154606433067\n",
      "Scaled KL Loss is: 0.04958019778132439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.227195658424631\n",
      "NLL Loss is: 1.327055698282158\n",
      "Scaled KL Loss is: 0.04320145398378372\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702571522659417\n",
      "NLL Loss is: 1.1840055089501726\n",
      "Scaled KL Loss is: 0.049454279243946075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2334597881941187\n",
      "NLL Loss is: 1.2982964393223384\n",
      "Scaled KL Loss is: 0.047957371920347214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3462538112426856\n",
      "NLL Loss is: 1.3876491406639349\n",
      "Scaled KL Loss is: 0.04560672119259834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4332558618565332\n",
      "NLL Loss is: 1.3175732287411466\n",
      "Scaled KL Loss is: 0.043959230184555054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3615324589257016\n",
      "NLL Loss is: 1.241084712873147\n",
      "Scaled KL Loss is: 0.04898231104016304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.29006702391331\n",
      "NLL Loss is: 1.2095474390314223\n",
      "Scaled KL Loss is: 0.04596662521362305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2555140642450453\n",
      "NLL Loss is: 1.4089162209119845\n",
      "Scaled KL Loss is: 0.046644799411296844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4555610203232814\n",
      "NLL Loss is: 1.2452497092012722\n",
      "Scaled KL Loss is: 0.04785820469260216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2931079138938744\n",
      "NLL Loss is: 1.6646508896623504\n",
      "Scaled KL Loss is: 0.03816908225417137\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7028199719165218\n",
      "NLL Loss is: 1.3116751071784138= 1.322; test loss = 1.362\n",
      "Scaled KL Loss is: 0.04873942211270332\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3604145292911172\n",
      "NLL Loss is: 1.305790914163639\n",
      "Scaled KL Loss is: 0.04631223902106285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3521031531847019\n",
      "NLL Loss is: 1.3250392497216579\n",
      "Scaled KL Loss is: 0.04798964411020279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3730288938318607\n",
      "NLL Loss is: 1.357141308878666\n",
      "Scaled KL Loss is: 0.049188032746315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.406329341624981\n",
      "NLL Loss is: 1.3060010779442512\n",
      "Scaled KL Loss is: 0.04360979050397873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34961086844823\n",
      "NLL Loss is: 1.338516653755563\n",
      "Scaled KL Loss is: 0.049053534865379333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3875701886209424\n",
      "NLL Loss is: 1.3604564172139044\n",
      "Scaled KL Loss is: 0.0443691611289978\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4048255783429022\n",
      "NLL Loss is: 1.3008339577121495\n",
      "Scaled KL Loss is: 0.04477394372224808\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3456079014343976\n",
      "NLL Loss is: 1.369303366095425\n",
      "Scaled KL Loss is: 0.04319271445274353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4124960805481686\n",
      "NLL Loss is: 1.2246483888743567\n",
      "Scaled KL Loss is: 0.049799997359514236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.274448386233871\n",
      "NLL Loss is: 1.2344044152822966\n",
      "Scaled KL Loss is: 0.043170016258955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2775744315412516\n",
      "NLL Loss is: 1.3804828314178976\n",
      "Scaled KL Loss is: 0.04675993323326111\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4272427646511587\n",
      "NLL Loss is: 1.2102905909147648\n",
      "Scaled KL Loss is: 0.05019552633166313\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260486117246428\n",
      "NLL Loss is: 1.4050850839639861\n",
      "Scaled KL Loss is: 0.047485336661338806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.452570420625325\n",
      "NLL Loss is: 1.2173154958224972\n",
      "Scaled KL Loss is: 0.0469202883541584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2642357841766556\n",
      "NLL Loss is: 1.3943948155234482\n",
      "Scaled KL Loss is: 0.05114717409014702\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4455419896135953\n",
      "NLL Loss is: 1.3150995237995204\n",
      "Scaled KL Loss is: 0.04756806790828705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3626675917078075\n",
      "NLL Loss is: 1.2777841516205615\n",
      "Scaled KL Loss is: 0.04735403135418892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3251381829747504\n",
      "NLL Loss is: 1.2002347953294026\n",
      "Scaled KL Loss is: 0.04770059883594513\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2479353941653477\n",
      "NLL Loss is: 1.3053264067663646\n",
      "Scaled KL Loss is: 0.04573759064078331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3510639974071479\n",
      "NLL Loss is: 1.2322005201848427\n",
      "Scaled KL Loss is: 0.0456710085272789\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2778715287121216\n",
      "NLL Loss is: 1.3090761502651458\n",
      "Scaled KL Loss is: 0.04616335779428482\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3552395080594306\n",
      "NLL Loss is: 1.2172802523795847\n",
      "Scaled KL Loss is: 0.04679301008582115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2640732624654059\n",
      "NLL Loss is: 1.5513288241697125\n",
      "Scaled KL Loss is: 0.049128998070955276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.6004578222406678\n",
      "NLL Loss is: 1.1209820926826337\n",
      "Scaled KL Loss is: 0.04679866135120392\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1677807540338376\n",
      "NLL Loss is: 1.2587611582336076\n",
      "Scaled KL Loss is: 0.050328344106674194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3090895023402818\n",
      "NLL Loss is: 1.3092155966558232\n",
      "Scaled KL Loss is: 0.052296899259090424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3615124959149136\n",
      "NLL Loss is: 1.0954900721491037\n",
      "Scaled KL Loss is: 0.04984232783317566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1453323999822793\n",
      "NLL Loss is: 1.251840826723441\n",
      "Scaled KL Loss is: 0.04839726909995079\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300238095823392\n",
      "NLL Loss is: 1.082846399123494\n",
      "Scaled KL Loss is: 0.04908644035458565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1319328394780797\n",
      "NLL Loss is: 1.1439548767089185\n",
      "Scaled KL Loss is: 0.044236887246370316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1881917639552888\n",
      "NLL Loss is: 1.305525307268552\n",
      "Scaled KL Loss is: 0.04788729548454285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3534126027530948\n",
      "NLL Loss is: 1.3187660926639904\n",
      "Scaled KL Loss is: 0.04558785632252693\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3643539489865173\n",
      "NLL Loss is: 1.2243040308140771\n",
      "Scaled KL Loss is: 0.04600098356604576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2703050143801229\n",
      "NLL Loss is: 1.4052304719267108\n",
      "Scaled KL Loss is: 0.04674217477440834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4519726467011191\n",
      "NLL Loss is: 1.3950569037893006\n",
      "Scaled KL Loss is: 0.04625773802399635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.441314641813297\n",
      "NLL Loss is: 1.222829048855984\n",
      "Scaled KL Loss is: 0.052340615540742874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275169664396727\n",
      "NLL Loss is: 1.1974952995765762\n",
      "Scaled KL Loss is: 0.050394248217344284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2478895477939205\n",
      "NLL Loss is: 1.3080284172931267\n",
      "Scaled KL Loss is: 0.04840829223394394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564367095270706\n",
      "NLL Loss is: 1.4281332915271707\n",
      "Scaled KL Loss is: 0.04827805981040001\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4764113513375707\n",
      "NLL Loss is: 1.1510707361143218\n",
      "Scaled KL Loss is: 0.04931610822677612\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2003868443410979\n",
      "NLL Loss is: 1.15729174548863\n",
      "Scaled KL Loss is: 0.044454798102378845\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2017465435910089\n",
      "NLL Loss is: 1.1949423346797954\n",
      "Scaled KL Loss is: 0.050134871155023575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.245077205834819\n",
      "NLL Loss is: 1.2025063358955452\n",
      "Scaled KL Loss is: 0.0543990284204483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2569053643159935\n",
      "NLL Loss is: 1.2731565768611568\n",
      "Scaled KL Loss is: 0.04543795436620712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318594531227364\n",
      "NLL Loss is: 1.2030923410800833\n",
      "Scaled KL Loss is: 0.050260309129953384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2533526502100367\n",
      "NLL Loss is: 1.2372198780957746\n",
      "Scaled KL Loss is: 0.050652191042900085\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2878720691386747\n",
      "NLL Loss is: 1.1379195643342583\n",
      "Scaled KL Loss is: 0.05358452722430229\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1915040915585606\n",
      "NLL Loss is: 1.2415685809088546\n",
      "Scaled KL Loss is: 0.04983726888895035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.291405849797805\n",
      "NLL Loss is: 1.1604802830912788\n",
      "Scaled KL Loss is: 0.049529772251844406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2100100553431232\n",
      "NLL Loss is: 1.2538268368849672\n",
      "Scaled KL Loss is: 0.05030883848667145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3041356753716387\n",
      "NLL Loss is: 1.280750996305133\n",
      "Scaled KL Loss is: 0.04651946946978569\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3272704657749186\n",
      "NLL Loss is: 1.186570601356508\n",
      "Scaled KL Loss is: 0.050014249980449677\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2365848513369577\n",
      "NLL Loss is: 1.2937870378583907\n",
      "Scaled KL Loss is: 0.04737016186118126\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341157199719572\n",
      "NLL Loss is: 1.3693438209151614\n",
      "Scaled KL Loss is: 0.04601925611495972\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415363077030121\n",
      "NLL Loss is: 1.348017005237308\n",
      "Scaled KL Loss is: 0.045368045568466187\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3933850508057741\n",
      "NLL Loss is: 1.3680979662457589\n",
      "Scaled KL Loss is: 0.04932374879717827\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4174217150429371\n",
      "NLL Loss is: 1.2297397853105816\n",
      "Scaled KL Loss is: 0.04720163345336914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2769414187639507\n",
      "NLL Loss is: 1.193115424136473\n",
      "Scaled KL Loss is: 0.04556306079030037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2386784849267733\n",
      "NLL Loss is: 1.1412882408534337\n",
      "Scaled KL Loss is: 0.050438493490219116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1917267343436528\n",
      "NLL Loss is: 1.239609618968493\n",
      "Scaled KL Loss is: 0.04914756119251251\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2887571801610056\n",
      "NLL Loss is: 1.2533566102654246\n",
      "Scaled KL Loss is: 0.048043955117464066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3014005653828886\n",
      "NLL Loss is: 1.3353979445649444\n",
      "Scaled KL Loss is: 0.04748009517788887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3828780397428333\n",
      "NLL Loss is: 1.260974533475187\n",
      "Scaled KL Loss is: 0.04899735748767853\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3099718909628655\n",
      "NLL Loss is: 1.2394501293404285\n",
      "Scaled KL Loss is: 0.045416686683893204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2848668160243217\n",
      "NLL Loss is: 1.3547354133813627\n",
      "Scaled KL Loss is: 0.04674988240003586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4014852957813986\n",
      "NLL Loss is: 1.3614045968621715\n",
      "Scaled KL Loss is: 0.04930996894836426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4107145658105358\n",
      "NLL Loss is: 1.2985395240545428\n",
      "Scaled KL Loss is: 0.04697578772902489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3455153117835676\n",
      "NLL Loss is: 1.2551390935084887\n",
      "Scaled KL Loss is: 0.05084770545363426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.305986798962123\n",
      "NLL Loss is: 1.2362685875893278\n",
      "Scaled KL Loss is: 0.04703259468078613\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.283301182270114\n",
      "NLL Loss is: 1.4129115603756714\n",
      "Scaled KL Loss is: 0.04817471280694008\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4610862731826115\n",
      "NLL Loss is: 1.2928139500733988\n",
      "Scaled KL Loss is: 0.04529538005590439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3381093301293032\n",
      "NLL Loss is: 1.2780158161574724\n",
      "Scaled KL Loss is: 0.051563818007707596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32957963416518\n",
      "NLL Loss is: 1.3026341029019033\n",
      "Scaled KL Loss is: 0.04910798370838165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351742086610285\n",
      "NLL Loss is: 1.3779542571310233\n",
      "Scaled KL Loss is: 0.047326210886240005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4252804680172633\n",
      "NLL Loss is: 1.244943642265899\n",
      "Scaled KL Loss is: 0.04422858729958534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2891722295654844\n",
      "NLL Loss is: 1.3714465429140383\n",
      "Scaled KL Loss is: 0.045233990997076035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4166805339111144\n",
      "NLL Loss is: 1.3693477534983227\n",
      "Scaled KL Loss is: 0.04670749604701996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4160552495453427\n",
      "NLL Loss is: 1.323208596590503\n",
      "Scaled KL Loss is: 0.04702449589967728\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702330924901802\n",
      "NLL Loss is: 1.2225960938040152\n",
      "Scaled KL Loss is: 0.045546241104602814\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.268142334908618\n",
      "NLL Loss is: 1.3112153758798908\n",
      "Scaled KL Loss is: 0.04607275500893593\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3572881308888267\n",
      "NLL Loss is: 1.1762909398875265\n",
      "Scaled KL Loss is: 0.04964200407266617\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2259329439601927\n",
      "NLL Loss is: 1.3265548804385872\n",
      "Scaled KL Loss is: 0.043229732662439346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3697846131010265\n",
      "NLL Loss is: 1.1833609466851407\n",
      "Scaled KL Loss is: 0.049505021423101425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2328659681082421\n",
      "NLL Loss is: 1.297210295259871\n",
      "Scaled KL Loss is: 0.04797946661710739\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3451897618769784\n",
      "NLL Loss is: 1.3864870539397325\n",
      "Scaled KL Loss is: 0.045654430985450745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4321414849251832\n",
      "NLL Loss is: 1.3168042879616007\n",
      "Scaled KL Loss is: 0.044012926518917084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3608172144805177\n",
      "NLL Loss is: 1.2396998005428586\n",
      "Scaled KL Loss is: 0.049014862626791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2887146631696496\n",
      "NLL Loss is: 1.2086762224800136\n",
      "Scaled KL Loss is: 0.04604136198759079\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2547175844676044\n",
      "NLL Loss is: 1.408201945311326\n",
      "Scaled KL Loss is: 0.046700067818164825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4549020131294907\n",
      "NLL Loss is: 1.2444585398114318\n",
      "Scaled KL Loss is: 0.047917891293764114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.292376431105196\n",
      "NLL Loss is: 1.664750356407587\n",
      "Scaled KL Loss is: 0.03818938508629799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702939741493885\n",
      "NLL Loss is: 1.311163130514919 = 1.321; test loss = 1.361\n",
      "Scaled KL Loss is: 0.04877438396215439\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3599375144770733\n",
      "NLL Loss is: 1.3049050940650133\n",
      "Scaled KL Loss is: 0.046378955245018005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3512840493100313\n",
      "NLL Loss is: 1.3239028009059879\n",
      "Scaled KL Loss is: 0.04803857207298279\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3719413729789707\n",
      "NLL Loss is: 1.356468933623758\n",
      "Scaled KL Loss is: 0.04918866977095604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4056576033947141\n",
      "NLL Loss is: 1.304819952610787\n",
      "Scaled KL Loss is: 0.04365776851773262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3484777211285197\n",
      "NLL Loss is: 1.3375582471223628\n",
      "Scaled KL Loss is: 0.049113720655441284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.386671967777804\n",
      "NLL Loss is: 1.3593979481688816\n",
      "Scaled KL Loss is: 0.04447547718882561\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4038734253577072\n",
      "NLL Loss is: 1.2997822307942795\n",
      "Scaled KL Loss is: 0.04484840855002403\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3446306393443035\n",
      "NLL Loss is: 1.3686200953973398\n",
      "Scaled KL Loss is: 0.04323474317789078\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4118548385752305\n",
      "NLL Loss is: 1.2237160647274192\n",
      "Scaled KL Loss is: 0.04983831197023392\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2735543766976531\n",
      "NLL Loss is: 1.2331842409748328\n",
      "Scaled KL Loss is: 0.04318840429186821\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276372645266701\n",
      "NLL Loss is: 1.3795975380287362\n",
      "Scaled KL Loss is: 0.04682520776987076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.426422745798607\n",
      "NLL Loss is: 1.2095481529335514\n",
      "Scaled KL Loss is: 0.050241634249687195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2597897871832386\n",
      "NLL Loss is: 1.4040819916865848\n",
      "Scaled KL Loss is: 0.047518447041511536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4516004387280963\n",
      "NLL Loss is: 1.2163869327689296\n",
      "Scaled KL Loss is: 0.04699470102787018\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2633816337967998\n",
      "NLL Loss is: 1.3933400345213982\n",
      "Scaled KL Loss is: 0.05123917758464813\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4445792121060463\n",
      "NLL Loss is: 1.3139122369076086\n",
      "Scaled KL Loss is: 0.04766230657696724\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3615745434845758\n",
      "NLL Loss is: 1.276779193702853\n",
      "Scaled KL Loss is: 0.04740402102470398\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.324183214727557\n",
      "NLL Loss is: 1.1991327716641522\n",
      "Scaled KL Loss is: 0.04777064174413681\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246903413408289\n",
      "NLL Loss is: 1.3040831309691305\n",
      "Scaled KL Loss is: 0.04581424593925476\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3498973769083853\n",
      "NLL Loss is: 1.2307837883728925\n",
      "Scaled KL Loss is: 0.04570763185620308\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2764914202290956\n",
      "NLL Loss is: 1.3077369937272747\n",
      "Scaled KL Loss is: 0.04626770317554474\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3540046969028194\n",
      "NLL Loss is: 1.2157831554853533\n",
      "Scaled KL Loss is: 0.046883609145879745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.262666764631233\n",
      "NLL Loss is: 1.5511185924417175\n",
      "Scaled KL Loss is: 0.04914943501353264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.60026802745525\n",
      "NLL Loss is: 1.119787246099544\n",
      "Scaled KL Loss is: 0.04684419557452202\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.166631441674066\n",
      "NLL Loss is: 1.2576740320965891\n",
      "Scaled KL Loss is: 0.05035271495580673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3080267470523959\n",
      "NLL Loss is: 1.3081810306835533\n",
      "Scaled KL Loss is: 0.05234899744391441\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3605300281274677\n",
      "NLL Loss is: 1.0934806304280744\n",
      "Scaled KL Loss is: 0.04990674555301666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.143387375981091\n",
      "NLL Loss is: 1.2505123931985376\n",
      "Scaled KL Loss is: 0.04842438921332359\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2989367824118612\n",
      "NLL Loss is: 1.0814405570390269\n",
      "Scaled KL Loss is: 0.049132339656353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1305728966953799\n",
      "NLL Loss is: 1.142416430065081\n",
      "Scaled KL Loss is: 0.04425428435206413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1866707144171451\n",
      "NLL Loss is: 1.3041809266608522\n",
      "Scaled KL Loss is: 0.0479082427918911\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3520891694527433\n",
      "NLL Loss is: 1.3178822088555133\n",
      "Scaled KL Loss is: 0.045607347041368484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3634895558968818\n",
      "NLL Loss is: 1.2231884490571545\n",
      "Scaled KL Loss is: 0.04600640758872032\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2691948566458748\n",
      "NLL Loss is: 1.404547470262344\n",
      "Scaled KL Loss is: 0.04674917459487915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.451296644857223\n",
      "NLL Loss is: 1.394421031712971\n",
      "Scaled KL Loss is: 0.04626263678073883\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4406836684937099\n",
      "NLL Loss is: 1.2211498605711821\n",
      "Scaled KL Loss is: 0.05229217931628227\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2734420398874644\n",
      "NLL Loss is: 1.1971502875964815\n",
      "Scaled KL Loss is: 0.05043765902519226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2475879466216737\n",
      "NLL Loss is: 1.3081144220739256\n",
      "Scaled KL Loss is: 0.04843992739915848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356554349473084\n",
      "NLL Loss is: 1.42695519077413\n",
      "Scaled KL Loss is: 0.04826074093580246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4752159317099325\n",
      "NLL Loss is: 1.1495360653250921\n",
      "Scaled KL Loss is: 0.04935002699494362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1988860923200357\n",
      "NLL Loss is: 1.1565086138894762\n",
      "Scaled KL Loss is: 0.044486191123723984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2009948050132002\n",
      "NLL Loss is: 1.1941109130952434\n",
      "Scaled KL Loss is: 0.050206203013658524\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.244317116108902\n",
      "NLL Loss is: 1.2014480447783908\n",
      "Scaled KL Loss is: 0.05437181517481804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2558198599532089\n",
      "NLL Loss is: 1.2721037333664784\n",
      "Scaled KL Loss is: 0.0454133041203022\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3175170374867806\n",
      "NLL Loss is: 1.2023042381491638\n",
      "Scaled KL Loss is: 0.05029195547103882\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2525961936202026\n",
      "NLL Loss is: 1.2368981015052156\n",
      "Scaled KL Loss is: 0.05062614381313324\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2875242453183489\n",
      "NLL Loss is: 1.136888109101917\n",
      "Scaled KL Loss is: 0.053642209619283676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1905303187212006\n",
      "NLL Loss is: 1.2411490943289822\n",
      "Scaled KL Loss is: 0.04979890212416649\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2909479964531487\n",
      "NLL Loss is: 1.1595532785529707\n",
      "Scaled KL Loss is: 0.04953768104314804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2090909595961188\n",
      "NLL Loss is: 1.2530010130456446\n",
      "Scaled KL Loss is: 0.05030965805053711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3033106710961817\n",
      "NLL Loss is: 1.28004759057277\n",
      "Scaled KL Loss is: 0.046484582126140594\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3265321726989105\n",
      "NLL Loss is: 1.185163237969642\n",
      "Scaled KL Loss is: 0.04998617619276047\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2351494141624024\n",
      "NLL Loss is: 1.2927631258041972\n",
      "Scaled KL Loss is: 0.047416865825653076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3401799916298502\n",
      "NLL Loss is: 1.3679825411113384\n",
      "Scaled KL Loss is: 0.046001896262168884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4139844373735073\n",
      "NLL Loss is: 1.3466248295904393\n",
      "Scaled KL Loss is: 0.0453728623688221\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3919976919592614\n",
      "NLL Loss is: 1.3671350046633108\n",
      "Scaled KL Loss is: 0.049306921660900116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416441926324211\n",
      "NLL Loss is: 1.229530602814509\n",
      "Scaled KL Loss is: 0.047178078442811966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276708681257321\n",
      "NLL Loss is: 1.1919003988110166\n",
      "Scaled KL Loss is: 0.04558181017637253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2374822089873891\n",
      "NLL Loss is: 1.1405742119897349\n",
      "Scaled KL Loss is: 0.05041201040148735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1909862223912222\n",
      "NLL Loss is: 1.2390050796990026\n",
      "Scaled KL Loss is: 0.04916564002633095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2881707197253336\n",
      "NLL Loss is: 1.2520707296355018\n",
      "Scaled KL Loss is: 0.04804210737347603\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3001128370089778\n",
      "NLL Loss is: 1.3340193023318119\n",
      "Scaled KL Loss is: 0.04747357219457626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3814928745263881\n",
      "NLL Loss is: 1.2605035958374995\n",
      "Scaled KL Loss is: 0.04905620589852333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3095598017360228\n",
      "NLL Loss is: 1.2383753497682226\n",
      "Scaled KL Loss is: 0.04541363939642906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2837889891646517\n",
      "NLL Loss is: 1.354219583397467\n",
      "Scaled KL Loss is: 0.04675324633717537\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4009728297346424\n",
      "NLL Loss is: 1.3603216218797198\n",
      "Scaled KL Loss is: 0.0493653230369091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.409686944916629\n",
      "NLL Loss is: 1.2975885137370649\n",
      "Scaled KL Loss is: 0.04696040600538254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3445489197424474\n",
      "NLL Loss is: 1.2539913619999425\n",
      "Scaled KL Loss is: 0.05083855986595154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304829921865894\n",
      "NLL Loss is: 1.2349698164568563\n",
      "Scaled KL Loss is: 0.047034911811351776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.282004728268208\n",
      "NLL Loss is: 1.411890025760019\n",
      "Scaled KL Loss is: 0.04819105193018913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4600810776902082\n",
      "NLL Loss is: 1.2916161927098748\n",
      "Scaled KL Loss is: 0.0453202985227108\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3369364912325856\n",
      "NLL Loss is: 1.277268809454953\n",
      "Scaled KL Loss is: 0.05158624053001404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.328855049984967\n",
      "NLL Loss is: 1.3016405421673574\n",
      "Scaled KL Loss is: 0.04913598299026489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3507765251576223\n",
      "NLL Loss is: 1.3770415837580623\n",
      "Scaled KL Loss is: 0.04734215512871742\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4243837388867797\n",
      "NLL Loss is: 1.2441370216206165\n",
      "Scaled KL Loss is: 0.04424191266298294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2883789342835994\n",
      "NLL Loss is: 1.3708963891763852\n",
      "Scaled KL Loss is: 0.045213256031274796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.41610964520766\n",
      "NLL Loss is: 1.369184250732782\n",
      "Scaled KL Loss is: 0.046745918691158295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4159301694239403\n",
      "NLL Loss is: 1.3233507604526755\n",
      "Scaled KL Loss is: 0.04698145389556885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3703322143482444\n",
      "NLL Loss is: 1.2216576184566015\n",
      "Scaled KL Loss is: 0.04554770514369011\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2672053236002916\n",
      "NLL Loss is: 1.3104135588849053\n",
      "Scaled KL Loss is: 0.046078670769929886\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564922296548352\n",
      "NLL Loss is: 1.174950246505351\n",
      "Scaled KL Loss is: 0.04966237023472786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2246126167400788\n",
      "NLL Loss is: 1.326055873089672\n",
      "Scaled KL Loss is: 0.043213505297899246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3692693783875713\n",
      "NLL Loss is: 1.1826690612985056\n",
      "Scaled KL Loss is: 0.04951176047325134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.232180821771757\n",
      "NLL Loss is: 1.2961514467334785\n",
      "Scaled KL Loss is: 0.04795226454734802\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3441037112808265\n",
      "NLL Loss is: 1.3853897074751416\n",
      "Scaled KL Loss is: 0.04566796496510506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4310576724402466\n",
      "NLL Loss is: 1.3160927867161432\n",
      "Scaled KL Loss is: 0.04402412846684456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3601169151829877\n",
      "NLL Loss is: 1.2382639739028505\n",
      "Scaled KL Loss is: 0.04900241643190384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2872663903347543\n",
      "NLL Loss is: 1.2077106200038974\n",
      "Scaled KL Loss is: 0.046079691499471664\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.253790311503369\n",
      "NLL Loss is: 1.4074615839663767\n",
      "Scaled KL Loss is: 0.046718958765268326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.454180542731645\n",
      "NLL Loss is: 1.2436559694611973\n",
      "Scaled KL Loss is: 0.04793914034962654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2915951098108238\n",
      "NLL Loss is: 1.6646587375511526\n",
      "Scaled KL Loss is: 0.038171105086803436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702829842637956\n",
      "NLL Loss is: 1.3106012057429748= 1.320; test loss = 1.360\n",
      "Scaled KL Loss is: 0.04876674711704254\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3593679528600173\n",
      "NLL Loss is: 1.3040879160553671\n",
      "Scaled KL Loss is: 0.04639817774295807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3504860937983252\n",
      "NLL Loss is: 1.3230738837583065\n",
      "Scaled KL Loss is: 0.04804151877760887\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3711154025359154\n",
      "NLL Loss is: 1.3558973199086006\n",
      "Scaled KL Loss is: 0.04912916570901871\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4050264856176193\n",
      "NLL Loss is: 1.3037596458385439\n",
      "Scaled KL Loss is: 0.043658141046762466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3474177868853063\n",
      "NLL Loss is: 1.3368457584800706\n",
      "Scaled KL Loss is: 0.04911886900663376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3859646274867043\n",
      "NLL Loss is: 1.3582480204004752\n",
      "Scaled KL Loss is: 0.0445299856364727\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.402778006036948\n",
      "NLL Loss is: 1.298696738803992\n",
      "Scaled KL Loss is: 0.044862836599349976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343559575403342\n",
      "NLL Loss is: 1.3678551213355652\n",
      "Scaled KL Loss is: 0.04322092980146408\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4110760511370293\n",
      "NLL Loss is: 1.222878179302146\n",
      "Scaled KL Loss is: 0.049814093858003616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2726922731601495\n",
      "NLL Loss is: 1.2319166177186565\n",
      "Scaled KL Loss is: 0.0431344136595726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275051031378229\n",
      "NLL Loss is: 1.3785586516403863\n",
      "Scaled KL Loss is: 0.046834927052259445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4253935786926457\n",
      "NLL Loss is: 1.2088574423769085\n",
      "Scaled KL Loss is: 0.050232045352458954\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2590894877293675\n",
      "NLL Loss is: 1.4031293430297098\n",
      "Scaled KL Loss is: 0.04748866334557533\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4506180063752852\n",
      "NLL Loss is: 1.215472708797916\n",
      "Scaled KL Loss is: 0.04700795188546181\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2624806606833778\n",
      "NLL Loss is: 1.3923950091845847\n",
      "Scaled KL Loss is: 0.05128040164709091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4436754108316756\n",
      "NLL Loss is: 1.312916800912455\n",
      "Scaled KL Loss is: 0.047709379345178604\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3606261802576336\n",
      "NLL Loss is: 1.275807760768826\n",
      "Scaled KL Loss is: 0.04740001633763313\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3232077771064592\n",
      "NLL Loss is: 1.1983381490749514\n",
      "Scaled KL Loss is: 0.047789353877305984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2461275029522574\n",
      "NLL Loss is: 1.302930808008295\n",
      "Scaled KL Loss is: 0.04584287852048874\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3487736865287838\n",
      "NLL Loss is: 1.2298455056615345\n",
      "Scaled KL Loss is: 0.045688241720199585\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275533747381734\n",
      "NLL Loss is: 1.3064300172887513\n",
      "Scaled KL Loss is: 0.04632926359772682\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3527592808864781\n",
      "NLL Loss is: 1.2146634976764519\n",
      "Scaled KL Loss is: 0.046939000487327576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2616024981637795\n",
      "NLL Loss is: 1.5501302130888035\n",
      "Scaled KL Loss is: 0.04913754388689995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5992677569757034\n",
      "NLL Loss is: 1.1189553729944661\n",
      "Scaled KL Loss is: 0.046855662018060684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1658110350125268\n",
      "NLL Loss is: 1.2568904224005348\n",
      "Scaled KL Loss is: 0.05033766105771065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3072280834582455\n",
      "NLL Loss is: 1.3072955930643082\n",
      "Scaled KL Loss is: 0.052362844347953796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359658437412262\n",
      "NLL Loss is: 1.0926020341077503\n",
      "Scaled KL Loss is: 0.04992068186402321\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1425227159717735\n",
      "NLL Loss is: 1.2495221654051485\n",
      "Scaled KL Loss is: 0.048427242785692215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2979494081908407\n",
      "NLL Loss is: 1.0802755023307666\n",
      "Scaled KL Loss is: 0.04914747178554535\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.129422974116312\n",
      "NLL Loss is: 1.1416877278109916\n",
      "Scaled KL Loss is: 0.04423968121409416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1859274090250858\n",
      "NLL Loss is: 1.30319464953088\n",
      "Scaled KL Loss is: 0.04790566489100456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3511003144218845\n",
      "NLL Loss is: 1.3170635125098356\n",
      "Scaled KL Loss is: 0.04559524729847908\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3626587598083146\n",
      "NLL Loss is: 1.2227616817002371\n",
      "Scaled KL Loss is: 0.045988939702510834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.268750621402748\n",
      "NLL Loss is: 1.4040973431375605\n",
      "Scaled KL Loss is: 0.04673924297094345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.450836586108504\n",
      "NLL Loss is: 1.392917134890042\n",
      "Scaled KL Loss is: 0.046242985874414444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4391601207644564\n",
      "NLL Loss is: 1.2205047402340095\n",
      "Scaled KL Loss is: 0.05221886932849884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2727236095625083\n",
      "NLL Loss is: 1.196981706270206\n",
      "Scaled KL Loss is: 0.05045498162508011\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.247436687895286\n",
      "NLL Loss is: 1.3074891058090925\n",
      "Scaled KL Loss is: 0.04845009371638298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3559391995254755\n",
      "NLL Loss is: 1.4260829856402892\n",
      "Scaled KL Loss is: 0.048224303871393204\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4743072895116824\n",
      "NLL Loss is: 1.148411070014271\n",
      "Scaled KL Loss is: 0.049351222813129425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1977622928274003\n",
      "NLL Loss is: 1.1555124954894347\n",
      "Scaled KL Loss is: 0.04449541121721268\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2000079067066474\n",
      "NLL Loss is: 1.1933402250024805\n",
      "Scaled KL Loss is: 0.05026375502347946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.24360398002596\n",
      "NLL Loss is: 1.200676407002146\n",
      "Scaled KL Loss is: 0.054327864199876785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2550042712020228\n",
      "NLL Loss is: 1.2711546084008436\n",
      "Scaled KL Loss is: 0.04538305103778839\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.316537659438632\n",
      "NLL Loss is: 1.2016067107770534\n",
      "Scaled KL Loss is: 0.0503162182867527\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.251922929063806\n",
      "NLL Loss is: 1.2365481412318264\n",
      "Scaled KL Loss is: 0.05059567466378212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2871438158956086\n",
      "NLL Loss is: 1.1359635804681736\n",
      "Scaled KL Loss is: 0.053697723895311356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.189661304363485\n",
      "NLL Loss is: 1.2407383660067597\n",
      "Scaled KL Loss is: 0.049763135612010956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2905015016187706\n",
      "NLL Loss is: 1.1586881938211855\n",
      "Scaled KL Loss is: 0.04955292120575905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2082411150269445\n",
      "NLL Loss is: 1.252426490125181\n",
      "Scaled KL Loss is: 0.0503201000392437\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3027465901644246\n",
      "NLL Loss is: 1.2792129577158264\n",
      "Scaled KL Loss is: 0.046462200582027435\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3256751582978539\n",
      "NLL Loss is: 1.1842412563990339\n",
      "Scaled KL Loss is: 0.04997703805565834\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2342182944546922\n",
      "NLL Loss is: 1.2918106900233692\n",
      "Scaled KL Loss is: 0.04747286066412926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3392835506874985\n",
      "NLL Loss is: 1.3673036671726424\n",
      "Scaled KL Loss is: 0.04599738493561745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4133010521082598\n",
      "NLL Loss is: 1.3454094377150108\n",
      "Scaled KL Loss is: 0.04538960009813309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3907990378131438\n",
      "NLL Loss is: 1.3664349296766338\n",
      "Scaled KL Loss is: 0.0493023544549942\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415737284131628\n",
      "NLL Loss is: 1.229267337319398\n",
      "Scaled KL Loss is: 0.04717002809047699\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276437365409875\n",
      "NLL Loss is: 1.190686539050111\n",
      "Scaled KL Loss is: 0.045611362904310226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2362979019544211\n",
      "NLL Loss is: 1.139805235715757\n",
      "Scaled KL Loss is: 0.05040156841278076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1902068041285379\n",
      "NLL Loss is: 1.2383754149616664\n",
      "Scaled KL Loss is: 0.04919450730085373\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.28756992226252\n",
      "NLL Loss is: 1.250862339834441\n",
      "Scaled KL Loss is: 0.04805469885468483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2989170386891258\n",
      "NLL Loss is: 1.332687444305166\n",
      "Scaled KL Loss is: 0.04748370125889778\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3801711455640637\n",
      "NLL Loss is: 1.2599769141353137\n",
      "Scaled KL Loss is: 0.04912514239549637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.30910205653081\n",
      "NLL Loss is: 1.237292985691801\n",
      "Scaled KL Loss is: 0.045428209006786346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2827211946985873\n",
      "NLL Loss is: 1.3536267711039789\n",
      "Scaled KL Loss is: 0.046772196888923645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4003989679929025\n",
      "NLL Loss is: 1.359281078931259\n",
      "Scaled KL Loss is: 0.04943327233195305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.408714351263212\n",
      "NLL Loss is: 1.296664639726485\n",
      "Scaled KL Loss is: 0.04696366563439369\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3436283053608786\n",
      "NLL Loss is: 1.2528842236894173\n",
      "Scaled KL Loss is: 0.050846125930547714\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.303730349619965\n",
      "NLL Loss is: 1.2336749233046802\n",
      "Scaled KL Loss is: 0.04705587401986122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2807307973245414\n",
      "NLL Loss is: 1.4108372087649608\n",
      "Scaled KL Loss is: 0.04822288081049919\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.45906008957546\n",
      "NLL Loss is: 1.2905097461615478\n",
      "Scaled KL Loss is: 0.04535743221640587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3358671783779537\n",
      "NLL Loss is: 1.2765654440544272\n",
      "Scaled KL Loss is: 0.05162237212061882\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.328187816175046\n",
      "NLL Loss is: 1.3007418604741912\n",
      "Scaled KL Loss is: 0.049179527908563614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3499213883827548\n",
      "NLL Loss is: 1.3761329756116822\n",
      "Scaled KL Loss is: 0.04737512394785881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423508099559541\n",
      "NLL Loss is: 1.243393602910548\n",
      "Scaled KL Loss is: 0.0442722924053669\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2876658953159148\n",
      "NLL Loss is: 1.370323147384336\n",
      "Scaled KL Loss is: 0.045213986188173294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4155371335725093\n",
      "NLL Loss is: 1.3684690433403524\n",
      "Scaled KL Loss is: 0.0467928908765316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415261934216884\n",
      "NLL Loss is: 1.3234772668569212\n",
      "Scaled KL Loss is: 0.046965789049863815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370443055906785\n",
      "NLL Loss is: 1.2207060317450387\n",
      "Scaled KL Loss is: 0.04556676745414734\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.266272799199186\n",
      "NLL Loss is: 1.3095892852882896\n",
      "Scaled KL Loss is: 0.04610111564397812\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3556904009322677\n",
      "NLL Loss is: 1.1735886537365152\n",
      "Scaled KL Loss is: 0.049699604511260986\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2232882582477762\n",
      "NLL Loss is: 1.3255689118102254\n",
      "Scaled KL Loss is: 0.04321786016225815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3687867719724836\n",
      "NLL Loss is: 1.1820177875848636\n",
      "Scaled KL Loss is: 0.049539923667907715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2315577112527714\n",
      "NLL Loss is: 1.2951129094400093\n",
      "Scaled KL Loss is: 0.04794890806078911\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3430618175007984\n",
      "NLL Loss is: 1.3842558053377432\n",
      "Scaled KL Loss is: 0.045692212879657745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.429948018217401\n",
      "NLL Loss is: 1.3153986907977333\n",
      "Scaled KL Loss is: 0.04405432194471359\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.359453012742447\n",
      "NLL Loss is: 1.2369362048402543\n",
      "Scaled KL Loss is: 0.04900854825973511\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2859447530999895\n",
      "NLL Loss is: 1.2068582641415395\n",
      "Scaled KL Loss is: 0.04613092169165611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2529891858331956\n",
      "NLL Loss is: 1.4067779777733063\n",
      "Scaled KL Loss is: 0.04674902185797691\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4535269996312832\n",
      "NLL Loss is: 1.2428624084309243\n",
      "Scaled KL Loss is: 0.04797367379069328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2908360822216176\n",
      "NLL Loss is: 1.6647016583952794\n",
      "Scaled KL Loss is: 0.03816695511341095\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7028686135086903\n",
      "NLL Loss is: 1.3100912734231431= 1.320; test loss = 1.359\n",
      "Scaled KL Loss is: 0.04877805709838867\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3588693305215318\n",
      "NLL Loss is: 1.3032387130863707\n",
      "Scaled KL Loss is: 0.046442288905382156\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.349681001991753\n",
      "NLL Loss is: 1.3221079798100186\n",
      "Scaled KL Loss is: 0.04806491732597351\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370172897135992\n",
      "NLL Loss is: 1.355234213716297\n",
      "Scaled KL Loss is: 0.04910273477435112\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.404336948490648\n",
      "NLL Loss is: 1.3026635930134034\n",
      "Scaled KL Loss is: 0.043681591749191284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3463451847625947\n",
      "NLL Loss is: 1.3360052371980153\n",
      "Scaled KL Loss is: 0.04915346950292587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3851587067009412\n",
      "NLL Loss is: 1.3571883265235616\n",
      "Scaled KL Loss is: 0.04461091756820679\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4017992440917684\n",
      "NLL Loss is: 1.2976654919379567\n",
      "Scaled KL Loss is: 0.04491420090198517\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3425796928399418\n",
      "NLL Loss is: 1.3671700226527848\n",
      "Scaled KL Loss is: 0.04323958605527878\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4104096087080635\n",
      "NLL Loss is: 1.2220230398245968\n",
      "Scaled KL Loss is: 0.049823418259620667\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2718464580842175\n",
      "NLL Loss is: 1.2307067625147794\n",
      "Scaled KL Loss is: 0.043124374002218246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2738311365169976\n",
      "NLL Loss is: 1.3776125074131942\n",
      "Scaled KL Loss is: 0.04687422141432762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4244867288275218\n",
      "NLL Loss is: 1.2081637417729565\n",
      "Scaled KL Loss is: 0.05024942755699158\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.258413169329948\n",
      "NLL Loss is: 1.402126976654624\n",
      "Scaled KL Loss is: 0.04749380424618721\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4496207809008113\n",
      "NLL Loss is: 1.2145445864569024\n",
      "Scaled KL Loss is: 0.04705717787146568\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2616017643283681\n",
      "NLL Loss is: 1.3914171662003327\n",
      "Scaled KL Loss is: 0.051343683153390884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4427608493537236\n",
      "NLL Loss is: 1.3118920428389191\n",
      "Scaled KL Loss is: 0.04777661710977554\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3596686599486947\n",
      "NLL Loss is: 1.274834283730417\n",
      "Scaled KL Loss is: 0.047423481941223145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32225776567164\n",
      "NLL Loss is: 1.1974498868868377\n",
      "Scaled KL Loss is: 0.04783166944980621\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.245281556336644\n",
      "NLL Loss is: 1.3017493853818052\n",
      "Scaled KL Loss is: 0.04589352384209633\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3476429092239015\n",
      "NLL Loss is: 1.2288089093998744\n",
      "Scaled KL Loss is: 0.045700304210186005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2745092136100604\n",
      "NLL Loss is: 1.3051332609340858\n",
      "Scaled KL Loss is: 0.04641268029808998\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3515459412321758\n",
      "NLL Loss is: 1.2134573963301154\n",
      "Scaled KL Loss is: 0.04701526463031769\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.260472660960433\n",
      "NLL Loss is: 1.5491996666112124\n",
      "Scaled KL Loss is: 0.04915516823530197\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5983548348465144\n",
      "NLL Loss is: 1.1180725155593638\n",
      "Scaled KL Loss is: 0.04689102992415428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.164963545483518\n",
      "NLL Loss is: 1.2560320367132303\n",
      "Scaled KL Loss is: 0.0503501258790493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3063821625922796\n",
      "NLL Loss is: 1.306356771973509\n",
      "Scaled KL Loss is: 0.052404798567295074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.358761570540804\n",
      "NLL Loss is: 1.091624306599002\n",
      "Scaled KL Loss is: 0.04996035620570183\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1415846628047037\n",
      "NLL Loss is: 1.248464375658135\n",
      "Scaled KL Loss is: 0.048456478863954544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2969208545220896\n",
      "NLL Loss is: 1.07900480169426\n",
      "Scaled KL Loss is: 0.04919636994600296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.128201171640263\n",
      "NLL Loss is: 1.140925113209025\n",
      "Scaled KL Loss is: 0.044262684881687164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1851877980907122\n",
      "NLL Loss is: 1.3022727479867942\n",
      "Scaled KL Loss is: 0.04793938994407654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3502121379308707\n",
      "NLL Loss is: 1.316254250704584\n",
      "Scaled KL Loss is: 0.04562697932124138\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3618812300258254\n",
      "NLL Loss is: 1.2222161715279183\n",
      "Scaled KL Loss is: 0.04601229727268219\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2682284688006005\n",
      "NLL Loss is: 1.403595749419726\n",
      "Scaled KL Loss is: 0.046764396131038666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4503601455507646\n",
      "NLL Loss is: 1.3915010975685917\n",
      "Scaled KL Loss is: 0.046264804899692535\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4377659024682843\n",
      "NLL Loss is: 1.2198156448731028\n",
      "Scaled KL Loss is: 0.05219240114092827\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.272008046014031\n",
      "NLL Loss is: 1.1966810177424194\n",
      "Scaled KL Loss is: 0.05050729587674141\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2471883136191608\n",
      "NLL Loss is: 1.3068942137317938\n",
      "Scaled KL Loss is: 0.048502419143915176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355396632875709\n",
      "NLL Loss is: 1.4251969392438826\n",
      "Scaled KL Loss is: 0.048237551003694534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4734344902475771\n",
      "NLL Loss is: 1.1472758474981892\n",
      "Scaled KL Loss is: 0.04940081387758255\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1966766613757718\n",
      "NLL Loss is: 1.1545045953146997\n",
      "Scaled KL Loss is: 0.04454544559121132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.199050040905911\n",
      "NLL Loss is: 1.1924671456449958\n",
      "Scaled KL Loss is: 0.050354957580566406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2428221032255622\n",
      "NLL Loss is: 1.200010009412578\n",
      "Scaled KL Loss is: 0.054332979023456573\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2543429884360346\n",
      "NLL Loss is: 1.2702019716706923\n",
      "Scaled KL Loss is: 0.045395851135253906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3155978228059462\n",
      "NLL Loss is: 1.200838113384336\n",
      "Scaled KL Loss is: 0.05037185177206993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.251209965156406\n",
      "NLL Loss is: 1.2361271545401329\n",
      "Scaled KL Loss is: 0.05060286074876785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2867300152889007\n",
      "NLL Loss is: 1.1350679636341032\n",
      "Scaled KL Loss is: 0.05378158763051033\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1888495512646136\n",
      "NLL Loss is: 1.2402717902699036\n",
      "Scaled KL Loss is: 0.04976295679807663\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2900347470679803\n",
      "NLL Loss is: 1.1577709133127998\n",
      "Scaled KL Loss is: 0.04960339888930321\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.207374312202103\n",
      "NLL Loss is: 1.251779357308649\n",
      "Scaled KL Loss is: 0.050359904766082764\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3021392620747319\n",
      "NLL Loss is: 1.2783962350327602\n",
      "Scaled KL Loss is: 0.046471841633319855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.32486807666608\n",
      "NLL Loss is: 1.1833049242028044\n",
      "Scaled KL Loss is: 0.050000932067632675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.233305856270437\n",
      "NLL Loss is: 1.2908616416545198\n",
      "Scaled KL Loss is: 0.047552213072776794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3384138547272966\n",
      "NLL Loss is: 1.3665843440732772\n",
      "Scaled KL Loss is: 0.046015169471502304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4125995135447795\n",
      "NLL Loss is: 1.3442003883129139\n",
      "Scaled KL Loss is: 0.045428089797496796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3896284781104107\n",
      "NLL Loss is: 1.365764199628918\n",
      "Scaled KL Loss is: 0.04931951314210892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415083712771027\n",
      "NLL Loss is: 1.2289436107247314\n",
      "Scaled KL Loss is: 0.04718371853232384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2761273292570552\n",
      "NLL Loss is: 1.1894399091998293\n",
      "Scaled KL Loss is: 0.045657046139240265\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2350969553390696\n",
      "NLL Loss is: 1.1390211373676165\n",
      "Scaled KL Loss is: 0.05041217803955078\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1894333154071672\n",
      "NLL Loss is: 1.2377756785399634\n",
      "Scaled KL Loss is: 0.04923802241683006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2870137009567935\n",
      "NLL Loss is: 1.2497300270239848\n",
      "Scaled KL Loss is: 0.04808180406689644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2978118310908813\n",
      "NLL Loss is: 1.3313110478670196\n",
      "Scaled KL Loss is: 0.04750703647732735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.378818084344347\n",
      "NLL Loss is: 1.2593825831200627\n",
      "Scaled KL Loss is: 0.04920404031872749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3085866234387902\n",
      "NLL Loss is: 1.2362151748039414\n",
      "Scaled KL Loss is: 0.045449450612068176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2816646254160096\n",
      "NLL Loss is: 1.3530970640921358\n",
      "Scaled KL Loss is: 0.046795375645160675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3998924397372965\n",
      "NLL Loss is: 1.3582088627740685\n",
      "Scaled KL Loss is: 0.049504250288009644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4077131130620781\n",
      "NLL Loss is: 1.2957142156499355\n",
      "Scaled KL Loss is: 0.04696730896830559\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.342681524618241\n",
      "NLL Loss is: 1.251836462100073\n",
      "Scaled KL Loss is: 0.050854332745075226\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3026907948451483\n",
      "NLL Loss is: 1.2324610631571677\n",
      "Scaled KL Loss is: 0.04707435891032219\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27953542206749\n",
      "NLL Loss is: 1.4097402296135024\n",
      "Scaled KL Loss is: 0.04825315997004509\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4579933895835475\n",
      "NLL Loss is: 1.2894354495212372\n",
      "Scaled KL Loss is: 0.04539217799901962\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3348276275202569\n",
      "NLL Loss is: 1.2759591413679339\n",
      "Scaled KL Loss is: 0.05165532976388931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3276144711318232\n",
      "NLL Loss is: 1.2998012341367131\n",
      "Scaled KL Loss is: 0.04922119528055191\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.349022429417265\n",
      "NLL Loss is: 1.3753758576484725\n",
      "Scaled KL Loss is: 0.04740460589528084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4227804635437533\n",
      "NLL Loss is: 1.2426390638366194\n",
      "Scaled KL Loss is: 0.04429754242300987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2869366062596292\n",
      "NLL Loss is: 1.3698160100136088\n",
      "Scaled KL Loss is: 0.04521042853593826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.415026438549547\n",
      "NLL Loss is: 1.3676393260252062\n",
      "Scaled KL Loss is: 0.046836890280246735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414476216305453\n",
      "NLL Loss is: 1.3234847893675123\n",
      "Scaled KL Loss is: 0.046946994960308075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3704317843278204\n",
      "NLL Loss is: 1.2198380256062331\n",
      "Scaled KL Loss is: 0.04558507725596428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2654231028621974\n",
      "NLL Loss is: 1.3088745211717656\n",
      "Scaled KL Loss is: 0.04611814767122269\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3549926688429883\n",
      "NLL Loss is: 1.1723147308479123\n",
      "Scaled KL Loss is: 0.04973556846380234\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2220502993117146\n",
      "NLL Loss is: 1.325081805274022\n",
      "Scaled KL Loss is: 0.043217744678258896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.368299549952281\n",
      "NLL Loss is: 1.181459425213009\n",
      "Scaled KL Loss is: 0.04956662654876709\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2310260517617762\n",
      "NLL Loss is: 1.2941830843897635\n",
      "Scaled KL Loss is: 0.04794130101799965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3421243854077631\n",
      "NLL Loss is: 1.3832062396412608\n",
      "Scaled KL Loss is: 0.0457121878862381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4289184275274989\n",
      "NLL Loss is: 1.3147186825437729\n",
      "Scaled KL Loss is: 0.04408182203769684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3588005045814697\n",
      "NLL Loss is: 1.2357090348977555\n",
      "Scaled KL Loss is: 0.049011070281267166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2847201051790227\n",
      "NLL Loss is: 1.205978487988028\n",
      "Scaled KL Loss is: 0.04618007689714432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2521585648851723\n",
      "NLL Loss is: 1.4060708479017137\n",
      "Scaled KL Loss is: 0.04677592217922211\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4528467700809358\n",
      "NLL Loss is: 1.2421541136464689\n",
      "Scaled KL Loss is: 0.04800580069422722\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.290159914340696\n",
      "NLL Loss is: 1.6646672821301909\n",
      "Scaled KL Loss is: 0.03815563768148422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702822919811675\n",
      "NLL Loss is: 1.3095431847959458= 1.319; test loss = 1.359\n",
      "Scaled KL Loss is: 0.04878566786646843\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3583288526624142\n",
      "NLL Loss is: 1.3023549707507238\n",
      "Scaled KL Loss is: 0.046483997255563736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3488389680062876\n",
      "NLL Loss is: 1.3211411807083067\n",
      "Scaled KL Loss is: 0.04808764532208443\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.369228826030391\n",
      "NLL Loss is: 1.354591895726829\n",
      "Scaled KL Loss is: 0.04907454922795296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.403666444954782\n",
      "NLL Loss is: 1.3015685174031404\n",
      "Scaled KL Loss is: 0.04370446875691414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3452729861600545\n",
      "NLL Loss is: 1.3351242675621617\n",
      "Scaled KL Loss is: 0.049189191311597824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3843134588737596\n",
      "NLL Loss is: 1.3561541420396481\n",
      "Scaled KL Loss is: 0.04469280689954758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4008469489391957\n",
      "NLL Loss is: 1.2966573724151038\n",
      "Scaled KL Loss is: 0.044969070702791214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341626443117895\n",
      "NLL Loss is: 1.3664753661398352\n",
      "Scaled KL Loss is: 0.04326093569397926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4097363018338145\n",
      "NLL Loss is: 1.2211866003185081\n",
      "Scaled KL Loss is: 0.04983585327863693\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.271022453597145\n",
      "NLL Loss is: 1.229526210961401\n",
      "Scaled KL Loss is: 0.043120577931404114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.272646788892805\n",
      "NLL Loss is: 1.376715448991809\n",
      "Scaled KL Loss is: 0.04691476747393608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.423630216465745\n",
      "NLL Loss is: 1.2074349262002975\n",
      "Scaled KL Loss is: 0.050269126892089844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2577040530923873\n",
      "NLL Loss is: 1.4011126551877016\n",
      "Scaled KL Loss is: 0.04750499501824379\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4486176502059454\n",
      "NLL Loss is: 1.2136463525341243\n",
      "Scaled KL Loss is: 0.04711455851793289\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2607609110520572\n",
      "NLL Loss is: 1.3904455582058353\n",
      "Scaled KL Loss is: 0.05140853300690651\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4418540912127418\n",
      "NLL Loss is: 1.310859200030495\n",
      "Scaled KL Loss is: 0.04784330353140831\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3587025035619034\n",
      "NLL Loss is: 1.2739347594402983\n",
      "Scaled KL Loss is: 0.04744768515229225\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3213824445925906\n",
      "NLL Loss is: 1.1965519217536835\n",
      "Scaled KL Loss is: 0.04787072539329529\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2444226471469788\n",
      "NLL Loss is: 1.3005924116555692\n",
      "Scaled KL Loss is: 0.04593919962644577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346531611282015\n",
      "NLL Loss is: 1.2277781779169519\n",
      "Scaled KL Loss is: 0.04570886865258217\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.273487046569534\n",
      "NLL Loss is: 1.3038822320978296\n",
      "Scaled KL Loss is: 0.04648805409669876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3503702861945284\n",
      "NLL Loss is: 1.2123418975645621\n",
      "Scaled KL Loss is: 0.04708414524793625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2594260428124984\n",
      "NLL Loss is: 1.54824034060613\n",
      "Scaled KL Loss is: 0.04916121065616608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.597401551262296\n",
      "NLL Loss is: 1.1172271708949395\n",
      "Scaled KL Loss is: 0.04691212251782417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1641392934127637\n",
      "NLL Loss is: 1.2552686345040087\n",
      "Scaled KL Loss is: 0.050345953553915024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3056145880579237\n",
      "NLL Loss is: 1.3054808313798538\n",
      "Scaled KL Loss is: 0.0524309016764164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3579117330562702\n",
      "NLL Loss is: 1.0907321220293391\n",
      "Scaled KL Loss is: 0.04998058080673218\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1407127028360713\n",
      "NLL Loss is: 1.2475356405142208\n",
      "Scaled KL Loss is: 0.048469178378582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2960048188928028\n",
      "NLL Loss is: 1.0778757205268128\n",
      "Scaled KL Loss is: 0.04922410845756531\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.127099828984378\n",
      "NLL Loss is: 1.1401928410382676\n",
      "Scaled KL Loss is: 0.04426470771431923\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1844575487525868\n",
      "NLL Loss is: 1.3013077498618435\n",
      "Scaled KL Loss is: 0.04795200377702713\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3492597536388706\n",
      "NLL Loss is: 1.3155444892478028\n",
      "Scaled KL Loss is: 0.04563425853848457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3611787477862873\n",
      "NLL Loss is: 1.2217714904662806\n",
      "Scaled KL Loss is: 0.04601144790649414\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2677829383727748\n",
      "NLL Loss is: 1.4030814529792122\n",
      "Scaled KL Loss is: 0.0467689111828804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4498503641620926\n",
      "NLL Loss is: 1.3900801181708773\n",
      "Scaled KL Loss is: 0.04626242443919182\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.436342542610069\n",
      "NLL Loss is: 1.219167350309443\n",
      "Scaled KL Loss is: 0.05213768407702446\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2713050343864674\n",
      "NLL Loss is: 1.1964495280964518\n",
      "Scaled KL Loss is: 0.05053739994764328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246986928044095\n",
      "NLL Loss is: 1.30623926411106\n",
      "Scaled KL Loss is: 0.04853099212050438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3547702562315644\n",
      "NLL Loss is: 1.4243622300396754\n",
      "Scaled KL Loss is: 0.04822374880313873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4725859788428142\n",
      "NLL Loss is: 1.1462312917496196\n",
      "Scaled KL Loss is: 0.0494222491979599\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1956535409475795\n",
      "NLL Loss is: 1.153565820662465\n",
      "Scaled KL Loss is: 0.04457072541117668\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1981365460736417\n",
      "NLL Loss is: 1.191623356283902\n",
      "Scaled KL Loss is: 0.0504247322678566\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2420480885517586\n",
      "NLL Loss is: 1.1992585176581017\n",
      "Scaled KL Loss is: 0.05431115999817848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2535696776562801\n",
      "NLL Loss is: 1.269317311647483\n",
      "Scaled KL Loss is: 0.04538298025727272\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3147002919047557\n",
      "NLL Loss is: 1.2001396090969059\n",
      "Scaled KL Loss is: 0.050405438989400864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2505450480863067\n",
      "NLL Loss is: 1.2357460276460988\n",
      "Scaled KL Loss is: 0.05058324709534645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2863292747414452\n",
      "NLL Loss is: 1.1342039682911322\n",
      "Scaled KL Loss is: 0.053843334317207336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1880473026083396\n",
      "NLL Loss is: 1.2398855762446548\n",
      "Scaled KL Loss is: 0.049736108630895615\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2896216848755504\n",
      "NLL Loss is: 1.15694180326261\n",
      "Scaled KL Loss is: 0.04963082820177078\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2065726314643808\n",
      "NLL Loss is: 1.2512367171639116\n",
      "Scaled KL Loss is: 0.050378262996673584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3016149801605852\n",
      "NLL Loss is: 1.2776224360088335\n",
      "Scaled KL Loss is: 0.04645980894565582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3240822449544893\n",
      "NLL Loss is: 1.182464537775021\n",
      "Scaled KL Loss is: 0.05000677332282066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2324713110978416\n",
      "NLL Loss is: 1.2899384480801543\n",
      "Scaled KL Loss is: 0.047615550458431244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3375539985385856\n",
      "NLL Loss is: 1.365886377095245\n",
      "Scaled KL Loss is: 0.04601553827524185\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4119019153704868\n",
      "NLL Loss is: 1.3430104165782055\n",
      "Scaled KL Loss is: 0.04545325040817261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3884636669863781\n",
      "NLL Loss is: 1.3650480895867512\n",
      "Scaled KL Loss is: 0.04932373762130737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4143718272080585\n",
      "NLL Loss is: 1.228740730164998\n",
      "Scaled KL Loss is: 0.04718899726867676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2759297274336747\n",
      "NLL Loss is: 1.188272585868474\n",
      "Scaled KL Loss is: 0.045695021748542786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2339676076170167\n",
      "NLL Loss is: 1.1382691606834892\n",
      "Scaled KL Loss is: 0.050419874489307404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1886890351727966\n",
      "NLL Loss is: 1.2373056472334185\n",
      "Scaled KL Loss is: 0.04926976189017296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2865754091235915\n",
      "NLL Loss is: 1.2486471781645998\n",
      "Scaled KL Loss is: 0.04809267073869705\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2967398489032969\n",
      "NLL Loss is: 1.3298385090403086\n",
      "Scaled KL Loss is: 0.047511547803878784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3773500568441874\n",
      "NLL Loss is: 1.2588756796865608\n",
      "Scaled KL Loss is: 0.049263957887887955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3081396375744487\n",
      "NLL Loss is: 1.2352332553002063\n",
      "Scaled KL Loss is: 0.04544825851917267\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.280681513819379\n",
      "NLL Loss is: 1.3523479291200167\n",
      "Scaled KL Loss is: 0.04679417610168457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3991421052217012\n",
      "NLL Loss is: 1.3571361768966022\n",
      "Scaled KL Loss is: 0.04954934120178223\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4066855180983844\n",
      "NLL Loss is: 1.2948071677295234\n",
      "Scaled KL Loss is: 0.04693405702710152\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341741224756625\n",
      "NLL Loss is: 1.2508454131168056\n",
      "Scaled KL Loss is: 0.05082303285598755\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3016684459727932\n",
      "NLL Loss is: 1.2314113354154446\n",
      "Scaled KL Loss is: 0.047047752887010574\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2784590883024551\n",
      "NLL Loss is: 1.4085779786254204\n",
      "Scaled KL Loss is: 0.048243198543787\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4568211771692074\n",
      "NLL Loss is: 1.2883157875390525\n",
      "Scaled KL Loss is: 0.04538702219724655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.333702809736299\n",
      "NLL Loss is: 1.2753973450993183\n",
      "Scaled KL Loss is: 0.05163666978478432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3270340148841027\n",
      "NLL Loss is: 1.2987623260149173\n",
      "Scaled KL Loss is: 0.04921555891633034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3479778849312476\n",
      "NLL Loss is: 1.3747885671091127\n",
      "Scaled KL Loss is: 0.04738573357462883\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4221743006837415\n",
      "NLL Loss is: 1.241706698074568\n",
      "Scaled KL Loss is: 0.04427184537053108\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.285978543445099\n",
      "NLL Loss is: 1.3693912676843696\n",
      "Scaled KL Loss is: 0.04514512047171593\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4145363881560855\n",
      "NLL Loss is: 1.3672544512449614\n",
      "Scaled KL Loss is: 0.04684210196137428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4140965532063356\n",
      "NLL Loss is: 1.3233182922193982\n",
      "Scaled KL Loss is: 0.04685892537236214\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3701772175917604\n",
      "NLL Loss is: 1.2191763861347644\n",
      "Scaled KL Loss is: 0.04555140435695648\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.264727790491721\n",
      "NLL Loss is: 1.3083181409235904\n",
      "Scaled KL Loss is: 0.04608459398150444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544027349050949\n",
      "NLL Loss is: 1.171129368177008\n",
      "Scaled KL Loss is: 0.04972080513834953\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2208501733153576\n",
      "NLL Loss is: 1.3246544457084082\n",
      "Scaled KL Loss is: 0.043160565197467804\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.367815010905876\n",
      "NLL Loss is: 1.1809083968093126\n",
      "Scaled KL Loss is: 0.0495331808924675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.23044157770178\n",
      "NLL Loss is: 1.2933945386093786\n",
      "Scaled KL Loss is: 0.04786890745162964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3412634460610082\n",
      "NLL Loss is: 1.3823478444260358\n",
      "Scaled KL Loss is: 0.04569529369473457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4280431381207703\n",
      "NLL Loss is: 1.3141552111639365\n",
      "Scaled KL Loss is: 0.044052790850400925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3582080020143374\n",
      "NLL Loss is: 1.2344108526840385\n",
      "Scaled KL Loss is: 0.04896056652069092\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2833714192047294\n",
      "NLL Loss is: 1.204877985452188\n",
      "Scaled KL Loss is: 0.046190209686756134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2510681951389442\n",
      "NLL Loss is: 1.4053477378068673\n",
      "Scaled KL Loss is: 0.046764664351940155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4521124021588074\n",
      "NLL Loss is: 1.2414395120018151\n",
      "Scaled KL Loss is: 0.047991346567869186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2894308585696843\n",
      "NLL Loss is: 1.6641641773081557\n",
      "Scaled KL Loss is: 0.03809887915849686\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7022630564666525\n",
      "NLL Loss is: 1.3088763453489998= 1.318; test loss = 1.358\n",
      "Scaled KL Loss is: 0.04873716086149216\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.357613506210492\n",
      "NLL Loss is: 1.3014034767243132\n",
      "Scaled KL Loss is: 0.04646703600883484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.347870512733148\n",
      "NLL Loss is: 1.3203375751727249\n",
      "Scaled KL Loss is: 0.048059847205877304\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3683974223786022\n",
      "NLL Loss is: 1.3541527262847584\n",
      "Scaled KL Loss is: 0.04897347465157509\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4031262009363334\n",
      "NLL Loss is: 1.3006218462217498\n",
      "Scaled KL Loss is: 0.043675072491168976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3442969187129188\n",
      "NLL Loss is: 1.3340548472280023\n",
      "Scaled KL Loss is: 0.04916509613394737\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3832199433619496\n",
      "NLL Loss is: 1.355133569147283\n",
      "Scaled KL Loss is: 0.04472113028168678\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3998546994289698\n",
      "NLL Loss is: 1.2955641816542396\n",
      "Scaled KL Loss is: 0.044955551624298096\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3405197332785377\n",
      "NLL Loss is: 1.3654867651696645\n",
      "Scaled KL Loss is: 0.043225206434726715\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4087119716043912\n",
      "NLL Loss is: 1.2204366335314785\n",
      "Scaled KL Loss is: 0.04978526011109352\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270221893642572\n",
      "NLL Loss is: 1.2284349724203485\n",
      "Scaled KL Loss is: 0.043047621846199036\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2714825942665475\n",
      "NLL Loss is: 1.3758474538432488\n",
      "Scaled KL Loss is: 0.0468977615237236\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4227452153669724\n",
      "NLL Loss is: 1.2066349025556256\n",
      "Scaled KL Loss is: 0.05023903772234917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2568739402779747\n",
      "NLL Loss is: 1.400462100546906\n",
      "Scaled KL Loss is: 0.04744778573513031\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4479098862820363\n",
      "NLL Loss is: 1.212773717853834\n",
      "Scaled KL Loss is: 0.04710889607667923\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2598826139305133\n",
      "NLL Loss is: 1.389596333118126\n",
      "Scaled KL Loss is: 0.05142619088292122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4410225240010472\n",
      "NLL Loss is: 1.3097901093982585\n",
      "Scaled KL Loss is: 0.04786309227347374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3576532016717322\n",
      "NLL Loss is: 1.2732569382904508\n",
      "Scaled KL Loss is: 0.047416094690561295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3206730329810121\n",
      "NLL Loss is: 1.1959473213471254\n",
      "Scaled KL Loss is: 0.047863662242889404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2438109835900149\n",
      "NLL Loss is: 1.2994550990137135\n",
      "Scaled KL Loss is: 0.04594244062900543\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.345397539642719\n",
      "NLL Loss is: 1.226563985535427\n",
      "Scaled KL Loss is: 0.0456632636487484\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2722272491841753\n",
      "NLL Loss is: 1.3026264789884947\n",
      "Scaled KL Loss is: 0.046523500233888626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3491499792223833\n",
      "NLL Loss is: 1.2112129573671648\n",
      "Scaled KL Loss is: 0.047112058848142624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2583250162153075\n",
      "NLL Loss is: 1.5474244948431903\n",
      "Scaled KL Loss is: 0.049116943031549454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5965414378747398\n",
      "NLL Loss is: 1.1165466972837537\n",
      "Scaled KL Loss is: 0.04689157381653786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1634382711002915\n",
      "NLL Loss is: 1.2544618954799083\n",
      "Scaled KL Loss is: 0.050301626324653625\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304763521804562\n",
      "NLL Loss is: 1.3045980530174395\n",
      "Scaled KL Loss is: 0.05241789296269417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3570159459801336\n",
      "NLL Loss is: 1.0899190705579813\n",
      "Scaled KL Loss is: 0.04996567219495773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.139884742752939\n",
      "NLL Loss is: 1.2466092181490667\n",
      "Scaled KL Loss is: 0.04844144731760025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.295050665466667\n",
      "NLL Loss is: 1.0767855022912278\n",
      "Scaled KL Loss is: 0.04921753332018852\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1260030356114163\n",
      "NLL Loss is: 1.139662084300806\n",
      "Scaled KL Loss is: 0.04423242807388306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1838945123746891\n",
      "NLL Loss is: 1.3004513144135543\n",
      "Scaled KL Loss is: 0.04792891815304756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3483802325666019\n",
      "NLL Loss is: 1.3148843263854846\n",
      "Scaled KL Loss is: 0.04560525715351105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3604895835389956\n",
      "NLL Loss is: 1.2213637112217828\n",
      "Scaled KL Loss is: 0.045977089554071426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2673408007758542\n",
      "NLL Loss is: 1.4025178452140346\n",
      "Scaled KL Loss is: 0.04674113169312477\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4492589769071593\n",
      "NLL Loss is: 1.388538922920432\n",
      "Scaled KL Loss is: 0.04622677341103554\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4347656963314674\n",
      "NLL Loss is: 1.2186617227151322\n",
      "Scaled KL Loss is: 0.052049119025468826\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270710841740601\n",
      "NLL Loss is: 1.1963258214398618\n",
      "Scaled KL Loss is: 0.05053463950753212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246860460947394\n",
      "NLL Loss is: 1.30558948721055\n",
      "Scaled KL Loss is: 0.048526786267757416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3541162734783074\n",
      "NLL Loss is: 1.4235440478639283\n",
      "Scaled KL Loss is: 0.048176493495702744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.471720541359631\n",
      "NLL Loss is: 1.1452202774837954\n",
      "Scaled KL Loss is: 0.049409978091716766\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1946302555755122\n",
      "NLL Loss is: 1.15260257330842\n",
      "Scaled KL Loss is: 0.04456818848848343\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1971707617969034\n",
      "NLL Loss is: 1.1908359993040412\n",
      "Scaled KL Loss is: 0.050469160079956055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2413051593839972\n",
      "NLL Loss is: 1.19873037052354\n",
      "Scaled KL Loss is: 0.054255545139312744\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2529859156628527\n",
      "NLL Loss is: 1.2684723906359239\n",
      "Scaled KL Loss is: 0.045345958322286606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3138183489582105\n",
      "NLL Loss is: 1.1994946256376504\n",
      "Scaled KL Loss is: 0.0504186674952507\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2499132931329011\n",
      "NLL Loss is: 1.2354462297377637\n",
      "Scaled KL Loss is: 0.05054442584514618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.28599065558291\n",
      "NLL Loss is: 1.1333784342049622\n",
      "Scaled KL Loss is: 0.0538877472281456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1872661814331078\n",
      "NLL Loss is: 1.239475905642192\n",
      "Scaled KL Loss is: 0.04969469830393791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.28917060394613\n",
      "NLL Loss is: 1.156126788194516\n",
      "Scaled KL Loss is: 0.04964502528309822\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2057718134776143\n",
      "NLL Loss is: 1.2507078986856894\n",
      "Scaled KL Loss is: 0.05038386583328247\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.301091764518972\n",
      "NLL Loss is: 1.2768251930937198\n",
      "Scaled KL Loss is: 0.04643819108605385\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3232633841797736\n",
      "NLL Loss is: 1.1816625675000485\n",
      "Scaled KL Loss is: 0.050001222640275955\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2316637901403245\n",
      "NLL Loss is: 1.2890392503321788\n",
      "Scaled KL Loss is: 0.04766895994544029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336708210277619\n",
      "NLL Loss is: 1.3653510981890689\n",
      "Scaled KL Loss is: 0.04600837081670761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4113594690057765\n",
      "NLL Loss is: 1.341898701173486\n",
      "Scaled KL Loss is: 0.045473337173461914\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3873720383469479\n",
      "NLL Loss is: 1.364416975270757\n",
      "Scaled KL Loss is: 0.04932089522480965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4137378704955665\n",
      "NLL Loss is: 1.2285568047489965\n",
      "Scaled KL Loss is: 0.047184932976961136\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2757417377259577\n",
      "NLL Loss is: 1.1871299990396462\n",
      "Scaled KL Loss is: 0.04572677984833717\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2328567788879834\n",
      "NLL Loss is: 1.1374548989439552\n",
      "Scaled KL Loss is: 0.05041666701436043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1878715659583157\n",
      "NLL Loss is: 1.2367316760791247\n",
      "Scaled KL Loss is: 0.04930044710636139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.286032123185486\n",
      "NLL Loss is: 1.2475952041755891\n",
      "Scaled KL Loss is: 0.048106756061315536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2957019602369046\n",
      "NLL Loss is: 1.328554700230809\n",
      "Scaled KL Loss is: 0.04752501845359802\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376079718684407\n",
      "NLL Loss is: 1.258289860694863\n",
      "Scaled KL Loss is: 0.049330566078424454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3076204267732874\n",
      "NLL Loss is: 1.2342025873232172\n",
      "Scaled KL Loss is: 0.045463576912879944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2796661642360971\n",
      "NLL Loss is: 1.3517818674783564\n",
      "Scaled KL Loss is: 0.04681260511279106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3985944725911474\n",
      "NLL Loss is: 1.3561327434853934\n",
      "Scaled KL Loss is: 0.04961412027478218\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4057468637601755\n",
      "NLL Loss is: 1.2939423626230115\n",
      "Scaled KL Loss is: 0.04693606123328209\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3408784238562936\n",
      "NLL Loss is: 1.2498468888070278\n",
      "Scaled KL Loss is: 0.05082784593105316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300674734738081\n",
      "NLL Loss is: 1.2302618627555932\n",
      "Scaled KL Loss is: 0.047065477818250656\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.277327340573844\n",
      "NLL Loss is: 1.4075099934605515\n",
      "Scaled KL Loss is: 0.048273246735334396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.455783240195886\n",
      "NLL Loss is: 1.2872744918857655\n",
      "Scaled KL Loss is: 0.04542030766606331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3326947995518288\n",
      "NLL Loss is: 1.274787505644851\n",
      "Scaled KL Loss is: 0.05166752263903618\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3264550282838872\n",
      "NLL Loss is: 1.2978834261639085\n",
      "Scaled KL Loss is: 0.04925313964486122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3471365658087697\n",
      "NLL Loss is: 1.3739720275671854\n",
      "Scaled KL Loss is: 0.047410979866981506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.421383007434167\n",
      "NLL Loss is: 1.240991463399302\n",
      "Scaled KL Loss is: 0.04429508000612259\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2852865434054246\n",
      "NLL Loss is: 1.3688836328851475\n",
      "Scaled KL Loss is: 0.045138996094465256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4140226289796127\n",
      "NLL Loss is: 1.3661675128240378\n",
      "Scaled KL Loss is: 0.04688221961259842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4130497324366362\n",
      "NLL Loss is: 1.3233192694285472\n",
      "Scaled KL Loss is: 0.04683919623494148\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3701584656634886\n",
      "NLL Loss is: 1.2183839204877196\n",
      "Scaled KL Loss is: 0.04556877538561821\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2639526958733378\n",
      "NLL Loss is: 1.307604639321583\n",
      "Scaled KL Loss is: 0.046097975224256516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3537026145458395\n",
      "NLL Loss is: 1.1699539569875852\n",
      "Scaled KL Loss is: 0.049755580723285675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2197095377108709\n",
      "NLL Loss is: 1.3242166012823031\n",
      "Scaled KL Loss is: 0.043157562613487244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3673741638957904\n",
      "NLL Loss is: 1.1804198129351122\n",
      "Scaled KL Loss is: 0.04955488443374634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2299746973688586\n",
      "NLL Loss is: 1.2925011228630956\n",
      "Scaled KL Loss is: 0.04785948619246483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3403606090555604\n",
      "NLL Loss is: 1.381293268377534\n",
      "Scaled KL Loss is: 0.0457092747092247\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4270025430867588\n",
      "NLL Loss is: 1.3134916851670266\n",
      "Scaled KL Loss is: 0.04407937452197075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3575710596889974\n",
      "NLL Loss is: 1.2332546221701297\n",
      "Scaled KL Loss is: 0.04895930737257004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2822139295426997\n",
      "NLL Loss is: 1.2040868599090624\n",
      "Scaled KL Loss is: 0.046235162764787674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.25032202267385\n",
      "NLL Loss is: 1.4046981131567509\n",
      "Scaled KL Loss is: 0.0467870719730854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4514851851298363\n",
      "NLL Loss is: 1.240778330715827\n",
      "Scaled KL Loss is: 0.04801876097917557\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2887970916950027\n",
      "NLL Loss is: 1.664159274997516\n",
      "Scaled KL Loss is: 0.03808612376451492\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702245398762031\n",
      "NLL Loss is: 1.3083882295857068= 1.317; test loss = 1.357\n",
      "Scaled KL Loss is: 0.048741187900304794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3571294174860116\n",
      "NLL Loss is: 1.3005654068541903\n",
      "Scaled KL Loss is: 0.04650508239865303\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3470704892528433\n",
      "NLL Loss is: 1.319273850790887\n",
      "Scaled KL Loss is: 0.04807591438293457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3673497651738216\n",
      "NLL Loss is: 1.3535360356486603\n",
      "Scaled KL Loss is: 0.048937804996967316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4024738406456276\n",
      "NLL Loss is: 1.2995029112401313\n",
      "Scaled KL Loss is: 0.04369092360138893\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431938348415202\n",
      "NLL Loss is: 1.3331902813597076\n",
      "Scaled KL Loss is: 0.04919318109750748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382383462457215\n",
      "NLL Loss is: 1.3540868313915888\n",
      "Scaled KL Loss is: 0.04479723423719406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3988840656287829\n",
      "NLL Loss is: 1.2945420207794\n",
      "Scaled KL Loss is: 0.04500008001923561\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3395421007986357\n",
      "NLL Loss is: 1.364830047309192\n",
      "Scaled KL Loss is: 0.04324058070778847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4080706280169806\n",
      "NLL Loss is: 1.2195949236305905\n",
      "Scaled KL Loss is: 0.049785781651735306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2693807052823258\n",
      "NLL Loss is: 1.2272479022774494\n",
      "Scaled KL Loss is: 0.04303157702088356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270279479298333\n",
      "NLL Loss is: 1.374942641787408\n",
      "Scaled KL Loss is: 0.04692500829696655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4218676500843745\n",
      "NLL Loss is: 1.2060144571856557\n",
      "Scaled KL Loss is: 0.05024426430463791\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2562587214902936\n",
      "NLL Loss is: 1.3995337101957483\n",
      "Scaled KL Loss is: 0.04744301363825798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4469767238340063\n",
      "NLL Loss is: 1.2118779693603232\n",
      "Scaled KL Loss is: 0.04715419188141823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2590321612417414\n",
      "NLL Loss is: 1.3886029321788373\n",
      "Scaled KL Loss is: 0.05147750675678253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4400804389356199\n",
      "NLL Loss is: 1.3088189205577212\n",
      "Scaled KL Loss is: 0.047919854521751404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3567387750794726\n",
      "NLL Loss is: 1.2723457747699682\n",
      "Scaled KL Loss is: 0.04743431508541107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3197800898553793\n",
      "NLL Loss is: 1.1950297350090855\n",
      "Scaled KL Loss is: 0.04789841175079346\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.242928146759879\n",
      "NLL Loss is: 1.298291753867511\n",
      "Scaled KL Loss is: 0.045986007899045944\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344277761766557\n",
      "NLL Loss is: 1.2255221389772537\n",
      "Scaled KL Loss is: 0.045677121728658676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2711992607059124\n",
      "NLL Loss is: 1.3013670241933715\n",
      "Scaled KL Loss is: 0.04660140350461006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3479684276979815\n",
      "NLL Loss is: 1.2099986327978707\n",
      "Scaled KL Loss is: 0.04718467965722084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2571833124550915\n",
      "NLL Loss is: 1.546601726694949\n",
      "Scaled KL Loss is: 0.049138143658638\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.595739870353587\n",
      "NLL Loss is: 1.1157572622410843\n",
      "Scaled KL Loss is: 0.046929530799388885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1626867930404732\n",
      "NLL Loss is: 1.2535990743308656\n",
      "Scaled KL Loss is: 0.050318554043769836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3039176283746354\n",
      "NLL Loss is: 1.3036901426305982\n",
      "Scaled KL Loss is: 0.052465345710515976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3561554883411142\n",
      "NLL Loss is: 1.0890167697644757\n",
      "Scaled KL Loss is: 0.050005290657281876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1390220604217576\n",
      "NLL Loss is: 1.2455783013063493\n",
      "Scaled KL Loss is: 0.04847469553351402\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2940529968398633\n",
      "NLL Loss is: 1.075475655548262\n",
      "Scaled KL Loss is: 0.04927569627761841\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1247513518258805\n",
      "NLL Loss is: 1.1390821361377101\n",
      "Scaled KL Loss is: 0.04427046328783035\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1833525994255405\n",
      "NLL Loss is: 1.2996766086212803\n",
      "Scaled KL Loss is: 0.04797792807221413\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3476545366934944\n",
      "NLL Loss is: 1.314146247213941\n",
      "Scaled KL Loss is: 0.04565852880477905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35980477601872\n",
      "NLL Loss is: 1.2208187365969898\n",
      "Scaled KL Loss is: 0.04601991921663284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2668386558136226\n",
      "NLL Loss is: 1.4020075201205355\n",
      "Scaled KL Loss is: 0.04678105190396309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4487885720244986\n",
      "NLL Loss is: 1.3870901930003499\n",
      "Scaled KL Loss is: 0.04626812785863876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4333583208589886\n",
      "NLL Loss is: 1.2181110875456367\n",
      "Scaled KL Loss is: 0.05204840004444122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270159487590078\n",
      "NLL Loss is: 1.195982931432508\n",
      "Scaled KL Loss is: 0.050600264221429825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2465831956539377\n",
      "NLL Loss is: 1.3049529916817262\n",
      "Scaled KL Loss is: 0.04859821870923042\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3535512103909566\n",
      "NLL Loss is: 1.4226887225953577\n",
      "Scaled KL Loss is: 0.048214200884103775\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4709029234794615\n",
      "NLL Loss is: 1.144172447243882\n",
      "Scaled KL Loss is: 0.049482036381959915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1936544836258418\n",
      "NLL Loss is: 1.1516016842622105\n",
      "Scaled KL Loss is: 0.044637978076934814\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1962396623391454\n",
      "NLL Loss is: 1.1899285989298631\n",
      "Scaled KL Loss is: 0.050575315952301025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2405039148821642\n",
      "NLL Loss is: 1.198199426220291\n",
      "Scaled KL Loss is: 0.05428944528102875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2524888715013198\n",
      "NLL Loss is: 1.2675256757042788\n",
      "Scaled KL Loss is: 0.04538622871041298\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3129119044146917\n",
      "NLL Loss is: 1.1987768932192966\n",
      "Scaled KL Loss is: 0.05047689005732536\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.249253783276622\n",
      "NLL Loss is: 1.2350189393816893\n",
      "Scaled KL Loss is: 0.0505666546523571\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2855855940340464\n",
      "NLL Loss is: 1.132548087719789\n",
      "Scaled KL Loss is: 0.05397851765155792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.186526605371347\n",
      "NLL Loss is: 1.239037286608877\n",
      "Scaled KL Loss is: 0.049703020602464676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2887403072113417\n",
      "NLL Loss is: 1.155327176084568\n",
      "Scaled KL Loss is: 0.04970145598053932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2050286320651074\n",
      "NLL Loss is: 1.2501559860139009\n",
      "Scaled KL Loss is: 0.05042581260204315\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.300581798615944\n",
      "NLL Loss is: 1.276105715225629\n",
      "Scaled KL Loss is: 0.04644807055592537\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3225537857815544\n",
      "NLL Loss is: 1.1807912752811216\n",
      "Scaled KL Loss is: 0.050029706209897995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2308209814910196\n",
      "NLL Loss is: 1.2882067320194628\n",
      "Scaled KL Loss is: 0.04774605110287666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3359527831223394\n",
      "NLL Loss is: 1.3646226428249109\n",
      "Scaled KL Loss is: 0.04601909592747688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4106417387523877\n",
      "NLL Loss is: 1.340715494727845\n",
      "Scaled KL Loss is: 0.045506443828344345\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3862219385561894\n",
      "NLL Loss is: 1.3637790970261299\n",
      "Scaled KL Loss is: 0.04933199658989906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.413111093616029\n",
      "NLL Loss is: 1.2282932305298746\n",
      "Scaled KL Loss is: 0.04719134047627449\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.275484571006149\n",
      "NLL Loss is: 1.1858939270764364\n",
      "Scaled KL Loss is: 0.045769546180963516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2316634732573999\n",
      "NLL Loss is: 1.136635034173414\n",
      "Scaled KL Loss is: 0.05042647197842598\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.18706150615184\n",
      "NLL Loss is: 1.2362206994263085\n",
      "Scaled KL Loss is: 0.04934239387512207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2855630933014306\n",
      "NLL Loss is: 1.246518007535646\n",
      "Scaled KL Loss is: 0.048132240772247314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2946502483078932\n",
      "NLL Loss is: 1.327161583988786\n",
      "Scaled KL Loss is: 0.04755060002207756\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3747121840108636\n",
      "NLL Loss is: 1.2576765833800845\n",
      "Scaled KL Loss is: 0.049410052597522736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3070866359776072\n",
      "NLL Loss is: 1.2331859232925981\n",
      "Scaled KL Loss is: 0.045490629971027374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2786765532636255\n",
      "NLL Loss is: 1.3511875204754407\n",
      "Scaled KL Loss is: 0.046843256801366806\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3980307772768075\n",
      "NLL Loss is: 1.3551209464305103\n",
      "Scaled KL Loss is: 0.04968906193971634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4048100083702266\n",
      "NLL Loss is: 1.2930846763975672\n",
      "Scaled KL Loss is: 0.04695058614015579\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.340035262537723\n",
      "NLL Loss is: 1.2488661381044284\n",
      "Scaled KL Loss is: 0.05084572359919548\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2997118617036238\n",
      "NLL Loss is: 1.2291118498726632\n",
      "Scaled KL Loss is: 0.04709552600979805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2762073758824612\n",
      "NLL Loss is: 1.4064754572510307\n",
      "Scaled KL Loss is: 0.04831365868449211\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4547891159355228\n",
      "NLL Loss is: 1.2862264409833934\n",
      "Scaled KL Loss is: 0.045463766902685165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3316902078860786\n",
      "NLL Loss is: 1.274143959094511\n",
      "Scaled KL Loss is: 0.05171322077512741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3258571798696384\n",
      "NLL Loss is: 1.2970413131058263\n",
      "Scaled KL Loss is: 0.0493021197617054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3463434328675317\n",
      "NLL Loss is: 1.3730979235401128\n",
      "Scaled KL Loss is: 0.047449130564928055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.420547054105041\n",
      "NLL Loss is: 1.240235999824411\n",
      "Scaled KL Loss is: 0.044332973659038544\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2845689734834496\n",
      "NLL Loss is: 1.3683561732840515\n",
      "Scaled KL Loss is: 0.04514996334910393\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4135061366331554\n",
      "NLL Loss is: 1.3652705565594545\n",
      "Scaled KL Loss is: 0.046927571296691895\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4121981278561464\n",
      "NLL Loss is: 1.3233174421374552\n",
      "Scaled KL Loss is: 0.046837810426950455\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3701552525644056\n",
      "NLL Loss is: 1.2175537505915006\n",
      "Scaled KL Loss is: 0.04559965804219246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.263153408633693\n",
      "NLL Loss is: 1.306898600603914\n",
      "Scaled KL Loss is: 0.04612509161233902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.353023692216253\n",
      "NLL Loss is: 1.1686432626485346\n",
      "Scaled KL Loss is: 0.04980135336518288\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2184446160137175\n",
      "NLL Loss is: 1.323775801362132\n",
      "Scaled KL Loss is: 0.04316922277212143\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3669450241342533\n",
      "NLL Loss is: 1.1798273990473085\n",
      "Scaled KL Loss is: 0.04959334805607796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2294207471033864\n",
      "NLL Loss is: 1.2915719309736795\n",
      "Scaled KL Loss is: 0.047866836190223694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3394387671639032\n",
      "NLL Loss is: 1.3802449724807315\n",
      "Scaled KL Loss is: 0.04573076218366623\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4259757346643978\n",
      "NLL Loss is: 1.3128698087161395\n",
      "Scaled KL Loss is: 0.04411694034934044\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35698674906548\n",
      "NLL Loss is: 1.2320754358331707\n",
      "Scaled KL Loss is: 0.04897505044937134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.281050486282542\n",
      "NLL Loss is: 1.20326127813085\n",
      "Scaled KL Loss is: 0.04629284143447876\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2495541195653288\n",
      "NLL Loss is: 1.4040738080869983\n",
      "Scaled KL Loss is: 0.046820640563964844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4508944486509632\n",
      "NLL Loss is: 1.2400471881873694\n",
      "Scaled KL Loss is: 0.04805595800280571\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.288103146190175\n",
      "NLL Loss is: 1.6641383256811988\n",
      "Scaled KL Loss is: 0.03808378055691719\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702222106238116\n",
      "NLL Loss is: 1.3079158967231195= 1.316; test loss = 1.356\n",
      "Scaled KL Loss is: 0.04876120015978813\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3566770968829076\n",
      "NLL Loss is: 1.2997110350351326\n",
      "Scaled KL Loss is: 0.046559493988752365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346270529023885\n",
      "NLL Loss is: 1.3182914327336914\n",
      "Scaled KL Loss is: 0.048104479908943176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3663959126426346\n",
      "NLL Loss is: 1.3529126901148094\n",
      "Scaled KL Loss is: 0.04892510920763016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4018377993224396\n",
      "NLL Loss is: 1.2984430415543047\n",
      "Scaled KL Loss is: 0.04372004419565201\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3421630857499567\n",
      "NLL Loss is: 1.3322294903499232\n",
      "Scaled KL Loss is: 0.04924117401242256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3814706643623458\n",
      "NLL Loss is: 1.353137539815667\n",
      "Scaled KL Loss is: 0.04489057883620262\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3980281186518697\n",
      "NLL Loss is: 1.293588034538783\n",
      "Scaled KL Loss is: 0.04507295414805412\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.338660988686837\n",
      "NLL Loss is: 1.3642139732766938\n",
      "Scaled KL Loss is: 0.04328273609280586\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4074967093694997\n",
      "NLL Loss is: 1.2187640898093246\n",
      "Scaled KL Loss is: 0.04981601610779762\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2685801059171222\n",
      "NLL Loss is: 1.226211081681564\n",
      "Scaled KL Loss is: 0.04305446892976761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2692655506113315\n",
      "NLL Loss is: 1.374167286126725\n",
      "Scaled KL Loss is: 0.0469776950776577\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4211449812043826\n",
      "NLL Loss is: 1.2053117194559004\n",
      "Scaled KL Loss is: 0.050274379551410675\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255586099007311\n",
      "NLL Loss is: 1.3984786259313484\n",
      "Scaled KL Loss is: 0.04747053608298302\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4459491620143314\n",
      "NLL Loss is: 1.2110537745403933\n",
      "Scaled KL Loss is: 0.04723003879189491\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2582838133322882\n",
      "NLL Loss is: 1.387648619841397\n",
      "Scaled KL Loss is: 0.05154722183942795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.439195841680825\n",
      "NLL Loss is: 1.307751683199879\n",
      "Scaled KL Loss is: 0.0479947030544281\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355746386254307\n",
      "NLL Loss is: 1.2714312192067332\n",
      "Scaled KL Loss is: 0.04747762903571129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3189088482424445\n",
      "NLL Loss is: 1.1940659329840018\n",
      "Scaled KL Loss is: 0.04795300215482712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2420189351388289\n",
      "NLL Loss is: 1.2971356425053557\n",
      "Scaled KL Loss is: 0.04604645445942879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431820969647845\n",
      "NLL Loss is: 1.2243970850073653\n",
      "Scaled KL Loss is: 0.04571840167045593\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2701154866778213\n",
      "NLL Loss is: 1.3001197411019552\n",
      "Scaled KL Loss is: 0.04669448733329773\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346814228435253\n",
      "NLL Loss is: 1.2087444113836776\n",
      "Scaled KL Loss is: 0.04727006331086159\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2560144746945392\n",
      "NLL Loss is: 1.5458098464416645\n",
      "Scaled KL Loss is: 0.049176547676324844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5949863941179894\n",
      "NLL Loss is: 1.1149395826549138\n",
      "Scaled KL Loss is: 0.04698094353079796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1619205261857117\n",
      "NLL Loss is: 1.252756733207839\n",
      "Scaled KL Loss is: 0.05034570395946503\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3031024371673041\n",
      "NLL Loss is: 1.3028004665080903\n",
      "Scaled KL Loss is: 0.052521366626024246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3553218331341146\n",
      "NLL Loss is: 1.0881255395719969\n",
      "Scaled KL Loss is: 0.050049569457769394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1381751090297663\n",
      "NLL Loss is: 1.244586290125389\n",
      "Scaled KL Loss is: 0.04851454123854637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2931008313639354\n",
      "NLL Loss is: 1.0742055055905881\n",
      "Scaled KL Loss is: 0.049337342381477356\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1235428479720655\n",
      "NLL Loss is: 1.1384198197708246\n",
      "Scaled KL Loss is: 0.04431011900305748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.182729938773882\n",
      "NLL Loss is: 1.2988330460569677\n",
      "Scaled KL Loss is: 0.04802516847848892\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3468582145354566\n",
      "NLL Loss is: 1.3135065876909635\n",
      "Scaled KL Loss is: 0.04570825770497322\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3592148453959367\n",
      "NLL Loss is: 1.2202837500916572\n",
      "Scaled KL Loss is: 0.04605649784207344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2663402479337307\n",
      "NLL Loss is: 1.40151480931391\n",
      "Scaled KL Loss is: 0.04681537672877312\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4483301860426832\n",
      "NLL Loss is: 1.3857811340720219\n",
      "Scaled KL Loss is: 0.04630386829376221\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.432085002365784\n",
      "NLL Loss is: 1.2174289785477241\n",
      "Scaled KL Loss is: 0.05203510820865631\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2694640867563804\n",
      "NLL Loss is: 1.1956252134970784\n",
      "Scaled KL Loss is: 0.050658877938985825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2462840914360642\n",
      "NLL Loss is: 1.3044322017021042\n",
      "Scaled KL Loss is: 0.04866086691617966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3530930686182838\n",
      "NLL Loss is: 1.4218364773895076\n",
      "Scaled KL Loss is: 0.04824087396264076\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4700773513521483\n",
      "NLL Loss is: 1.1431784352974155\n",
      "Scaled KL Loss is: 0.049544382840394974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1927228181378104\n",
      "NLL Loss is: 1.1507360517907697\n",
      "Scaled KL Loss is: 0.04469698667526245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.195433038466032\n",
      "NLL Loss is: 1.189046932368597\n",
      "Scaled KL Loss is: 0.05067253112792969\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2397194634965267\n",
      "NLL Loss is: 1.1975272310142246\n",
      "Scaled KL Loss is: 0.05430975928902626\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.251836990303251\n",
      "NLL Loss is: 1.2666361816011433\n",
      "Scaled KL Loss is: 0.0454116016626358\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3120477832637791\n",
      "NLL Loss is: 1.1980521288906412\n",
      "Scaled KL Loss is: 0.05054153874516487\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.248593667635806\n",
      "NLL Loss is: 1.234591480136604\n",
      "Scaled KL Loss is: 0.050584033131599426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2851755132682035\n",
      "NLL Loss is: 1.1317582292352797\n",
      "Scaled KL Loss is: 0.05406893044710159\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1858271596823813\n",
      "NLL Loss is: 1.238575090096154\n",
      "Scaled KL Loss is: 0.04971920698881149\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2882942970849656\n",
      "NLL Loss is: 1.1544781233243655\n",
      "Scaled KL Loss is: 0.04976976662874222\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2042478899531077\n",
      "NLL Loss is: 1.2495274803281617\n",
      "Scaled KL Loss is: 0.050483688712120056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3000111690402818\n",
      "NLL Loss is: 1.2753258538065433\n",
      "Scaled KL Loss is: 0.046481139957904816\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.321806993764448\n",
      "NLL Loss is: 1.1798904747182\n",
      "Scaled KL Loss is: 0.05008314177393913\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.229973616492139\n",
      "NLL Loss is: 1.2872820988988725\n",
      "Scaled KL Loss is: 0.04784412309527397\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3351262219941464\n",
      "NLL Loss is: 1.3640179769061018\n",
      "Scaled KL Loss is: 0.04605261608958244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4100705929956843\n",
      "NLL Loss is: 1.3395941440159636\n",
      "Scaled KL Loss is: 0.04556949436664581\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3851636383826094\n",
      "NLL Loss is: 1.3630909032600311\n",
      "Scaled KL Loss is: 0.04936971887946129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4124606221394924\n",
      "NLL Loss is: 1.227944078695435\n",
      "Scaled KL Loss is: 0.04723871126770973\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2751827899631447\n",
      "NLL Loss is: 1.1847314435065657\n",
      "Scaled KL Loss is: 0.04583591967821121\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2305673631847769\n",
      "NLL Loss is: 1.1358134364146937\n",
      "Scaled KL Loss is: 0.05047603324055672\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1862894696552504\n",
      "NLL Loss is: 1.2356116963191832\n",
      "Scaled KL Loss is: 0.04941260814666748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2850243044658507\n",
      "NLL Loss is: 1.245486966963871\n",
      "Scaled KL Loss is: 0.0481938011944294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2936807681583005\n",
      "NLL Loss is: 1.3259004448544136\n",
      "Scaled KL Loss is: 0.04760834947228432\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.373508794326698\n",
      "NLL Loss is: 1.257077288061514\n",
      "Scaled KL Loss is: 0.04950922355055809\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.306586511612072\n",
      "NLL Loss is: 1.2321251320108328\n",
      "Scaled KL Loss is: 0.045546989887952805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2776721218987857\n",
      "NLL Loss is: 1.3506636993069634\n",
      "Scaled KL Loss is: 0.04689797759056091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3975616768975243\n",
      "NLL Loss is: 1.3540963952870453\n",
      "Scaled KL Loss is: 0.04978528246283531\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4038816777498806\n",
      "NLL Loss is: 1.2921952519913618\n",
      "Scaled KL Loss is: 0.04699608311057091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3391913351019327\n",
      "NLL Loss is: 1.2478812393396286\n",
      "Scaled KL Loss is: 0.05089269578456879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2987739351241974\n",
      "NLL Loss is: 1.2279682640864604\n",
      "Scaled KL Loss is: 0.047153715044260025\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2751219791307205\n",
      "NLL Loss is: 1.4054650556293529\n",
      "Scaled KL Loss is: 0.04837659373879433\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4538416493681472\n",
      "NLL Loss is: 1.2851610735786636\n",
      "Scaled KL Loss is: 0.04553007334470749\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.330691146923371\n",
      "NLL Loss is: 1.2734258941553458\n",
      "Scaled KL Loss is: 0.051787957549095154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.325213851704441\n",
      "NLL Loss is: 1.2962371854659636\n",
      "Scaled KL Loss is: 0.04937790334224701\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3456150888082106\n",
      "NLL Loss is: 1.3721753875392317\n",
      "Scaled KL Loss is: 0.047512345016002655\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4196877325552344\n",
      "NLL Loss is: 1.2394567595726305\n",
      "Scaled KL Loss is: 0.044396355748176575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.283853115320807\n",
      "NLL Loss is: 1.36779833637911\n",
      "Scaled KL Loss is: 0.045192454010248184\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4129907903893582\n",
      "NLL Loss is: 1.3644043082027795\n",
      "Scaled KL Loss is: 0.04699689894914627\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4114012071519257\n",
      "NLL Loss is: 1.3232768478568675\n",
      "Scaled KL Loss is: 0.04687166213989258\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37014850999676\n",
      "NLL Loss is: 1.2167566098752416\n",
      "Scaled KL Loss is: 0.045662522315979004\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2624191321912206\n",
      "NLL Loss is: 1.306190798545903\n",
      "Scaled KL Loss is: 0.046178240329027176\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35236903887493\n",
      "NLL Loss is: 1.1673952589533547\n",
      "Scaled KL Loss is: 0.04987870156764984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2172739605210046\n",
      "NLL Loss is: 1.3233219609151643\n",
      "Scaled KL Loss is: 0.04320819303393364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.366530153949098\n",
      "NLL Loss is: 1.1790927312854018\n",
      "Scaled KL Loss is: 0.04966409131884575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2287568226042476\n",
      "NLL Loss is: 1.2906048525162885\n",
      "Scaled KL Loss is: 0.04790562391281128\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3385104764290998\n",
      "NLL Loss is: 1.3791955119607793\n",
      "Scaled KL Loss is: 0.0457695908844471\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4249651028452264\n",
      "NLL Loss is: 1.3122407037919857\n",
      "Scaled KL Loss is: 0.044182632118463516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3564233359104492\n",
      "NLL Loss is: 1.2308737496576037\n",
      "Scaled KL Loss is: 0.049020782113075256\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.279894531770679\n",
      "NLL Loss is: 1.2023974777812552\n",
      "Scaled KL Loss is: 0.04637341946363449\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2487708972448897\n",
      "NLL Loss is: 1.4034878709596226\n",
      "Scaled KL Loss is: 0.04687396064400673\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4503618316036293\n",
      "NLL Loss is: 1.2392831332127556\n",
      "Scaled KL Loss is: 0.04811796173453331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.287401094947289\n",
      "NLL Loss is: 1.6641678630848635\n",
      "Scaled KL Loss is: 0.0381011888384819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7022690519233454\n",
      "NLL Loss is: 1.307437057261532 = 1.315; test loss = 1.356\n",
      "Scaled KL Loss is: 0.04881088808178902\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.356247945343321\n",
      "NLL Loss is: 1.2987989428056719\n",
      "Scaled KL Loss is: 0.046643465757369995\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3454424085630419\n",
      "NLL Loss is: 1.317348018866698\n",
      "Scaled KL Loss is: 0.04816213622689247\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3655101550935904\n",
      "NLL Loss is: 1.352258285863251\n",
      "Scaled KL Loss is: 0.04894934594631195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.401207631809563\n",
      "NLL Loss is: 1.2974094487619063\n",
      "Scaled KL Loss is: 0.04377397894859314\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3411834277104995\n",
      "NLL Loss is: 1.3312504870842887\n",
      "Scaled KL Loss is: 0.04931614175438881\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3805666288386775\n",
      "NLL Loss is: 1.3521913694859378\n",
      "Scaled KL Loss is: 0.045006588101387024\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3971979575873248\n",
      "NLL Loss is: 1.2925803817874024\n",
      "Scaled KL Loss is: 0.04517216235399246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3377525441413949\n",
      "NLL Loss is: 1.363569004825158\n",
      "Scaled KL Loss is: 0.04334710165858269\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4069161064837408\n",
      "NLL Loss is: 1.2179111761700776\n",
      "Scaled KL Loss is: 0.0498676560819149\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2677788322519925\n",
      "NLL Loss is: 1.2251360972372733\n",
      "Scaled KL Loss is: 0.0430995374917984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2682356347290717\n",
      "NLL Loss is: 1.37335855917\n",
      "Scaled KL Loss is: 0.047046683728694916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4204052428986949\n",
      "NLL Loss is: 1.20462256595117\n",
      "Scaled KL Loss is: 0.05031891539692879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2549414813480988\n",
      "NLL Loss is: 1.397490395619912\n",
      "Scaled KL Loss is: 0.047513868659734726\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4450042642796468\n",
      "NLL Loss is: 1.2101817510681367\n",
      "Scaled KL Loss is: 0.04732101410627365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2575027651744104\n",
      "NLL Loss is: 1.3866919855959134\n",
      "Scaled KL Loss is: 0.051625579595565796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4383175651914792\n",
      "NLL Loss is: 1.3067489878054124\n",
      "Scaled KL Loss is: 0.048079438507556915\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3548284263129693\n",
      "NLL Loss is: 1.2705062860365353\n",
      "Scaled KL Loss is: 0.047533802688121796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.318040088724657\n",
      "NLL Loss is: 1.1930834702981905\n",
      "Scaled KL Loss is: 0.04801639914512634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2410998694433168\n",
      "NLL Loss is: 1.2959872261017966\n",
      "Scaled KL Loss is: 0.046117108315229416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.342104334417026\n",
      "NLL Loss is: 1.2233551510816687\n",
      "Scaled KL Loss is: 0.045773934572935104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2691290856546038\n",
      "NLL Loss is: 1.2989201387796556\n",
      "Scaled KL Loss is: 0.04679615795612335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.345716296735779\n",
      "NLL Loss is: 1.2075069142038184\n",
      "Scaled KL Loss is: 0.04736526682972908\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2548721810335475\n",
      "NLL Loss is: 1.5449821828344854\n",
      "Scaled KL Loss is: 0.04922979697585106\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5942119798103365\n",
      "NLL Loss is: 1.1141053025581462\n",
      "Scaled KL Loss is: 0.04704507812857628\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1611503806867225\n",
      "NLL Loss is: 1.2519431399701915\n",
      "Scaled KL Loss is: 0.05038507282733917\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3023282127975306\n",
      "NLL Loss is: 1.3019316654771673\n",
      "Scaled KL Loss is: 0.052589092403650284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3545207578808176\n",
      "NLL Loss is: 1.0872883390606936\n",
      "Scaled KL Loss is: 0.05010354891419411\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1373918879748877\n",
      "NLL Loss is: 1.243602839510012\n",
      "Scaled KL Loss is: 0.048568133264780045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.292170972774792\n",
      "NLL Loss is: 1.0729277524600827\n",
      "Scaled KL Loss is: 0.04941121116280556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1223389636228882\n",
      "NLL Loss is: 1.1377977011618312\n",
      "Scaled KL Loss is: 0.04436476156115532\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1821624627229865\n",
      "NLL Loss is: 1.2980491059846866\n",
      "Scaled KL Loss is: 0.04808639734983444\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.346135503334521\n",
      "NLL Loss is: 1.312812652828075\n",
      "Scaled KL Loss is: 0.04577285051345825\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3585855033415333\n",
      "NLL Loss is: 1.2197916581198192\n",
      "Scaled KL Loss is: 0.046106647700071335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2658983058198905\n",
      "NLL Loss is: 1.401114620378425\n",
      "Scaled KL Loss is: 0.04685935750603676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4479739778844618\n",
      "NLL Loss is: 1.3844377699062276\n",
      "Scaled KL Loss is: 0.046350400894880295\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4307881708011079\n",
      "NLL Loss is: 1.2168070310689207\n",
      "Scaled KL Loss is: 0.05203353241086006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2688405634797808\n",
      "NLL Loss is: 1.1952671918424271\n",
      "Scaled KL Loss is: 0.0507245808839798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.245991772726407\n",
      "NLL Loss is: 1.3038893546565753\n",
      "Scaled KL Loss is: 0.04873155802488327\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3526209126814586\n",
      "NLL Loss is: 1.420997873458781\n",
      "Scaled KL Loss is: 0.04827592894434929\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4692738024031302\n",
      "NLL Loss is: 1.1422490353192791\n",
      "Scaled KL Loss is: 0.04961295798420906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1918619933034882\n",
      "NLL Loss is: 1.1498769813758218\n",
      "Scaled KL Loss is: 0.044763077050447464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1946400584262693\n",
      "NLL Loss is: 1.1881955569298523\n",
      "Scaled KL Loss is: 0.050775445997714996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2389710029275673\n",
      "NLL Loss is: 1.1968592437611618\n",
      "Scaled KL Loss is: 0.054337892681360245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.251197136442522\n",
      "NLL Loss is: 1.2657515940244322\n",
      "Scaled KL Loss is: 0.04544377326965332\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3111953672940855\n",
      "NLL Loss is: 1.197378875019674\n",
      "Scaled KL Loss is: 0.05060455575585365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2479834307755278\n",
      "NLL Loss is: 1.2341709168700838\n",
      "Scaled KL Loss is: 0.0506058968603611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.284776813730445\n",
      "NLL Loss is: 1.130982499623427\n",
      "Scaled KL Loss is: 0.05416111648082733\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1851436161042543\n",
      "NLL Loss is: 1.2381467755477655\n",
      "Scaled KL Loss is: 0.049736179411411285\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2878829549591768\n",
      "NLL Loss is: 1.153706392909223\n",
      "Scaled KL Loss is: 0.04983382672071457\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2035402196299376\n",
      "NLL Loss is: 1.2489908984660372\n",
      "Scaled KL Loss is: 0.05053939297795296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2995302914439901\n",
      "NLL Loss is: 1.2745506344576638\n",
      "Scaled KL Loss is: 0.04651028662919998\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3210609210868638\n",
      "NLL Loss is: 1.179054368290635\n",
      "Scaled KL Loss is: 0.050133153796195984\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.229187522086831\n",
      "NLL Loss is: 1.2864037127580554\n",
      "Scaled KL Loss is: 0.04793674871325493\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3343404614713104\n",
      "NLL Loss is: 1.3634705659970452\n",
      "Scaled KL Loss is: 0.04608152434229851\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4095520903393437\n",
      "NLL Loss is: 1.338481063808851\n",
      "Scaled KL Loss is: 0.04562493786215782\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3841060016710087\n",
      "NLL Loss is: 1.3624569355866278\n",
      "Scaled KL Loss is: 0.04940091073513031\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4118578463217581\n",
      "NLL Loss is: 1.2276128820317171\n",
      "Scaled KL Loss is: 0.04727569967508316\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2748885817068003\n",
      "NLL Loss is: 1.1835824501773322\n",
      "Scaled KL Loss is: 0.045893993228673935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2294764434060061\n",
      "NLL Loss is: 1.1350048977306977\n",
      "Scaled KL Loss is: 0.05051326006650925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.185518157797207\n",
      "NLL Loss is: 1.2350548994066033\n",
      "Scaled KL Loss is: 0.04947071149945259\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2845256109060559\n",
      "NLL Loss is: 1.2444585268134416\n",
      "Scaled KL Loss is: 0.048240598291158676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2926991251046003\n",
      "NLL Loss is: 1.3246187852408928\n",
      "Scaled KL Loss is: 0.04765066131949425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.372269446560387\n",
      "NLL Loss is: 1.2565083980731364\n",
      "Scaled KL Loss is: 0.049597129225730896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3061055272988673\n",
      "NLL Loss is: 1.2311186633094742\n",
      "Scaled KL Loss is: 0.045588169246912\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2767068325563862\n",
      "NLL Loss is: 1.3501420543295473\n",
      "Scaled KL Loss is: 0.046940311789512634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.39708236611906\n",
      "NLL Loss is: 1.353076919726695\n",
      "Scaled KL Loss is: 0.04986894503235817\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4029458647590531\n",
      "NLL Loss is: 1.2913513219943598\n",
      "Scaled KL Loss is: 0.04702047258615494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3383717945805147\n",
      "NLL Loss is: 1.2469339526317145\n",
      "Scaled KL Loss is: 0.050915997475385666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2978499501071001\n",
      "NLL Loss is: 1.226831842746813\n",
      "Scaled KL Loss is: 0.0471852570772171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.27401709982403\n",
      "NLL Loss is: 1.4044545832942714\n",
      "Scaled KL Loss is: 0.04841384291648865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.45286842621076\n",
      "NLL Loss is: 1.2841270432042584\n",
      "Scaled KL Loss is: 0.04556925594806671\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3296962991523251\n",
      "NLL Loss is: 1.2729014276558073\n",
      "Scaled KL Loss is: 0.05182381346821785\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3247252411240251\n",
      "NLL Loss is: 1.2953706716507758\n",
      "Scaled KL Loss is: 0.04941921308636665\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3447898847371424\n",
      "NLL Loss is: 1.3714723587359041\n",
      "Scaled KL Loss is: 0.04754312336444855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4190154821003527\n",
      "NLL Loss is: 1.2387330064250561\n",
      "Scaled KL Loss is: 0.04442763701081276\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2831606434358689\n",
      "NLL Loss is: 1.3673858101066503\n",
      "Scaled KL Loss is: 0.04519575089216232\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4125815609988126\n",
      "NLL Loss is: 1.3636373183255115\n",
      "Scaled KL Loss is: 0.0470404326915741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4106777510170856\n",
      "NLL Loss is: 1.3232190581661245\n",
      "Scaled KL Loss is: 0.046860694885253906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3700797530513784\n",
      "NLL Loss is: 1.2160208206324805\n",
      "Scaled KL Loss is: 0.045688431710004807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2617092523424853\n",
      "NLL Loss is: 1.3056016558388068\n",
      "Scaled KL Loss is: 0.046198103576898575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3517997594157054\n",
      "NLL Loss is: 1.1662655645635422\n",
      "Scaled KL Loss is: 0.04992062598466873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.216186190548211\n",
      "NLL Loss is: 1.322889372134003\n",
      "Scaled KL Loss is: 0.04321052134037018\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.366099893474373\n",
      "NLL Loss is: 1.1786621520694143\n",
      "Scaled KL Loss is: 0.049696341156959534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2283584932263738\n",
      "NLL Loss is: 1.2898242367863222\n",
      "Scaled KL Loss is: 0.04790348932147026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3377277261077924\n",
      "NLL Loss is: 1.3782497310636546\n",
      "Scaled KL Loss is: 0.04578306898474693\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4240328000484015\n",
      "NLL Loss is: 1.3116589331691053\n",
      "Scaled KL Loss is: 0.04421260207891464\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35587153524802\n",
      "NLL Loss is: 1.229826008451744\n",
      "Scaled KL Loss is: 0.049027442932128906\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.278853451383873\n",
      "NLL Loss is: 1.2015839813271478\n",
      "Scaled KL Loss is: 0.046426285058259964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2480102663854078\n",
      "NLL Loss is: 1.4028160223297965\n",
      "Scaled KL Loss is: 0.04690065234899521\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4497166746787917\n",
      "NLL Loss is: 1.238703369506373\n",
      "Scaled KL Loss is: 0.04815037176012993\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2868537412665029\n",
      "NLL Loss is: 1.6641228099243641\n",
      "Scaled KL Loss is: 0.03808894380927086\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702211753733635\n",
      "NLL Loss is: 1.3069256205758188= 1.315; test loss = 1.355\n",
      "Scaled KL Loss is: 0.048823073506355286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3557486940821741\n",
      "NLL Loss is: 1.298011369683083\n",
      "Scaled KL Loss is: 0.04668721184134483\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.344698581524428\n",
      "NLL Loss is: 1.3164633311836205\n",
      "Scaled KL Loss is: 0.04817675054073334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3646400817243538\n",
      "NLL Loss is: 1.3517510466947527\n",
      "Scaled KL Loss is: 0.04891173914074898\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4006627858355016\n",
      "NLL Loss is: 1.2963216034961207\n",
      "Scaled KL Loss is: 0.04378603771328926\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34010764120941\n",
      "NLL Loss is: 1.3306219912332151\n",
      "Scaled KL Loss is: 0.04933658987283707\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3799585811060522\n",
      "NLL Loss is: 1.3511213222344125\n",
      "Scaled KL Loss is: 0.04507672041654587\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3961980426509584\n",
      "NLL Loss is: 1.291487117498431\n",
      "Scaled KL Loss is: 0.04521014168858528\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3366972591870163\n",
      "NLL Loss is: 1.362910094060232\n",
      "Scaled KL Loss is: 0.04335761442780495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4062677084880368\n",
      "NLL Loss is: 1.2171111234590049\n",
      "Scaled KL Loss is: 0.04985661804676056\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2669677415057654\n",
      "NLL Loss is: 1.2239410268151607\n",
      "Scaled KL Loss is: 0.04307326674461365\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2670142935597744\n",
      "NLL Loss is: 1.3724361768954565\n",
      "Scaled KL Loss is: 0.047063324600458145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4194995014959146\n",
      "NLL Loss is: 1.2040711326456406\n",
      "Scaled KL Loss is: 0.0503106527030468\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2543817853486874\n",
      "NLL Loss is: 1.3966126471744342\n",
      "Scaled KL Loss is: 0.04749700427055359\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4441096514449878\n",
      "NLL Loss is: 1.2093381527385552\n",
      "Scaled KL Loss is: 0.0473557747900486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2566939275286038\n",
      "NLL Loss is: 1.3857569487223929\n",
      "Scaled KL Loss is: 0.05165876820683479\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4374157169292276\n",
      "NLL Loss is: 1.305874553277502\n",
      "Scaled KL Loss is: 0.04812270402908325\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3539972573065853\n",
      "NLL Loss is: 1.2696481109392481\n",
      "Scaled KL Loss is: 0.047541216015815735\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3171893269550639\n",
      "NLL Loss is: 1.1922260770087036\n",
      "Scaled KL Loss is: 0.04803486540913582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2402609424178395\n",
      "NLL Loss is: 1.2949041957359493\n",
      "Scaled KL Loss is: 0.04614674299955368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.341050938735503\n",
      "NLL Loss is: 1.2224437058480173\n",
      "Scaled KL Loss is: 0.04577645659446716\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2682201624424845\n",
      "NLL Loss is: 1.297724143206212\n",
      "Scaled KL Loss is: 0.046858351677656174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3445824948838683\n",
      "NLL Loss is: 1.2063970989322756\n",
      "Scaled KL Loss is: 0.04742180183529854\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2538189007675742\n",
      "NLL Loss is: 1.5441697585104164\n",
      "Scaled KL Loss is: 0.04923444986343384\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5934042083738502\n",
      "NLL Loss is: 1.1133856781549927\n",
      "Scaled KL Loss is: 0.047065362334251404\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.160451040489244\n",
      "NLL Loss is: 1.2511725686227333\n",
      "Scaled KL Loss is: 0.05038191378116608\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3015544824038994\n",
      "NLL Loss is: 1.301097076163901\n",
      "Scaled KL Loss is: 0.05261794477701187\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3537150209409128\n",
      "NLL Loss is: 1.0864467406847365\n",
      "Scaled KL Loss is: 0.050122663378715515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.136569404063452\n",
      "NLL Loss is: 1.2426641994900924\n",
      "Scaled KL Loss is: 0.048582471907138824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2912466713972313\n",
      "NLL Loss is: 1.0717154151542108\n",
      "Scaled KL Loss is: 0.0494488887488842\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.121164303903095\n",
      "NLL Loss is: 1.1372404597027637\n",
      "Scaled KL Loss is: 0.04438348487019539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.181623944572959\n",
      "NLL Loss is: 1.2972818922371394\n",
      "Scaled KL Loss is: 0.04811200872063637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3453939009577758\n",
      "NLL Loss is: 1.3121739916270618\n",
      "Scaled KL Loss is: 0.04580305516719818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.35797704679426\n",
      "NLL Loss is: 1.2192532905173727\n",
      "Scaled KL Loss is: 0.04612410068511963\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2653773912024924\n",
      "NLL Loss is: 1.4006416802279313\n",
      "Scaled KL Loss is: 0.04687320068478584\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4475148809127172\n",
      "NLL Loss is: 1.3831315645348152\n",
      "Scaled KL Loss is: 0.046367887407541275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4294994519423565\n",
      "NLL Loss is: 1.216194279544841\n",
      "Scaled KL Loss is: 0.05200265347957611\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2681969330244172\n",
      "NLL Loss is: 1.194988026423201\n",
      "Scaled KL Loss is: 0.050765808671712875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2457538350949138\n",
      "NLL Loss is: 1.3034040563189393\n",
      "Scaled KL Loss is: 0.04877813532948494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3521821916484242\n",
      "NLL Loss is: 1.4201524098219218\n",
      "Scaled KL Loss is: 0.04828793928027153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4684403491021933\n",
      "NLL Loss is: 1.1412825229599541\n",
      "Scaled KL Loss is: 0.049660664051771164\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1909431870117253\n",
      "NLL Loss is: 1.1490388524830677\n",
      "Scaled KL Loss is: 0.04480907320976257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1938479256928303\n",
      "NLL Loss is: 1.187354747477648\n",
      "Scaled KL Loss is: 0.05085775628685951\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2382125037645075\n",
      "NLL Loss is: 1.1963113844674056\n",
      "Scaled KL Loss is: 0.05434389412403107\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2506552785914367\n",
      "NLL Loss is: 1.2648748355397605\n",
      "Scaled KL Loss is: 0.04545673355460167\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3103315690943622\n",
      "NLL Loss is: 1.1967166177423767\n",
      "Scaled KL Loss is: 0.05064784735441208\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2473644650967888\n",
      "NLL Loss is: 1.2338338717919715\n",
      "Scaled KL Loss is: 0.0506085604429245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.284442432234896\n",
      "NLL Loss is: 1.1302392473090275\n",
      "Scaled KL Loss is: 0.05423594266176224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1844751899707897\n",
      "NLL Loss is: 1.2377505234173578\n",
      "Scaled KL Loss is: 0.049734629690647125\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.287485153108005\n",
      "NLL Loss is: 1.1529299266296729\n",
      "Scaled KL Loss is: 0.04988326132297516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.202813187952648\n",
      "NLL Loss is: 1.248483799728567\n",
      "Scaled KL Loss is: 0.05057751387357712\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.299061313602144\n",
      "NLL Loss is: 1.2738225550484936\n",
      "Scaled KL Loss is: 0.046521976590156555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3203445316386502\n",
      "NLL Loss is: 1.17822353536627\n",
      "Scaled KL Loss is: 0.050165943801403046\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.228389479167673\n",
      "NLL Loss is: 1.2855263381069693\n",
      "Scaled KL Loss is: 0.04801454022526741\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3335408783322367\n",
      "NLL Loss is: 1.3629424435928061\n",
      "Scaled KL Loss is: 0.04609399288892746\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4090364364817336\n",
      "NLL Loss is: 1.3374025867540735\n",
      "Scaled KL Loss is: 0.04566720500588417\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3830697917599577\n",
      "NLL Loss is: 1.3618299558554268\n",
      "Scaled KL Loss is: 0.049419548362493515\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4112495042179203\n",
      "NLL Loss is: 1.2273285621376835\n",
      "Scaled KL Loss is: 0.0473010390996933\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2746296012373768\n",
      "NLL Loss is: 1.1824700027920059\n",
      "Scaled KL Loss is: 0.045943547040224075\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.22841354983223\n",
      "NLL Loss is: 1.1342351324255597\n",
      "Scaled KL Loss is: 0.050542086362838745\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1847772187883985\n",
      "NLL Loss is: 1.2345018548001543\n",
      "Scaled KL Loss is: 0.04952152073383331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840233755339876\n",
      "NLL Loss is: 1.2434578935778802\n",
      "Scaled KL Loss is: 0.04828300699591637\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2917409005737965\n",
      "NLL Loss is: 1.3233800709133956\n",
      "Scaled KL Loss is: 0.04768804460763931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.371068115521035\n",
      "NLL Loss is: 1.255980773920997\n",
      "Scaled KL Loss is: 0.04967901110649109\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.305659785027488\n",
      "NLL Loss is: 1.2301269717796455\n",
      "Scaled KL Loss is: 0.045626815408468246\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2757537871881137\n",
      "NLL Loss is: 1.349652513812269\n",
      "Scaled KL Loss is: 0.046978458762168884\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.396630972574438\n",
      "NLL Loss is: 1.3520242918953957\n",
      "Scaled KL Loss is: 0.049947697669267654\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4019719895646634\n",
      "NLL Loss is: 1.2905194363751382\n",
      "Scaled KL Loss is: 0.047046829015016556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3375662653901548\n",
      "NLL Loss is: 1.2459933877302327\n",
      "Scaled KL Loss is: 0.050944093614816666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2969374813450494\n",
      "NLL Loss is: 1.2257284715557273\n",
      "Scaled KL Loss is: 0.04722447693347931\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2729529484892066\n",
      "NLL Loss is: 1.4034844176969432\n",
      "Scaled KL Loss is: 0.04845813661813736\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4519425543150806\n",
      "NLL Loss is: 1.283117418288529\n",
      "Scaled KL Loss is: 0.04561870917677879\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3287361274653078\n",
      "NLL Loss is: 1.2722734944867873\n",
      "Scaled KL Loss is: 0.051878273487091064\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3241517679738783\n",
      "NLL Loss is: 1.2945718807221447\n",
      "Scaled KL Loss is: 0.04947488382458687\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3440467645467316\n",
      "NLL Loss is: 1.3706290794842857\n",
      "Scaled KL Loss is: 0.04758915305137634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418218232535662\n",
      "NLL Loss is: 1.2380057972546836\n",
      "Scaled KL Loss is: 0.04447396472096443\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.282479761975648\n",
      "NLL Loss is: 1.366897194573855\n",
      "Scaled KL Loss is: 0.04522009193897247\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4121172865128275\n",
      "NLL Loss is: 1.3628102519031933\n",
      "Scaled KL Loss is: 0.047091759741306305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4099020116444996\n",
      "NLL Loss is: 1.3232109311546199\n",
      "Scaled KL Loss is: 0.04687439277768135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3700853239323012\n",
      "NLL Loss is: 1.2152311357275571\n",
      "Scaled KL Loss is: 0.045730460435152054\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2609615961627092\n",
      "NLL Loss is: 1.3049791474625325\n",
      "Scaled KL Loss is: 0.046233464032411575\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.351212611494944\n",
      "NLL Loss is: 1.1650528448462447\n",
      "Scaled KL Loss is: 0.04997880756855011\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2150316524147948\n",
      "NLL Loss is: 1.3224761002839938\n",
      "Scaled KL Loss is: 0.043231263756752014\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3657073640407458\n",
      "NLL Loss is: 1.1780496192269938\n",
      "Scaled KL Loss is: 0.049747027456760406\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2277966466837542\n",
      "NLL Loss is: 1.2889550243972696\n",
      "Scaled KL Loss is: 0.04792352393269539\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.336878548329965\n",
      "NLL Loss is: 1.3772689659784556\n",
      "Scaled KL Loss is: 0.04580503702163696\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4230740030000926\n",
      "NLL Loss is: 1.3110910890787681\n",
      "Scaled KL Loss is: 0.04425955191254616\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3553506409913143\n",
      "NLL Loss is: 1.2287097826977422\n",
      "Scaled KL Loss is: 0.04905406013131142\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2777638428290536\n",
      "NLL Loss is: 1.2007744298831904\n",
      "Scaled KL Loss is: 0.04649007320404053\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.247264503087231\n",
      "NLL Loss is: 1.4022390186855558\n",
      "Scaled KL Loss is: 0.046937912702560425\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4491769313881162\n",
      "NLL Loss is: 1.2380272454233543\n",
      "Scaled KL Loss is: 0.048193950206041336\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2862211956293956\n",
      "NLL Loss is: 1.6641822518742029\n",
      "Scaled KL Loss is: 0.03808893263339996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7022711845076028\n",
      "NLL Loss is: 1.306431446652259 = 1.314; test loss = 1.355\n",
      "Scaled KL Loss is: 0.0488535575568676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3552850042091267\n",
      "NLL Loss is: 1.2971731820685861\n",
      "Scaled KL Loss is: 0.04675408825278282\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.343927270321369\n",
      "NLL Loss is: 1.315549552177826\n",
      "Scaled KL Loss is: 0.048216335475444794\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3637658876532708\n",
      "NLL Loss is: 1.3511436842043691\n",
      "Scaled KL Loss is: 0.04891609027981758\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4000597744841867\n",
      "NLL Loss is: 1.2952927882796832\n",
      "Scaled KL Loss is: 0.04382403567433357\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3391168239540168\n",
      "NLL Loss is: 1.3297475938184868\n",
      "Scaled KL Loss is: 0.04939431697130203\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3791419107897889\n",
      "NLL Loss is: 1.3502018868216186\n",
      "Scaled KL Loss is: 0.04517674818634987\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3953786350079684\n",
      "NLL Loss is: 1.2905057899641605\n",
      "Scaled KL Loss is: 0.04529280588030815\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3357985958444687\n",
      "NLL Loss is: 1.362339441056844\n",
      "Scaled KL Loss is: 0.04340347275137901\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405742913808223\n",
      "NLL Loss is: 1.2163035258693202\n",
      "Scaled KL Loss is: 0.04988984018564224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2661933660549625\n",
      "NLL Loss is: 1.2228885312143911\n",
      "Scaled KL Loss is: 0.04310022294521332\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2659887541596044\n",
      "NLL Loss is: 1.3716446457369145\n",
      "Scaled KL Loss is: 0.04711594060063362\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.418760586337548\n",
      "NLL Loss is: 1.203463088862503\n",
      "Scaled KL Loss is: 0.05033766105771065\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2538007499202137\n",
      "NLL Loss is: 1.3956217021550348\n",
      "Scaled KL Loss is: 0.04752415046095848\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4431458526159933\n",
      "NLL Loss is: 1.2085297226257226\n",
      "Scaled KL Loss is: 0.047430574893951416\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.255960297519674\n",
      "NLL Loss is: 1.3848142213738455\n",
      "Scaled KL Loss is: 0.051721733063459396\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4365359544373049\n",
      "NLL Loss is: 1.3049404087842524\n",
      "Scaled KL Loss is: 0.04819262772798538\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3531330365122378\n",
      "NLL Loss is: 1.2687338399770893\n",
      "Scaled KL Loss is: 0.04758380725979805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3163176472368874\n",
      "NLL Loss is: 1.1912348324082698\n",
      "Scaled KL Loss is: 0.048084013164043427\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2393188455723132\n",
      "NLL Loss is: 1.2937867234741538\n",
      "Scaled KL Loss is: 0.04620467498898506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3399913984631389\n",
      "NLL Loss is: 1.221514168546627\n",
      "Scaled KL Loss is: 0.04581969976425171\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2673338683108788\n",
      "NLL Loss is: 1.2965733686335839\n",
      "Scaled KL Loss is: 0.04694634675979614\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.34351971539338\n",
      "NLL Loss is: 1.2052352059374232\n",
      "Scaled KL Loss is: 0.04750458151102066\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2527397874484438\n",
      "NLL Loss is: 1.5432920683477351\n",
      "Scaled KL Loss is: 0.049273762851953506\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5925658311996886\n",
      "NLL Loss is: 1.1125827262594505\n",
      "Scaled KL Loss is: 0.047116298228502274\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1596990244879528\n",
      "NLL Loss is: 1.250401592357111\n",
      "Scaled KL Loss is: 0.050405681133270264\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3008072734903813\n",
      "NLL Loss is: 1.3002736968630648\n",
      "Scaled KL Loss is: 0.052671097218990326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3529447940820551\n",
      "NLL Loss is: 1.085658492993902\n",
      "Scaled KL Loss is: 0.05016205087304115\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.135820543866943\n",
      "NLL Loss is: 1.241726376112852\n",
      "Scaled KL Loss is: 0.048621729016304016\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.290348105129156\n",
      "NLL Loss is: 1.0704928576024721\n",
      "Scaled KL Loss is: 0.04951182380318642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1200046814056586\n",
      "NLL Loss is: 1.136661964877524\n",
      "Scaled KL Loss is: 0.04442935064435005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.181091315521874\n",
      "NLL Loss is: 1.2965299375874735\n",
      "Scaled KL Loss is: 0.04816498979926109\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3446949273867346\n",
      "NLL Loss is: 1.3115660005990264\n",
      "Scaled KL Loss is: 0.04586264118552208\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3574286417845485\n",
      "NLL Loss is: 1.2187297034093034\n",
      "Scaled KL Loss is: 0.0461694709956646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.264899174404968\n",
      "NLL Loss is: 1.4002205341456917\n",
      "Scaled KL Loss is: 0.046912651509046555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4471331856547383\n",
      "NLL Loss is: 1.3818296903862757\n",
      "Scaled KL Loss is: 0.04641351476311684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4282432051493925\n",
      "NLL Loss is: 1.2156076910211915\n",
      "Scaled KL Loss is: 0.05200174078345299\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2676094318046445\n",
      "NLL Loss is: 1.194612066559966\n",
      "Scaled KL Loss is: 0.05083078145980835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2454428480197743\n",
      "NLL Loss is: 1.3028858642367727\n",
      "Scaled KL Loss is: 0.04885068163275719\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3517365458695298\n",
      "NLL Loss is: 1.419334947607125\n",
      "Scaled KL Loss is: 0.048328422009944916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.46766336961707\n",
      "NLL Loss is: 1.1403666382885513\n",
      "Scaled KL Loss is: 0.049735017120838165\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1901016554093895\n",
      "NLL Loss is: 1.1481943166524244\n",
      "Scaled KL Loss is: 0.04487951099872589\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1930738276511503\n",
      "NLL Loss is: 1.186504688450462\n",
      "Scaled KL Loss is: 0.05096103623509407\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237465724685556\n",
      "NLL Loss is: 1.195786338100557\n",
      "Scaled KL Loss is: 0.05437968671321869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2501660248137756\n",
      "NLL Loss is: 1.2640289475086497\n",
      "Scaled KL Loss is: 0.04549631103873253\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3095252585473822\n",
      "NLL Loss is: 1.1960074226963056\n",
      "Scaled KL Loss is: 0.05071672424674034\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.246724146943046\n",
      "NLL Loss is: 1.233436350510373\n",
      "Scaled KL Loss is: 0.050636742264032364\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2840730927744053\n",
      "NLL Loss is: 1.1295012460961122\n",
      "Scaled KL Loss is: 0.05433119088411331\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1838324369802256\n",
      "NLL Loss is: 1.2373182836862373\n",
      "Scaled KL Loss is: 0.0497586727142334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2870769564004707\n",
      "NLL Loss is: 1.1521229301939817\n",
      "Scaled KL Loss is: 0.049956463277339935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2020793934713216\n",
      "NLL Loss is: 1.247897424488599\n",
      "Scaled KL Loss is: 0.0506395548582077\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2985369793468067\n",
      "NLL Loss is: 1.2730823192059946\n",
      "Scaled KL Loss is: 0.04656004160642624\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3196423608124208\n",
      "NLL Loss is: 1.17735312589957\n",
      "Scaled KL Loss is: 0.050226859748363495\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2275799856479335\n",
      "NLL Loss is: 1.2846494916524653\n",
      "Scaled KL Loss is: 0.048113156110048294\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3327626477625136\n",
      "NLL Loss is: 1.362383849967463\n",
      "Scaled KL Loss is: 0.04612661898136139\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4085104689488244\n",
      "NLL Loss is: 1.336322136633021\n",
      "Scaled KL Loss is: 0.04572991281747818\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.382052049450499\n",
      "NLL Loss is: 1.3611983079436718\n",
      "Scaled KL Loss is: 0.04945829138159752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4106565993252693\n",
      "NLL Loss is: 1.2269676455985914\n",
      "Scaled KL Loss is: 0.047347839921712875\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2743154855203043\n",
      "NLL Loss is: 1.181348358107128\n",
      "Scaled KL Loss is: 0.04600748419761658\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2273558423047446\n",
      "NLL Loss is: 1.1334525172034944\n",
      "Scaled KL Loss is: 0.05059026926755905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1840427864710534\n",
      "NLL Loss is: 1.233947024923627\n",
      "Scaled KL Loss is: 0.04958532750606537\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2835323524296924\n",
      "NLL Loss is: 1.2425020804031333\n",
      "Scaled KL Loss is: 0.048338860273361206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2908409406764945\n",
      "NLL Loss is: 1.3221412251140037\n",
      "Scaled KL Loss is: 0.04773734509944916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3698785702134528\n",
      "NLL Loss is: 1.2554376455103329\n",
      "Scaled KL Loss is: 0.04976974427700043\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3052073897873333\n",
      "NLL Loss is: 1.2291451865187142\n",
      "Scaled KL Loss is: 0.045675959438085556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2748211459567997\n",
      "NLL Loss is: 1.3491907912022116\n",
      "Scaled KL Loss is: 0.04702674224972725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3962175334519389\n",
      "NLL Loss is: 1.350972211207999\n",
      "Scaled KL Loss is: 0.0500371977686882\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4010094089766871\n",
      "NLL Loss is: 1.2896686217564863\n",
      "Scaled KL Loss is: 0.04708956927061081\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3367581910270971\n",
      "NLL Loss is: 1.2450647904385947\n",
      "Scaled KL Loss is: 0.05098917707800865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2960539675166034\n",
      "NLL Loss is: 1.2246334407934485\n",
      "Scaled KL Loss is: 0.04728170856833458\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.271915149361783\n",
      "NLL Loss is: 1.4025334027221994\n",
      "Scaled KL Loss is: 0.048519428819417953\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4510528315416173\n",
      "NLL Loss is: 1.2820790262011335\n",
      "Scaled KL Loss is: 0.04568507894873619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3277641051498696\n",
      "NLL Loss is: 1.2715721295487252\n",
      "Scaled KL Loss is: 0.05195509269833565\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3235272222470609\n",
      "NLL Loss is: 1.2938191820267049\n",
      "Scaled KL Loss is: 0.04955136775970459\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3433705497864095\n",
      "NLL Loss is: 1.3697078248181478\n",
      "Scaled KL Loss is: 0.04765363037586212\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.41736145519401\n",
      "NLL Loss is: 1.2372436181464548\n",
      "Scaled KL Loss is: 0.04454047605395317\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.281784094200408\n",
      "NLL Loss is: 1.366368893731486\n",
      "Scaled KL Loss is: 0.04526837542653084\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4116372691580168\n",
      "NLL Loss is: 1.3620833521897793\n",
      "Scaled KL Loss is: 0.047158874571323395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4092422267611027\n",
      "NLL Loss is: 1.3232051710043182\n",
      "Scaled KL Loss is: 0.046915363520383835\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.370120534524702\n",
      "NLL Loss is: 1.2144464006656377\n",
      "Scaled KL Loss is: 0.04579608514904976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2602424858146875\n",
      "NLL Loss is: 1.30430914537514\n",
      "Scaled KL Loss is: 0.04628919064998627\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3505983360251264\n",
      "NLL Loss is: 1.1638441725580428\n",
      "Scaled KL Loss is: 0.05005895346403122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.213903126022074\n",
      "NLL Loss is: 1.3220493089140921\n",
      "Scaled KL Loss is: 0.0432729534804821\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3653222623945742\n",
      "NLL Loss is: 1.1772808498592442\n",
      "Scaled KL Loss is: 0.04982183501124382\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.227102684870488\n",
      "NLL Loss is: 1.288028169474851\n",
      "Scaled KL Loss is: 0.04796670004725456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3359948695221056\n",
      "NLL Loss is: 1.3762507413099379\n",
      "Scaled KL Loss is: 0.04584008455276489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4220908258627027\n",
      "NLL Loss is: 1.3105175588101574\n",
      "Scaled KL Loss is: 0.04432787001132965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.354845428821487\n",
      "NLL Loss is: 1.2275504212766335\n",
      "Scaled KL Loss is: 0.04910397529602051\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.276654396572654\n",
      "NLL Loss is: 1.199940118729963\n",
      "Scaled KL Loss is: 0.04657060652971268\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2465107252596757\n",
      "NLL Loss is: 1.4017033662871288\n",
      "Scaled KL Loss is: 0.04698990285396576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4486932691410945\n",
      "NLL Loss is: 1.2372878208641174\n",
      "Scaled KL Loss is: 0.04825374484062195\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2855415657047393\n",
      "NLL Loss is: 1.6642297224636349\n",
      "Scaled KL Loss is: 0.03810640797019005\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702336130433825\n",
      "NLL Loss is: 1.305972157112645 = 1.313; test loss = 1.354\n",
      "Scaled KL Loss is: 0.04890668764710426\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3548788447597493\n",
      "NLL Loss is: 1.2963004081419223\n",
      "Scaled KL Loss is: 0.04684256389737129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3431429720392936\n",
      "NLL Loss is: 1.3146836045526529\n",
      "Scaled KL Loss is: 0.04827714338898659\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3629607479416395\n",
      "NLL Loss is: 1.350486047421785\n",
      "Scaled KL Loss is: 0.048950109630823135\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3994361570526082\n",
      "NLL Loss is: 1.2943210783506425\n",
      "Scaled KL Loss is: 0.04388014227151871\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3382012206221612\n",
      "NLL Loss is: 1.328772140103871\n",
      "Scaled KL Loss is: 0.049474623054265976\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.378246763158137\n",
      "NLL Loss is: 1.3493343326040779\n",
      "Scaled KL Loss is: 0.04529443010687828\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3946287627109561\n",
      "NLL Loss is: 1.2895276664682127\n",
      "Scaled KL Loss is: 0.04539996385574341\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3349276303239561\n",
      "NLL Loss is: 1.361755816037973\n",
      "Scaled KL Loss is: 0.04346953704953194\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.405225353087505\n",
      "NLL Loss is: 1.2154959826909755\n",
      "Scaled KL Loss is: 0.04994538798928261\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265441370680258\n",
      "NLL Loss is: 1.2219215947133972\n",
      "Scaled KL Loss is: 0.04315346106886864\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2650750557822659\n",
      "NLL Loss is: 1.3709072519014556\n",
      "Scaled KL Loss is: 0.04718613997101784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4180933918724734\n",
      "NLL Loss is: 1.202792896325945\n",
      "Scaled KL Loss is: 0.05038219317793846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2531750895038836\n",
      "NLL Loss is: 1.3946716654119193\n",
      "Scaled KL Loss is: 0.047571491450071335\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4422431568619907\n",
      "NLL Loss is: 1.2077333451261227\n",
      "Scaled KL Loss is: 0.047524385154247284\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.25525773028037\n",
      "NLL Loss is: 1.3839178068985274\n",
      "Scaled KL Loss is: 0.05179488658905029\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4357126934875777\n",
      "NLL Loss is: 1.3039805844414918\n",
      "Scaled KL Loss is: 0.048275403678417206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.352255988119909\n",
      "NLL Loss is: 1.2678592145129253\n",
      "Scaled KL Loss is: 0.04764246940612793\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3155016839190532\n",
      "NLL Loss is: 1.1902689757382405\n",
      "Scaled KL Loss is: 0.048145126551389694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2384141022896302\n",
      "NLL Loss is: 1.292713352125161\n",
      "Scaled KL Loss is: 0.04627012088894844\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3389834730141095\n",
      "NLL Loss is: 1.2205382707474832\n",
      "Scaled KL Loss is: 0.04587947577238083\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.266417746519864\n",
      "NLL Loss is: 1.2954155533944192\n",
      "Scaled KL Loss is: 0.047043900936841965\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3424594543312611\n",
      "NLL Loss is: 1.2040704281547618\n",
      "Scaled KL Loss is: 0.047595586627721786\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2516660147824836\n",
      "NLL Loss is: 1.5424541673613208\n",
      "Scaled KL Loss is: 0.049326881766319275\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.59178104912764\n",
      "NLL Loss is: 1.1117861713565684\n",
      "Scaled KL Loss is: 0.04717785865068436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1589640300072528\n",
      "NLL Loss is: 1.249660956357512\n",
      "Scaled KL Loss is: 0.050440505146980286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3001014615044924\n",
      "NLL Loss is: 1.2994775298101506\n",
      "Scaled KL Loss is: 0.05273463577032089\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3522121655804715\n",
      "NLL Loss is: 1.0849054998928356\n",
      "Scaled KL Loss is: 0.050208680331707\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1351141802245426\n",
      "NLL Loss is: 1.2408199603622263\n",
      "Scaled KL Loss is: 0.048670265823602676\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289490226185829\n",
      "NLL Loss is: 1.0693040481572582\n",
      "Scaled KL Loss is: 0.04957890883088112\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1188829569881393\n",
      "NLL Loss is: 1.1360697649981648\n",
      "Scaled KL Loss is: 0.04447774216532707\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1805475071634919\n",
      "NLL Loss is: 1.2957561146513976\n",
      "Scaled KL Loss is: 0.04821716248989105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3439732771412887\n",
      "NLL Loss is: 1.3109476261134712\n",
      "Scaled KL Loss is: 0.04591738432645798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3568650104399291\n",
      "NLL Loss is: 1.2182949725781416\n",
      "Scaled KL Loss is: 0.046208515763282776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2645034883414243\n",
      "NLL Loss is: 1.399883955736466\n",
      "Scaled KL Loss is: 0.04694417864084244\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4468281343773084\n",
      "NLL Loss is: 1.3805622166554137\n",
      "Scaled KL Loss is: 0.046448130160570145\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4270103468159838\n",
      "NLL Loss is: 1.2149709286756016\n",
      "Scaled KL Loss is: 0.05198327824473381\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2669542069203354\n",
      "NLL Loss is: 1.1942895604516688\n",
      "Scaled KL Loss is: 0.05088204890489578\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2451716093565646\n",
      "NLL Loss is: 1.3024116304971722\n",
      "Scaled KL Loss is: 0.04890785738825798\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3513194878854302\n",
      "NLL Loss is: 1.4185339942878112\n",
      "Scaled KL Loss is: 0.04834815859794617\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4668821528857574\n",
      "NLL Loss is: 1.139546425721898\n",
      "Scaled KL Loss is: 0.04978793114423752\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1893343568661354\n",
      "NLL Loss is: 1.1474732569776607\n",
      "Scaled KL Loss is: 0.044931091368198395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.192404348345859\n",
      "NLL Loss is: 1.1857315888833992\n",
      "Scaled KL Loss is: 0.051047563552856445\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2367791524362557\n",
      "NLL Loss is: 1.1950163959712572\n",
      "Scaled KL Loss is: 0.0543929785490036\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2494093745202608\n",
      "NLL Loss is: 1.263217279275652\n",
      "Scaled KL Loss is: 0.04551295191049576\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3087302311861477\n",
      "NLL Loss is: 1.1954191391072413\n",
      "Scaled KL Loss is: 0.05075853317975998\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2461776722870013\n",
      "NLL Loss is: 1.2330678080370319\n",
      "Scaled KL Loss is: 0.05064023286104202\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2837080408980739\n",
      "NLL Loss is: 1.1287809446642325\n",
      "Scaled KL Loss is: 0.054408248513936996\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1831891931781695\n",
      "NLL Loss is: 1.2369588412792583\n",
      "Scaled KL Loss is: 0.04976095259189606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2867197938711543\n",
      "NLL Loss is: 1.151411035095135\n",
      "Scaled KL Loss is: 0.05000888183712959\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2014199169322646\n",
      "NLL Loss is: 1.2474488658993124\n",
      "Scaled KL Loss is: 0.05068264901638031\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2981315149156927\n",
      "NLL Loss is: 1.2723562681775782\n",
      "Scaled KL Loss is: 0.04657742753624916\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3189336957138273\n",
      "NLL Loss is: 1.1766116179364798\n",
      "Scaled KL Loss is: 0.05027027055621147\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2268818884926913\n",
      "NLL Loss is: 1.2838130683069615\n",
      "Scaled KL Loss is: 0.04819505289196968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3320081211989312\n",
      "NLL Loss is: 1.3619268565004226\n",
      "Scaled KL Loss is: 0.04614277556538582\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4080696320658084\n",
      "NLL Loss is: 1.3352535954601825\n",
      "Scaled KL Loss is: 0.0457758791744709\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3810294746346534\n",
      "NLL Loss is: 1.3605878311168944\n",
      "Scaled KL Loss is: 0.0494808554649353\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4100686865818297\n",
      "NLL Loss is: 1.226708746242129\n",
      "Scaled KL Loss is: 0.047378379851579666\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2740871260937086\n",
      "NLL Loss is: 1.1803028259025565\n",
      "Scaled KL Loss is: 0.046057142317295074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2263599682198516\n",
      "NLL Loss is: 1.132712743909814\n",
      "Scaled KL Loss is: 0.05062360689043999\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.183336350800254\n",
      "NLL Loss is: 1.2334722922865398\n",
      "Scaled KL Loss is: 0.04963529855012894\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2831075908366687\n",
      "NLL Loss is: 1.2415328772129954\n",
      "Scaled KL Loss is: 0.04838291183114052\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289915789044136\n",
      "NLL Loss is: 1.320911577676326\n",
      "Scaled KL Loss is: 0.047777820378541946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.368689398054868\n",
      "NLL Loss is: 1.2549834464976817\n",
      "Scaled KL Loss is: 0.049850448966026306\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.304833895463708\n",
      "NLL Loss is: 1.2282093980867541\n",
      "Scaled KL Loss is: 0.04571816697716713\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2739275650639212\n",
      "NLL Loss is: 1.3486511672467314\n",
      "Scaled KL Loss is: 0.04706603288650513\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3957172001332365\n",
      "NLL Loss is: 1.3499661888306878\n",
      "Scaled KL Loss is: 0.050117116421461105\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4000833052521489\n",
      "NLL Loss is: 1.288904967026775\n",
      "Scaled KL Loss is: 0.0471220538020134\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3360270208287883\n",
      "NLL Loss is: 1.244175662731429\n",
      "Scaled KL Loss is: 0.05102280154824257\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2951984642796717\n",
      "NLL Loss is: 1.2235106685123658\n",
      "Scaled KL Loss is: 0.047327712178230286\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.270838380690596\n",
      "NLL Loss is: 1.4016085524148547\n",
      "Scaled KL Loss is: 0.048569511622190475\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4501780640370452\n",
      "NLL Loss is: 1.281129193443156\n",
      "Scaled KL Loss is: 0.04574020579457283\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3268693992377287\n",
      "NLL Loss is: 1.2709482965166539\n",
      "Scaled KL Loss is: 0.05201863497495651\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3229669314916104\n",
      "NLL Loss is: 1.2930915941030314\n",
      "Scaled KL Loss is: 0.04961545020341873\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3427070443064502\n",
      "NLL Loss is: 1.368826723488216\n",
      "Scaled KL Loss is: 0.047707099467515945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.416533822955732\n",
      "NLL Loss is: 1.2365798368183074\n",
      "Scaled KL Loss is: 0.04459637030959129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2811762071278987\n",
      "NLL Loss is: 1.3658783824673577\n",
      "Scaled KL Loss is: 0.045306358486413956\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4111847409537717\n",
      "NLL Loss is: 1.3612406401734822\n",
      "Scaled KL Loss is: 0.04721338301897049\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4084540231924527\n",
      "NLL Loss is: 1.3232589103967962\n",
      "Scaled KL Loss is: 0.04694472253322601\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702036329300222\n",
      "NLL Loss is: 1.2136426524029078\n",
      "Scaled KL Loss is: 0.0458495169878006\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2594921693907084\n",
      "NLL Loss is: 1.3036803404736423\n",
      "Scaled KL Loss is: 0.046333808451890945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3500141489255333\n",
      "NLL Loss is: 1.1626247350223753\n",
      "Scaled KL Loss is: 0.050125427544116974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2127501625664923\n",
      "NLL Loss is: 1.3216502062987099\n",
      "Scaled KL Loss is: 0.043304767459630966\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3649549737583409\n",
      "NLL Loss is: 1.1766417777809846\n",
      "Scaled KL Loss is: 0.04988563433289528\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2265274121138798\n",
      "NLL Loss is: 1.287149841742656\n",
      "Scaled KL Loss is: 0.047999609261751175\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.335149451004407\n",
      "NLL Loss is: 1.3752440782482245\n",
      "Scaled KL Loss is: 0.045864809304475784\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4211088875527003\n",
      "NLL Loss is: 1.3099686229569638\n",
      "Scaled KL Loss is: 0.04438571259379387\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3543543355507577\n",
      "NLL Loss is: 1.2264797489277919\n",
      "Scaled KL Loss is: 0.04914197325706482\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2756217221848567\n",
      "NLL Loss is: 1.1991909188692151\n",
      "Scaled KL Loss is: 0.04663996770977974\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2458308865789949\n",
      "NLL Loss is: 1.401156821426378\n",
      "Scaled KL Loss is: 0.047030262649059296\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4481870840754374\n",
      "NLL Loss is: 1.2366183334400258\n",
      "Scaled KL Loss is: 0.048302728682756424\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2849210621227822\n",
      "NLL Loss is: 1.664393021990279\n",
      "Scaled KL Loss is: 0.03811437636613846\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7025073983564174\n",
      "NLL Loss is: 1.3055421057472507= 1.312; test loss = 1.353\n",
      "Scaled KL Loss is: 0.048948679119348526\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3544907848665992\n",
      "NLL Loss is: 1.2954957245824048\n",
      "Scaled KL Loss is: 0.04692179709672928\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.342417521679134\n",
      "NLL Loss is: 1.313805104018287\n",
      "Scaled KL Loss is: 0.04832690954208374\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3621320135603707\n",
      "NLL Loss is: 1.3498435494113088\n",
      "Scaled KL Loss is: 0.04897342994809151\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3988169793594003\n",
      "NLL Loss is: 1.2933417190641727\n",
      "Scaled KL Loss is: 0.04392851144075394\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3372702305049267\n",
      "NLL Loss is: 1.3278537875419019\n",
      "Scaled KL Loss is: 0.04954667016863823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37740045771054\n",
      "NLL Loss is: 1.348493248555458\n",
      "Scaled KL Loss is: 0.04540466517210007\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.393897913727558\n",
      "NLL Loss is: 1.2885831969362778\n",
      "Scaled KL Loss is: 0.04549939185380936\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3340825887900871\n",
      "NLL Loss is: 1.3612057004630795\n",
      "Scaled KL Loss is: 0.04352964833378792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4047353487968675\n",
      "NLL Loss is: 1.2147051784494038\n",
      "Scaled KL Loss is: 0.04999450594186783\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2646996843912717\n",
      "NLL Loss is: 1.220972706458504\n",
      "Scaled KL Loss is: 0.04320245608687401\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.264175162545378\n",
      "NLL Loss is: 1.3701982945318034\n",
      "Scaled KL Loss is: 0.04725184291601181\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4174501374478152\n",
      "NLL Loss is: 1.2021441185611537\n",
      "Scaled KL Loss is: 0.050423409789800644\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2525675283509543\n",
      "NLL Loss is: 1.3937286244351241\n",
      "Scaled KL Loss is: 0.047616925090551376\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4413455495256755\n",
      "NLL Loss is: 1.2069608162661394\n",
      "Scaled KL Loss is: 0.04761684313416481\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2545776594003042\n",
      "NLL Loss is: 1.3830450014239843\n",
      "Scaled KL Loss is: 0.051866643130779266\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4349116445547636\n",
      "NLL Loss is: 1.303011864037303\n",
      "Scaled KL Loss is: 0.04835633561015129\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3513681996474542\n",
      "NLL Loss is: 1.2670130747838904\n",
      "Scaled KL Loss is: 0.047700900584459305\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3147139753683497\n",
      "NLL Loss is: 1.1893385826790703\n",
      "Scaled KL Loss is: 0.04820604994893074\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.237544632628001\n",
      "NLL Loss is: 1.291655376388782\n",
      "Scaled KL Loss is: 0.04633544757962227\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3379908239684042\n",
      "NLL Loss is: 1.219530112599677\n",
      "Scaled KL Loss is: 0.04594052582979202\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265470638429469\n",
      "NLL Loss is: 1.2942764368504975\n",
      "Scaled KL Loss is: 0.04714098200201988\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3414174188525174\n",
      "NLL Loss is: 1.2028960182073576\n",
      "Scaled KL Loss is: 0.047685179859399796\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2505811980667574\n",
      "NLL Loss is: 1.5416636478578107\n",
      "Scaled KL Loss is: 0.04938018321990967\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5910438310777204\n",
      "NLL Loss is: 1.1109873535971102\n",
      "Scaled KL Loss is: 0.04723917320370674\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.158226526800817\n",
      "NLL Loss is: 1.2489006527597122\n",
      "Scaled KL Loss is: 0.050476543605327606\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2993771963650398\n",
      "NLL Loss is: 1.2986780811361698\n",
      "Scaled KL Loss is: 0.05279973894357681\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3514778200797466\n",
      "NLL Loss is: 1.0841170475523905\n",
      "Scaled KL Loss is: 0.05025697126984596\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1343740188222364\n",
      "NLL Loss is: 1.2398817858869273\n",
      "Scaled KL Loss is: 0.04872249439358711\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2886042802805144\n",
      "NLL Loss is: 1.0680774534020712\n",
      "Scaled KL Loss is: 0.049653761088848114\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1177312144909193\n",
      "NLL Loss is: 1.1354976906518262\n",
      "Scaled KL Loss is: 0.04453510791063309\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1800327985624592\n",
      "NLL Loss is: 1.295029303230399\n",
      "Scaled KL Loss is: 0.04828020930290222\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3433095125333012\n",
      "NLL Loss is: 1.3103514866532329\n",
      "Scaled KL Loss is: 0.04598842188715935\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3563399085403922\n",
      "NLL Loss is: 1.2177970040107118\n",
      "Scaled KL Loss is: 0.04626283422112465\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2640598382318364\n",
      "NLL Loss is: 1.3995231225617737\n",
      "Scaled KL Loss is: 0.04698988422751427\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.446513006789288\n",
      "NLL Loss is: 1.3792808617098244\n",
      "Scaled KL Loss is: 0.046500928699970245\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4257817904097947\n",
      "NLL Loss is: 1.2143892646117596\n",
      "Scaled KL Loss is: 0.05198895186185837\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.266378216473618\n",
      "NLL Loss is: 1.1939055303825399\n",
      "Scaled KL Loss is: 0.05094996467232704\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.244855495054867\n",
      "NLL Loss is: 1.3019043860556199\n",
      "Scaled KL Loss is: 0.04898534715175629\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3508897332073762\n",
      "NLL Loss is: 1.4177390595849795\n",
      "Scaled KL Loss is: 0.04839355871081352\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.466132618295793\n",
      "NLL Loss is: 1.1387017635144365\n",
      "Scaled KL Loss is: 0.0498662069439888\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1885679704584253\n",
      "NLL Loss is: 1.1466872820655198\n",
      "Scaled KL Loss is: 0.04500438645482063\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1916916685203405\n",
      "NLL Loss is: 1.184918067665484\n",
      "Scaled KL Loss is: 0.05115241929888725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2360704869643713\n",
      "NLL Loss is: 1.1944963923554328\n",
      "Scaled KL Loss is: 0.05443670600652695\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2489330983619598\n",
      "NLL Loss is: 1.2623952356552366\n",
      "Scaled KL Loss is: 0.04556012898683548\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.307955364642072\n",
      "NLL Loss is: 1.1947482299144319\n",
      "Scaled KL Loss is: 0.05083190277218819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.24558013268662\n",
      "NLL Loss is: 1.23266427106066\n",
      "Scaled KL Loss is: 0.050674550235271454\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2833388212959314\n",
      "NLL Loss is: 1.1280800362737062\n",
      "Scaled KL Loss is: 0.05450798571109772\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.182588021984804\n",
      "NLL Loss is: 1.2365433350564274\n",
      "Scaled KL Loss is: 0.04979356750845909\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2863369025648865\n",
      "NLL Loss is: 1.150616214716882\n",
      "Scaled KL Loss is: 0.050092004239559174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.200708218956441\n",
      "NLL Loss is: 1.2468529692100931\n",
      "Scaled KL Loss is: 0.05075502395629883\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.297607993166392\n",
      "NLL Loss is: 1.2716324833785817\n",
      "Scaled KL Loss is: 0.04662822186946869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3182607052480504\n",
      "NLL Loss is: 1.1757784741362978\n",
      "Scaled KL Loss is: 0.050347212702035904\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2261256868383337\n",
      "NLL Loss is: 1.2829391536490116\n",
      "Scaled KL Loss is: 0.048303473740816116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3312426273898277\n",
      "NLL Loss is: 1.361415184365449\n",
      "Scaled KL Loss is: 0.04618584364652634\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4076010280119753\n",
      "NLL Loss is: 1.3342113300415122\n",
      "Scaled KL Loss is: 0.04585103318095207\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3800623632224642\n",
      "NLL Loss is: 1.3599662497312024\n",
      "Scaled KL Loss is: 0.04953344538807869\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.409499695119281\n",
      "NLL Loss is: 1.2263163601451321\n",
      "Scaled KL Loss is: 0.04744395986199379\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.273760320007126\n",
      "NLL Loss is: 1.1792245152819407\n",
      "Scaled KL Loss is: 0.04613299295306206\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2253575082350028\n",
      "NLL Loss is: 1.1319355741965824\n",
      "Scaled KL Loss is: 0.05069255828857422\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1826281324851566\n",
      "NLL Loss is: 1.232875667551343\n",
      "Scaled KL Loss is: 0.04971441626548767\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2825900838168307\n",
      "NLL Loss is: 1.2406254408493558\n",
      "Scaled KL Loss is: 0.04845939576625824\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.289084836615614\n",
      "NLL Loss is: 1.3197772962794614\n",
      "Scaled KL Loss is: 0.04784773662686348\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3676250329063249\n",
      "NLL Loss is: 1.2544550627557682\n",
      "Scaled KL Loss is: 0.04995283856987953\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3044079013256478\n",
      "NLL Loss is: 1.2272114991582517\n",
      "Scaled KL Loss is: 0.04578575864434242\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.272997257802594\n",
      "NLL Loss is: 1.3482626535893893\n",
      "Scaled KL Loss is: 0.047128260135650635\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.39539091372504\n",
      "NLL Loss is: 1.3489546030800306\n",
      "Scaled KL Loss is: 0.05021734535694122\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3991719484369718\n",
      "NLL Loss is: 1.2880402622475855\n",
      "Scaled KL Loss is: 0.047179315239191055\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3352195774867766\n",
      "NLL Loss is: 1.2432709785177385\n",
      "Scaled KL Loss is: 0.051079362630844116\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2943503411485826\n",
      "NLL Loss is: 1.222457608340866\n",
      "Scaled KL Loss is: 0.047393426299095154\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2698510346399612\n",
      "NLL Loss is: 1.4006822163151293\n",
      "Scaled KL Loss is: 0.04863692820072174\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.449319144515851\n",
      "NLL Loss is: 1.2801213515673744\n",
      "Scaled KL Loss is: 0.045810528099536896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3259318796669113\n",
      "NLL Loss is: 1.2703212218178273\n",
      "Scaled KL Loss is: 0.052097421139478683\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.322418642957306\n",
      "NLL Loss is: 1.292338185461727\n",
      "Scaled KL Loss is: 0.049692172557115555\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3420303580188426\n",
      "NLL Loss is: 1.3679953905713274\n",
      "Scaled KL Loss is: 0.047771889716386795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4157672802877141\n",
      "NLL Loss is: 1.2358389824938765\n",
      "Scaled KL Loss is: 0.044663701206445694\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2805026837003222\n",
      "NLL Loss is: 1.3654083251669749\n",
      "Scaled KL Loss is: 0.04535682126879692\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4107651464357718\n",
      "NLL Loss is: 1.3605164881576541\n",
      "Scaled KL Loss is: 0.04728076979517937\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4077972579528335\n",
      "NLL Loss is: 1.3231921648230094\n",
      "Scaled KL Loss is: 0.046988215297460556\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.37018038012047\n",
      "NLL Loss is: 1.2129102463882941\n",
      "Scaled KL Loss is: 0.04591759666800499\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2588278430562991\n",
      "NLL Loss is: 1.3030880866977623\n",
      "Scaled KL Loss is: 0.046390362083911896\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3494784487816742\n",
      "NLL Loss is: 1.1615004380105616\n",
      "Scaled KL Loss is: 0.050207529217004776\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2117079672275664\n",
      "NLL Loss is: 1.3212221872767183\n",
      "Scaled KL Loss is: 0.04334735870361328\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3645695459803315\n",
      "NLL Loss is: 1.1759666493519063\n",
      "Scaled KL Loss is: 0.04996292665600777\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.225929576007914\n",
      "NLL Loss is: 1.2863209901676234\n",
      "Scaled KL Loss is: 0.04804421216249466\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.334365202330118\n",
      "NLL Loss is: 1.3742849533372956\n",
      "Scaled KL Loss is: 0.0458991602063179\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4201841135436135\n",
      "NLL Loss is: 1.309450287938775\n",
      "Scaled KL Loss is: 0.04445436969399452\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3539046576327696\n",
      "NLL Loss is: 1.2254046883397007\n",
      "Scaled KL Loss is: 0.04919331148266792\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2745979998223687\n",
      "NLL Loss is: 1.198377172660564\n",
      "Scaled KL Loss is: 0.04672195017337799\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.245099122833942\n",
      "NLL Loss is: 1.400607305997928\n",
      "Scaled KL Loss is: 0.04708227515220642\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4476895811501345\n",
      "NLL Loss is: 1.2359680863072493\n",
      "Scaled KL Loss is: 0.048362329602241516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2843304159094908\n",
      "NLL Loss is: 1.6644622615059146\n",
      "Scaled KL Loss is: 0.03813080117106438\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.702593062676979\n",
      "NLL Loss is: 1.305058151881147 = 1.312; test loss = 1.353\n",
      "Scaled KL Loss is: 0.04900301992893219\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3540611718100792\n",
      "NLL Loss is: 1.2946498115966127\n",
      "Scaled KL Loss is: 0.04701059311628342\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3416604047128962\n",
      "NLL Loss is: 1.3129591758052481\n",
      "Scaled KL Loss is: 0.048387058079242706\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3613462338844908\n",
      "NLL Loss is: 1.3492367464890025\n",
      "Scaled KL Loss is: 0.049005117267370224\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3982418637563727\n",
      "NLL Loss is: 1.2923751659720375\n",
      "Scaled KL Loss is: 0.043982744216918945\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3363579101889564\n",
      "NLL Loss is: 1.326991130142416\n",
      "Scaled KL Loss is: 0.04962364211678505\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.376614772259201\n",
      "NLL Loss is: 1.3476276763785604\n",
      "Scaled KL Loss is: 0.045518845319747925\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3931465216983083\n",
      "NLL Loss is: 1.2875720808588698\n",
      "Scaled KL Loss is: 0.04560314118862152\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3331752220474913\n",
      "NLL Loss is: 1.3606119830966101\n",
      "Scaled KL Loss is: 0.04359293356537819\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4042049166619883\n",
      "NLL Loss is: 1.2139156283848787\n",
      "Scaled KL Loss is: 0.05004580318927765\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2639614315741563\n",
      "NLL Loss is: 1.2199990726031626\n",
      "Scaled KL Loss is: 0.04325193166732788\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2632510042704905\n",
      "NLL Loss is: 1.369454106751181\n",
      "Scaled KL Loss is: 0.04731852561235428\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4167726323635352\n",
      "NLL Loss is: 1.2015079320253046\n",
      "Scaled KL Loss is: 0.05046306923031807\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2519710012556227\n",
      "NLL Loss is: 1.392839087931593\n",
      "Scaled KL Loss is: 0.04765954241156578\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4404986303431588\n",
      "NLL Loss is: 1.2061775971696624\n",
      "Scaled KL Loss is: 0.047706324607133865\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2538839217767963\n",
      "NLL Loss is: 1.3821850414471708\n",
      "Scaled KL Loss is: 0.051932334899902344\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4341173763470731\n",
      "NLL Loss is: 1.302104083124197\n",
      "Scaled KL Loss is: 0.048433199524879456\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3505372826490765\n",
      "NLL Loss is: 1.2661781932162475\n",
      "Scaled KL Loss is: 0.04775584489107132\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3139340381073188\n",
      "NLL Loss is: 1.188425234029351\n",
      "Scaled KL Loss is: 0.048261627554893494\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2366868615842446\n",
      "NLL Loss is: 1.2906270404454963\n",
      "Scaled KL Loss is: 0.04639369994401932\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3370207403895156\n",
      "NLL Loss is: 1.2186000405807418\n",
      "Scaled KL Loss is: 0.04599617421627045\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2645962147970122\n",
      "NLL Loss is: 1.2931186699768455\n",
      "Scaled KL Loss is: 0.047233857214450836\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3403525271912964\n",
      "NLL Loss is: 1.2017555706875125\n",
      "Scaled KL Loss is: 0.04776990786194801\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2495254785494605\n",
      "NLL Loss is: 1.5408765934122446\n",
      "Scaled KL Loss is: 0.04943111166357994\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.5903077050758245\n",
      "NLL Loss is: 1.1102524292394045\n",
      "Scaled KL Loss is: 0.04729554429650307\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1575479735359075\n",
      "NLL Loss is: 1.2481682673360084\n",
      "Scaled KL Loss is: 0.05050933361053467\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.298677600946543\n",
      "NLL Loss is: 1.2979081576308864\n",
      "Scaled KL Loss is: 0.05286058783531189\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3507687454661983\n",
      "NLL Loss is: 1.0833585901536336\n",
      "Scaled KL Loss is: 0.05030055344104767\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1336591435946812\n",
      "NLL Loss is: 1.2389865141789593\n",
      "Scaled KL Loss is: 0.04876887798309326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2877553921620526\n",
      "NLL Loss is: 1.0668932464777994\n",
      "Scaled KL Loss is: 0.049721140414476395\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1166143868922758\n",
      "NLL Loss is: 1.134926371459858\n",
      "Scaled KL Loss is: 0.04458649829030037\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1795128697501585\n",
      "NLL Loss is: 1.294310601702563\n",
      "Scaled KL Loss is: 0.04833661764860153\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3426472193511645\n",
      "NLL Loss is: 1.3097791212998304\n",
      "Scaled KL Loss is: 0.0460519939661026\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.355831115265933\n",
      "NLL Loss is: 1.2172912204098856\n",
      "Scaled KL Loss is: 0.046309247612953186\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2636004680228388\n",
      "NLL Loss is: 1.3991670332982735\n",
      "Scaled KL Loss is: 0.04702756181359291\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4461945951118664\n",
      "NLL Loss is: 1.378049366659006\n",
      "Scaled KL Loss is: 0.046544432640075684\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4245937992990816\n",
      "NLL Loss is: 1.2137989747492957\n",
      "Scaled KL Loss is: 0.05198586732149124\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.265784842070787\n",
      "NLL Loss is: 1.1935285270621\n",
      "Scaled KL Loss is: 0.051011718809604645\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2445402458717048\n",
      "NLL Loss is: 1.3014345255436277\n",
      "Scaled KL Loss is: 0.04905663803219795\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3504911635758257\n",
      "NLL Loss is: 1.4169454695775192\n",
      "Scaled KL Loss is: 0.04843374714255333\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4653792167200725\n",
      "NLL Loss is: 1.1378442625532559\n",
      "Scaled KL Loss is: 0.04994060844182968\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1877848709950856\n",
      "NLL Loss is: 1.1459546269571987\n",
      "Scaled KL Loss is: 0.045073430985212326\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.191028057942411\n",
      "NLL Loss is: 1.1841094623990116\n",
      "Scaled KL Loss is: 0.05125138536095619\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2353608477599678\n",
      "NLL Loss is: 1.1939310409003827\n",
      "Scaled KL Loss is: 0.05447496473789215\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2484060056382749\n",
      "NLL Loss is: 1.2616108824725223\n",
      "Scaled KL Loss is: 0.04559919610619545\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3072100785787177\n",
      "NLL Loss is: 1.1940821797049477\n",
      "Scaled KL Loss is: 0.050900816917419434\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.244982996622367\n",
      "NLL Loss is: 1.2322604699791706\n",
      "Scaled KL Loss is: 0.05069991573691368\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2829603857160843\n",
      "NLL Loss is: 1.1274318659480742\n",
      "Scaled KL Loss is: 0.0545995831489563\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.1820314490970305\n",
      "NLL Loss is: 1.236179845214082\n",
      "Scaled KL Loss is: 0.049818865954875946\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.285998711168958\n",
      "NLL Loss is: 1.1498929129689481\n",
      "Scaled KL Loss is: 0.05016383156180382\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.200056744530752\n",
      "NLL Loss is: 1.2466514789409786\n",
      "Scaled KL Loss is: 0.05081833153963089\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2974698104806095\n",
      "NLL Loss is: 1.2707593450935242\n",
      "Scaled KL Loss is: 0.04666591063141823\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3174252557249424\n",
      "NLL Loss is: 1.1754742193879126\n",
      "Scaled KL Loss is: 0.05041272193193436\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.225886941319847\n",
      "NLL Loss is: 1.282138954511177\n",
      "Scaled KL Loss is: 0.04839761555194855\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3305365700631255\n",
      "NLL Loss is: 1.361700602588475\n",
      "Scaled KL Loss is: 0.0462191179394722\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4079197205279472\n",
      "NLL Loss is: 1.3332769557035482\n",
      "Scaled KL Loss is: 0.045912645757198334\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3791896014607465\n",
      "NLL Loss is: 1.3595300422644516\n",
      "Scaled KL Loss is: 0.049576692283153534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4091067345476052\n",
      "NLL Loss is: 1.225875238990091\n",
      "Scaled KL Loss is: 0.04749694839119911\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2733721873812902\n",
      "NLL Loss is: 1.178178635550485\n",
      "Scaled KL Loss is: 0.046197548508644104\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2243761840591292\n",
      "NLL Loss is: 1.131204955832274\n",
      "Scaled KL Loss is: 0.05075010657310486\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.181955062405379\n",
      "NLL Loss is: 1.2322405352890937\n",
      "Scaled KL Loss is: 0.04978282377123833\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.282023359060332\n",
      "NLL Loss is: 1.239722361235536\n",
      "Scaled KL Loss is: 0.04852613806724548\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2882484993027814\n",
      "NLL Loss is: 1.3186701206215201\n",
      "Scaled KL Loss is: 0.04790819436311722\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3665783149846373\n",
      "NLL Loss is: 1.2539950815338383\n",
      "Scaled KL Loss is: 0.05004614219069481\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3040412237245331\n",
      "NLL Loss is: 1.226269889145141\n",
      "Scaled KL Loss is: 0.04584670066833496\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2721165898134759\n",
      "NLL Loss is: 1.347815218729053\n",
      "Scaled KL Loss is: 0.04718298837542534\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3949982071044784\n",
      "NLL Loss is: 1.347952350463512\n",
      "Scaled KL Loss is: 0.050310805439949036\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.398263155903461\n",
      "NLL Loss is: 1.2872908932219909\n",
      "Scaled KL Loss is: 0.047233931720256805\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3345248249422477\n",
      "NLL Loss is: 1.2423930391878288\n",
      "Scaled KL Loss is: 0.05113369971513748\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2935267389029663\n",
      "NLL Loss is: 1.2213249617845454\n",
      "Scaled KL Loss is: 0.047460149973630905\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2687851117581763\n",
      "NLL Loss is: 1.3998271701475427\n",
      "Scaled KL Loss is: 0.048702068626880646\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4485292387744233\n",
      "NLL Loss is: 1.279196487062604\n",
      "Scaled KL Loss is: 0.04587960243225098\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.325076089494855\n",
      "NLL Loss is: 1.2697177628997627\n",
      "Scaled KL Loss is: 0.05217650160193443\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3218942645016971\n",
      "NLL Loss is: 1.2916077396416572\n",
      "Scaled KL Loss is: 0.04977134242653847\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3413790820681957\n",
      "NLL Loss is: 1.3671607876168614\n",
      "Scaled KL Loss is: 0.04783729091286659\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.414998078529728\n",
      "NLL Loss is: 1.2351965503362399\n",
      "Scaled KL Loss is: 0.04473379626870155\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2799303466049414\n",
      "NLL Loss is: 1.3649604206762591\n",
      "Scaled KL Loss is: 0.04541283845901489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.410373259135274\n",
      "NLL Loss is: 1.3596513633754512\n",
      "Scaled KL Loss is: 0.047347091138362885\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4069984545138141\n",
      "NLL Loss is: 1.3232370541566214\n",
      "Scaled KL Loss is: 0.04703884944319725\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3702759035998187\n",
      "NLL Loss is: 1.2121373898312482\n",
      "Scaled KL Loss is: 0.04598892480134964\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2581263146325978\n",
      "NLL Loss is: 1.3024936243042753\n",
      "Scaled KL Loss is: 0.04644753783941269\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.348941162143688\n",
      "NLL Loss is: 1.1604233074010806\n",
      "Scaled KL Loss is: 0.05029155686497688\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2107148642660575\n",
      "NLL Loss is: 1.3208326785094808\n",
      "Scaled KL Loss is: 0.043393414467573166\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.364226092977054\n",
      "NLL Loss is: 1.17533702354304\n",
      "Scaled KL Loss is: 0.05004517734050751\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2253822008835475\n",
      "NLL Loss is: 1.2854934779295744\n",
      "Scaled KL Loss is: 0.04809471592307091\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3335881938526453\n",
      "NLL Loss is: 1.3732998077973588\n",
      "Scaled KL Loss is: 0.04593038558959961\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4192301933869584\n",
      "NLL Loss is: 1.3088769233245066\n",
      "Scaled KL Loss is: 0.04452874884009361\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.3534056721646002\n",
      "NLL Loss is: 1.2244167104417965\n",
      "Scaled KL Loss is: 0.04924619570374489\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2736629061455413\n",
      "NLL Loss is: 1.1976513476809114\n",
      "Scaled KL Loss is: 0.04680182784795761\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.244453175528869\n",
      "NLL Loss is: 1.4000937125750301\n",
      "Scaled KL Loss is: 0.04713265225291252\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.4472263648279426\n",
      "NLL Loss is: 1.2353625340876917\n",
      "Scaled KL Loss is: 0.048423364758491516\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.2837858988461832\n",
      "NLL Loss is: 1.6646423684122162\n",
      "Scaled KL Loss is: 0.03814727067947388\n",
      "Annealing coefficient is: 1.0\n",
      "Total Loss is: 1.7027896390916901\n",
      "Completed epoch 69; train loss = 1.311; test loss = 1.352\r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPOCHS = 70\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    \n",
    "    epoch_train_loss = []\n",
    "    epoch_test_loss = []\n",
    "\n",
    "    for batch_X, batch_s, batch_t in get_batches(train_X, train_s, train_t, batch_size=100):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        batch_predictions = model(batch_X)\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(batch_predictions, batch_s, batch_t, current_epoch=epoch_idx)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "        \n",
    "    for batch_X, batch_s, batch_t in get_batches(test_X, test_s, test_t, batch_size=100):\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        batch_predictions = model(batch_X)\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(batch_predictions, batch_s, batch_t, current_epoch=epoch_idx)\n",
    "        \n",
    "        # Gather data and report\n",
    "        epoch_test_loss.append(loss.item())\n",
    "        \n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    test_loss.append(np.mean(epoch_test_loss))\n",
    "            \n",
    "    print('Completed epoch %i; train loss = %.3f; test loss = %.3f' % (\n",
    "        epoch_idx, train_loss[-1], test_loss[-1]), end='\\r')\n",
    "          \n",
    "plt.plot(np.arange(len(train_loss)), train_loss, label='Training Loss')\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (Evidential NLL)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374315b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Dirichlet(batch_predictions)\n",
    "kl_divergence = torch.distributions.kl.kl_divergence(dist, Dirichlet(torch.ones_like(batch_predictions)))\n",
    "kl_loss = torch.mean(kl_divergence)\n",
    "kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Model output (Dirichlet distribution parameters)\n",
    "test_predictions = (\n",
    "    model(torch.tensor(test_X, dtype=torch.float))\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")\n",
    "\n",
    "# Calculate the event probabilities for each bin (mean of Dirichlet distribution)\n",
    "\n",
    "pred_mean = test_predictions / test_predictions.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Calculate the 2.5th and 97.5th percentiles \n",
    "pred_lower = np.percentile(pred_mean, 2.5, axis=0)\n",
    "pred_upper = np.percentile(pred_mean, 97.5, axis=0)\n",
    "\n",
    "# Plot the predicted event probabilities with error bars (95% CI)\n",
    "plt.bar(\n",
    "    np.arange(test_predictions.shape[1]),  # Bin positions (e.g., 0 to 10)\n",
    "    pred_mean.mean(axis=0),                 # Mean predicted probabilities\n",
    "    yerr=[pred_mean.mean(axis=0) - pred_lower, pred_upper - pred_mean.mean(axis=0)],  # Error bars (95% CI)\n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "plt.xlabel('Bin')\n",
    "plt.ylabel('Predicted Event Probability')\n",
    "plt.title('Predicted Event Probability vs. Number of Bins')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e38862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/Workbench/Academia/Rotations/EngelhardLab/utils')\n",
    "from tte_measures import kaplan_meier, xCI, xAUCt, xROCt, xAPt, xPRt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = BIN_BOUNDARIES[1:]\n",
    "\n",
    "cumulative_predicted_risk = np.cumsum(pred_mean, axis=1)[:, :-1]\n",
    "\n",
    "cp_mean = [0] + list(cumulative_predicted_risk.mean(axis=0))\n",
    "cp_std = [0] + list(cumulative_predicted_risk.std(axis=0))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "km_times, km_mean, km_var = kaplan_meier(test_s, test_t)\n",
    "\n",
    "ax[0].plot(km_times, 1 - km_mean)\n",
    "ax[0].fill_between(km_times, 1 - km_mean - np.sqrt(km_var), 1 - km_mean + np.sqrt(km_var), alpha=.3)\n",
    "\n",
    "ax[1].plot([0] + list(times), cp_mean)\n",
    "ax[1].fill_between(\n",
    "    [0] + list(times),\n",
    "    np.array(cp_mean) - np.array(cp_std),\n",
    "    np.array(cp_mean) + np.array(cp_std),\n",
    "    alpha=.3\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap_samples = 50\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "times = BIN_BOUNDARIES[1:]\n",
    "time_idx = 6\n",
    "time = times[time_idx]\n",
    "\n",
    "cumulative_predicted_risk = np.cumsum(pred_mean, axis=1)[:, :-1]\n",
    "\n",
    "auct, ci_low, ci_high = xAUCt(\n",
    "    test_s == 1, test_t, cumulative_predicted_risk, times,\n",
    "    n_bootstrap_samples=n_bootstrap_samples\n",
    ")\n",
    "\n",
    "ax[0].plot(times, auct, 'k-', label='All-All')\n",
    "ax[0].fill_between(times, ci_low, ci_high, color='k', alpha=.1)\n",
    "\n",
    "tprt, fprt, _ = xROCt(\n",
    "    test_s == 1, test_t, cumulative_predicted_risk[:, time_idx], time\n",
    ")\n",
    "\n",
    "ax[1].plot(\n",
    "    fprt, tprt, 'k-',\n",
    "    label='AUC$_t$ = %.2f (%.2f-%.2f)' % (\n",
    "        auct[time_idx], ci_low[time_idx], ci_high[time_idx]\n",
    "    )\n",
    ")\n",
    "\n",
    "(apt, prevt), (apt_low, prev_low), (apt_high, prev_high) = xAPt(\n",
    "    test_s == 1, test_t, cumulative_predicted_risk, times,\n",
    "    return_prevalence=True,\n",
    "    n_bootstrap_samples=n_bootstrap_samples\n",
    ")\n",
    "\n",
    "ax[2].plot(times, apt, 'k-', label='All')\n",
    "ax[2].fill_between(times, apt_low, apt_high, color='k', alpha=.1)\n",
    "ax[2].plot(times, prevt, 'k--')#, label='Prevalence at t')\n",
    "\n",
    "recallt, precisiont, _, prevt = xPRt(\n",
    "    test_s == 1, test_t, cumulative_predicted_risk[:, time_idx], time\n",
    ")\n",
    "\n",
    "ax[3].plot(\n",
    "    recallt, precisiont, 'k-',\n",
    "    label='AP$_t$ = %.2f (%.2f-%.2f)' % (\n",
    "        apt[time_idx], apt_low[time_idx], apt_high[time_idx]\n",
    "    )\n",
    ")\n",
    "\n",
    "ax[3].plot([0, 1], [prevt, prevt], 'k--')#, label='Prevalence at t')\n",
    "\n",
    "ax[0].plot(times, times * 0 + .5, 'k--')\n",
    "ax[0].set_ylim([0.45, 1.])\n",
    "ax[0].set_ylabel('AUC$_t$')\n",
    "ax[0].set_xlabel('Time (t)')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot([0, 1], [0, 1], 'k--')\n",
    "ax[1].set_ylabel('True Positive Rate (t=%i)' % time)\n",
    "ax[1].set_xlabel('False Positive Rate (t=%i)' % time)\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].set_ylabel('AP$_t$')\n",
    "ax[2].set_xlabel('Time (t)')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].set_ylabel('Precision (t=%i)' % time)\n",
    "ax[3].set_xlabel('Recall (t=%i)' % time)\n",
    "ax[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidentialDiscreteFailureTimeNLL(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, bin_boundaries, tolerance=1e-8, annealing_step=10):\n",
    "        super(EvidentialDiscreteFailureTimeNLL, self).__init__()\n",
    "        self.bin_starts = torch.tensor(bin_boundaries[:-1])\n",
    "        self.bin_ends = torch.tensor(bin_boundaries[1:])\n",
    "        self.bin_lengths = self.bin_ends - self.bin_starts\n",
    "        self.tolerance = tolerance\n",
    "        self.annealing_step = annealing_step\n",
    "\n",
    "    def _discretize_times(self, times):\n",
    "        return (\n",
    "            (times[:, None] > self.bin_starts[None, :])\n",
    "            & (times[:, None] <= self.bin_ends[None, :])\n",
    "        )\n",
    "\n",
    "    def _get_proportion_of_bins_completed(self, times):\n",
    "        return torch.maximum(\n",
    "            torch.minimum(\n",
    "                (times[:, None] - self.bin_starts[None, :]) / self.bin_lengths[None, :],\n",
    "                torch.tensor(1.0)\n",
    "            ),\n",
    "            torch.tensor(0.0)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, alphas, event_indicators, event_times, current_epoch):\n",
    "        dirichlet_dist = Dirichlet(alphas)\n",
    "        predictions = dirichlet_dist.mean  # Expected probabilities for each bin\n",
    "        event_likelihood = torch.sum(\n",
    "            self._discretize_times(event_times) * predictions[:, :-1],\n",
    "            -1\n",
    "        ) + self.tolerance\n",
    "\n",
    "        nonevent_likelihood = 1 - torch.sum(\n",
    "            self._get_proportion_of_bins_completed(event_times) * predictions[:, :-1],\n",
    "            -1\n",
    "        ) + self.tolerance\n",
    "        \n",
    "        log_likelihood = event_indicators * torch.log(event_likelihood)\n",
    "        log_likelihood += (1 - event_indicators) * torch.log(nonevent_likelihood)\n",
    "        nll_loss = -torch.mean(log_likelihood)\n",
    "        kl_divergence = torch.distributions.kl.kl_divergence(dirichlet_dist, Dirichlet(torch.ones_like(alphas)))\n",
    "        kl_loss = torch.mean(kl_divergence)\n",
    "        annealing_coefficient = min(1.0, current_epoch / self.annealing_step)\n",
    "        evidential_loss = nll_loss + annealing_coefficient * kl_loss\n",
    "        \n",
    "        return evidential_loss \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
